\documentclass{article}

\usepackage{longtable}
\usepackage{booktabs}
\def\tightlist{}

\usepackage{charter}
\usepackage{fancyhdr}
\pagestyle{fancy}

\usepackage{amsmath,amssymb}
\usepackage[colorlinks=true]{hyperref}
\usepackage{color}
\definecolor{myurlcolor}{rgb}{0.6,0,0}
\definecolor{mycitecolor}{rgb}{0,0,0.8}
\definecolor{myrefcolor}{rgb}{0,0,0.8}
\hypersetup{linkcolor=myrefcolor,citecolor=mycitecolor,urlcolor=myurlcolor}

\renewcommand{\texttt}[1]{%
  \begingroup
  \ttfamily
  \begingroup\lccode`~=`/\lowercase{\endgroup\def~}{/\discretionary{}{}{}}%
  \begingroup\lccode`~=`[\lowercase{\endgroup\def~}{[\discretionary{}{}{}}%
  \begingroup\lccode`~=`.\lowercase{\endgroup\def~}{.\discretionary{}{}{}}%
  \catcode`/=\active\catcode`[=\active\catcode`.=\active
  \scantokens{#1\noexpand}%
  \endgroup
}

\usepackage{titlesec}
\newcommand{\sectionbreak}{\clearpage}
\renewcommand{\thesection}{Week~\arabic{section}}
\titleformat{\section}[display]{\normalfont}{\Large\bfseries\thesection}{1em}{\large\normalfont}

\usepackage{titletoc}
\titlecontents{section}[0em]{\normalfont}{\bfseries\thecontentslabel\hspace{1em}\normalfont\small}{}{\titlerule*[0.3pc]{.}\small\itshape\thecontentspage}[\vspace{0.5em}]

\usepackage[toc]{multitoc}
\renewcommand*{\multicolumntoc}{2}
\setlength{\columnseprule}{0.5pt}

\title{This Week's Finds in Mathematical Physics (151--200)}
\author{John Baez}
\date{June 26, 2000 to December 31, 2003}

\usepackage{tikz}
\usetikzlibrary{knots}
\usetikzlibrary{arrows}

\usepackage{tikz-cd}

\usepackage{graphicx}

\makeatletter
\newcommand{\xRightarrow}[2][]{\ext@arrow 0359\Rightarrowfill@{#1}{#2}}
\makeatother

\setcounter{section}{150}

\begin{document}

\begin{titlepage}
  \begin{center}
    {\Huge\textbf{This Week's Finds in}}
  \\[0.7em]{\Huge\textbf{Mathematical Physics}}
  \\[1em]{\huge\textit{Weeks 151 to 200}}
  \\[4em]{\LARGE \textit{June 26, 2000} to \textit{December 31, 2003}}
  \\[4em]{\huge by John Baez}
  \\[0.5em]{\Large{Typeset by Tim Hosgood}}
  \end{center}
\end{titlepage}

\tableofcontents

\hypertarget{week151}{%
\section{June 26, 2000}\label{week151}}

Recently I've been talking a bit about elliptic cohomology, but I've
really just been nibbling around the edges so far. Sometime I want to
dig deeper, but not just now. Right now, I instead want to say a bit
more about the physics lurking in the space \(K(\mathbb{Z},2)\).

But first, here's a cool article on violins:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Colin Gough, ``Science and the Stradivarius'', \emph{Physics World},
  vol.~\textbf{13} no. 4, April 2000, 27--33.
\end{enumerate}

Before reading this, I never knew how a string on a violin vibrates!
Lots of well-known European physicists have studied the violin, and in
the 19th century, Helmholtz showed that the bow excites a mode of the
violin string that is quite unlike the sine waves we all know and love.
In this ``Helmholtz waveform'', the string consists of two straight-line
segments separated by a kink:

\begin{verbatim}
                         .   
                    .       .
               .               .
          .                       .
\end{verbatim}

As time passes, the kink travels back and forth along the string, being
reflected at the ends. The beauty of this becomes apparent as we watch
the string right at the point where the bow is rubbing over it, near the
bottom end of the string. When the kink is between the bow and the top
end of the string:

\begin{verbatim}
                            bow
                             |
                             ^
                         .   |
   TOP              .       .|          BOTTOM
               .             | .
          .                  |    .
                             |
                             |
\end{verbatim}

this point in the string moves at the same speed and in the same
direction as the bow. This is called the ``sticking regime'', because
the static friction of the rosin-coated bow is enough to pull the string
along with it. But when the kink moves past the bow:

\begin{verbatim}
                            |
                            ^
                            |  .
                         .  | 
   TOP              .       |   .     BOTTOM
               .            | 
          .                 |    .
                            |
\end{verbatim}

the string slips off the bow and starts moving in the opposite direction
to it. This is called the ``sliding regime''. Since the coefficient of
sliding friction is less than the coefficient of static friction, the
string can slide against the motion of the bow in this regime.

The really nice thing is that the string is vibrating almost freely: the
violinist just needs to apply the right amount of pressure to keep this
vibrational mode excited --- too much pressure will ruin it! Being able
to delicately control the Helmholtz waveform is part of what
distinguishes the virtuoso from the blood-curdling amateur.

The full physics of the violin is infinitely more complicated than this,
of course. The vibrating string excites the bridge which excites the
sound box, and \emph{that} produces most of the sound we hear. For more
information try these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  A. H. Benade, \emph{Fundamentals of Musical Acoustics}, Oxford
  University Press, Oxford, 1976.

  L. Cremer, \emph{The Physics of the Violin}, MIT Press, Cambridge,
  Massachusetts, 1984.

  N. H. Fletcher and T. D. Rossing, \emph{The Physics of Musical
  Instruments}, 2nd edition, Springer, New York, 1998.

  C. Hutchins and V. Benade, editors, \emph{Research Papers on Violin
  Acoustics 1975--1993}, 2 volumes, Acoustical Society of America, New
  York, 1997.
\end{enumerate}

Okay, now on to \(K(\mathbb{Z},2)\)! I explained a bit about this space
in \protect\hyperlink{week149}{``Week 149''}, but I've been pondering it
a lot lately, so I'd like to say a bit more.

First let me review and elaborate on some basic stuff I said already. If
G is any topological group, there is a topological space \(BG\) with a
basepoint such that the space of loops in \(BG\) starting and ending at
this point is homotopy equivalent to \(G\). This space \(BG\) is unique
up to homotopy equivalence. {[}1{]}

\(BG\) is important because it's the ``classifying space for
\(G\)-bundles''. What this means is that there's a principal
\(G\)-bundle over \(BG\) called the ``universal \(G\)-bundle'', with the
marvelous property that \emph{any} principal \(G\)-bundle over
\emph{any} space \(X\) is a pullback of this one by some map
\[f\colon X \to BG.\] (I explained in \protect\hyperlink{week149}{``Week
149''} how to pull back complex line bundles, and pulling back principal
\(G\)-bundles works the same way.) Even better, two \(G\)-bundles that
we get this way are isomorphic if and only if the maps they come from
are homotopic! So there is a one-to-one correspondence between:

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\tightlist
\item
  isomorphism classes of principal \(G\)-bundles over \(X\)
\end{enumerate}

and

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  homotopy classes of maps from \(X\) to \(BG\).
\end{enumerate}

Now, suppose \(G\) is an \emph{abelian} topological group. Then \(BG\)
is better than a topological space with basepoint. It's an abelian
topological group!

This means that we can \emph{iterate} this trick. Starting with an
abelian topological group \(G\) we can form \(BG\), and \(BBG\), and
\(BBBG\), and so on. This is called ``delooping'', because the loop
space of each of these spaces is the previous one.

It's always fun to iterate any process whenever you can --- Freud called
this ``repetition compulsion'' --- but there's more going on here than
just that. In \protect\hyperlink{week149}{``Week 149''} I said that when
we have a list of spaces, each being the loop space of the previous one,
it's called a ``spectrum''. And I said that we can use a spectrum to get
a generalized cohomology theory. So we now have a trick for getting a
generalized cohomology theory from a topological abelian group!

In particular, suppose we start with a plain old abelian group \(A\). We
can think of it as a topological group with the discrete topology ---
let's call this \(K(A,0)\). Then we can define \[
  \begin{gathered}
    K(A,1) = B(K(A,0))
  \\K(A,2) = B(K(A,1))
  \\K(A,3) = B(K(A,2))
  \end{gathered}
\] \ldots{} and so on. We get a spectrum \(K(A,n)\) called an
``Eilenberg-MacLane spectrum''. The corresponding generalized cohomology
theory is just ordinary cohomology with coeffients in the abelian group
\(A\)! This means that \[H^n(X,A) = [X, K(A,n)]\] where the right-hand
side is the set of homotopy classes of maps from \(X\) to \(K(A,n)\). In
short, \(K(A,n)\) knows everything there is to know about the \(n\)th
cohomology with coefficients in \(A\).

We've seen this trick a couple of times lately, and it's actually a big
theme in homotopy theory: whenever we have some interesting invariant of
spaces, we try to cook up a space that ``represents'' this invariant. I
could say a LOT more about THIS idea, but that would propel us into
further heights of abstraction, when what I really want is to come down
to earth a bit. Just a little bit\ldots.

So: let's take \(A\) to be the integers, \(\mathbb{Z}\). As I said in
\protect\hyperlink{week149}{``Week 149''}, we then get
\[K(\mathbb{Z},0) = Z,\] \[K(\mathbb{Z},1) = \mathrm{U}(1),\] where
\(\mathrm{U}(1)\) is the group of ``phases'' or unit complex numbers,
and \[K(\mathbb{Z},2) = \mathbb{CP}^\infty\] where
\(\mathbb{CP}^\infty\) is infinite-dimensional complex projective space.
There are a couple of slightly different versions of this. Topologists
like to start with the direct limit of the spaces \(\mathbb{C}^n\),
which they call \(C^\infty\). Then they take the space of all
\(1\)-dimensional subspaces and call that \(\mathbb{CP}^\infty\).
Mathematical physicists prefer to start with a Hilbert space of
countable dimension. Then they take the space of unit vectors modulo
phase. Both these versions are equally good models of
\(K(\mathbb{Z},2)\). The first one is a lean, stripped-down version of
the second.

Now \(\mathrm{U}(1)\) is very important in quantum theory, and so are
unit vectors modulo phase in a Hilbert space --- physicists call these
``pure states''. So something cool is going on here. For some mysterious
reason, it looks like \(K(\mathbb{Z},n)\)'s are important quantum
physics! This is especially interesting because the abstract definition
of the \(K(\mathbb{Z},n)\)'s has nothing to do with the complex numbers
--- just the integers. The complex numbers show up on their own accord.
So maybe this hints at some explanation of why the complex numbers are
important in quantum mechanics.

Why are \(K(\mathbb{Z},n)\)'s connected to quantum theory? I don't
really know. But we can get some clues by asking some more specific
questions.

First of all, why is \(K(\mathbb{Z},2)\) the same as
\(\mathbb{CP}^\infty\)? In \protect\hyperlink{week149}{``Week 149''} I
just asserted this without proof. That's one of the fun things I'm
allowed to do in this column. But let me sketch why it's true.

First I need to remind you of some more basic facts about topology.
Suppose \(G\) is any topological group, and let \(P \to X\) be any
principal \(G\)-bundle. This gives us a long exact sequence of homotopy
groups:
\[\ldots \to \pi_{n+1}(X) \to \pi_n(G) \to \pi_n(P) \to \pi_n(X) \to \pi_{n-1}(G) \to \ldots\]
Two-thirds of the arrows in this sequence come from the maps
\[G \to P \to X\] while the less obvious remaining one-third come from
the map \[LX \to G\] sending each loop in the base space to the holonomy
of some connection on our bundle. Here \(LX\) means the space of based
loops in \(X\), and we're using the fact that
\[\pi_n(LX) = \pi_{n+1}(X)\] which is obvious from the definition of the
homotopy groups.

But now suppose \(P\) is contractible! Then all its homotopy groups
vanish, so the above long exact sequence breaks up into lots of puny
exact sequences like this: \[0 \to \pi_{n+1}(X) \to \pi_n(G) \to 0\] or
in other words: \[0 \to \pi_n(LX) \to \pi_n(G) \to 0\] This says that
the map from \(LX\) to \(G\) induces isomorphisms on all homotopy
groups. By the Whitehead theorem, this implies that this map is a
homotopy equivalence! So \(LX\) is really just \(G\)!! So \(X\) is just
\(BG\)!!!

In short: if we have a space \(X\) with a principal \(G\)-bundle \(P\)
over it, and \(P\) is contractible, \(X\) must be \(BG\). {[}2{]}

Now let's use this fact to show that \(\mathbb{CP}^\infty\) is
\(K(\mathbb{Z},2)\). Remember that by our recursive definition,
\[K(\mathbb{Z},2) = B(K(\mathbb{Z},1)) = B(\mathrm{U}(1))\] so to show
that \(\mathbb{CP}^\infty\) is \(K(\mathbb{Z},2)\), we just need to find
a principal \(\mathrm{U}(1)\)-bundle over it with a contractible total
space.

In \protect\hyperlink{week149}{``Week 149''} we discussed a complex line
bundle over \(\mathbb{CP}^\infty\) called the ``universal complex line
bundle''. If you take the space of unit vectors in a complex line bundle
you get a principal \(\mathrm{U}(1)\)-bundle. So let's do this to the
universal complex line bundle. What do we get? We get a principal
\(\mathrm{U}(1)\)-bundle like this: \[S^\infty \to \mathbb{CP}^\infty\]
Being a mathematical physicist, I'm using \(S^\infty\) here to stand for
the unit sphere in some countable-dimensional Hilbert space, and the map
sends each unit vector to the corresponding pure state, or unit vector
mod phase. Since there's a circle of unit vectors for each pure state,
this is indeed a principal \(\mathrm{U}(1)\)-bundle. But now for the
cool part: the unit sphere in an infinite-dimensional Hilbert space is
contractible! So we've got a principal \(\mathrm{U}(1)\)-bundle with a
contractible total space sitting over \(\mathbb{CP}^\infty\), proving
that \(\mathbb{CP}^\infty\) is \(K(\mathbb{Z},2)\). Even better, the
bundle \[S^\infty \to \mathbb{CP}^\infty\] is the universal principal
\(\mathrm{U}(1)\)-bundle.

I can't resist explaining why the unit sphere in an infinite-dimensional
Hilbert space is contractible. It seems very odd that a sphere could be
contractible, but this is one of those funny things about infinite
dimensions. Take our Hilbert space to be \(L^2[0,1]\) and consider any
function \(f\) in the unit sphere of this Hilbert space:
\[\int |f(x)|^2 dx = 1\] For \(t\) between \(0\) and \(1\), let
\(f_t(x)\) be a function that equals \(1\) for \(x < t\), and a sped-up
version of \(f\) for \(x\) greater than or equal to \(t\). If you do
this right \(f_t\) will still lie in the unit sphere, and you'll have a
way of contracting the whole unit sphere down to a single point, namely
the constant function \(1\).

Cute, huh?

Next question: how does \(\mathbb{CP}^\infty\) become an abelian
topological group? There's a very pretty answer. Consider the space of
rational functions of a single complex variable. This is a
infinite-dimensional complex vector space, and there's a natural way to
give it the topology of \(\mathbb{C}^\infty\). This gives us a nice way
to think of \(\mathbb{CP}^\infty\): it's just the \emph{nonzero}
rational functions modulo multiplication by constants.

But nonzero rational functions form an abelian group under
multiplication! And this is still true when we mod out by constant
factors! So \(\mathbb{CP}^\infty\) becomes an abelian group --- and in
fact an abelian topological group.

We can visualize \(\mathbb{CP}^\infty\) quite easily this way. A
rational function of a single complex variable has a bunch of zeros and
poles --- think of them as points on the Riemann sphere. We should
really stick an integer at each of these points: a positive integer at
each zero, and a negative integer at each pole, to tell us the order of
that zero or pole. This gives enough information to completely specify
the rational function up to a constant factor. So a point in
\(\mathbb{CP}^\infty\) is the same as a finite set of points on the
sphere labelled by integers --- which must add up to zero.

Of course, we have to get the right topology on \(\mathbb{CP}^\infty\).
As we move our point in \(\mathbb{CP}^\infty\) around in a continuous
way, the corresponding points on the sphere all move around
continuously, like a swarm of flies\ldots{} but when points collide,
their numbers add! For example, when a point labelled by the number 7
collides with a point labelled by the number -3, it turns into a point
labelled by the number \(7 - 3 = 4\).

In the lingo of physics, we've got a picture of points in
\(\mathbb{CP}^\infty\) as ``collections of particles and antiparticles
on the sphere''. The integer at any point on the sphere tells us the
number of particles sitting there --- but if it's negative, it means
we've got \emph{antiparticles} there. Particle-antiparticle pairs can be
created out of nothing, and they annihilate when they collide\ldots{}
it's very nice!

By the way, there's something called the Thom-Dold theorem that lets us
generalize the heck out of this. We just showed that if you take the
2-sphere and consider the space of particle-antiparticle swarms in it,
you get \(K(\mathbb{Z},2)\). But suppose instead we started with the
\(n\)-sphere and considered the space of particle-antiparticle swarms in
\emph{that}. Then we'd get \(K(\mathbb{Z},n)\)!

More generally, suppose we didn't use integers to say how many particles
were at each point in the \(n\)-sphere --- suppose we used elements of
some abelian group \(A\). Then we'd get \(K(A,n)\)!

For more tricks like this, try this paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Dusa McDuff, ``Configuration spaces of positive and negative
  particles'', \emph{Topology} \textbf{14} (1975), 91--107.
\end{enumerate}

Now let me mention a different picture of \(K(\mathbb{Z},2)\), that's
also nice, and also related to quantum theory. Take any
countable-dimensional Hilbert space \(H\) and let \(\mathrm{U}(H)\) be
the group of unitary operators on \(H\). Just like the unit sphere in
this Hilbert space is contractible, it turns out that \(\mathrm{U}(H)\)
is contractible if we give it the norm topology or the strong topology.

Anyway, now let \(\mathrm{PU}(H)\) be the ``projective unitary group''
of \(H\), meaning the group of unitary operators modulo phase. There's
an obvious map \[\mathrm{U}(H) \to \mathrm{PU}(H)\] sending a circle's
worth of points to each point in \(\mathrm{PU}(H)\). It's easy to check
that this is a principal \(\mathrm{U}(1)\)-bundle. Since the total space
\(\mathrm{U}(H)\) is contractible, it follows that \(\mathrm{PU}(H)\) is
\(K(\mathbb{Z},2)\)!

This give a \emph{nonabelian} group structure on \(K(\mathbb{Z},2)\),
which may seem kind of weird, given that we just made it into an
\emph{abelian} group a minute ago. But I guess this other product is
``abelian up to homotopy'' in a very strong sense, so it's just as good
as abelian for the purposes of homotopy theory.

Anyway, some people in Australia have figured out an extra trick you can
do with this \(\mathrm{PU}(H)\) group:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Alan L. Carey, Diarmuid Crowley and Michael K. Murray, ``Principal
  bundles and the Dixmier-Douady class'', \emph{Comm. Math. Physics}
  \textbf{193} (1998) 171--196, preprint available as
  \href{https://arxiv.org/abs/hep-th/9702147}{\texttt{hep-th/9702147}}.
\end{enumerate}

Here's how it goes, at least in part. We say a linear operator
\[A\colon  H \to  H\] is ``Hilbert-Schmidt'' if the trace of \(AA^*\) is
finite. The space of Hilbert-Schmidt operators is a Hilbert space in its
own right, with this inner product:
\[\langle A,B\rangle = \operatorname{tr}(AB^*)\] Let's call this Hilbert
space \(X\). \(\mathrm{U}(H)\) acts on \(X\) by conjugation, and this
gives an action of \(\mathrm{PU}(H)\) on \(X\), because phases commute
with everything. This in turn gives an action of \(\mathrm{PU}(H)\) on
\(\mathrm{U}(X)\)! Is your brain melting yet? Anyway, it turns out that
this makes \(\mathrm{U}(X)\) into the total space of a principal
\(\mathrm{PU}(H)\)-bundle:
\[\mathrm{PU}(H) \to \mathrm{U}(X) \to \mathrm{U}(X)/\mathrm{PU}(H)\]
But \(X\) is a countable-dimensional Hilbert space, so \(\mathrm{U}(X)\)
is contractible, so this is the \emph{universal} principal
\(\mathrm{PU}(H)-bundle\). And as we've seen, this means that
\[\mathrm{U}(X)/\mathrm{PU}(H) = B(\mathrm{PU}(H))\] but we just saw
that \[\mathrm{PU}(H) = K(\mathbb{Z},2)\] so
\[\mathrm{U}(X)/\mathrm{PU}(H) = B(\mathrm{PU}(H)) = B(K(\mathbb{Z},2)) = K(\mathbb{Z},3) \,\text{!}\]

In \protect\hyperlink{week149}{``Week 149''}, I said I'd like
\(K(\mathbb{Z},3)\) to be some sort of infinite-dimensional manifold
closely related to quantum physics. I'm happier now, because here we are
getting just that --- technically, we're getting it to be a ``Banach
manifold''. Of course, I could still complain that this description
doesn't make the \emph{abelian group structure} on \(K(\mathbb{Z},3)\)
obvious. But it's definitely a big step towards understanding what
\(K(\mathbb{Z},n)\)'s have to do with quantum theory.

While I'm at it, I should report some other things people have told me
via email. If you ponder what I've said, you can see that
\(\mathbb{CP}^\infty\) has 2nd homology equal to \(\mathbb{Z}\), and
that the generator of this homology group --- the ``universal cycle''
--- is given geometrically by the obvious way of sticking the sphere
\(\mathbb{CP}^1\) inside \(\mathbb{CP}^\infty\). This is nice because
\(\mathbb{CP}^1\) is actually a submanifold of the manifold
\(\mathbb{CP}^\infty\). But according to email from Mark Goresky, Rene
Thom has shown that for \(n > 6\), we cannot make \(K(\mathbb{Z},n)\)
into a manifold in such a way that the universal cycle is represented by
a submanifold!

On the other hand, Michael Murray reports that Pawel Gajer has managed
to make \(K(\mathbb{Z},n)\) into something called a ``differential
space'', which is not quite a manifold, but good enough to do geometry
on. I'm not sure how this relates to Thom's work\ldots{} but anyway, I
should read this stuff:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Pawel Gajer, ``Geometry of Deligne cohomology'', \emph{Invent. Math.}
  \textbf{127} (1997), 155--207, also available as
  \href{https://arxiv.org/abs/alg-geom/9601025}{\texttt{alg-geom/9601025}}.

  Pawel Gajer, ``Higher holonomies, geometric loop groups and smooth
  Deligne cohomology'', \emph{Advances in Geometry}, Birkhauser, Boston,
  1999, pp.~195--235.
\end{enumerate}

Now, so far I've been restraining myself from talking about ``gerbes'',
but if you've gotten this far you must be pretty comfortable with
abstract nonsense, so you'll probably like gerbes. Very roughly
speaking, a gerbe is a categorified version of a principal bundle!
Actually it's a categorified version of a sheaf, but sometimes we can
think of it as analogous to the sheaf of sections of a bundle. And just
as \(K(\mathbb{Z},2)\) is the classifying space for \(\mathrm{U}(1)\)
bundles, \(K(\mathbb{Z},3)\) is the classifying space for a certain sort
of gerbe!

I sort of explained how this works in \protect\hyperlink{week25}{``Week
25''}, but you can read the details here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Jean-Luc Brylinski, \emph{Loop Spaces, Characteristic Classes and
  Geometric Quantization}, Birkhauser, Boston, 1993.
\end{enumerate}

What this means is that as we explore the meaning of these
\(K(\mathbb{Z},n)\)'s for quantum theory, we are really
\emph{categorifying} familiar ideas from quantum theory. In particular,
this story should keep going on forever: \(K(\mathbb{Z},4)\) should be
the classifying space for a certain sort of 2-gerbe, and so on. But I
don't think people have worked out the details beyond the case of
2-gerbes. If you want to learn about 2-gerbes, you have to read this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Lawrence Breen, ``On the Classification of 2-Gerbes and 2-Stacks'',
  \emph{Asterisque} \textbf{225}, 1994.
\end{enumerate}

Finally, for more applications to physics, try these papers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\item
  Alan L. Carey and Michael K. Murray, ``Faddeev's anomaly and bundle
  gerbes'', \emph{Lett. Math. Phys.} \textbf{37} (1996), 29--36.

  Jouko Mickelsson, ``Gerbes and Hamiltonian quantization of chiral
  fermions'', in \emph{Lie Theory and Its Applications in Physics},
  World Scientific, Singapore, 1996, pp.~216--225.

  Michael K. Murray, ``Bundle gerbes'', \emph{J. London Math. Soc.}
  \textbf{54} (1996), 403--416.

  Alan L. Carey, Jouko Mickelsson and Michael K. Murray, ``Index theory,
  gerbes, and Hamiltonian quantization'', \emph{Comm. Math. Phys.}
  \textbf{183} (1997), 707--722, preprint available as
  \href{https://arxiv.org/abs/hep-th/9511151}{\texttt{hep-th/9511151}}.

  Alan L. Carey, Michael K. Murray and B. L. Wang, ``Higher bundle
  gerbes and cohomology classes in gauge theories'', \emph{J. Geom.
  Phys.} \textbf{21} (1997) 183--197, preprint available as
  \href{https://arxiv.org/abs/hep-th/9511169}{\texttt{hep-th/9511169}}.

  Alan L. Carey, Jouko Mickelsson and Michael K. Murray, ``Bundle gerbes
  applied to quantum field theory'', \emph{Rev.~Math. Phys.} \textbf{12}
  (2000), 65--90, preprint available as
  \href{https://arxiv.org/abs/hep-th/9711133}{\texttt{hep-th/9711133}}.
\end{enumerate}

I thank N. Christopher Phillips of the University of Oregon, Michael K.
Murray and Diarmuid Crowley of the University of Adelaide, and Mark
Goresky of IHES for educating me about these matters\ldots{} all
remaining errors are mine!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Footnotes:

{[}1{]} I'm being sloppy here. Throughout this discussion, when I say
``homotopy equivalent'', I really mean ``weakly homotopy equivalent''
--- a technical nuance that you can read about in any good book on
homotopy theory.

{[}2{]} Moreover, \(P\) must be the universal principal \(G\)-bundle.
Conversely, for any topological group \(G\) the total space of the
universal principal \(G\)-bundle is contractible. Everything fits
together very neatly! But I don't need all this stuff now.



\hypertarget{week152}{%
\section{July 5, 2000}\label{week152}}

I've been reading about the mathematical physicist William Rowan
Hamilton lately, because I'm writing a review article about the
octonions --- that famous nonassociative \(8\)-dimensional division
algebra.

You see, the day after Hamilton discovered the quaternions and carved
the crucial formula \[i^2=j^2=k^2=ijk=-1\] on the Brougham bridge, he
mailed a letter explaining his discovery to his friend John Graves. And
about two months later, Graves discovered the octonions! In December
1843, he sent a letter about them to Hamilton.

Graves called them ``octaves'' at first, but later introduced the term
``octonions''. He showed they were a normed division algebra and used
this to prove the 8 squares theorem, which says that the product of two
sums of 8 perfect squares is again a sum of 8 perfect squares. The
complex numbers and quaternions allow one to prove similar theorems for
2 and 4 squares. In January 1844, Graves considered the idea of a
general theory of ``\(2^m\)-ions''. He tried to construct a
\(16\)-dimensional normed division algebra and use it to prove a 16
squares theorem, but he ``met with an unexpected hitch'' and came to
doubt that this was possible.

(If you read \protect\hyperlink{week59}{``Week 59''} you'll see why.)

Hamilton was the one who noticed that the octonions were nonassociative
--- in fact, he invented the word ``associative'' right about this time.
He offered to write a paper publicizing Graves' work, and Graves
accepted the offer, but Hamilton kept putting it off. He was probably
busy working on the quaternions!

Meanwhile, Arthur Cayley had heard about the quaternions right when
Hamilton announced his discovery, and he eventually discovered the
octonions on his own. He published a description of them in the March
1845 issue of the Philosophical Magazine. Graves was upset, so he added
a postscript about the octonions to a paper of his that was due to
appear in the following issue of the same journal, asserting that he'd
known about them since Christmas 1843. Also, Hamilton eventually got his
act together and published a short note about Graves' discovery in the
June 1847 issue of the Proceedings of the Royal Irish Academy. But by
then it was too late --- everyone was calling the octonions ``Cayley
numbers''.

Of course it wasn't \emph{really} too late, since everybody who cares
can now tell that Graves was the first to discover the octonions. And
anyway, it doesn't really make a difference who discovered them first,
except as a matter of historical interest.

But just for the heck of it, I'm trying to find out everything I can
about the early history of the octonions. Hamilton is very famous, and
much has been written about him, but Graves is mainly famous for being
Hamilton's friend --- so to learn stuff about Graves, I have to read
books on Hamilton. In the process, I've learned some interesting things
that aren't really relevant to my review article. And I want to tell you
about some of them before I forget!

Hamilton was a strangely dreamy sort of guy. He spent most of his life
as the head of a small observatory near Dublin, but quickly lost
interest in actually staying up nights to make observations. Instead, he
preferred writing poetry. He was friends with Coleridge, who introduced
him to the philosophy of Kant, which influenced him greatly. He was also
friends with Wordsworth --- who told him to not to write poetry. He fell
deeply in love with a woman named Catherine Disney, who was forced by
her parents to marry a wealthy man 15 years older than her. Hamilton
remained hopelessly in love with her the rest of his life, though he
eventually married someone else. He became an alcoholic, then foreswore
drink, then relapsed. Eventually, many years later, Catherine began a
secret correspondence with him --- she still loved him! Her husband
became suspicious, she attempted suicide by taking laudanum\ldots{} and
then, five years later, she became ill.~Hamilton visited her and gave
her a copy of his ``Lectures on Quaternions'' --- they kissed at long
last --- and then she died two weeks later. He carried her picture with
him ever afterwards and talked about her to anyone who would listen. A
very sad and very Victorian tale.

He was a bit too far ahead of his time to have maximum impact during his
own life. The Hamiltonian approach to mechanics and the Hamilton-Jacobi
equation relating waves and particles became really important only when
quantum mechanics came along. Luckily Klein liked this stuff, and told
Schroedinger about it. But it's a pity that Hamilton's unification of
particle and wave mechanics came along right when the advocates of the
wave theory of light seemed to have definitively won the battle against
the particle theory --- the need for a compromise became clear only
later.

Quaternions, too, might have had more impact if they'd come along later,
when people were trying to understand spin-\(1/2\) particles. After all,
the unit quaternions form the group \(\mathrm{SU}(2)\), which is perfect
for studying spin-\(1/2\) particles. But the way things actually went,
quaternions were not very popular by the time people dreamt of
spin-\(1/2\) particles --- so Pauli just used \(2\times\) complex
matrices to describe the generators of \(\mathrm{SU}(2)\).

I like what Hamilton wrote about quaternions, space, and time:

\begin{quote}
The quaternion was born, as a curious offspring of a quaternion of
parents, say of geometry, algebra, metaphysics, and poetry\ldots{} I
have never been able to give a clearer statement of their nature and
their aim than I have done in two lines of a sonnet addressed to Sir
John Herschel:

\begin{quote}
\begin{verbatim}
           "And how the One of Time, of Space the Three
            Might in the Chain of Symbols girdled be."
\end{verbatim}
\end{quote}
\end{quote}

It's also amusing how Hamilton responded when de Morgan told him about
the four-color conjecture: ``I am not likely to attempt your `quaternion
of colours' very soon.'' The pun is ironic, given the relations people
have recently discovered between what is now the four-color theorem, the
vector cross product, and the group \(\mathrm{SU}(2)\). (See
\protect\hyperlink{week8}{``Week 8''} and
\protect\hyperlink{week92}{``Week 92''} for more.)

Of course quaternions were very influential for a while --- they were
taught in many mathematics departments in America in the late 1800s, and
were even a mandatory topic of study at Dublin! But then they were
driven out by the vector notation of Gibbs and Heaviside. If you don't
know this story, you've got to read this book --- it's fascinating:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Michael J. Crowe, \emph{A History of Vector Analysis}, University of
  Notre Dame Press, Notre Dame, 1967.
\end{enumerate}

Check out the graphs showing how many books were written on quaternions:
the big boom in the 1860s, and then the bust!

I hadn't even known about what many people at the time considered
Hamilton's greatest achievement: the prediction of ``conical
refraction'' by a biaxial crystal like aragonite. Folks compared this to
the discovery of Neptune by Adams and Leverrier --- another triumph of
prediction --- and Hamilton won a knighthood for it.

Does anyone understand how this phenomenon works? I don't.

Personally, I think one of Hamilton's greatest triumphs was his
treatment of complex numbers as pairs of real numbers --- this finally
exorcised the long-standing fears about whether imaginary numbers
``really exist'', and helped opened up the way for other algebras.
Interestingly, the person who got him interested in this problem was
John Graves. Graves was the one who introduced Hamilton to John Warren's
book ``A Treatise on the Geometrical Representation of the Square Root
of Negative Quantities'', which explained the concept of the complex
plane. Hamilton turned this from geometry into algebra.

One of Hamilton's last inventions was the icosian calculus. Faithful
fans of This Week's Finds will remember the icosians from
\protect\hyperlink{week20}{``Week 20''}. These were invented by Conway
and Sloane; Hamilton's original icosian calculus was a bit different. In
August 1856, Hamilton went to the British Association Meeting at
Cheltenham and stayed at the house of his pal John Graves. He enjoyed
talking to Graves and reading his books: ``Conceive me shut up and
revelling for a fortnight in John Graves' Paradise of Books! of which he
has really an astonishingly extensive collection, especially in the
curious and mathematical kinds. Such new works from the Continent he has
picked up! and such rare old ones too!'' Graves posed some puzzles to
Hamilton, and either Graves or his books got Hamilton to thinking about
regular polyhedra. When Hamilton returned to Dublin he thought about the
symmetry group of the icosahedron, and used it to invent an algebra he
called the ``icosians''. He then sent a letter to Graves explaining the
icosians.

He basically said: assume we've got three symbols \(I\), \(K\), and
\(L\) satisfying these relations:
\[I^2 = 1,\quad K^3 = 1,\quad L^5 = 1,\quad L = IK \] together with the
associative law but not the commutative law. You can think of \(L\) as
corresponding to rotating an icosahedron \(1/5\) of a turn around a
vertex. \(K\) corresponds to rotating it \(1/3\) of a turn around a
face, and \(I\) corresponds to rotating it \(1/2\) of a turn around an
edge. The relations above all follow from this idea.

These days, we would call the icosians the ``group algebra of \(A_5\)''.
In modern lingo, the symmetry group of the icosahedron is called
\(A_5\), since it's the group of all even permutations of 5 things. If
you don't know why this is true, check this out:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  John Baez, ``Some thoughts on the number six'',
  \texttt{http://math.ucr.edu/home/baez/six.html}
\end{enumerate}

We form the ``group algebra'' of a group by taking all formal linear
combinations of group elements with real coefficients, and defining a
product of such combinations using the product in the group. The
dimension of a group algebra is just the number of elements in the
group. Since \(A_5\) has 60 elements, the icosians are a 60-dimensional
algebra. These days this stuff is no big deal. But back then, I bet a
60-dimensional noncommutative algebra was really mindblowing!

In a way that I don't fully understand, Hamilton connected the icosian
calculus to the problem of travelling along the edges of a dodecahedron,
hitting each vertex just once, and coming back to where you started. In
graph theory, this sort of thing is now called a ``Hamiltonian
circuit''. Hamilton even invented a puzzle where the first player takes
the first five steps any way they want, and the other player has to
complete the Hamiltonian circuit. He called this the ``icosian game''.

It was John Graves' idea to actually design a game board with the
dodecahedron graph drawn on it and holes at the vertices that you could
put small cylindrical markers into. In 1859, a friend of Graves
manufactured a version where the game board had legs like a small table,
and sent a copy to Hamilton. Naturally Hamilton was delighted! Graves
put Hamilton in contact with a London toymaker named John Jacques, and
Hamilton sold Jacques the rights to the game for 25 pounds and 6 copies.
Jacques marketed two versions, one for the parlor, which was played on a
flat board, and another for the ``traveler'', which was played on an
actual dodecahedron --- there was a nail at each vertex, and the players
wound string about these nails as they traced out their Hamiltonian
circuit.

With charming naivete, Hamilton had hopes that the game would sell
wildly. Alas, it did not. Jacques never even recouped his investment.
The problem was that the icosian game was too easy, even for children!
Amusingly, Hamilton had more trouble with it than most people ---
perhaps because he was using the icosian calculus to figure out his
moves, instead of just trying different paths.

By the way, if anyone knows any good source of information about Graves
or the invention of the octonions, I'd love to hear about it. So far
I've gotten most of my stuff from the following sources. First of all,
there's this nice biography of Hamilton:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Thomas L. Hankins, \emph{Sir William Rowan Hamilton}, John Hopkins
  University Press, Baltimore, 1980.
\end{enumerate}

Check out the picture of the icosian game on page 342!

Then there's this much longer biography, which includes lots of
correspondence:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Robert Perceval Graves, \emph{Life of Sir William Rowan Hamilton}, 3
  volumes, Arno Press, New York 1975.
\end{enumerate}

Robert Perceval Graves was the brother of John Graves! He idolized
Hamilton, so this is not the most balanced account of his work.

Then there is this very helpful summary of the Hamilton-Graves
correspondence on octonions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  W. R. Hamilton, ``Four and eight square theorems'', Appendix 3 of
  vol.~III of \emph{The Mathematical Papers of William Rowan Hamilton},
  eds.~H. Halberstam and R. E. Ingram, Cambridge University Press,
  Cambridge, 1967.
\end{enumerate}

Unfortunately this does not include Graves' first letter to Hamilton
about the octonions. Is it lost?

Finally, there's this history of later work on the octonions and the
eight square theorem:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  L. E. Dickson, ``On quaternions and their generalization and the
  history of the eight square theorem'', \emph{Ann. Math.} \textbf{20}
  (1919), 155--171.
\end{enumerate}

It turns out the eight square theorem was proved in 1822, before Graves.
Also, there's some good material in here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Heinz-Dieter Ebbinghaus et al, \emph{Numbers}, Springer, New York,
  1990.
\end{enumerate}

This book is a lot of fun for anyone interested in all sorts of
``numbers''.

Finally, for an excellent \emph{online} source of information on the
history of quaternions, octonions, and other ``hypercomplex number
systems'', this is the place to go:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Jeff Biggus, ``A history of hypercomplex numbers'',
  \texttt{http://history.hyperjeff.net/hypercomplex.html}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Addendum:} On April 14th, 2005 I received the following email
from Geoff Corbishley in response to my plea for more information about
John Graves:

\begin{quote}
John

Your page asks for information on John Graves. I am reading
\emph{Goodbye to all That}, the autobiography of Robert Graves who also
wrote \emph{I Claudius} and other books. Chapter 1 (page 14 in my
Penguin paperback) records that John Thomas Graves helped WR Hamilton
with quaternions and gives a list of other relatives. Very little extra
detail is given about JT Graves, sadly.

Hope that has not been reported too often\ldots.

Geoff
\end{quote}

Fans of Hamilton might like to see my webpage with photos of the plaque
on Brougham Bridge commemorating his discovery of the quaternions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  John Baez, Brougham Bridge,
  \texttt{http://math.ucr.edu/home/baez/octonions/node24.html}
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week153}{%
\section{July 15, 2000}\label{week153}}

This one is going to be a bit rough at the edges, because in a few hours
I'm taking a plane to London. I'm going to the International Congress on
Mathematical Physics, where I'll get to hear talks by Ashtekar, Atiyah,
Buchholz, Connes, Dijkgraaf, Donaldson, Faddeev, Freed, Froehlich,
Kreimer, Ruelle, Schwartz, Shor, Thirring, 't Hooft, and other
math/physics heavyweights. I'm also gonna talk a bit myself --- they'd
have to pay me to shut up! I hope to report on this stuff in future
issues.

But today, I want to say a bit about counting.

Archimedes loved to count. In his Sand Reckoner, he invented a notation
for enormous numbers going far beyond what the Greeks had previously
considered. He made up a nice problem to showcase these large numbers:
how many grains of sand would it take to fill the universe? He then
computed an upper bound, based on assumptions such as these:

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\item
  No more than 10,000 grains of sand can fit into a sphere whose
  diameter was \(1/40\)th a finger-width.
\item
  The circumference of the earth is no more than 3,000,000 stades. A
  ``stade'' is about 160 meters --- different Greek cities used
  different stades, so it difficult to be very precise about this.
\item
  The diameter of the earth is greater than the diameter of the moon.
\item
  The diameter of the sun is no more than 30 times the diameter of the
  moon. (Of course this one is way off!)
\item
  The diameter of the sun is greater than the side of a regular
  chiliagon inscribed in a great circle in the sphere of the universe. A
  chiliagon is a thousand-sided polygon.
\end{enumerate}

He concluded that no more than \(10^{63}\) grains of sand would be
needed to fill the universe. Of course, he didn't use modern exponential
notation! Instead, he used a system of his own devising. The largest
number the Greeks had a notation for was a ``myriad myriads'', or
\(10^8\), since a ``myriad'' means 10,000. Archimedes called \(10^8\) a
number of the ``first order''. He then invented a number of the ``second
order'', namely \(10^{16}\), and the ``third order'', namely \(10^{24}\)
--- and so on, up to the myriad-myriadth order, i.e.~\(10^8\) to the
\(10^8\)th power.

He then said all these numbers were of the ``first period'', and went on
to define higher periods of numbers, up to a number of the myriadth
period, which was \(10^{80,000,000,000,000,000}\). After this exercise,
the number of grains of sand in the universe must have seemed rather
puny --- merely a thousand myriads of numbers of the eighth order!

Actually, this counting exercise is one of Archimedes' lesser feats. He
pioneered many of the concepts of mechanics and calculus. He also had
the neat idea to use mechanical methods to do calculations and ``prove
theorems''. He wrote about this in a treatise called ``Methods of
Mechanical Theorems''. There is only one surviving copy of this
treatise, and that is a fascinating story in itself. It is part of the
``Archimedes Palimpsest'', a copy of various works of Archimedes which
dates back to the 10th century A.D.. A ``palimpsest'' is a parchment
which was reused and written over --- in this case, by Greek monks. The
Archimedes palimpsest has a long and complicated history, and only in
1998 was it made publicly accessible at the Walters Art Gallery. For
more on this, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Reviel Netz, ``The origins of mathematical physics: new light on an
  old question'', \emph{Physics Today}, June 2000, 32--37.
\item
  The Walters Art Gallery, Archimedes Palimpsest website,
  \texttt{http://www.thewalters.org/archimedes/frame.html}
\end{enumerate}

For more on Archimedes, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Chris Rorres, Archimedes website,
  \texttt{http://www.mcs.drexel.edu/\textasciitilde{}crorres/Archimedes/contents.html}
\end{enumerate}

Anyway, back to counting. These days I'm interested in generalizations
of ``cardinality''. The cardinality of a set S is just its number of
elements, which I'll denote by \(|S|\). The great thing about this is
that if you know the cardinality of a set, you know that set up to
isomorphism: any two sets with the same number of elements are
isomorphic. Of course, this is no coincidence: it's exactly what numbers
were invented for!

I explained this using the ``parable of the shepherd'' in
\protect\hyperlink{week121}{``Week 121''}, so I won't run through that
spiel again. Instead, I'll just remind you of the basic facts: there's a
category \(\mathsf{FinSet}\) whose objects are finite sets and whose
morphisms are functions. We can ``decategorify'' any category by forming
the set of isomorphism classes of objects. When we do this to
\(\mathsf{FinSet}\) we get the set of natural numbers, \(\mathbb{N}\).
So given any finite set \(S\), its isomorphism class \(|S|\) is just a
natural number --- its cardinality!

Via this trick the natural numbers inherit all their basic operations
from corresponding operations in \(\mathsf{FinSet}\). For example, given
two finite sets \(S\) and \(T\) we can form their disjoint union
\(S + T\) and their Cartesian product, and these operations give birth
to addition and multiplication of natural numbers, via these formulas:
\[
  \begin{aligned}
    |S + T| &= |S| + |T|
  \\|S \times T| &= |S| \times |T|
  \end{aligned}
\] Now the advantage of this rather esoteric view of basic arithmetic is
that it suggests vast generalizations which unify all sorts of seemingly
disparate stuff. For example, we can play this ``decategorification''
game to categories other than \(\mathsf{FinSet}\). For example, we can
do it to the category \(\mathsf{Vect}\) whose objects are vector spaces
and whose morphisms are linear functions --- and what do we get? The set
\(\mathbb{N}\) again! But this time we don't call the isomorphism class
of a vector space its ``cardinality'' --- we call it the ``dimension''.
And this time, addition and multiplication of natural numbers correspond
to direct sum and tensor product of vector spaces.

Well, this example is so familiar that it may seem that we're still not
getting anywhere interesting. But suppose we consider the category of
\(\mathsf{Vect}(X)\) of vector \emph{bundles} over a topological space
\(X\). If we take X to be a single point this is just \(\mathsf{Vect}\)
--- a vector bundle over a point is a vector space. But if we take \(X\)
to be more interesting, when we decategorify \(\mathsf{Vect}(X)\) we get
an interesting set that depends on \(X\). Since we can take direct sums
and tensor products of vector bundles, this set has addition and
multiplication operations. Like the natural numbers, this set is not a
ring, since it doesn't have additive inverses. It's a mere ``rig'' --- a
``ring without negatives''.

But just as we created the integers by making up additive inverses for
the natural numbers, we can take this set and throw in formal additive
inverses to get a ring. What ring do we get? Well, it depends on \(X\):
it's called the ``K-theory of \(X\)'', and denoted \(K(X)\). Studying
this ring \(K(X)\) is a wonderful way to understand the space \(X\).
K-theory is a great example of a generalized cohomology theory (see
\protect\hyperlink{week149}{``Week 149''} and
\protect\hyperlink{week150}{``Week 150''}). To explain it in detail
would require a book. Luckily, such books already exist. In fact there
are a bunch! Here are 3 of my favorites:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\item
  Raoul Bott, \emph{Lectures on K(X)}, Harvard University, Cambridge,
  1963.
\item
  Michael Atiyah, \emph{K-theory}, W. A. Benjamin, New York, 1967.
\item
  Max Karoubi, \emph{K-theory: an Introduction}, Springer, Berlin, 1978.
\end{enumerate}

There are a million variations on this decategorification trick: for
example, we can decategorify the category of complex line bundles on the
space \(X\), and get a set called \(H^2(X)\) --- the ``second cohomology
group of \(X\)''. This is an abelian group thanks to the fact that we
can take tensor products of line bundles. The isomorphism class of any
complex line bundle gives an element of \(H^2(X)\) called the ``first
Chern class'' of the line bundle. For more about this see
\protect\hyperlink{week149}{``Week 149''}\ldots. my point here is that
this is just a generalization of the idea of cardinality!

Or, we can start with the category of finite-dimensional representations
of a group \(G\). When we decategorify this we get a rig, since we can
take direct sums and tensor products of representations. If we throw in
additive inverses, we get a ring \(R(G)\) called the ``representation
ring'' of \(G\). The isomorphism class of any representation gives an
element of \(R(G)\) which people call the ``character'' of that
representation.

Or start with the category where an object is an action of \(G\) on a
finite set! Decategorifying and then throwing in additive inverses, we
get something called the ``Burnside ring'' of \(G\).

In fact, the last two examples are special cases of something more
general: we can start with the category
\(\operatorname{Hom}(G,\mathcal{C})\) where the objects are actions of
\(G\) on objects in some category \(\mathcal{C}\)! Different choices of
\(\mathcal{C}\) give different views of the group \(G\), and different
structures on \(\mathcal{C}\) will give us a group, or a rig, when we
decategorify \(\operatorname{Hom}(G,\mathcal{C})\). I am tempted to
launch into a detailed disquisition on how this works, but I fear such
generality will exhaust the patience of all but the true lovers of
abstraction --- who can figure it out for themselves anyway! So let me
descend earthwards a few hundred meters and let the winds hasten me
towards my ultimate goal, which is\ldots{} elliptic cohomology.

Suppose we decategorify the category of compact oriented smooth
manifolds! What are the morphisms in this category? Well, let's take
them to be cobordisms. And to simplify life let's throw in formal
inverses to all these morphisms, so manifolds with a cobordism between
them get counted as isomorphic. We get a category where all the
morphisms are isomorphisms. And when decategorify this, we get a big
set. This set becomes a rig thanks to our ability to take disjoint
unions and Cartesian products of compact oriented smooth manifolds. In
fact it's a ring, because the orientation-reversed version of any
manifold serves as its additive inverse. This ring is obviously
commutative. People call it the ``oriented cobordism ring''. And believe
or not, people know quite a bit about this ring.

To simplify this ring a bit, let's tensor it with the complex numbers.
We get an algebra that's easy to describe: it's just the algebra of
complex polynomials in countably many variables! These variables
correspond to the complex projective spaces \(\mathbb{CP}^2\),
\(\mathbb{CP}^4\), \(\mathbb{CP}^6,\) etcetera --- so folks sometimes
write this algebra as follows:
\[\mathbb{C}[\mathbb{CP}^2,\mathbb{CP}^4,\mathbb{CP}^6,\ldots]\] Now,
using this algebra we can cook up various notions analogous to the
``cardinality'' of a compact oriented smooth manifold. But people don't
say ``cardinality'', they say ``genus''. Don't be fooled --- if you know
about the genus of a surface, this isn't that! In this definition, a
``genus'' assigns to each compact oriented manifold \(M\) a complex
number \(|M|\) such that \[
  \begin{aligned}
    |M + N| &= |M| + |N|
  \\|M \times N| &= |M| \times |N|
  \end{aligned}
\] and \(|M| = |M'|\) if there is a cobordism from \(M\) to \(M'\). If
you stare at this definition carefully, you'll see that a genus is
really just a homomorphism from
\(\mathbb{C}[\mathbb{CP}^2,\mathbb{CP}^4,\mathbb{CP}^6,\ldots]\) to the
complex numbers.

As any classicist will tell you, the plural of genus is ``genera''.
Examples of genera include the signature and \(\hat{A}\) genus, both
beloved by topologists and differential geometers. The Euler
characteristic is \emph{not} a genus since it is not cobordism invariant
--- very much a pity, since it's so much like the cardinality in so many
ways (see \protect\hyperlink{week146}{``Week 146''}.)

Since the algebra
\(\mathbb{C}[\mathbb{CP}^2,\mathbb{CP}^4,\mathbb{CP}^6,\ldots]\) is
generated by the guys \(\mathbb{CP}^{2n}\), all the information to
describe a genus is contained in the ``logarithm''
\[\log(x) = \sum \frac{|\mathbb{CP}^{2n}|x^{2n+1}}{2n+1}\] Classifying
genera is hard, but it gets easier if we impose some extra conditions.
Suppose \[F \to E \to B\] is a fiber bundle with compact connected
structure group. The space \(E\) is like a ``twisted product'' of \(F\)
and \(B\), so it makes sense to demand that \[|E| = |F| |B|.\] In this
case we say we have an ``elliptic genus''. And in this case Ochanine
proved that in this case the logarithm is an elliptic integral:
\[\log(x) = \int_0^x \frac{dt}{\sqrt{1 - 2dt^2 + et^4}}\] for some
numbers \(d\) and \(e\). This is the inverse of an elliptic function,
and this elliptic function is periodic with respect to some lattice
\(L\) in the complex plane.

(You don't remember what elliptic functions are, and what they have to
do with lattices? Then go back to \protect\hyperlink{week13}{``Week
13''}.)

We can think of the elliptic genus as a function of the lattice \(L\).
If we do this, something nice happens: if we rescale \((d,e)\) to
\((c^{2d},c^{4e})\), this changes the lattice \(L\) to \(L/c\) and
changes the genus \(|M|\) to \(c^{\dim(M)/2} |M|\). Folks summarize this
and some other stuff by saying that the elliptic genus \(|M|\), thought
of as a function of the lattice \(L\), is a ``modular form of weight
\(\dim(M)/2\)''.

Now for the final punchline: if we think of our elliptic genus as taking
values in a ring where \(d\) and \(e\) are formal variables, the
resulting ``universal elliptic genus'' has a nice interpretation in
terms of elliptic cohomology --- a generalized cohomology theory that I
discussed in \protect\hyperlink{week151}{``Week 151''}. To compute the
universal elliptic genus \(|M|\), we just take the fundamental class of
\(M\) (in elliptic cohomology) and push it forwards via the map from
\(M\) to a point!

(We can do this ``pushforward'' because elliptic cohomology is a complex
oriented cobordism theory and acts very much like ordinary cohomology or
K-theory.)

It's very interesting how elliptic functions, modular forms and the like
appear out of the blue in what I've just been talking about. Why??? The
explanation seems to involve loop groups, vertex operator algebras and
that sort of stuff\ldots{} but alas, I don't have time to even
\emph{try} to explain this now! For now, I just urge you to read these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\item
  Graeme Segal, ``Elliptic cohomology'', \emph{Asterisque}
  \textbf{161--162} (1988), 187--201.
\item
  Hirotaka Tamanoi, \emph{Elliptic Genera and Vertex Operator
  Super-Algebras}, Springer Lecture Notes in Mathematics \textbf{1704},
  Springer, Berlin, 1999.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{It is like walking through a constantly shifting illusion, routes
appearing and decaying, the solvable and the utterly impossible snuggled
so close together that they cannot be told apart.} --- Craig Childs,
Soul of Nowhere



\hypertarget{week154}{%
\section{August 12, 2000}\label{week154}}

At the 13th International Congress on Mathematical Physics, held at
Imperial College in London, I was surprised at how much energy was
focussed on quantum computation and quantum cryptography. But it makes
perfect sense --- this is one area where fundamental physics still has
the potential to drastically affect everyday life. I'm not sure quantum
computation will ever be practical, but it's certainly worth checking
out. Quantum cryptography is well on its way --- though people are busy
arguing just \emph{how} practical it will be:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Hoi-Kwong Lo, ``Will quantum cryptography ever become a successful
  technology in the marketplace?'', preprint available as
  \href{https://arxiv.org/abs/quant-ph/9912011}{\texttt{quant-ph/9912011}}
\end{enumerate}

It seems that both quantum computation and quantum cryptography are
becoming part of a bigger subject, perhaps called ``quantum information
theory'' --- the study of how information can be transmitted and
manipulated in the context of quantum theory. There's certainly a need
for good theorems and definitions in this subject, as well as more
experiments. For example, nobody seems sure how to calculate the
information capacity of a quantum channel --- or even how to define it!

If you're interested in this, it might be good to start with John
Preskill's lecture notes, which are available for free on the web:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  John Preskill, Lecture notes on quantum computation and quantum
  information theory, available at
  \texttt{http://www.theory.caltech.edu/people/preskill/ph229}
\end{enumerate}

Also try the references, homework problems, and links on this webpage.

There was also a lot of stuff about quantum gravity and string theory at
the ICMP. I especially enjoyed Robert Dijkgraaf's talk, for example. Not
just the cute animated movies of strings and D-branes, but the highly
\(n\)-categorical flavor of the whole thing --- he even presented a
picture proof the Atiyah-Singer index theorem! It wasn't clear how
relevant this is to the physics of our particular universe, but at the
end of the talk Dijkgraaf urged us not to worry about that too much:
after all, the math is so pretty in its own right. Insofar as I'm a
physicist this makes me unhappy --- but in my other persona, as a
mathematician, it makes sense.

I prefer to stay one or two trends behind the times when it comes to
string theory, since I'm not actually working on the subject --- so it's
easier for me to learn about stuff after it's been prettied up a bit by
the mathematicians. Dijkgraaf's talk made me feel a vague responsibility
to tell you all about what's been going on lately in string
theory\ldots. but I'm not really up on this stuff, so I will discharge
this duty in the laziest manner possible, by listing the 10 papers most
cited by preprints on hep-th during the year 1999.

Here they are, from the top-cited one on down:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Juan Maldacena, ``The large \(N\) limit of superconformal field
  theories and supergravity'', \emph{Adv. Theor. Math. Phys.} \textbf{2}
  (1998) 231--252, preprint available as
  \href{https://arxiv.org/abs/hep-th/9711200}{\texttt{hep-th/9711200}}.
\end{enumerate}

This one launched the ``AdS-CFT'' craze, by pointing out an interesting
relation between supergravity on anti-DeSitter spacetime and conformal
field theories on its ``boundary at infinity''.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Nathan Seiberg and Edward Witten, ``Electric-magnetic duality,
  monopole condensation, and confinement in \(N=2\) supersymmetric
  Yang-Mills theory'', \emph{Nucl. Phys.} \textbf{B426} (1994) 19--52,
  preprint available as
  \href{https://arxiv.org/abs/hep-th/9407087}{\texttt{hep-th/9407087}}.
\end{enumerate}

This one is ancient history by now, but it's still near the top of the
list! For mathematicians, this paper marked the birth of Seiberg-Witten
theory as a substitute for Donaldson theory when it comes to the study
of \(4\)-dimensional smooth manifolds. (See
\protect\hyperlink{week44}{``Week 44''} and
\protect\hyperlink{week45}{``Week 45''}.) But for physicists, it
highlighted the growing importance of ``dualities'' relating seemingly
different physical theories --- of which the AdS-CFT craze is a more
recent outgrowth.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Edward Witten, ``String theory dynamics in various dimensions'',
  \emph{Nucl. Phys.} \textbf{B443} (1995) 85--126, preprint available as
  \href{https://arxiv.org/abs/hep-th/9503124}{\texttt{hep-th/9503124}}.
\end{enumerate}

This paper was also important in the quest to understand dualities:
among other things, it argued that the type IIA superstring in 10
dimensions is related to \(11\)-dimensional supergravity --- reduced to
10 dimensions by curling up one dimension into a very \emph{large}
circle. And as I described in \protect\hyperlink{week118}{``Week 118''},
this helped lead to the search for ``M-theory'', of which
\(11\)-dimensional supergravity is hoped to be a low-energy limit.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Edward Witten, ``Anti-DeSitter space and holography'', \emph{Adv.
  Theor. Math. Phys.} \textbf{2} (1998) 253--291, preprint available as
  \href{https://arxiv.org/abs/hep-th/9802150}{\texttt{hep-th/9802150}}.
\end{enumerate}

More on the AdS-CFT business.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  S. S. Gubser, I. R. Klebanov, and A. M. Polyakov, ``Gauge theory
  correlators from noncritical string theory'', \emph{Phys. Lett.}
  \textbf{B428} (1998) 105--114, preprint available as
  \href{https://arxiv.org/abs/hep-th/9802109}{\texttt{hep-th/9802109}}.
\end{enumerate}

Still more on the AdS-CFT business.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Joseph Polchinski, ``Dirichlet branes and Ramond-Ramond charges'',
  \emph{Phys. Rev.~Lett.} \textbf{75} (1995) 4724--4727, preprint
  available as
  \href{https://arxiv.org/abs/hep-th/9510017}{\texttt{hep-th/9510017}}.
\end{enumerate}

This helped launch the D-brane revolution: the realization that when we
take nonperturbative effects into account, open strings seem to have
their ends ``stuck'' on higher-dimensional surfaces called D-branes.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Nathan Seiberg and Edward Witten, ``Monopoles, duality and chiral
  symmetry breaking in \(N=2\) supersymmetric QCD'', \emph{Nucl. Phys.}
  \textbf{B431} (1994) 484--550, preprint available as
  \href{https://arxiv.org/abs/hep-th/9408099}{\texttt{hep-th/9408099}}.
\end{enumerate}

More on what's now called Seiberg-Witten theory.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  T. Banks, W. Fischler, S. H. Shenker, and L. Susskind, ``M-theory as a
  matrix model: a conjecture'', \emph{Phys. Rev.} \textbf{D55} (1997),
  5112--5128, preprint available as
  \href{https://arxiv.org/abs/hep-th/9610043}{\texttt{hep-th/9610043}}.
\end{enumerate}

This was an attempt to given an explicit formulation for M-theory in
terms of a matrix model.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{10}
\tightlist
\item
  C. M. Hull and P. K. Townsend, ``Unity of superstring dualities'',
  \emph{Nucl. Phys.} \textbf{B438} (1995) 109--137, preprint available
  as
  \href{https://arxiv.org/abs/hep-th/9410167}{\texttt{hep-th/9410167}}.
\end{enumerate}

More about dualities, obviously! (But also some stuff about the
exceptional Lie group \(\mathrm{E}_7\), which is bound to tickle the
fancy of any exceptionologist.)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{11}
\tightlist
\item
  Edward Witten, ``Bound states of strings and \(p\)-branes'',
  \emph{Nucl. Phys.} \textbf{B460} (1996), 335--350, preprint available
  as
  \href{https://arxiv.org/abs/hep-th/9510135}{\texttt{hep-th/9510135}}.
\end{enumerate}

More on D-branes.

By the way: if you do physics, you can look up your \emph{own} top cited
papers on the SPIRES database, at least if someone has cited you 50 or
more times:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{12}
\tightlist
\item
  Searching top cited papers on SPIRES, at
  \texttt{http://www.slac.stanford.edu/spires/hep/topcite.html}
\end{enumerate}

This will allow you to measure your fame in milliwittens.

And now for something completely different:

I've been thinking about Clifford algebras a lot recently, because I'm
writing a review article on the octonions and exceptional Lie groups,
and a good way to undestand this stuff is to use a lot of Clifford
algebras machinery. I talked about Clifford algebras in
\protect\hyperlink{week82}{``Week 82''},
\protect\hyperlink{week93}{``Week 93''}, and
\protect\hyperlink{week105}{``Week 105''}, but here are some more nice
books about them.

First, when I was giving a little talk on Clifford algebras at
Nottingham University after the ICMP, I needed to look up a few things,
and I bumped into this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{13}
\tightlist
\item
  P. Budinich and A. Trautman, \emph{The Spinorial Chessboard},
  Springer-Verlag, Berlin, 1988.
\end{enumerate}

Unfortunately it's out of print, but John Barrett happened to have a
copy. Springer should reprint it! It has a nice discussion of the
``Clifford algebra clock'': \[
  \begin{tikzpicture}
    \draw (0,0) circle[radius=2.65cm];
    \node[label=below:{$\mathbb{R}$}] at (90:2.3) {0};
    \node[label=below left:{$\mathbb{C}$}] at (45:2.3) {1};
    \node[label=left:{$\mathbb{H}$}] at (0:2.3) {2};
    \node[label={[label distance=-2mm]above left:{$\mathbb{H}\oplus\mathbb{H}$}}] at (-45:2.3) {3};
    \node[label=above:{$\mathbb{H}$}] at (-90:2.3) {4};
    \node[label=above right:{$\mathbb{C}$}] at (-135:2.3) {5};
    \node[label=right:{$\mathbb{R}$}] at (180:2.3) {6};
    \node[label={[label distance=-2mm]below right:{$\mathbb{R}\oplus\mathbb{R}$}}] at (135:2.3) {7};
    \foreach \a in {0,45,90,135,180,-135,-90,-45}
      \draw (\a:2.5) to (\a:2.65);
  \end{tikzpicture}
\] As I explained in \protect\hyperlink{week105}{``Week 105''}, this
clock easily lets you remember the real Clifford algebras in every
dimension and signature of spacetime. Bott periodicity explains why it
loops around after 8 hours. The spinorial chessboard presents the same
information in the form of an \(8\times 8\) grid. I won't draw it here,
but it's a picture of the Clifford algebras with \(p\) roots of \(-1\)
and \(q\) roots of \(1\) for \(p,q =0,1,2,3,4,5,6,7\). The black squares
correspond to cases that admit chiral spinors; the red ones correspond
to cases that don't. Black is when \(p+q\) is even; red is when it's
odd.

By the way, I have a little question: why does the above clock have a
reflection symmetry along the line joining \(\mathbb{R}+\mathbb{R}\) and
\(\mathbb{H}+\mathbb{H}\)?

Later, by coincidence, when I was in the library I discovered that
Chevalley's work on spinors has been reprinted:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\tightlist
\item
  Claude Chevalley, \emph{The Algebraic Theory of Spinors}, Springer,
  Berlin, 1991.
\end{enumerate}

It has a lot of neat stuff on ``pure spinors'', which are closely
related to the ``simple bivectors'' that describe 2-planes in
\(n\)-space. The latter play an important role in spin foam models of
quantum gravity, so I bet pure spinors will too.

Here's another fundamental text, which really helped get the whole
subject going:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{15}
\tightlist
\item
  Eli Cartan, \emph{The Theory of Spinors}, Dover Press, 1966.
\end{enumerate}

While I'm at it, I should mention this book by the infamous Pertti
Lounesto, which is also good:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{16}
\tightlist
\item
  Pertti Lounesto, \emph{Clifford Algebras and Spinors}, Cambridge U.
  Press, Cambridge, 1997.
\end{enumerate}

I also saw this book at a book fair:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{17}
\tightlist
\item
  Dominic Joyce, \emph{Compact Manifolds with Special Holonomy}, Oxford
  U. Press, Oxford, 2000.
\end{enumerate}

There's some incredible stuff here about \(7\)-dimensional Riemannian
manifolds whose holonomy groups lie in the exceptional Lie group
\(\mathrm{G}_2\). I bet this stuff is gonna be important in string
theory someday --- if it isn't already. After all, \(\mathrm{G}_2\) is
the automorphism group of the octonions, and it has a \(7\)-dimensional
irreducible representation on the imaginary octonions; as explained in
\protect\hyperlink{week104}{``Week 104''} by Robert Helling, the
octonions are secretly what let you write down the superstring
Lagrangian in 10d spacetime.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Footnote:

Andrzej Trautman answered my question about reflection symmetry in the
Clifford algebra clock by noting that
\[\mathrm{Cliff}(p,q) \otimes \mathbb{R}(2) = \mathrm{Cliff}(q+2,p)\]
where \(\mathbb{R}(2)\) is the algebra of \(2\times2\) real matrices. A
proof of this (actually well-known) fact appears in (7.8b) of his book.

In response to my list of most-cited papers, Aaron Bergman suggested the
following 261-page review article on the AdS-CFT correspondence:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{18}
\tightlist
\item
  O. Aharony, S. S. Gubser, J. Maldacena, H. Ooguri and Y. Oz, ``Large
  \(N\) field theories, string theory and gravity'', \emph{Phys. Rept.}
  \textbf{323} (2000) 183--386, preprint available as
  \href{https://arxiv.org/abs/hep-th/9905111}{\texttt{hep-th/9905111}}.
\end{enumerate}

For a similarly enormous review article on D-branes, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{19}
\tightlist
\item
  Clifford V. Johnson, ``D-brane primer'', preprint available as
  \href{https://arxiv.org/abs/hep-th/0007170}{\texttt{hep-th/0007170}}.
\end{enumerate}

Finally, it turns out that manifolds with \(\mathrm{G}_2\) holonomy
\emph{are} important in superstring theory, where they go by the name of
``Joyce manifolds''. Here are some places to read about them:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{20}
\item
  G. Papadopoulos and P. K. Townsend, ``Compactification of \(D=11\)
  supergravity on spaces of exceptional holonomy'', preprint available
  as
  \href{https://arxiv.org/abs/hep-th/9506150}{\texttt{hep-th/9506150}}.
\item
  B. S. Acharya, ``\(N=1\) heterotic-supergravity duality and Joyce
  manifolds'', preprint available as
  \href{https://arxiv.org/abs/hep-th/9508046}{\texttt{hep-th/9508046}}.

  ``\(N=1\) heterotic/M-theory duality and Joyce manifolds'', preprint
  available as
  \href{https://arxiv.org/abs/hep-th/9603033}{\texttt{hep-th/9603033}}.

  ``\(N=1\) M-theory-heterotic duality in three dimensions and Joyce
  manifolds'', preprint available as
  \href{https://arxiv.org/abs/hep-th/9604133}{\texttt{hep-th/9604133}}.

  ``Dirichlet Joyce manifolds, discrete torsion and duality'', preprint
  available as
  \href{https://arxiv.org/abs/hep-th/9611036}{\texttt{hep-th/9611036}}.

  ``M theory, Joyce orbifolds and super Yang-Mills'', preprint available
  as
  \href{https://arxiv.org/abs/hep-th/9812205}{\texttt{hep-th/9812205}}.
\item
  Chien-Hao Liu, ``On the global structure of some natural fibrations of
  Joyce manifolds'', preprint available as
  \href{https://arxiv.org/abs/hep-th/9809007}{\texttt{hep-th/9809007}}.
\end{enumerate}

I learned this thanks to Allen Knutson and Paul Schocklee. Paul also had
the following interesting comments:

\begin{quote}
John Baez wrote:
\end{quote}

\begin{quote}
\begin{quote}
There's some incredible stuff here about \(7\)-dimensional Riemannian
manifolds whose holonomy groups lie in the exceptional Lie group
\(\mathrm{G}_2\).\\
I bet this stuff is gonna be important in string theory someday --- if
it isn't already.
\end{quote}
\end{quote}

\begin{quote}
They are important!
\end{quote}

\begin{quote}
If you want to directly compactify \(11\)-dimensional
supergravity/M-theory to a theory with \(N=1\) supersymmetry in 4
dimensions, which is what people like for phenomenological reasons, you
need a \(7\)-dimensional manifold of \(\mathrm{G}_2\) holonomy (just as
you need manifolds of \(\mathrm{SU}(3)\) holonomy, i.e. Calabi-Yau
manifolds, in six dimensions). I have seen these referred to as ``Joyce
manifolds,'' after Dominic Joyce, who constructed several examples of
such spaces. (I didn't know there was so much known about them. I'll
have to check out the above book; I see that our library in Iceland has
a copy.)
\end{quote}

\begin{quote}
Unfortunately, these models are afflicted by the usual problem of 11-d
SUGRA compactifications, which is that they are non-chiral, so these
days people seem to be concentrating more on Horava-Witten
compactifications, with M-theory on \(S^1/\mathbb{Z}_2\) times a
Calabi-Yau, or on an orbifold.
\end{quote}

\begin{quote}
If you're interested, you might want to check out Papadopoulos and
Townsend, ``Compactification of D=11 supergravity on spaces of
exceptional holonomy,'' https://arxiv.org/abs/hep-th/9506150.
\end{quote}

\begin{quote}
-- Paul Shocklee Graduate Student, Department of Physics, Princeton
University Researcher, Science Institute, Dunhaga 3, 107 Reykjavk,
Iceland Phone: +354-525-4429
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week155}{%
\section{August 16, 2000}\label{week155}}

It's a hot summer day here in Riverside, so I just want to have fun.
Break out the Klein bottles and Platonic solids!

I still remember the day as a kid when I first made a Möbius strip, and
saw how it didn't fall apart when cut in half. I could see it, but I
couldn't quite grok it. I was fascinated --- and more than a little
annoyed when it turned out my dad already knew about it.

I don't remember exactly when I first saw a Klein bottle, but I loved it
at first sight:

\begin{verbatim}
            A mathematician named Klein
            Thought the Möbius strip was divine.
            Said he: "If you glue 
            The edges of two
            You'll get a weird bottle like mine!"
\end{verbatim}

Recently, when I was trying to explain some stuff about Klein bottles to
my friend Oz on \texttt{sci.physics.research}, I bumped into the website
of a company that sells the things --- Acme Klein Bottles. I couldn't
resist mentioning to the world at large that I'd dearly like one. And lo
and behold, a regular reader of This Week's Finds took me up on this:
Timothy J. Kordas. After a few weeks, a handcrafted glass Klein bottle
arrived via United Parcel Service. It's great! --- it sits on my desk
now, gleaming contentedly. I think everybody should have one. You can
even buy them sliced in half, exhibiting the Möbius strip quite clearly:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Acme Klein bottles sliced in half,
  \texttt{http://www.kleinbottle.com/sliced\_klein\_bottles.htm}
\end{enumerate}

Meanwhile, I've been thinking about the Platonic solids lately, and also
their generalizations to higher dimensions --- the so-called ``regular
polytopes''. To really learn about regular polytopes, you have to go to
the source: the king of geometry, Harold Scott Macdonald Coxeter. But
for some reason I didn't get around to reading his books until just
recently:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  H. S. M. Coxeter, \emph{Regular Polytopes}, 3rd edition, Dover, New
  York, 1973.

  \emph{Regular Complex Polytopes}, 2nd edition, Cambridge U. Press,
  Cambridge, 1991.
\end{enumerate}

Now my head is full of neat facts about regular polytopes, so I want to
rattle some off before I forget!

Let's start in 3 dimensions. I assume you're friends with the
tetrahedron, cube, octahedron, dodecahedron and icosahedron. But you
might not know all the nice relationships between them!

For example, there's a nice way to fit a tetrahedron snugly into a cube:
if you take every other vertex of the cube, you get the vertices of a
tetrahedron. And of course I mean a \emph{regular} tetrahedron --- I'm
not interested in any other kind, here. There are two ways to do this,
and if you put both these tetrahedra inside the cube, they combine to
form a star-shaped solid called the ``stella octangula''. This was
discovered and given its name by Kepler, who was really fond of this
sort of thing.

Here's a picture:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Eric Weisstein, stella octangula,
  \texttt{http://mathworld.wolfram.com/StellaOctangula.html}
\end{enumerate}

You can rotate it by grabbing it with your mouse!

Similarly, there is a nice way to fit a cube in a dodecahedron. The
dodecahedron has 20 vertices, and we can use 8 of these as the vertices
of a cube. This becomes obvious once we realize that these points are
the vertices of a dodecahedron: \[
  \begin{gathered}
    (\pm 1/G, \pm G, 0),
  \\(\pm G, 0, \pm 1/G),
  \\(0, \pm 1/G, \pm G)
  \\(\pm1, \pm1, \pm1).
  \end{gathered}
\] where \(G = (\sqrt{5} + 1)/2\) is the golden ratio and we get to pick
each of the plus or minus signs independently. The points
\((\pm1, \pm1, \pm1)\) form the vertices of a cube.

By rotating the whole picture, we get some other ways of putting a cube
in a dodecahedron: 5 in all. Any rotation of the dodecahedron permutes
these 5 cubes, and we get all even permutations of the cubes this way:
this is one nice way to prove that the rotational symmetry group of the
dodecahedron is \(A_5\) (the group of even permutations of 5 things).

If we put all 5 cubes inside the dodecahedron, we get a fancy shape that
would make a marvelous Christmas tree decoration --- I don't know what
it's called, but you can see a picture of it in Coxeter's ``Regular
Polytopes'', and also here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Eric Weisstein, cube 5-compound,
  \texttt{http://mathworld.wolfram.com/Cube5-Compound.html}
\end{enumerate}

Now let's combine these two tricks. If we put a tetrahedron in a cube,
and then put the cube in a dodecahedron, we get a way of fitting the
tetrahedron snugly into the dodecahedron! If we choose one way of doing
this and then rotate the picture to get other ways, we get 5 tetrahedra
in the dodecahedron. Putting these all together gives a scary-looking
shape:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Eric Weisstein, tetrahedron 5-compound,
  \texttt{http://mathworld.wolfram.com/Tetrahedron5-Compound.html}
\end{enumerate}

but the coolest thing about this shape is that it has an inherent
handedness --- like a sugar molecule, it comes in ``levo'' and
``dextro'' forms! If we reflect it, we get 5 \emph{other} ways to put a
tetrahedron into a dodecahedron, for a total of 10. All of these
tetrahedra taken together form a mirror-symmetric shape:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Eric Weisstein, tetrahedron 10-compound,
  \texttt{http://mathworld.wolfram.com/Tetrahedron10-Compound.html}
\end{enumerate}

Okay. So far we've related the tetrahedron, the cube and the
dodecahedron. What about the other two Platonic solids: the octahedron
and icosahedron? Well, from the point of view of \emph{symmetry groups}
these guys are redundant. The octahedron is dual to the cube, so it has
the same rotational symmmetry group. Similarly, the icosahedron is dual
to the dodecahedron and has the same symmetry group.

From the group-theoretic viewpoint, here's what's really going on. Our
trick for fitting the tetrahedron in the cube lets us turn any symmetry
of the tetrahedron into a symmetry of the cube. The rotational symmetry
group of the tetrahedron is \(A_4\) --- that is, all even permutations
of the 4 vertices. The symmetry group of the cube is \(S_4\) --- that
is, all permutations of the 4 lines connecting opposite vertices. So
what we've got is a trick for making \(A_4\) into a subgroup of \(S_4\).

(This immediately leads to a little puzzle. There's an \emph{obvious}
way to find \(A_4\) as a subgroup of \(S_4\), since even permutations
are a special case of permutations. So: does the above trick give this
obvious way, or some other way?)

Anyway, it's also true that any way of fitting the tetrahedron in the
dodecahedron lets us turn any symmetry of the tetrahedron into a
symmetry of the dodecahedron. So we've also got a trick for making
\(A_4\) into a subgroup of \(A_5\).

(You might also think that our trick for fitting the cube in the
dodecahedron gives a way to turn any symmetry of the cube into a
symmetry of the dodecahedron. I thought this for a while, but it's not
true! For starters, if it \emph{were} true, we'd get a trick for making
\(S_4\) into a subgroup of \(A_5\) --- which is impossible, since the
order of the group \(S_4\) doesn't divide that of \(A_5\). And the
problem turns out to be this: a 90 degree rotation of the cube does not
correspond to a symmetry of the dodecahedron.)

Playing with this stuff would be a nice way to start learning group
theory --- but even if you already know group theory, it's sort of fun.
For more along these lines, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  John Baez, Some thoughts on the number 6,
  \texttt{http://math.ucr.edu/home/baez/six.html}
\end{enumerate}

Check out the new link to Greg Egan's website illustrating some of the
concepts!

Now, despite their redundancy from the group-theoretic viewpoint, it's
unfair to leave the octahedron and icosahedron out in the cold. These
guys should be related somehow. After all, the octahedron has 12 edges,
while the icosahedron has 12 vertices. Is there any way we can exploit
this fact?

Yes! The octahedron is the only Platonic solid whose faces can be
colored black and white so that no two faces of the same color share an
edge. So go ahead: grab a regular octahedron and color it like that.
Next, pick an edge and start marching along it with the white face to
your left and the black face to your right. Go \(1/G\)th of the way,
where \(G\) is the golden ratio again, and mark this point with a dot.
Now do this for all the edges. You'll get 12 dots --- and these dots
form the vertices of a regular icosahedron!

Next, let's take a quick tour of the 4th dimension. This is the most
exciting dimension for regular polytopes. In all higher dimensions there
are only three --- analogues of the tetrahedron, cube and octahedron.
But in 4 dimensions, there are six.

I won't describe these systematically here. For that you should read
Coxeter's books, or if you're in a rush, my webpage:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  John Baez, ``Platonic solids in all dimensions'',
  \texttt{http://math.ucr.edu/home/baez/platonic.html}
\end{enumerate}

Instead, I'll just talk about a cool relationship between my two
favorite 4d regular polytopes: the 24-cell and the 600-cell.

First let me set the stage, by reminding you what these look like. A
24-cell looks like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Eric Weisstein, 24-cell,
  \texttt{http://mathworld.wolfram.com/24-Cell.html}
\end{enumerate}

To visualize it on your own, first imagine a hypercube with vertices
\[(\pm1,\pm1,\pm1,\pm1)\] Then imagine the \(4\)-dimensional analogue of
an octahedron --- usually called a ``cross-polytope'' --- with vertices
\[
  \begin{gathered}
    (\pm2,0,0,0),
  \\(0,\pm2,0,0),
  \\(0,0,\pm2,0),
  \\(0,0,0,\pm2).
  \end{gathered}
\] The hypercube has 16 vertices and the cross-polytope has 8. I've set
things up so that all 24 of these points have the same distance from the
origin. These are the vertices of the 24-cell!

But the 24-cell does not get its name from having 24 vertices. It gets
its name from having 24 faces! It has 24 octahedral faces, 96 triangles,
96 edges and 24 vertices. The symmetry here comes from the fact that the
24-cell is self-dual --- which comes from the fact that we've built it
from two polytopes that are dual to each other: the hypercube and the
cross-polytope.

What would happen if we had tried this trick in 3 dimensions? Let's see!
Take a cube and take an octahedron. Center them both at the origin, line
them up nicely, and rescale them so all their vertices are the same
distance from the origin: say \[(\pm1,\pm1,\pm1)\] and \[
  \begin{gathered}
    (\pm\sqrt{3},0,0),
  \\(0,\pm\sqrt{3},0),
  \\(0,0,\pm\sqrt{3}).
  \end{gathered}
\] We get a shape with \(8 + 6 = 14\) vertices. But it's not a Platonic
solid --- it's a rhombic dodecahedron! Apparently this too was first
discovered by Kepler. You can view one, and even rotate it by hand, at
this webpage:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Kevin Brown, Kepler's rhombic dodecahedron,
  \texttt{http://www.seanet.com/\textasciitilde{}ksbrown/coinc2.htm}
\end{enumerate}

Here's another way to think about this stuff. Take two cubes, equal in
size. Chop one up into 6 pyramids, each having one face of the cube as
its base, and each having the cube's center as its apex. Now take these
6 pyramids and glue their bases onto the faces of the other cube. What
do you get? A rhombic dodecahedron! If can't visualize this, go here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{10}
\tightlist
\item
  Mark Newbold's rhombic dodecahedron page,
  \texttt{http://dogfeathers.com/mark/rhdodec.html}
\end{enumerate}

Now do the same thing in 4 dimensions. Take two hypercubes, equal in
size. Chop one up into 8 ``hyperpyramids'', each having one face of the
hypercube as its base, and each having the hypercube's center as its
apex. Now take these hyperpyramids and glue their bases onto the faces
of the other hypercube. What do you get? The 24-cell!

(Of course, one can play this game in any dimension, but it works best
in dimension 4. I could explain why, but it's probably better to figure
it out yourself.)

Okay. Now for the 600-cell. This one is harder: it has 600 tetrahedral
faces, 1200 triangles, 720 edges, and 120 vertices. When Buckminster
Fuller died and went to heaven, he probably took up residence in one of
these. It looks like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{11}
\tightlist
\item
  Eric Weisstein, 600-cell,
  \texttt{http://mathworld.wolfram.com/600-Cell.html}
\end{enumerate}

Here's how you build one. Start with 600 regular tetrahedra. Take 20 of
them and glue them together so they all meet at one vertex and the
outside looks just like an icosahedron. Of course you can't do this in
flat \(3\)-dimensional space: there's ``wiggle room'' left over when you
try! So you have to bend the whole setup a little bit into the 4th
dimension, like a piece of a 4d geodesic dome. Then keep adding more
tetrahedra, always making sure that 20 meet at each vertex in an
icosahedral pattern. By the time you've used up all of them, your
600-cell will be complete --- a nice rigid structure.

Of course, if you're a mathematician, there are other more elegant ways
to build your 600-cell. For example: start with an icosahedron. Its
rotational symmetry group is a 60-element subgroup of
\(\mathrm{SO}(3)\). Using the double cover
\(\mathrm{SU}(2) \to \mathrm{SO}(3)\) lift this to a 120-element
subgroup of \(\mathrm{SU}(2)\). But \(\mathrm{SU}(2)\) is isomorphic to
the unit quaternions, so we get 120 points on the unit sphere in 4
dimensions. These are the vertices of the 600-cell!

In fact we can construct the 24-cell in the same way, as I explained in
\href{week91.html}{week91}. Here we start with the tetrahedron, whose
rotational symmetry group is a 12-element subgroup of
\(\mathrm{SO}(3)\), and we get 24 points on the unit sphere in 4
dimensions, which are the vertices of the 24-cell.

But if you really want to show off, you can build a 600-cell starting
from a 24-cell! Here's how. It's a bit like the trick where we started
with an octahedron, systematically marked a point \(1/G\)th of the way
along each edge, and got the vertices of an icosahedron. But it's
fancier.

Start with the 24-cell. Take any edge, start walking down it, and when
you've gone \(1/G\)th of the way, mark that point with a dot. Of course
these instructions are ambiguous, since I didn't tell you which end of
the edge to start at! I could tell you, but I won't --- I'll just say
that if you do it \emph{the right way}, you'll get 96 dots which are the
vertices of a marvelous polytope in 4 dimensions. It's not a regular
polytope, but it's ``semiregular'': it has 24 regular icosahedra and 120
regular tetrahedra as faces. Coxeter calls it \(s\{3,4,3\}\), but it
really deserves a more glamorous name.

Now as we've seen, in 4 dimensions there is a way to glue 20 tetrahedra
together in an icosahedral pattern. You can picture this as a squat
pyramid-shaped gadget with a regular icosahedron as base and 20
tetrahedral faces all meeting at the apex.

So: glue one of these pyramid-shaped gadgets onto each of the 24
icosahedral faces of our \(s\{3,4,3\}\). We get a polytope which has
\(20\times 24\) new tetrahedral faces in addition to the 120 original
tetrahedral faces of our \(s\{3,4,3\}\), for a total of 600. Voila ---
it's the 600-cell!

For the proof that all this works as advertised, read Coxeter's
``Regular Polytopes''. Note that it's really easier to work backwards:
start with the 600-cell, then truncate it to get \(s\{3,4,3\}\).

Okay, now for one last trick. I actually thought of this myself ---
though I can't believe it's new. It gives a way to see the vertices of
the 24-cell as a subset of the vertices of the 600-cell.

As I already said, the rotational symmetry group of the tetrahedron has
a ``double cover'' consisting of 24 unit quaternions, which happen to be
precisely the vertices of the 24-cell.

Similarly, the rotational symmetry group of the dodecahedron has a
``double cover'' consisting of 120 unit quaternions, which happen to be
precisely the vertices of the 600-cell.

Any way of fitting the tetrahedron snugly into the dodecahedron
therefore gives a way of making the vertices of the 24-cell into a
subset of the vertices of the 600-cell!

Now, we've already seen 10 ways of snugly fitting the tetrahedron into
the dodecahedron: 5 which make the ``levo'' form of that scary-looking
shape, and 5 which make the ``dextro'' form. The first 5 give 5
different ways of stuffing the 24-cell into the 600-cell. But the second
5 give nothing new.

So this trick actually gives us 5 ways of making the vertices of the
24-cell into a subset of the vertices of the 600-cell. And all these
ways have one vertex in common, corresponding to the element 1 of the
unit quaternions.

Okay, that's it for this week. No serious stuff this time. I just want
to mention that in addition to the above websites, there are a lot that
show polyhedra in a way that requires red-blue 3d glasses or a VRML
plugin. Since I don't have either of these, and you might not either,
I've avoided links to those pages. By the way, VRML stands for ``virtual
reality modelling language'', but it's really just a language for
delivering interactive 3d objects over the web. If you can handle VRML,
you can probably have a lot of fun here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{12}
\tightlist
\item
  George W. Hart's Pavilion of Polyhedrality,
  \texttt{http://www.georgehart.com/pavilion.html}
\end{enumerate}

If you don't, you can still enjoy the annotated bibliography and links
to other websites. You can also get a lot out of Vladimir Bulatov's
collection of polyhedra without VRML, but again, it's better if you have
it:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{13}
\tightlist
\item
  Victor Bulatov's Polyhedra Collection,
  \texttt{http://www.physics.orst.edu/\textasciitilde{}bulatov/polyhedra/index.html}
\end{enumerate}

Finally, if you're good at crossing your eyes, you can see some
4-dimensional polytopes at this website, which also has a lot of cool
information on how the 4d regular polytopes are related to other
branches of math:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\tightlist
\item
  Tony Smith, 24-cell animation, 120-cell, 600-cell,
  \texttt{http://www.innerx.net/personal/tsmith/24anime.html}
\end{enumerate}

I thank Jim Heckman and Noam Elkies for helping me fix some errors in
the original version of this article.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week156}{%
\section{September 17, 2000}\label{week156}}

This week I want to catch you up on some of the experiments that have
been going on lately. Mathematical physics is no fun without some
experiments to think about now and then. So here's some news about black
holes, superfluid hydrogen, T violation, the \(\tau\) neutrino, and the
Higgs boson.

I like black holes because they are a nice example of what general
relativity can do. Once upon a time they seemed very exotic, but now it
seems they're common. In particular, there appear to be black holes with
masses between a million and several billion times that of the Sun at
the centers of all galaxies with a ``bulge''. This includes galaxies
like the Milky Way, which has a central bulge in addition to a flat
spinning disk, and also elliptical galaxies, which consist solely of a
bulge. Many of these supermassive black holes emit lots of X-rays as
they swallow hapless stars. As I mentioned in
\href{week144.html}{week144}, the X-ray telescope Chandra has seen
evidence for about 70 million of these black holes!

Recently, two teams of researchers have found that the mass of these
central black holes is correlated very closely to the dispersion of
stellar velocities in the galaxy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  John Kormendy, ``Monsters at the heart of galaxy formation'',
  \emph{Science} \textbf{289} (2000), 1484--1485. Available online at
  \texttt{http://www.sciencemag.org/cgi/content/full/289/5484/1484}
\item
  Laura Ferrarese and David Merritt, ``A fundamental relation between
  supermassive black holes and their host galaxies'', \emph{Astrophys.
  J. Lett.} \textbf{539}, (2000) L9, preprint available as
  \href{https://arxiv.org/abs/astro-ph/0006053}{\texttt{astro-ph/0006053}}.
\item
  Karl Gebhardt et al, ``A relationship between nuclear black hole mass
  and galaxy velocity dispersion'', \emph{Astrophys. J. Lett.}
  \textbf{539}, (2000) L13, preprint available as
  \href{https://arxiv.org/abs/astro-ph/0006289}{\texttt{astro-ph/0006289}}.
\end{enumerate}

Tight correlations are a bit rare in astrophysics, so they tend to be
important when they exist. If you look at a graph you'll see how nice
this one is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Supermassive Black Hole Group, ``Theory of black holes and galaxies'',
  \texttt{http://www.physics.rutgers.edu/\textasciitilde{}merritt/theory.htm}
\end{enumerate}

Ferrarese and Merrit estimate that the black hole mass grows as roughly
the 4.8th power of the stellar velocity dispersion, which they define as
the standard deviation of the radial component of the velocities of
stars in the galaxy.

But what does this correlation \emph{mean}? Astrophysicists are still
arguing about that. But at the very least, it suggests an intimate
relation between supermassive black holes and the process of galaxy
formation.

Part of the puzzle is that nobody knows how these supermassive black
holes formed. You see, until very recently, all we've ever seen are
small black holes formed by the collapse of a single star (between 3 and
20 solar masses), and these supermassive ones at the centers of
galaxies. But last year, people started seeing middle- sized ones!
Colbert and Mushotzky found black holes between 100 and 10,000 solar
masses in about half of 30 nearby spiral and elliptical galaxies that
they examined:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Ed Colbert's homepage,
  \texttt{http://www.pha.jhu.edu/\textasciitilde{}colbert/}

  E. J. M. Colbert and R. F. Mushotzky, ``The nature of accreting black
  holes in nearby galaxy nuclei'', preprint available as
  \href{https://arxiv.org/abs/astro-ph/9901023}{\texttt{astro-ph/9901023}}.
\end{enumerate}

Ptak and Griffiths found a black hole of over 460 solar masses in an
irregular galaxy called M82:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  A. Ptak, R. Griffiths, ``Hard X-ray variability in M82: evidence for a
  nascent AGN?'', preprint available as
  \href{https://arxiv.org/abs/astro-ph/9903372}{\texttt{astro-ph/9903372}}.
\end{enumerate}

This is a ``starburst galaxy'', meaning that it's full of supernovae
going off like a big firework display. When a star dies in a supernova
explosion, that's when a neutron star or black hole is formed --- so it
seems likely that this black hole in M82 was formed by the merger of
several such black holes. Could we be seeing the gradual formation of a
supermassive black hole?

Maybe someday we'll understand the complete ecology of black holes. I
can't help but feel there's some important role they play which we don't
understand yet. (For one theory about this, see the end of
\href{week33.html}{week33}.)

Now: you've all heard how helium-4 becomes a superfluid below 2.18
kelvin and helium-3 does it below 2.4 millikelvin. But what about
superfluid hydrogen? Unlike helium, hydrogen is not a snobbish loner:
it's a friendly, sticky molecule. So usually it solidifies before it
gets cold enough to go superfluid! But in 1997, some folks at the
University of Illinois noticed a possible loophole: films of liquid
hydrogen about one molecule thick on a silver substrate should form a 2d
superfluid at a temperature of 1.2 kelvin. Here's a picture of a
computer simulation:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  David Ceperley et al, ``Prospective superfluid molecular hydrogen'',
  \texttt{http://www.aip.org/physnews/graphics/html/h2.htm}
\end{enumerate}

Since then, other people have cooked up other schemes.

Now it seems people have actually made the stuff. Tiny amounts of it!
The way they do it is to take superfluid helium and put in a bit of
carbonyl sulfide (OCS) and hydrogen. About 14 to 16 hydrogen molecules
stick to the carbonyl sulfide molecule, and when the temperature drops
to .15 kelvin, these molecules form a superfluid. The hard part is
checking experimentally that this really happens --- and even
\emph{defining} what it means for a cluster of so few molecules to be a
superfluid. I can't explain the details; for that you'll have to read
the paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Slava Grebenev, Boris Sartakov, J. Peter Toennies, and Andrei F.
  Vilesov, ``Evidence for superfluidity in para-hydrogen clusters inside
  helium-4 droplets at 0.15 Kelvin'', \emph{Science} \textbf{5484}
  (2000), 1532--1535, available online at
  \texttt{http://www.sciencemag.org/cgi/content/abstract/289/5484/1532}
\end{enumerate}

Here ``para-hydrogen'' refers to a molecule of hydrogen where the spins
on the two nuclei are anti-parallel --- as opposed to
``ortho-hydrogen'', where they're lined up. The two states have
different properties and this matters a lot in delicate situations like
these.

Next: T violation. Once people thought the laws of physics were
symmetrical under exchanging either particles with their antiparticles,
left with right, or future with past. These three symmetries are called
C (for ``charge conjugation''), P (for ``parity'') and T (for ``time
reversal''). The weak interaction is now believed to violate all of
these.

Very briefly, the story goes like this: Yang and Lee won the Nobel prize
for helping discover P violation in the \(\beta\) decay of radioactive
cobalt back in 1956, though in retrospect it was only the sexism of the
Nobel committee that prevented Wu from sharing this prize --- she did
the actual experiment. In \(\beta\) decay, a neutron turns into a
proton, an electron and an electron anti-neutrino via the weak
interaction. Since the electron anti-neutrino only comes in a
right-handed form, this process violates P symmetry.

Cronin and Fitch won the Nobel prize for discovering in 1964 that
neutral kaons decay in a way that violates CP symmetry --- i.e., the
symmetry where you switch particles with their antiparticles \emph{and}
switch left with right. I believe that neutral kaons are still the only
system where CP violation has been seen.

Now there's something called the CPT theorem which says that various
reasonable axioms for a quantum field theory imply symmetry under the
\emph{combination} of C, P and T. For the math of this, the obvious
place to go is this classic text on axiomatic quantum field theory:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  R. F. Streater and A. S. Wightman, \emph{PCT, Spin and Statistics, and
  All That}, Addison-Wesley, Reading, Massachusetts, 1989.
\end{enumerate}

In case you're worried, PCT is the same thing as CPT. I like this book a
lot. The only thing I dislike is how it unleashed a flood of physics
papers whose titles end with ``and all that''. For example:

\begin{itemize}
\tightlist
\item
  ``CFT, BCFT, ADE and all that''
\item
  ``Quantum cohomology and all that''
\item
  ``String theory, supersymmetry, unification, and all that''
\item
  ``Anti-de Sitter space, branes, singletons, superconformal field
  theories and all that''
\item
  ``The modified Bargmann-Wigner formalism: longitudinal fields, parity
  and all that''
\item
  ``The Zamolodchikov C-Function, classical closed string field theory,
  the Duistermaat-Heckman theorem, the renormalization group, and all
  that''
\end{itemize}

Enough! Listen, guys: it was funny once, but now it's just lame. Stop
it!

But I digress. Where was I? Oh yeah: given the CPT theorem, from CP
violation we can conclude T violation. The future and the past are
slightly different --- but of all the known forces, only the weak force
notices the difference! This is bizarre and fascinating. But the way we
reached this conclusion was not completely satisfying, since we needed
to assume the usual axioms of quantum field theory to get the CPT
theorem. What if the axioms are wrong? It would be better to have more
\emph{direct} evidence of T violation, given how important this issue
is.

So in the late 1990s, people in the CPLEAR collaboration at CERN did
some precision experiments on neutral kaon decay, and found more direct
evidence of T violation!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\item
  CPLEAR homepage,
  \texttt{http://cplear.web.cern.ch/cplear/Welcome.html}
\item
  CPLEAR collaboration, ``First direct observation of time-reversal
  non-invariance in the neutral kaon system'', \emph{Phys. Lett.}
  \textbf{B 444} (1998) 43, available online with all other papers by
  this collaboration at
  \texttt{http://cplear.web.cern.ch/cplear/cplear\_pub.html}
\end{enumerate}

Now we can all sit back and rack our brains even harder about what T
violation really \emph{means}. So far, all we know is that it arises
from the darkest corner of the Standard Model: the Kobayashi-Maskawa
matrix. This is a matrix describing quarks' couplings to the Higgs. The
fact that it's not diagonal means that the ``flavor eigenstates'' of the
quarks - up and down, strange and charmed, bottom and top --- are not
the ``mass eigenstates''. Why does the Kobayashi-Maskawa matrix equal
what it equals? Why is it of a form that violates T symmetry? Nobody
knows.

Another nice confirmation of what we already believed was the recent
discovery of direct evidence for the \(\tau\) neutrino. If you don't
remember the particles in the Standard Model, try
\href{week119.html}{week119}: you'll see that it has 3 generations of
quarks (listed above) and 3 generations of leptons: the electron, muon
and \(\tau\) and their corresponding neutrinos. Of the leptons, the
\(\tau\) is the heaviest and thus hardest to produce. Tau neutrinos are
produced by the decay of \(\tau\) particles, but since it's hard to make
these particles and hard to catch neutrinos, until recently nobody had
ever done the clinching experiment: creating a beam of a \(\tau\)
neutrinos and letting it collide with some stuff to form \(\tau\)
particles again.

On July 21st, 2000, the DONUT collaboration at Fermilab announced that
they had successfully done this experiment:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{11}
\tightlist
\item
  Christina Hebert, ``Phyisicists find first direct evidence for
  \(\tau\) neutrino at Fermilab'',
  \texttt{http://www.fnal.gov/directorate/public\_affairs/story\_neutrino/p1.html}
\end{enumerate}

In case you're wondering, ``DONUT'' stands for ``Direct Observation of
the Nu Tau'', where \(\nu_\tau\) is the standard abbrevation for
\(\tau\) neutrino.

In short, the final details of the Standard Model are all falling into
place just as expected --- except for the fact that neutrinos are doing
lots of weird stuff they shouldn't be doing! As I explained in
\href{week130.html}{week130}, neutrino physics is the big place for
surprises in particle physics these days. This is yet another reason why
it was good to directly observe the \(\tau\) neutrino.

And then, of course, there's the Higgs --- the final particle in the
Standard Model. As you've probably heard, we're getting awfully close to
seeing it --- or at least definitively \emph{not} seeing it. Right now
they're looking for it at LEP --- the big particle accelerator at CERN,
in Geneva. They're just about to shut LEP down, since it's done pretty
much all it can do, and they need to deactivate it to build an even more
powerful accelerator --- LHC, the Large Hadron Collider. But at the last
minute they decided to extend its life to November 2nd, 2000:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{12}
\tightlist
\item
  LEP shutdown postponed by one month,
  \texttt{http://press.web.cern.ch/Press/Releases00/PR08.00ELEPRundelay.html}
\end{enumerate}

They're going for broke, boosting its power to the utter max, so that
they can see hints of the Higgs as long as its mass is 114 GeV or so. In
fact they have already seen a couple of events that suggest a Higgs of
about this mass.

Whether or not LEP sees the Higgs the folks at the Tevatron at Fermilab
should see it when they start Run II in a while, as long as its mass
below 130 GeV. And if \emph{they} don't see it, folks at CERN should see
it with the LHC accelerator by around 2005, as long as its mass is below
180 GeV. A Higgs more massive than that would mean the Standard Model is
seriously screwed up, so at that point, even \emph{not} seeing the Higgs
would be an important discovery.

The folks getting ready to analyze the Run II data at the Tevatron are
doing so with a few theories in mind: the Standard Model, the minimal
supersymmetric extension of the Standard Model, and a
``next-to-minimal'' supersymmetric extension. This is a major project;
you can find lots of details here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{13}
\tightlist
\item
  Higgs Working Group webpage,
  \texttt{http://fnth37.fnal.gov/higgs/higgs.html}
\end{enumerate}

That's basically it for this week. I just have a couple of questions
about CPT. A while back on sci.physics.research I emphasized a little
theorem that says: any self-dual irreducible unitary group
representation H must admit an antiunitary intertwiner
\(J\colon H \to H\) with either \(J^2 = 1\) or \(J^2 = -1\). In the
first case \(H\) comes from a real representation; in the second case it
comes from a quaternionic representation. For more details, try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\tightlist
\item
  John Baez, Symplectic, quaternionic, fermionic,
  \texttt{http://math.ucr.edu/home/baez/symplectic.html}
\end{enumerate}

Now, after I mentioned this, someone who goes by the name of ``squark''
suggested that the CPT operator for massive spin-\(1/2\) particles was
an antiunitary intertwiner with \((\mathrm{CPT})^2 = -1\). I'm not sure
this is true, but it's definitely antiunitary, so we have an intesting
question: which unitary irreducible representations of the Poincare
group are self-dual? Of these, which come from real representations and
which come from quaternionic ones? My hunch is that the bosonic (i.e.
integral-spin) reps are real and the fermionic (i.e.~half-integral-spin)
reps are quaternionic. And then the question is: is the operator \(J\)
just the the CPT operator? This would certainly shed some nice
mathematical light on the meaning of CPT symmetry.

By the way, This Week's Finds has a nice new feature, courtesy of
Laurent Bartholdi: now you can search all the old issues for a keyword
or phrase! This is very useful, at least for me. Check it out on my
website.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Footnotes:

Squark found in Volume 1 of Weinberg's ``Quantum Field Theory'' that the
CPT operator on the Hilbert space of a spin-\(j\) representation of the
Poincare group is an antiunitary operator with
\((\mathrm{CPT})^2 = -1^{2j}\). So indeed we do have
\((\mathrm{CPT})^2 = 1\) in the bosonic case, making these
representations real, and \((\mathrm{CPT})^2 = -1\) in the fermionic
case, making these representations quaternionic.

Allen Knutson points out that Streater and Wightman's title ``PCT, Spin
and Statistics, and All That'' was itself modelled after that of Sellar
and Yeatman's humorous history: ``1066 and all that; a memorable history
of England, comprising all the parts you can remember including one
hundred and three good things, five bad kings and two genuine dates.''

Martin Hardcastle wonders if Streater and Wightman were inspired by the
similarity of their names to those of Sellar and Yeatman!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week157}{%
\section{September 24, 2000}\label{week157}}

I never write issues of This Week's Finds about topics that people
request. I only write about what I happen to be studying at a given
moment --- nothing else seems to work. But when my friend Minhyong Kim
asked me to do an issue on Young diagrams, I decided to break this rule
just once. Young diagrams are too cool to ignore.

Physics relies a lot on \emph{symmetry} to simplify problems, and there
are two kinds of diagrams that show up a lot in this context: Dynkin
diagrams and Young diagrams.

Dynkin diagrams first show up when you study shapes with lots of
reflection symmetries, like crystals and Platonic solids. They wind up
being good for all sorts of other stuff, like classifying simple Lie
groups and their representations. I talked about them in
\protect\hyperlink{week62}{``Week 62''} --
\protect\hyperlink{week65}{``Week 65''}.

But what about Young diagrams? These are also important for studying
group representations, but for a more limited class of groups: the
``classical'' groups.

As with composers of music, there's no precise list of groups that count
as ``classical''. But in general, a classical group should consist of
linear transformations that preserve some nice geometrical structure on
a vector space. A good example is \(\mathrm{SU}(N)\), the group of all
linear transformations of an \(N\)-dimensional complex vector space that
preserve an inner product and volume form. In less elevated language,
\(\mathrm{SU}(N)\) is the group of all \(N\times N\) unitary matrices
with determinant \(1\).

The symmetric group \(S_n\) may also be considered an honorary classical
group, even though it's defined in terms of a \emph{set} rather than a
\emph{vector space}. \(S_n\) is the group of all permutations of an
\(n\)-element set.

Rather amazingly, Young diagrams can be used to classify all 3 of these
things, which at first seem quite different in flavor:

\begin{itemize}
\tightlist
\item
  conjugacy classes in \(S_n\)
\item
  irreducible representations of \(S_n\)
\item
  irreducible representations of \(\mathrm{SU}(N)\)
\end{itemize}

Let me sketch how this goes, and then say a bit about the \emph{other}
things you can do with Young diagrams.

Say we have any permutation \(g\) in \(S_n\), like this: \[
  \begin{aligned}
    1 &\to 2
  \\2 &\to 4 
  \\3 &\to 3
  \\4 &\to 1
  \\5 &\to 6
  \\6 &\to 5
  \\7 &\to 7  
  \end{aligned}
\] Note that 1 gets mapped to 2, which gets mapped to 4, which gets
mapped back to 1 again. Similarly, 5 gets mapped to 6, which gets mapped
back to 5. The number 3 gets mapped to itself right away, as does 7. No
matter where we start, we always cycle back eventually. So our
permutation consists of a bunch of ``cycles'': \[(1,2,4) (5,6) (3) (7)\]
and writing down this ``cycle decomposition'' completely describes the
permutation. To simplify life, we always write down these cycles in
order of decreasing length. We also write the lowest number in each
cycle first.

Now suppose we conjugate our permutation \(g\) by some other
permutation, say \(h\). This gives the permutation \(hgh^{-1}\). How
does the cycle decomposition of this compare with that of \(g\)? It
looks almost the same! For example, it might look like this:
\[(2,7,6) (1,3) (4) (5)\] There are the same number of cycles, each the
same length as before. The only thing that changes are the numbers in
each cycle. These get switched around by means of the permutation \(h\).

In short, when we conjugate a permutation, all that remains unchanged is
the picture we get by writing down its cycle decomposition and blotting
out the specific numbers in each cycle, like this:
\[(\square,\square,\square) (\square,\square) (\square) (\square)\]
Folks usually write each cycle as a row, like this: \[
  \begin{array}{lll}
    \square&\square&\square
  \\\square&\square&
  \\\square&&
  \\\square&&
  \end{array}
\] This is called a ``Young diagram''! So a Young diagram is just a
bunch of rows of boxes, arranged in order of decreasing length.

Okay: so far I've shown how conjugacy classes of permutations in \(S_n\)
correspond to Young diagrams with a total of \(n\) boxes. Now I want to
do the same for irreducible representations of \(S_n\).

This is cool for the following reason: for any finite group, the number
of irreducible representations is the same as the number of conjugacy
classes of group elements. But in general there's no natural way to
match up irreducible representations with conjugacy classes. The group
\(S_n\) just happens to be specially nice in this way.

Here I must turn up the math level slightly\ldots{} for example, I'll
assume you know what ``irreducible representations'' means! I'll even
show off by calling them ``irreps'' for short. But to be nice, I'll
start by reviewing some general facts about representations of finite
groups.

Suppose \(G\) is a finite group. Then \(G\) has only finitely many
irreps, all finite-dimensional. Every finite-dimensional representation
of G is a direct sum of copies of these irreps.

To get our hands on these irreps, let \(\mathbb{C}[G]\) be the space of
formal linear combinations of elements of \(G\). This is called the
``group algebra'' of \(G\), since it becomes an algebra using the
product in \(G\). Any representation of the group \(G\) becomes a
representation of \(\mathbb{C}[G]\) in an obvious way, and vice versa.

With some work, one can show that \(\mathbb{C}[G]\) is isomorphic to an
algebra of block diagonal matrices. For example, \(\mathbb{C}[S_3]\) is
isomorphic to the algebra of matrices like this: \[
  \left(
    \begin{array}{cccc}
      * & * & 0 & 0
    \\* & * & 0 & 0
    \\0 & 0 & * & 0
    \\0 & 0 & 0 & *
    \end{array}
  \right)
\] where the \(*\) entries can be any complex number whatsoever. Since
matrices act on vectors by matrix multiplication, we can use this to get
a bunch of representations of \(\mathbb{C}[G]\), and thus of \(G\) ---
one representation for each block. And this trick gives us all the
irreps of \(G\)! For example, \(S_3\) has one \(2\)-dimensional irrep,
coming from the \(2\times 2\) block in the above matrix, and two
\(1\)-dimensional irreps, coming from the two \(1\times 1\) blocks.

This wonderful fact does not solve all our problems. If someone hands us
a finite group \(G\), we still need to work to find which algebra of
block diagonal matrices \(\mathbb{C}[G]\) is isomorphic to. How do we do
this?

The trick is to find elements of \(\mathbb{C}[G]\) corresponding to
matrices that are the identity matrix in one block and zero in the rest,
like these: \[
  \underbrace{
    \left(
      \begin{array}{cccc}
        1&0&0&0
      \\0&1&0&0
      \\0&0&0&0
      \\0&0&0&0
      \end{array}
    \right)}_{p_1}
  \qquad
  \underbrace{
    \left(
      \begin{array}{cccc}
        0&0&0&0
      \\0&0&0&0
      \\0&0&1&0
      \\0&0&0&0
      \end{array}
    \right)}_{p_2}
  \qquad
  \underbrace{
    \left(
      \begin{array}{cccc}
        0&0&0&0
      \\0&0&0&0
      \\0&0&0&0
      \\0&0&0&1
      \end{array}
    \right)}_{p_3}
\] If we can find these guys, the rest is easy: \(\mathbb{C}[G]\) is a
direct sum of ``blocks'' \[\{p_i a p_i \mid a \in\mathbb{C}[G]\}\] each
of which is isomorphic to some algebra of \(n\times n\) matrices.

How do we find these guys \(p_i\) in \(\mathbb{C}[G]\)? It's actually
pretty straightforward to characterize them:

\begin{itemize}
\tightlist
\item
  They are idempotent: \(p_i^2 = p_i\).
\item
  They are central: \(p_i x = x p_i\) for all \(x\) in
  \(\mathbb{C}[G]\).
\item
  They are minimal: if \(p_i\) is the sum of two central idempotents,
  one of them must be zero.
\end{itemize}

So we've reduced the problem of finding the irreps of a finite group
\(G\) to the problem of finding ``minimal central idempotents'' in the
group algebra \(\mathbb{C}[G]\).

To go further, we need to know more about our group \(G\). So now I'll
take \(G\) to be the permutation group \(S_n\) and tell you how to get
the minimal central idempotents. We'll get one for each Young diagram
with \(n\) boxes!

Say we have a Young diagram with \(n\) boxes, like this: \[
  \begin{array}{lll}
    \square&\square&\square
  \\\square&\square&
  \\\square&&
  \\\square&&
  \end{array}
\] Then we can pack it with numbers from \(1\) to \(n\) like this: \[
  \begin{array}{lll}
    1&2&3
  \\4&5&
  \\6&&
  \\7&&
  \end{array}
\] There are a bunch of permutations in \(S_n\) called ``column
permutations'', that only permute the numbers within each column of our
Young diagram. And there are a bunch called ``row permutations'', that
only permute the numbers within each row.

We can form an idempotent \(p\) in \(\mathbb{C}[S_n]\) that
antisymmetrizes over all column permutations. We get \(p\) by taking the
sum of all \emph{even} column permutations minus the sum of all
\emph{odd} column permutations, and then dividing by the total number of
column permutations.

Similarly, we can form an idempotent \(q\) in \(\mathbb{C}[S_n]\) that
symmetrizes over all row permutations. We get \(q\) by taking the sum of
all row permutations divided by the number of row permutations.

Now here's the cool part: \(pq\) is a minimal central idempotent in
\(\mathbb{C}[S_n]\), and we get all minimal central idempotents this
way! This isn't very obvious, but I went over the proof before writing
this, so I know it's true.

Consider \(n = 3\), for example. There are 3 Young diagrams in this
case: \[
  \begin{array}{lll}
    \square&\square&\square
  \end{array}
  \qquad\quad
  \begin{array}{lll}
    \square&\square&
  \\\square
  \end{array}
  \qquad\quad
  \begin{array}{lll}
    \square
  \\\square
  \\\square
  \end{array}
\] so \(S_3\) has 3 minimal central idempotents and thus 3 irreps,
confirming something I already said.

There is a lot more to say about this, but now I want to switch gears
and tell you how representations of \(\mathrm{SU}(N)\) are classified by
Young diagrams. Since \(\mathrm{SU}(N)\) consists of \(N\times N\)
matrices, it has an obvious representation on the vector space
\(\mathbb{C}^N\), which people call the ``fundamental'' representation.
This is an irrep. If we're trying to cook up irreps of
\(\mathrm{SU}(N)\), this is an obvious place to start.

How can we get a bunch of representations of \(\mathrm{SU}(N)\) starting
from the fundamental representation? One way is to take the fundamental
representation and tensor it with itself a bunch of times, say \(n\)
times:
\[\underbrace{\mathbb{C}^N\otimes\mathbb{C}^N\otimes\ldots\otimes\mathbb{C}^N}_{\mbox{$n$ copies}}\]
There's no reason in the world this new representation should be
irreducible. But we can try to chop it up into irreducible bits. And the
easiest way to do this is to look for bits that transform in nice ways
when we permute the \(n\) copies of \(\mathbb{C}^N\). In physics lingo,
we have a space of tensors with \(n\) indices, and we can look for
subspaces consisting of tensors that transform in specified ways when we
permute the indices. For example, there will be a subspace consisting of
``totally symmetric'' tensors that don't change at all when we permute
the indices. And a subspace of ``totally antisymmetric'' tensors that
change sign whenever we interchange two indices. And so on\ldots.

But to make the ``and so on'' precise, we need Young diagrams. After
all, these describe all the representations of the permutation group.

Here's how it works. The space
\[V = \underbrace{\mathbb{C}^N\otimes\mathbb{C}^N\otimes\ldots\otimes\mathbb{C}^N}_{\mbox{$n$ copies}}\]
is not only a representation of \(\mathrm{SU}(N)\); it's also a
representation of \(S_n\). And the actions of these two groups commute!
This means that we can chop up \(V\) into subspaces using the minimal
central idempotents in \(S_n\), and each of these subspaces will be a
representation of \(\mathrm{SU}(N)\).

This much is obvious. The really cool part is that all these subspaces
are \emph{irreducible} representations of \(\mathrm{SU}(N)\). Even
better, we get \emph{all} the irreps of \(\mathrm{SU}(N)\) by this
process, as we let \(n\) vary.

In other words, any Young diagram gives us an irrep of
\(\mathrm{SU}(N)\) consisting of tensors that transform in a certain way
under permutation of indices, and we get all irreps this way.

If you think about it, some of these irreps will be a bit silly. If we
have a Young diagram with more than \(N\) rows, we'll be
antisymmetrizing over more than \(N\) indices, which gives a
zero-dimensional representation of \(\mathrm{SU}(N)\). We can ignore
these.

Also, if we have a Young diagram that has just one column and exactly
\(N\) rows, we'll get the space of completely antisymmetric tensors with
\(N\) indices. This is a \(1\)-dimensional space. Applying a matrix in
\(\mathrm{SU}(N)\) to a tensor of this sort just multiplies it by the
determinant of that matrix, which is 1 by the definition of
\(\mathrm{SU}(N)\). So this Young diagram gives the trivial
representation of \(\mathrm{SU}(N)\). That's not too silly --- the
trivial representation is important, in its own trivial sort of way. But
notice: the trivial representation is already described by the Young
diagram with \emph{no} boxes! So it's redundant to also consider the
Young diagram with one column and \(N\) rows.

By the same logic, we can remove any column with exactly \(N\) rows from
a Young diagram without changing the rep of \(\mathrm{SU}(N)\) that we
get.

So here's the bottom line: irreps of \(\mathrm{SU}(N)\) correspond in a
1-1 way with Young diagrams having fewer than \(N\) rows.

Okay, I've shown you how Young diagrams classify conjugacy classes of
\(S_n\), irreps of \(S_n\), and irreps of \(\mathrm{SU}(N)\). But this
is really just the tip of the iceberg!

First of all, we can use Young diagrams packed with numbers, called
``Young tableaux'', to do all sorts of calculations involving irreps of
\(S_n\) and \(\mathrm{SU}(N)\). Say we tensor two irreps and want to
decompose it as a direct sum of irreps: how do we do it? Well, we play a
little game with Young tableaux and out pops the answer. One relevant
buzzword is ``Littlewood-Richardson rules''. Or say we have an irrep of
\(S_n\) and want to know how it decomposes into irreps when we restrict
it to a subgroup like \(S_{n-1}\). Or the same for \(\mathrm{SU}(N)\)
and \(\mathrm{SU}(N-1)\). How do we do this? More messing with Young
tableaux. Here one relevant buzzword is ``branching rules''.

I'll warn you right now: there is an \emph{enormous} literature on this
stuff. The combinatorics of Young diagrams is one of those things that
everyone has worked on, from hardnosed chemists to starry-eyed category
theorists. It takes a lifetime to master this material, and I certainly
have \emph{not}. But learning even a little is fun, so don't be
\emph{too} scared.

Second of all, Young diagrams are also good for studying the
representations of other classical groups, notably \(\mathrm{GL}(N)\),
\(\mathrm{SL}(N)\), \(\mathrm{O}(N)\), \(\mathrm{SO}(N)\),
\(\mathrm{U}(N)\) and \(\mathrm{Sp}(N)\). All these groups have an
obvious ``fundamental representation'', and we can cook up lots of reps
by taking the nth tensor power of the fundamental representation and
hitting it with minimal central idempotents in \(\mathbb{C}[S_n]\). The
story I just told you for \(\mathrm{SU}(N)\) can be repeated with slight
or not-so-slight variations for all these other groups.

Third, we can ``\(q\)-deform'' the whole story, replacing any one of
these classical groups by the associated ``quantum group'', and
replacing \(\mathbb{C}[S_n]\) by the corresponding ``Hecke algebra''.
This is really important in topological quantum field theory and the
theory of type II subfactors.

Fourth, there are nice relationships between Young diagrams and
algebraic geometry, like the ``Schubert calculus'' for the cohomology
ring of a Grassmanian.

And there's a lot more, but I have to stop somewhere.

So, how does one start learning this stuff?

If you have a certain amount of patience for old-fashioned terminology,
I might recommend going back to the classic text on classical groups:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Hermann Weyl, \emph{The Classical Groups, Their Invariants and
  Representations}, Princeton U. Press, Princeton, 1997.
\end{enumerate}

Weyl coined the term ``classical groups'' for the purposes of this book,
which was first published in 1939. His prose is beautiful, but I warn
you, this book is not the way to learn Young diagrams in a hurry.

For a user-friendly approach that's aimed at physicists, but still
includes proofs of all the key results, you can't beat this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Irene Verona Schensted, \emph{A Course on the Applications of Group
  Theory to Quantum Mechanics}, NEO Press, Box 32, Peaks Island, Maine.
\end{enumerate}

A girlfriend of mine gave me a copy when I was a college student, but
only much later did I realize how great a book it is. Unfortunately it's
out of print! Someone should reprint this gem.

Here's another book that covers Young diagrams together with
applications to physics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Shlomo Sternberg, \emph{Group Theory and Physics}, Cambridge U. Press,
  Cambridge, 1994.
\end{enumerate}

Both these books, but especially the latter, describe applications of
Young diagrams to particle physics, like Gell-Mann's famous ``eight-fold
way'', which was based on positing an \(\mathrm{SU}(3)\) symmetry
between the up, down and strange quarks.

Then there are more advanced texts, for when your addiction to Young
diagrams becomes more serious. For the combinatorial side of things,
these are good:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\item
  Gordon Douglas James and Adalbert Kerber, \emph{The Representation
  Theory of the Symmetric Group}, Addison-Wesley, Reading,
  Massachusetts, 1981.
\item
  Bruce Eli Sagan, \emph{The Symmetric Group: Representations,
  Combinatorial Algorithms, and Symmetric Functions}, Wadsworth and
  Brooks, Pacific Grove, California, 1191.
\end{enumerate}

For a more conceptual approach to representation theory that puts Young
diagrams in a bigger context, try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Roe Goodman and Nolan R. Wallach, \emph{Representations and Invariants
  of the Classical Groups}, Cambridge University Press, Cambridge, 1998.
\end{enumerate}

It's sort of an updated version of Weyl's book. Finally, here's a
mathematically sophisticated book that really gives you a Young diagram
workout:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  William Fulton, \emph{Young Tableaux: With Applications to
  Representation Theory and Geometry}, Cambridge U. Press, Cambridge,
  1997.
\end{enumerate}

Now, my friend Allen Knutson is a real Young diagram fiend. Together
with Terry Tao, he helped prove something called ``Horn's conjecture'',
which had been bugging people for decades, and has implications for a
huge number of questions. I have a feeling Allen is going to send me a
nasty email saying that I didn't actually say anything
\emph{interesting} about Young diagrams. In an attempt to pacify him,
I'll direct you to Fulton's excellent review article on this subject:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  William Fulton, ``Eigenvalues, invariant factors, highest weights, and
  Schubert calculus'', \emph{Bull. Amer. Math. Soc.} \textbf{37} (2000),
  209--249, also available as
  \href{http://arXiv.org/abs/math.AG/9908012}{math.AG/9908012}.
\end{enumerate}

as well as Allen and Terry's papers on the subject:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\item
  Allen Knutson and Terence Tao, ``The honeycomb model of
  \(\mathrm{GL}(n)\) tensor products I: the saturation conjecture'',
  preprint available as
  \href{http://arXiv.org/abs/math.RT/9807160}{math.RT/9807160}
\item
  Allen Knutson, ``The symplectic and algebraic geometry of Horn's
  problem'', preprint available as
  \href{http://arXiv.org/abs/math.LA/9911088}{math.LA/9911088}.
\item
  Allen Knutson and Terence Tao, ``Honeycombs and sums of Hermitian
  matrices'', preprint available as
  \href{http://arXiv.org/abs/math.RT/0009048}{math.RT/0009048}
\end{enumerate}

But I should also mention the question that Horn's conjecture settles!

There are many ways to phrase it; here's the easiest one. If you know
the eigenvalues of two \(n\times n\) Hermitian matrices \(A\) and \(B\),
what are the possible eigenvalues of their sum? There are a bunch of
linear inequalities that must hold; find a necessary and sufficient set.

This may not seem related to Young diagrams, but it is\ldots.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Devin had been studying this region for ten years, poking his way
through a place not much larger than the town in which he lived, and had
still not deciphered half its routes. This hugeness inside of smallness
creates a matrix of intersections, precious and incalculable channels
one after the next. It is a fractal landscape like the surface of a
leaf, veins within veins, or the arborescent feathers of ice forming
barbs within barbs across the surface of a pond.} --- Craig Childs, Soul
of Nowhere



\hypertarget{week158}{%
\section{October 16, 2000}\label{week158}}

Like lots of mathematicians these days, I'm trying to understand
M-theory. It's a bit difficult, partially because the theory doesn't
really \emph{exist} yet. If it existed, it would explain lots of stuff:
on that everyone agrees. But nobody knows how to formulate M-theory in a
precise way, so you can't open up a paper and stare at ``the fundamental
equation of M-theory'', or anything like that. There are some
conjectures about what M-theory might be like, but no solid agreement.

One thing that \emph{does} exist is \(11\)-dimensional supergravity.
This is supposed to be some kind of classical limit of M-theory. But the
good thing is, it's a classical field theory with a Lagrangian that you
can write down and ponder to your heart's content. So I'm trying to
learn a bit about this.

Unfortunately, being a mathematician, I like to understand everything
rather carefully, preferably in a conceptual way that doesn't involve
big equations with indices dangling all over the place. This is slowing
me down, because all the descriptions I've seen make \(11\)-dimensional
supergravity look sort of ugly, when in fact it should be really pretty.
The physicists always point out that it's a lot simpler than the
supergravity theories in lower dimensions. On that I agree! But I don't
find it to be quite as simple as I'd like.

Now, mathematicians always whine like this when they are trying to learn
physics that hasn't been pre-processed by some other mathematician. So
just to show that I'm not completely making this stuff up, let me show
you the Lagrangian for 11d supergravity, as taken from the famous string
theory text by Green, Schwarz and Witten (see
\protect\hyperlink{week118}{``Week 118''}): \[
  \begin{aligned}
    L =
    &- \left(\frac{1}{2k^2}\right) eR
  \\&- \left(\frac{1}{2}\right) e\psi_M^* \Gamma^{MNP} D_N\left[\frac{\omega+\omega'}{2}\right]\psi_P
  \\&- \left(\frac{1}{48}\right) eF^2
  \\&- \left(\frac{\sqrt{2k}}{384}\right) e(\psi_M^* \Gamma^{MNPQRS}\psi_S + 12\psi^{*N}\Gamma^{PQ}\psi^R)(F+F')_{NPQR}
  \\&- \left(\frac{\sqrt{2k}}{3456}\right) \varepsilon^{M_1\ldots M_{11}}F_{M_1\ldots M_4}F_{M_5\ldots M_8}A_{M_9\ldots M_{11}}
  \end{aligned}
\] \textbf{???} \textbf{is it \(\sqrt{2k}\) or \(\sqrt{2}k\) ???}
\textbf{is it \(M1\) or \(M_1\) or what ???} For comparison, here's the
Lagrangian for ordinary gravity: \[L = e R\] Here \(e\) is the volume
form and \(R\) is the Ricci scalar curvature. Of course, there is a lot
of stuff packed into this ``\(R\)''. General relativity didn't look so
slick when Einstein first made it up! But by now, mathematicians have
gnawed away at it for long enough that there's a nice theory of
differential geometry, where after a few months of work you learn about
``\(R\)''. And after you've done this work, you realize that ``\(R\)''
is a very natural concept. I want to get to this point for the
Lagrangian for 11d supergravity, but I'm not there yet.

You'll note that apart from a constant, the Lagrangian for 11d
supergravity starts out basically like the Lagrangian for ordinary
gravity. So \emph{that} part I understand. It's just the other stuff
that's the problem.

Modulo some subtleties discussed below, the whole Lagrangian is built
from just three ingredients, which are the three basic fields in the
theory:

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\item
  a Lorentzian metric \(g\) on the \(11\)-dimensional manifold
  representing spacetime,
\item
  a field \(\psi\) on this manifold which takes values in the real
  spin-\(3/2\) representation of \(\mathrm{SO}(10,1)\),
\item
  a \(3\)-form field \(A\) on this manifold.
\end{enumerate}

Physicists call the metric the ``graviton''. They call the spin-\(3/2\)
field the ``gravitino'' or a ``Rarita-Schwinger field''. And they call
the \(3\)-form a ``gauge field'', by analogy to the \(1\)-form that
appears in electromagnetism. Above it's written as ``\(A\)'', to remind
us of this analogy, but people often use a ``\(C\)'' instead --- for
reasons I'll explain later.

Let me say a bit more about these three items. To define a spin-\(3/2\)
field on a manifold we need to give the manifold a spin structure.
Locally, we can do this by picking a smoothly varying basis of tangent
vectors. Such a thing is called a ``frame field'', but it also has other
names: in \(4\)-dimensional spacetime people call it a ``tetrad'' or
``vierbein'', after the German word for ``four legs'', but in
11-dimensional spacetime people call it an ``elfbein'', after the German
word for ``eleven legs''. Anyway, this frame field determines a spin
structure, and also a metric, if we declare the basis to be orthonormal.

The metric, in turn, determines the Levi-Civita connection on the
tangent bundle. However, in modern Lagrangians for gravity, people often
treat the frame field and connection as independent variables. This
amounts to dropping the requirement that the connection be torsion-free
(while still requiring that it be metric-preserving). Only when you work
out the equations of motion from the Lagrangian do you get back the
equation saying the connection is torsion-free --- and even this only
happens when there are no fields with \emph{spin} around. In these
theories, spin creates torsion! But the torsion doesn't propagate: it
just sits there, determined by other fields. So we are basically just
repackaging the same data when we work with a frame field and connection
instead of a metric.

As a slight variant, instead of working with a frame field and
connection on the tangent bundle, we can work with a frame field and
``spin connection'' --- a connection on the spin bundle. We need to do
this whenever we have fields with half-integer spin around, as in
supergravity.

Okay, so we'll use a frame field and spin connection to describe the
graviton. What about the gravitino? I'm less clear about this, but I
guess the idea is that we think of the spin-\(3/2\) representation of
the Lorentz group \(\mathrm{SO}(10,1)\) as sitting inside the tensor
product of the spin-\(1\) representation and the spin-\(1/2\)
representation. This allows us to think of the gravitino as a
spinor-valued \(1\)-form on spacetime. That's why people write it as
\(\psi_N\): the subscript indicates that we've got some sort of
\(1\)-form on our hands. One thing I don't understand is what, if any,
constraints there are on a spinor-valued \(1\)-form to make it lie in
the spin-\(3/2\) representation.

What are spinors like in \(11\)-dimensional spacetime? For this, go back
and reread \protect\hyperlink{week93}{``Week 93''}. You'll see that by
Bott periodicity, spinors in \((n+8)\)-dimensional spacetime are just
like spinors in \(n\)-dimensional spacetime, but tensored with
\(\mathbb{R}^{16}\). So spinors in 11-dimensional spacetime are a lot
like spinors in \(3\)-dimensional spacetime! In 3 dimensions, the double
cover of the Lorentz group is just \(\mathrm{SL}(2,\mathbb{R})\), and
its spinor representation is \(\mathbb{R}^2\). Actually these are
``real'' spinors, or what physicists call ``Majorana'' spinors. We could
complexify and get ``complex'' or ``Dirac'' spinors --- but we won't!

Since the space of Majorana spinors in 3d spacetime is \(\mathbb{R}^2\),
the space of Majorana spinors in 11d spacetime is
\(\mathbb{R}^2 \otimes \mathbb{R}^{16} = \mathbb{R}^{32}\). The
gravitino is a \(1\)-form taking values in this space.

Finally, what about the \(3\)-form that appears in 11d supergravity? Why
is it called a ``gauge field''? Well, if you've made it this far, you
probably know that the \(1\)-form in electromagnetism (the ``vector
potential'') is perfectly suited for integrating along the worldline of
a charged point particle. Classically, the resulting number is just the
\emph{action} In quantum theory, the exponential of the action describes
how the particle's \emph{phase} changes.

If we're dealing with strings instead of point particles, we can pull
the same trick using a \(2\)-form, which is the right sort of thing to
integrate over the \(2\)-dimensional worldsheet of a string. Since
people call the \(1\)-form in electromagnetism \(A\), they naturally
took to calling this \(2\)-form \(B\). People like to study strings
propagating in a background metric that satisfies the vacuum Einstein
equations, but they also study what happens when you throw in a
background \(B\) field like this, and add a term to the string action
that's proportional to the integral of \(B\) over the string worldsheet.
It works out nice when the \(B\) field satisfies the obvious analogues
of the vacuum Maxwell equations: \[dF = 0,\quad d^*F = 0\] where the
``curvature'' or ``field strength tensor'' \(F\) is given by \(F=dB\).

Like Maxwell's equations, these equations are ``gauge-invariant'', in
the sense that we can change \(B\) like this without changing the field
strength tensor: \[B \mapsto B + dw\] where \(w\) is any \(1\)-form.

Similarly, people believe that M-theory involves \(2\)-dimensional
membranes called ``2-branes''. A \(2\)-brane traces out a
\(3\)-dimensional ``world-volume'' in spacetime. The \(3\)-form field in
11d supergravity is perfectly suited for integrating over this
world-volume! So we're really dealing with a still higher-dimensional
analog of electromagnetism. Since we've already talked about a
\(1\)-form \(A\) that couples to point particles and a \(2\)-form field
\(B\) that couples to strings, it makes sense to call this \(3\)-form
\(C\). Lots of people do that. But I'll stick with Green, Schwarz and
Witten, and call it \(A\). I'll write \(F\) for the corresponding field
strength (which is \(6dA\) if we use their nutty normalization).

Let's look at that Lagrangian again, and see how much of it we can
understand now: \[
  \begin{aligned}
    L =
    &- \left(\frac{1}{2k^2}\right) eR
  \\&- \left(\frac{1}{2}\right) e\psi_M^* \Gamma^{MNP} D_N\left[\frac{\omega+\omega'}{2}\right]\psi_P
  \\&- \left(\frac{1}{48}\right) eF^2
  \\&- \left(\frac{\sqrt{2k}}{384}\right) e(\psi_M^* \Gamma^{MNPQRS}\psi_S + 12\psi^{*N}\Gamma^{PQ}\psi^R)(F+F')_{NPQR}
  \\&- \left(\frac{\sqrt{2k}}{3456}\right) \varepsilon^{M_1\ldots M_{11}}F_{M_1\ldots M_4}F_{M_5\ldots M_8}A_{M_9\ldots M_{11}}
  \end{aligned}
\] The number ``\(k\)'' is just a coupling constant. The quantity
``\(e\)'' is the volume form cooked up from the frame field. The
quantity ``\(R\)'' is the Ricci scalar cooked up from the spin
connection. ``\(\psi_N\)'' is the gravitino field, and physicists write
the inner product on spinors as ``\(\overline{\psi_N} \psi^N\)''.
``\(A\)'' is the \(3\)-form field and ``\(F\)'' is the field strength.
There's also some other weird stuff I haven't explained yet.

Note: the first, middle, and last terms in this Lagrangian only involve
the bosonic fields --- not the gravitino. They have the following
meanings:

The first term, the ``\(e R\)'' part, is just the Lagrangian for the
gravitational field.

The middle term is, up to a constant, just what I'd call
``\(F\wedge*F\)'': the Lagrangian for the \(3\)-form analog of Maxwell's
equations.

The last term is, again up to a constant, just what I'd
``\(F\wedge F\wedge A\)''. This is an \(11\)-dimensional analog of the
Chern-Simons term \(F\wedge A\) that you can add on to the
electromagnetic Lagrangian in 3d spacetime.

The other two terms involve the gravitino. This is where I start getting
nervous. We've got this:
\[-\left(\frac{1}{2}\right) e\psi_M^* \Gamma^{MNP} D_N\left[\frac{\omega+\omega'}{2}\right]\psi_P\]
and this:
\[- \left(\frac{\sqrt{2k}}{384}\right) e(\psi_M^* \Gamma^{MNPQRS}\psi_S + 12\psi^{*N}\Gamma^{PQ}\psi^R)(F+F')_{NPQR}\]
The first one is mainly about how the gravitino propagates in a given
metric --- it's a kind of spin-\(3/2\) analog of the Lagrangian for the
Dirac equation. The second one is mainly about the coupling of the
gravitino to the \(3\)-form field \(A\) - it's sort of like the coupling
between the electron and electromagnetic field in QED. But there's some
funky stuff going on here!

The ``\(\Gamma\)'' gadgets are antisymmetrized products of \(\gamma\)
matrices, i.e. Clifford algebra generators. I don't mind that. It's the
stuff involving \(\omega'\) and \(F'\) that confuses me. ``\(\omega\)''
is just a name for the spin connection, so \(D_v[\omega]\) would mean
``covariant differentiation with respect to the spin connection''. But
instead of using that, we use \(D_v[(\omega + \omega')/2]\), where
\(\omega'\) is the ``supercovariantization'' of the spin connection.
Don't ask me that that means! I know it amounts to adding some terms
that are quadratic in the gravitino field, and I know it's required to
get the whole Lagrangian to be invariant under a ``supersymmetry
transformation'', which mixes up the gravitino field with the graviton
and \(3\)-form fields. But I don't really understand the geometrical
meaning of what's going on, especially because the supersymmetry only
works ``on shell'' --- i.e., assuming the equations of motion.
Similarly, I guess \(F'\) is some sort of ``supercovariantization'' of
the field strength tensor --- but again, it seems fairly mysterious.

Anyway, we can summarize all this by saying we've got gravity, a
gravitino, and a \(3\)-form gauge field interacting in a manner vaguely
reminiscent of how gravity, the electron and the electromagnetic field
interact in the Einstein-Dirac-Maxwell equations --- except that there's
a ``four-fermion'' term where four gravitinos interact directly.

Stepping back a bit, one is tempted to ask: what exactly is so great
about this theory?

There are various ways to focus this question a bit. For example: the
Lagrangian for ordinary gravity makes sense in a spacetime of any
dimension. The 11d supergravity Lagrangian, on the other hand, only
makes sense in 11 dimensions. Why is that?

Well, if you ask a physicist, they'll tell you something like this:

\begin{quote}
Eleven is the maximum spacetime dimension in which one can formulate a
consistent supergravity, as was first recognized by Nahm in his
classification of supersymmetry algebras. The easiest way to see this is
to start in four dimensions and note that one supersymmetry relates
states differing by one half unit of helicity. If we now make the
reasonable assumption that there be no massless particles with spins
greater than two, then we can allow up to a maximum of \(N = 8\)
supersymmetries taking us from the helicity \(-2\) through to helicity
\(+2\). Since the minimal supersymmetry generator is a Majorana spinor
with four offshell components, this means a total of 32 spinor
components. Now in a spacetime with \(D\) dimensions and signature
\((1,D-1)\), the maximum value of \(D\) admitting a 32 component spinor
is \(D = 11\).
\end{quote}

In case you're wondering, this is from the first paragraph of this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \emph{The World in Eleven Dimensions: Supergravity, Supermembranes and
  M-theory}, ed.~M. J. Duff, Institute of Physics Publishing, Bristol,
  1999.
\end{enumerate}

which is a collection of the most important articles on these topics.
It's a fun book to carry around --- you can really impress people with
the title. But if you're a mathematician trying to decipher the above
passage, it helps to note a few things.

First, this explanation of why 11d supergravity is good boils down to
saying that it's the biggest, baddest supergravity theory around that
doesn't give particles of spin greater than two when we compactify the
extra dimensions in order to get a 4d theory.

Second, why is it ``reasonable'' to assume that there aren't massless
particles with spin greater than two? Because it's physics folklore that
quantum field theories with such particles are bad, nasty and evil ---
in fact, so evil that nobody even dares explain why! Well, actually
there's a paper by Witten in the above book that contains references to
papers that supposedly explain why particles of spin \(> 2\) are bad.
It's an excellent paper, too:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Edward Witten, ``Search for a realistic Kaluza-Klein theory'',
  \emph{Nucl. Phys.} \textbf{B186} (1981), 412--428.
\end{enumerate}

Maybe someday I'll get up the nerve to read those references.

Third, once we buy into this ``spin \(> 2\) bad'' idea, the rest of the
argument is largely stuff about spinors and Clifford algebras. This is
easy for mathematicians to learn, at least after a little physics jargon
has been explained. For example, a ``Majorana'' spinor is just a real
spinor, and ``offshell components'' refer to the components of a field
that are independent before you impose the equations of motion.

Fourth, if you're a mathematician wondering what ``supersymmetry
algebras'' are, there are places where you can start learning about this
without needing to know lots of physics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  \emph{Quantum Fields and Strings: A Course for Mathematicians}, 2
  volumes, eds.~P. Deligne, P. Etinghof, D. Freed, L. Jeffrey, D.
  Kazhdan, D. Morrison and E. Witten, American Mathematical Society,
  Providence, Rhode Island, 1999.
\end{enumerate}

Unfortunately, this book does not cover supergravity theories.

Fifth, Nahm's classification of supersymmetry algebras looks like the
sort of thing an algebraist should be able to understand, though I
haven't yet understood it. You can find it in Duff's book, or in the
original paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  W. Nahm, ``Supersymmetries and their representations'', \emph{Nucl.
  Phys.} \textbf{B135} (1978), 149--166.
\end{enumerate}

Next I want to mention some wild guesses and speculations about 11d
supergravity and M-theory. I'm guessing these theories are somehow a
cousin of 3d Chern-Simons theory, related in a way that involves Bott
periodicity. And I'm guessing that there's something deeply octonionic
about this theory. There's probably something wrong about these guesses,
since I can't quite get everything to fall in line. But there's also
probably something right about them.

We've seen two clues already:

First, the 11d spinors are related to 3d spinors via Bott periodicity,
which amounts to tensoring with \(\mathbb{R}^{16}\) --- the space of
Majorana spinors in 8d Euclidean space. Given the relation between
octonion, 8d spinors and Bott periodicity (see
\protect\hyperlink{week61}{``Week 61''} and
\protect\hyperlink{week105}{``Week 105''}), it's also very natural to
think of these Majorana spinors as pairs of octonions.

Second, the Chern-Simons-like term \(F\wedge F\wedge A\) in 11d
supergravity is akin to the 3d Chern-Simons Lagrangian \(F\wedge A\).
But this relation is a bit odd, since a crucial part of it involves
switching from a \(1\)-form gauge field in the 3d case to a \(3\)-form
gauge field in the 11d case. To really understand this, we first need to
understand the geometry of these generalized ``gauge fields''. These
higher gauge fields are really not connections on bundles, but
connections on ``\(n\)-gerbes'', which are categorified analogues of
bundles. I explained this to some extent in
\protect\hyperlink{week25}{``Week 25''} and
\protect\hyperlink{week151}{``Week 151''}, but the basic idea is that
there's an analogy like this:

:-------- \textbar{} :------------------ \textbar{} :------------------
\textbar{}\\
\(1\)-forms \textbar{} connections on bundles \textbar{} parallel
transport of point particles \textbar{}\\
\(2\)-forms \textbar{} connections on gerbes \textbar{} parallel
transport of strings \textbar{}\\
\(3\)-forms \textbar{} connections on 2-gerbes \textbar{} parallel
transport \(2\)-branes \textbar{}\\
\(4\)-forms \textbar{} connections on 3-gerbes \textbar{} parallel
transport \(3\)-branes \textbar{}\\
\(\vdots\) \textbar{} \(\vdots\) \textbar{} \(\vdots\) \textbar{}

and so on. Just as connections on bundles naturally give rise to Chern
classes and the Chern-Simons secondary characteristic classes, the same
should be true for these higher analogues of connections.

There is also another clue: as I mentioned in
\protect\hyperlink{week118}{``Week 118''}, you can only write down
Lagrangians for supersymmetric membranes in certain dimensions. There
are supposedly 4 basic cases, which correspond to the 4 normed division
algebras:

\begin{itemize}
\tightlist
\item
  the \(2\)-brane in dimension 4 --- real numbers
\item
  the \(3\)-brane in dimension 6 --- complex numbers
\item
  the \(5\)-brane in dimension 10 --- quaternions
\item
  the \(2\)-brane in dimension 11 --- octonions
\end{itemize}

Part of the point is that the in these theories there are 1, 2, 4, or 8
dimensions transverse to the worldvolume of the brane in question. So
2-branes in 11 dimensions, in particular, are inherently ``octonionic''.
This seems like a wonderful clue, but so far I don't really understand
it. The evidence is lurking here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  T. Kugo and P. Townsend, ``Supersymmetry and the division algebras'',
  \emph{Nucl. Phys.} \textbf{B221} (1983), 357--380.
\item
  G. Sierra, ``An application of the theories of Jordan algebras and
  Freudenthal triple systems to particles and strings'', \emph{Class.
  Quant. Grav.} \textbf{4} (1987) 227.
\item
  J. M. Evans, ``Supersymmetric Yang-Mills theories and division
  algebras'', \emph{Nucl. Phys.} \textbf{B298} (1988), 92.
\item
  M. J. Duff, ``Supermembranes: the first fifteen weeks'', \emph{Class.
  Quant. Grav.} \textbf{5} (1988), 189--205.
\end{enumerate}

There are also tantalizing clues scattered through these fascinating
books:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\item
  Feza Gursey and Chia-Hsiung Tze, \emph{On the Role of Division,
  Jordan, and Related Algebras in Particle Physics}, World Scientific,
  Singapore, 1996.
\item
  Jaak Lohmus, Eugene Paal and Leo Sorgsepp, \emph{Nonassociative
  Algebras in Physics}, Hadronic Press, Palm Harbor, Florida, 1994.
\end{enumerate}

However, these books are frustrating to me, because they make some
interesting claims without providing solid evidence.

Anyway, I'll try to keep gnawing away at this bone until I get to the
marrow! Any help would be appreciated.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Addenda:} Here is an article that Maxime Bagnoud posted to
\texttt{sci.physics.research}, which answers some of my questions
above\ldots.

\begin{quote}
John Baez wrote:

\begin{quote}
One thing that does exist is \(11\)-dimensional supergravity.
\end{quote}

Unfortunately, only at the classical level, presumably. The quantum
theory doesn't seem to exist, neither. It's non-renormalizable, despite
the large amount of SUSY. We were not sure about this until quite
recently, actually (2 years ago?) You probably know this, but maybe not
all the readers of the ``Finds''.

\begin{quote}
Okay, so we'll use a frame field and spin connection to describe the
graviton. What about the gravitino? I'm less clear about this, but I
guess the idea is that we think of the spin-\(3/2\) representation of
the Lorentz group \(\mathrm{SO}(10,1)\) as sitting inside the tensor
product of the spin-\(1\) representation and the spin-\(1/2\)
representation. This allows us to think of the gravitino as a
spinor-valued \(1\)-form on spacetime. That's why people write it as
\(\psi_N\): the subscript indicates that we've got some sort of
\(1\)-form on our hands. One thing I don't understand is what, if any,
constraints there are on a spinor-valued \(1\)-form to make it lie in
the spin-\(3/2\) representation.
\end{quote}

As you guessed, there is a Clebsch-Gordan relationship like:

\(1 \otimes 1/2 = 3/2 \oplus 1/2\) (where \(\otimes\) is tensor product,
\(\oplus\) is direct sum)

in fact, out of a general spinor-vector, you can form a linear
combination of its components to get a spin 1/2 spinor by multiplying
\(\psi_M\) with a \(\Gamma^M\) matrix and summing of course on the
vector index. The remaining part of the representation is irreducible
and it's the gravitino. (You can look for example at Polchinski vol.~II,
page 23).

I guess that was your question.

\begin{quote}
Similarly, people believe that M-theory involves \(2\)-dimensional
membranes called ``2-branes''. A \(2\)-brane traces out a
\(3\)-dimensional ``world-volume'' in spacetime. The \(3\)-form field in
11d supergravity is perfectly suited for integrating over this
world-volume! So we're really dealing with a still higher-dimensional
analog of electromagnetism. Since we've already talked about a
\(1\)-form \(A\) that couples to point particles and a \(2\)-form field
\(B\) that couples to strings, it makes sense to call this \(3\)-form
\(C\). Lots of people do that. But I'll stick with Green, Schwarz and
Witten, and call it \(A\). I'll write \(F\) for the corresponding field
strength (which is 6dA if we use their nutty normalization).
\end{quote}

\begin{verbatim}
>
\end{verbatim}

\begin{quote}
Let's look at that Lagrangian again, and see how much of it we can
understand now: \[
  \begin{aligned}
    L =
    &- \left(\frac{1}{2k^2}\right) eR
  \\&- \left(\frac{1}{2}\right) e\psi_M^* \Gamma^{MNP} D_N\left[\frac{\omega+\omega'}{2}\right]\psi_P
  \\&- \left(\frac{1}{48}\right) eF^2
  \\&- \left(\frac{\sqrt{2k}}{384}\right) e(\psi_M^* \Gamma^{MNPQRS}\psi_S + 12\psi^{*N}\Gamma^{PQ}\psi^R)(F+F')_{NPQR}
  \\&- \left(\frac{\sqrt{2k}}{3456}\right) \varepsilon^{M_1\ldots M_{11}}F_{M_1\ldots M_4}F_{M_5\ldots M_8}A_{M_9\ldots M_{11}}
  \end{aligned}
\] The middle term is, up to a constant, just what I'd call
``\(F\wedge *F\)'': the Lagrangian for the \(3\)-form analog of
Maxwell's equations.
\end{quote}

Now, it's time for me to answer one of your old questions! You seem to
be ready to hear the answer (you see, I never forget\ldots). Why should
there be a \(5\)-form in M-theory? You nicely have replaced \(F^2\) by
\(F\wedge*F\). Cool! Now, we can go further. \(A\) is a \(3\)-form, so
\(F\) is a \(4\)-form, then \(*F\) is a \(11-4=7\)-form, then it should
be the field strength tensor of some \(6\)-form potential, \(dA_6=*F\),
But a \(6\)-form is perfectly suited to be integrated over a
\(6\)-dimensional world-volume, i.e.~a \(5\)-brane! Here comes the
M5-brane into the play. Of course, in 11D SUGRA, the membrane is the
fundamental object and the M5-brane is a solitonic solution, but in a
non-perturbative theory, solitonic solutions can become fundamental at
strong coupling and vice-versa. That's why we expect that the M5-brane
will play an important role in M-theory.

The other question was what this had to do with the theory of Smolin?

In the BFSS matrix model, there is only one kind of objects,
matrix-valued \(1\)-forms (D0-branes).

These have a nice interpretation in terms of M2-branes (that's how
modern-day physicists write membranes\ldots:-\textgreater) wrapped on
the two light-cone coordinates, but what is the role of M5-branes in
this game is unclear. While in the matrix model proposed by Smolin in
hep-th/0002009, there are more terms involving also a \(4\)-form, which
might be related with a wrapped M5-brane. This raises the hope that this
matrix model might be a better try for a non-perturbative version of
M-theory than the usual BFSS one. But this has to be investigated in
more detail, of course; that's more or less what I'm doing now.

\begin{quote}
Second, why is it ``reasonable'' to assume that there aren't massless
particles with spin greater than two? Because it's physics folklore that
quantum field theories with such particles are bad, nasty and evil ---
in fact, so evil that nobody even dares explain why! Well, actually
there's a paper by Witten in the above book that contains references to
papers that supposedly explain why particles of spin \(> 2\) are bad.
It's an excellent paper, too:
\end{quote}

\begin{verbatim}
>
\end{verbatim}

\begin{quote}
\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Edward Witten, ``Search for a realistic Kaluza-Klein theory'',
  \emph{Nucl. Phys.} \textbf{B186} (1981), 412--428.
\end{enumerate}
\end{quote}

I'm not a specialist of this, but higher spins involve the
representation theory of W-algebras, which can hardly be described as
easy. Of course, that's not an argument, but I think that this has
prevented many physicists from pursuing the matter too far.

\begin{quote}
Unfortunately, this book does not cover supergravity theories.
\end{quote}

As a matter of fact, there are some books on supergravity in 4D, but no
books covering higher-dimensional supergravity theories with a
reasonable amount of explanations.

Of course, people really able to do this properly are a handful on this
planet, and even for them, this would require an enormous amount of work
to get things consistent all the way with a coherent choice of
conventions and check all the horrible formulas. On the other hand, when
you hear their talks, you usually don't get the feeling that they really
want you to understand it, but rather that they try to hide the truth
about SUGRA in a well-hidden ``grimoire'', maybe somewhere in Wizard's
castle.

I hope some other people can shed more light on the subject, for example
on the supercovariantization of the spin connection (which I don't
understand very deeply, neither), maybe Aaron?

In any case, best regards to everyone, and thanks John for the ``This
Week's Finds''.

Maxime
\end{quote}

And here is one by Robert Helling:

\begin{quote}
John Baez wrote, concerning 11d supergravity:

\begin{verbatim}
 >I knew that people thought it wasn't renormalizable --- that's not 
 >very new --- but I didn't know people had become sure about it.
\end{verbatim}

Well, it depends a bit on your definition of ``non-renormalizable''. In
a strict sense, it means that renormalization would require an
\emph{infinite} number of different counter terms. In order to fix all
their coefficients one would have to do an infinite number of
experiments before the theory becomes predictive. This should be
compared to renormalizable theories that get along with a finite number
although their coefficients have to be adopted a each order of
pertubation theory. Better are superrenormalizable theories that also
have a finite number of counter terms but there coefficients are not
changed after some order in pertubation theory.

The status of supergravity is as follows (in my understanding): Long ago
(what you refer to as thought) people figured out an additional term in
the action that might appears as counter term and that is invariant
under all symmetries of the action (well, in 11d not all symmetries, the
full supermultiplet is not known and is expected to be infinite but with
\emph{fixed} relative coefficients. So there is still just one
parameter). E.g. in 4D, the situation is simpler because there a
superspace formulation is at hand that allows you to write expressions
that are automatically supersymmetric.

What people didn't know was whether this counter term really arises in
loop integrals. But now, in 11D Deser at al have calculated that a
certain combitation of four Riemann tensors appears as a counterterm
(has a non-zero coefficient) at 2 loop order.

This should be compared to Einstein's theory in 4D: There it was known
that a certain combination of two Weyl tensors does not vanish by
Bianchi identities or is topological. Therefore it is a possible
counterterm. 10 years ago, people did a 3 loop calculation (this is
really hard work!) to show that it actually arises. 4D sugra does not
allow this term and its first possible counter term appears only at the
next loop order. I know somebody personally that spend the last 10 years
doing this calcualtion and hasn't got very far (luckily he still has a
job in physics).

But finding one counter term that was not in the classical action does
not show a theory is non-renormalizable (remember this is a statement
about infinitely many counter terms, so it is about an infinity of
orders of pertubation theory). It might just be that this one term has
been in the classical action just with coefficient (coupling constant) 0
that is renormalized at higher orders. This behaviour is highly unlikely
but a mathematical possibility.

Actually showing a theory to be non-renormalizable is as hard as showing
a theory is renormalizable (not too long ago a Nobel prize was awarded
for such a proof ;-))

Now for your point: ``Is renormalizability a must?''. I think it is very
old fashioned to give an affirmative answer to this question. A more
modern answer would probably be: It's fine for a theory to be
non-renormalizable as long as it is only an effective theory. Fermi
\(\psi^4\) theory is not renormalizable and is a nice theory of weak
interactions as long as one stays away from the EW breaking scale.

The appearance of the infinity of counter terms just shows that there is
some understanding of the high energy degrees of freedom missing. And
there will be a more fundamental theory lurking around that reduces to
this effective theory for small energies.

So for a string theorist, non-renormalizability for sugra is just fine:
It's just the low energy effective theory of string or M theory. It does
not contain all degrees of freedom, just the light ones. One way of
thinking about this is that string theory is just a fancy way of
regulating sugra. It supplies finite coefficients for the infinity of
possible counter terms. For example, in 10D sugra has a one loop
counterterm of the form \(\mathbb{R}^4\). This is just an infinity in
sugra. But in string theory, this has to be a finite number, and in fact
it is. It is \[\zeta(3) = \sum_n n^{-3}.\] The same thing is expected
for 11D sugra and M-Theory. But as long as nobody really knows what
M-Theory really is this does not help very much.

Let me add a personal remark: In \texttt{hep-th/9905183} we have tried
to do exactly this thing for M(atrix)-Theory, but as it turned out,
there are problems remaining.

\begin{quote}
\begin{quote}
\begin{quote}
Unfortunately, this book does not cover supergravity theories.
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
As a matter of fact, there are some books on supergravity in 4D, but no
books covering higher-dimensional supergravity theories with a
reasonable amount of explanations.
\end{quote}
\end{quote}

\begin{quote}
I've noticed! It's scandalous!
\end{quote}

\begin{quote}
\begin{quote}
Of course, people really able to do this properly are a handful on this
planet, and even for them, this would require an enormous amount of work
to get things consistent all the way with a coherent choice of
conventions and check all the horrible formulas.
\end{quote}
\end{quote}

I know that at least three of the sugra hot shots of the eighties
independently started such projects and there are sugra\_book.tex files
of various stages on their hard disks. They all gave up or made it a
really long term project since they figured out that it would cost them
years to basically redo all calculations in a coherent formalism.

This is just a horrible mess. Dealing with fermions just increases the
pain. Doing a calculation twice you never get the same signs. I have
already spend days figuring out what + h.c. in the stony brook textbook
on 4D sugra meant (actually, it should have read --- h.c. since what was
computed was a anti- hermitian quantity). They never stated what their
conventions for hermititan conjugation are. Does it also reverse the
order of differential operators? What about index positions (remember,
for anticommuting variables \(\psi^a \varphi_a = - \psi_a \varphi^a\))
and all these kinds of things?

In addition, the old guys that have done many of the calcualtions use
very strange (aka ``convenient'') conventions, like
\[\psi^2 = \frac12 \psi^a \psi_a\] or they raise and lower
\(\mathrm{SL}(2,\mathbb{C}\)) not with the \(\varepsilon\) tensor, but
with \(i\) times the \(\varepsilon\) tensor (relate this to h.c.!) This
is just a mess and you always get the feeling that you are wasting your
time with such things but in the end your calculations are not even
reliable!

This was all 4D, but the horror starts in higher dimensions. There
\(\gamma\) matrix algebra becomes interesting. Again there are \(N+1\)
conventions if N people work on something and you have to have hunderets
of Fierz identities at hand. I know a grad student that spend months
working them out on a computer and thought it would be a good service to
the community to write a paper like ``Gamma identities and Fierzing in
diverse dimensions''. This would probably be like the PhysRep by Slansky
and Lie algebra stuff. But his advisor told him not to do that ``This is
your capital. Put it in your drawer and lock it. Be sure, erverybody in
the field has such a drawer!''

And this is why there will never be such a text. But I heard people say
that working out for yourself that 11d sugra is indeed supersymmetric is
a good exercise. I have never done it.

Robert
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week159}{%
\section{October 29, 2000}\label{week159}}

Today I want to continue talking about 11d supergravity. I mainly want
to describe this paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Yi Ling and Lee Smolin, Eleven dimensional supergravity as a
  constrained topological field theory, available as
  \href{https://arxiv.org/abs/hep-th/0003285}{\texttt{hep-th/0003285}}.
\end{enumerate}

This paper gives an elegant new formulation of 11d supergravity by
starting from a kind of BF theory and then imposing constraints, very
much like Plebanski's formulation of ordinary gravity in 4d spacetime.
Recall that in Plebanski's formalism, we start with:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  a Lorentz connection \(A\), which can locally be thought of as a
  \(1\)-form taking values in the Lie algebra of the Lorentz group,
\end{enumerate}

and:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  a field \(B\), which can locally be thought of as a \(2\)-form valued
  in the Lie algebra of the Lorentz group.
\end{enumerate}

We get a topological field theory by using the Lagrangian
\[\operatorname{tr}(B \wedge F)\] where \(F\) is the curvature of \(A\).
The equations of motion say that both the curvature of \(A\) and the
exterior covariant derivative of \(B\) vanish. All solutions of these
equations are locally gauge-equivalent, so there are no local degrees of
freedom --- that's what I mean by saying we get a topological field
theory.

But if we impose the constraint that \[B = e\wedge e\] where e is a
``cotetrad'' --- which locally amounts to a \(1\)-form taking values in
\(\mathbb{R}^4\) --- we get the equations of general relativity! We can
impose this constraint by throwing an extra term into the Lagrangian,
involving an extra ``Lagrange multiplier'' field. The sole purpose of
this extra field is to ensure that when we compute the variation of the
action with respect to it, we get zero iff \(B = e\wedge e\).

Similarly, in Ling and Smolin's formulation of 11d supergravity we start
with:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  a super-Poincare superconnection \(A\), which can locally be described
  as a \(1\)-form taking values in the super-Lie algebra of the
  super-Poincare group --- or ``super-Poincare algebra'', for short.
\item
  a \(3\)-form \(C\).
\item
  a \(6\)-form \(D\).
\end{enumerate}

We think of all three of these as ``gauge fields''. I already mentioned
in \protect\hyperlink{week157}{``Week 157''} how a \(p\)-form can be
viewed as a generalization of the electromagnetic vector potential which
couples naturally to a membrane that traces out a \(p\)-dimensional
surface in spacetime: we just integrate the \(p\)-form over this surface
to get the action. Annoyingly, physicists call a membrane that traces
out a \(p\)-dimensional surface in spacetime a ``\((p-1)\)-brane'', so a
string is a \(1\)-brane, a point particle is a \(0\)-brane\ldots{} and
an instanton is a \(-1\)-brane. They should have remembered to count
spacetime dimensions instead of space dimensions! Then we wouldn't have
this nasty ``minus one'' stuff.

But anyway, the usual formulation of 11d supergravity (see
\protect\hyperlink{week157}{``Week 157''}) involves a \(3\)-form field,
which couples naturally to \(2\)-branes. This is nice because there's
lots of evidence that M-theory has a lot to do with \(2\)-branes. The
nice thing about Ling and Smolin's formulation is that it also includes
a \(6\)-form field, which couples to \(5\)-branes. There's also a lot of
evidence that M-theory is related to \(5\)-branes, but these have always
been a bit more mysterious than the \(2\)-branes. Now, however, they're
staring us in the face right from the start!

Next, before I go further, I should say what the ``super-Poincare
algebra'' is!

In fact, I've been pretty coy all along about explaining supersymmetry.
Let me quickly try to remedy that. The basic idea of supersymmetry is
that we should build the distinction between bosons and fermions into
all the math we ever do. So instead of doing math with vector spaces, we
should do it with ``supervector spaces''. A supervector space is just a
direct sum of two vector spaces, called the ``even'' or ``bosonic''
space and the ``odd'' or ``fermionic'' space. So, for example, the
Hilbert space of a quantum system built out of bosons and fermions will
always be a supervector space.

Supervector spaces work a lot like ordinary vector spaces, so we can
redo all of math replacing vector spaces by supervector spaces. To do
this, we just copy all the usual stuff, EXCEPT that whenever we switch
two vectors past each other in our formulas, we stick in an extra minus
sign when they're both odd! This reflects the way fermions actually work
in nature: when you exchange two of them, their wavefunction picks up a
phase of \(-1\).

Supervector spaces are also an obvious idea if you've studied enough
math. For example, differential forms of odd degree anticommute with
each other, while forms of even degree commute with everything. So the
differential forms on a manifold really form a supervector space, and in
fact, a ``supercommutative algebra''. For reasons like this,
mathematicians and physicists got together back in the 1980s and figured
out how to redo huge wads of algebra in the context of supervector
spaces. It's actually very easy if you use a little category
theory\ldots.

Anyway, using this trick we can come up with the notion of a ``super-Lie
algebra''. It's almost like a Lie algebra, except that the bracket
\([A,B]\) of two odd elements \(A\) and \(B\) behaves like an
anticommutator \(AB+BA\) instead of the usual commutator \(AB-BA\). This
means we need to throw in suitable signs into the Jacobi identity and
other Lie algebra axioms: an extra minus sign whenever two odd elements
get switched!

Now, how about the super-Poincare algebra?

As you probably know, the Lie algebra of the Poincare group has
translation generators \(P_a\) and rotation/boost generators \(L_{ab}\),
where the indices go from \(1\) to \(n\) if spacetime has \(n\)
dimensions. I won't bother writing down the well-known commutation
relations between these guys.

The super-Lie algebra of the super-Poincare group contains all this
stuff as its even part, but it also has an odd part! The odd part has a
basis of ``supertranslation generators'' \(Q_A\), where \(A\) ranges
over a basis of real spinors. Now, spinors are like ``square roots of
vectors'': there's a natural symmetric bilinear map taking a pair of
spinors to a vector. So it's natural to define the bracket of two
supertranslations by: \[[Q_A,Q_B] = \Gamma_{AB}^a P_a\] where the
so-called ``\(\gamma\) matrix'' \(\Gamma_{AB}^a\) is just the
physicist's coordinate-ridden way of describing this map taking a pair
of spinors to a vector. Since this map is symmetric, we have
\[[Q_A,Q_B] = [Q_B,Q_A]\] If you're used to Lie algebras, this equation
must look like it's missing a minus sign --- but we're doing super-Lie
algebras, and the supertranslation generators are odd, so we expect
that!

To complete the definition, we need to describe the brackets between
supertranslations and the even elements of our super-Lie algebra. This
is easy. The bracket of an ordinary translation and a supertranslation
is zero. The bracket of a rotation/boost and a supertranslation is
defined using the usual action of the Lie algebra of the Lorentz group
on spinors.

Okay, now let's go back and think a minute about what the
``superconnection'' in Ling and Smolin's formulation of 11d supergravity
is really like. If we work locally, we can think of this as a \(1\)-form
taking values in the super-Poincare algebra. Thus it really consists of
3 parts:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  a \(1\)-form taking values in the Lorentz Lie algebra
  \(\mathfrak{so}(10,1)\). This is secretly the ``spin connection'' in
  the usual formulation of 11d supergravity, as described last week.
\end{enumerate}

a') a \(1\)-form taking values in the translation Lie algebra
\(\mathbb{R}^{11}\). This is secretly the ``elfbein'' in the usual
formulation of 11d supergravity, as described last week.

a'\,') a \(1\)-form taking values in the space of real spinors. This is
just the ``gravitino'' in the usual formulation of 11d supergravity, as
described last week.

So you see, this fancy-schmancy super-baloney really helps simplify our
description of what's going on!

I'm getting a little worn out, so I'll just summarize the rest of the
story. First, how do Ling and Smolin get their 11d topological field
theory? Like I said, it's a kind of BF theory, where the Lagrangian is
like \(\operatorname{tr}(B\wedge F)\). But there are a bunch of \(F\)
fields --- i.e., curvatures --- and thus a bunch of \(B\) fields.
Namely, we've got the curvature of the superconnection \(A\), the
curvature \(dC\) of the \(3\)-form \(C\), and the curvature \(dD\) of
the \(6\)-form \(D\). And if you analyze it, the curvature of the
superconnection consists of 3 separate parts. So we really have five
\(F\) fields. Each one has its corresponding \(B\) field, and the
Lagrangian is a sum of terms of the form
\(\operatorname{tr}(B\wedge F)\).

To get 11d supergravity, we have to impose a bunch of constraints by
throwing extra terms into the Lagrangian. There is one term like this
for each \(F\) field. We also have to throw in a term which gives the
analog of Maxwell's equations for the \(3\)-form field \(C\). So the
paper's title is a mild lie! We're not seeing 11d supergravity as simply
a constrained topological field theory --- there's also an extra
interaction.

By the way, if you've never seen the Plebanski formulation of 4d gravity
as a constrained BF theory, here's the original paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  M. J. Plebanski, ``On the separation of Einsteinian substructures'',
  \emph{J. Math. Phys.} \textbf{18} (1977), 2511.
\end{enumerate}

Ling and Smolin's formulation of 11d supergravity is related to some
work of Fre and collaborators, which I haven't read yet:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\item
  Pietro Fre, ``Comments on the six index photon in \(D = 11\)'',
  preprint \texttt{TH-3884-CERN}.
\item
  R. D'Auria and P. Fre, ``Geometric supergravity in \(D = 11\) and its
  hidden supergroup'', \emph{Nucl. Phys.} \textbf{B201} (1982), 101.
  Erratum, \emph{Nucl. Phys.} \textbf{B206} (182), 496.
\item
  L. Castellani, P. Fre and P. van Nieuwenhuizen, ``A review of the
  group manifold approach and its applications to conformal
  supergravity'', \emph{Ann. Phys.} \textbf{136} (1981), 398.
\end{enumerate}

Here's another formulation of 11d supergravity I'd like to check out:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Martin Cederwall, Ulf Gran, Mikkel Nielsen, and Bengt Nillson,
  ``Generalised \(11\)-dimensional supergravity'', available as
  \href{https://arxiv.org/abs/hep-th/0010042}{\texttt{hep-th/0010042}}.
\end{enumerate}

Cederwall has done interesting work on octonions and physics, so I want
to look here for clues that 11d supergravity is related to the
octonions.

Actually, now that I've said a bit about supersymmetry, I can explain a
bit about how it's related to division algebras and exceptional groups.
All this stuff will be described in more detail in my review article on
octonions, which I'll finish by March of next year. But I can't resist
saying a little right now\ldots.

As we've seen, a crucial part of the super-Poincare algebra is the map
taking a pair of real spinors to a vector. Abstractly we can write this
as follows: \[m\colon  S \times S \to  V.\] In certain dimensions we can
split the spinor space \(S\) into spaces of left- and right-handed
spinors, say \(S_+\) and \(S_-\). Then we get a map
\[m\colon  S_+ \times S_- \to  V.\] This stuff works both for Minkowski
spacetime and for Euclidean space. If we do it for Euclidean space, we
find a marvelous fact\ldots.

In certain special cases --- namely dimensions 1 and 2 --- the dimension
of \(V\) matches the dimension of \(S\). This lets us identify \(V\)
with \(S\). Then the map \[m\colon  S \times S \to V\] turns out to be
\emph{multiplication} for the real and complex numbers, respectively.

In other special cases --- namely dimensions 4 and 8 --- the dimension
of \(V\) matches the dimension of \(S_+\), and also \(S_-\). This lets
us identify \(V\) with \(S_+\) and \(S_-\). Then the map
\[m\colon  S_+ \times S_- \to  V\] turns out to be \emph{multiplication}
for the quaternions and octonions, respectively.

In other words, the vector-spinor interaction which plays such an
important role in physics:

\begin{verbatim}
                  \
                   \
                    \
                     ~~~~~~~~~
                    /
                   /
                  /
\end{verbatim}

also gives rise to all the division algebras! (Here I've drawn the usual
picture of a spinor particle and a spinor antiparticle annihilating to
form a vector boson: this is a physics application of the map \(m\).)

Another crucial part of the super-Poincare algebra is the action of the
Lorentz Lie algebra on spinors. Again, this has a Euclidean analogue,
where the Lie algebra of the Lorentz group gets replaced by that of the
rotation group. In \(n\) dimensions, we thus get an action
\[\mathfrak{so}(n) \times S \to S\] which we can also dualize to get a
map \[S \times S \to \mathfrak{so}(n).\] Of course, we also have the Lie
bracket
\[\mathfrak{so}(n) \times \mathfrak{so}(n) \to \mathfrak{so}(n).\] So
it's natural to ask: can we use all three of these maps to define a Lie
bracket on the direct sum of \(\mathfrak{so}(n)\) and the spinor space
\(S\)?

And the answer is: yes, but only if \(n = 9\). Then we get the
exceptional Lie algebra \(\mathrm{F}_4\).

Spurred on by our success, we can ask: what if we use right-handed
spinors instead? If we restrict the above maps to right-handed spinors,
can we define a Lie bracket on the direct sum of \(\mathfrak{so}(n)\)
and the space \(S_+\)?

And the answer is: yes, but only if \(n = 16\). Then we get the
exceptional Lie algebra \(\mathrm{E}_8\).

And then we ask: can we get the other exceptional Lie algebras by some
variant of this trick?

And the answer is: yes, at least for \(\mathrm{E}_6\) and
\(\mathrm{E}_7\).

If \(n = 10\), the spinor space \(S\) is naturally a complex vector
space, so \(\mathrm{u}(1)\) acts on it. Using this and the above maps,
we can make the direct sum of \(\mathfrak{so}(10)\), \(S\) and
\(\mathrm{u}(1)\) into a Lie algebra, which turns out to be
\(\mathrm{E}_6\).

If \(n = 12\), the right-handed spinor space \(S_+\) is naturally a
quaternionic vector space, so \(\mathfrak{su}(2)\) acts on it. Using
this and the above maps, we can make the direct sum of
\(\mathfrak{so}(12)\), \(S_+\) and \(\mathfrak{su}(2)\) into a Lie
algebra, which turns out to be \(\mathrm{E}_7\).

In short, we have the following story:

\begin{quote}
natural maps involving vectors and spinors give: - \(\mathbb{R}\) in
dimension 1 - \(\mathbb{C}\) in dimension 2 - \(\mathbb{H}\) in
dimension 4 - \(\mathbb{O}\) in dimension 8

natural maps involving \(\mathfrak{so}(n)\) and spinors give: -
\(\mathrm{F}_4\) in dimension 9 - \(\mathrm{E}_6\) in dimension 10 -
\(\mathrm{E}_7\) in dimension 12 - \(\mathrm{E}_8\) in dimension 16
\end{quote}

And you'll note that the dimensions in the second list are 8 more than
the corresponding dimensions in the first list. This is no coincidence!
It has to do with the octonions. But I'm too tired to explain that
now\ldots.

Anyway, my main point was just that the natural maps involving
rotation/boost generators (i.e.~the Lorentz Lie algebra, or rotation Lie
algebra), translation generators (i.e.~vectors) and supertranslation
generators (i.e.~spinors) are the essential ingredient for constructing:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  the super-Poincare algebra
\item
  the division algebras \(\mathbb{R}\), \(\mathbb{C}\), \(\mathbb{H}\)
  and \(\mathbb{O}\)
\item
  the exceptional Lie algebras \(\mathrm{F}_4\), \(\mathrm{E}_6\),
  \(\mathrm{E}_7\) and \(\mathrm{E}_8\)
\end{enumerate}

So it's not really odd to expect relations between these three things!

Of course, I've shown how items b) and c) are related to rotations,
spinors and vectors in Euclidean space, while item a) is related to
rotations/boosts, spinors and vectors in Minkowski spacetime. To round
off the picture, I'd have to describe the relation between spinors in
n-dimensional Euclidean space to spinors in \((n+2)\)-dimensional
Minkowski spacetime. It's this relation that gives the isomorphisms \[
  \begin{gathered}
    \mathfrak{so}(2,1) = \mathfrak{sl}(2,\mathbb{R})
  \\\mathfrak{so}(3,1) = \mathfrak{sl}(2,\mathbb{C})
  \\\mathfrak{so}(5,1) = \mathfrak{sl}(2,\mathbb{H})
  \\\mathfrak{so}(9,1) = \mathfrak{sl}(2,\mathbb{O})
  \end{gathered}
\] which I mentioned already in \protect\hyperlink{week104}{``Week
104''}. This is what lets us write down the super-Yang-Mills Lagrangians
and superstring Lagrangians in spacetimes of dimension 3, 4, 6, and 10
--- i.e., 2 more than the magic numbers 1, 2, 4, and 8. Adding 8, we can
guess there should also be fun stuff in spacetimes of dimensions 11, 12,
14 and 18, related to \(\mathrm{F}_4\), \(\mathrm{E}_6\),
\(\mathrm{E}_7\) and \(\mathrm{E}_8\), respectively. Is this true? Is
the 11d case related to 11d supergravity --- or M-theory? I don't know.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week160}{%
\section{November 20, 2000}\label{week160}}

Anyone who grew up on science fiction in the 1960s probably read a bunch
about adventures on strange planets, and dreamt of our future in space.
At least I did. Asimov, Clarke, Heinlein\ldots{} they helped get me
interested in science, but they also painted a romantic vision of human
destiny. Only later did it become clear that \emph{for now}, the real
adventures will come from the microscopic realm: from applications of
integrated circuits, biotechnology, nanotechnology, and the like. When
you're trying to have lots of fun in a hurry, the speed limit is the
speed of light --- and this makes interstellar travel a drag.

Nonetheless, when you imbibe a romantic dream in childhood, it can be
hard to shake it it as an adult. So I still like to read about strange
planets, even if know rationally that I can have more fun at home.

So --- let me start by talking about a world where it might rain
methane!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Ralph D. Lorenz, ``The weather on Titan'', \emph{Science} \textbf{290}
  (October 20, 2000), 467--468.

  Caitlin A. Griffith, Joseph L. Hall and Thomas R. Geballe, ``Detection
  of daily clouds on Titan'', \emph{Science} \textbf{290} (October 20,
  2000), 509--513.
\end{enumerate}

Titan is the largest moon of Saturn, and it's the only moon in our solar
system with a significant atmosphere. Its atmosphere is mostly nitrogen,
with a surface pressure 1.5 times that of the air pressure here on
Earths' surface. However, there is also a fair amount of methane, and
even some ethane. At the surface of Titan, it's cold enough for these
compounds to liquefy. People have even seen what look like pitch-black
oceans of hydrocarbon compounds, hundreds of kilometers in size!

However, 14 kilometers or more from the surface, it gets cold enough for
methane to freeze. And the news is that recently Caitlin Griffith et al
have spotted things that look like methane clouds. Compared to Earth,
which is usually 30 percent covered with clouds, the cloud cover on
Titan seems spotty. There's not really enough methane for lots of
clouds. But there may be rain! The drops would be larger than
terrestrial raindrops, and fall slowly in the gravity of Titan, which is
like that of our moon. Since the near-surface atmosphere usually has a
relative humidity of at most 60\%, the drops would tend to evaporate
before hitting the ground. (I've seen a similar thing in New Mexico.)
However, in a big rainstorm the evaporation of the first drops might
elevate the humidity to the point where later drops could reach the
surface. So there might even be erosion on the surface of Titan. With
any luck, the Cassini spacecraft will arrive at Saturn in 2004 and make
about 40 flybys of Titan in the following 4 years, getting a good look
at this stuff.

Now for a crazy speculation of my own. Once upon a time James Lovelock
argued that you could tell there was life on earth simply by noting that
the atmosphere contains lots of oxygen, despite the fact that oxygen is
highly reactive. This means the atmosphere is far from equilibrium. Yet
the percentage of oxygen in the atmosphere has remained fairly constant
for long periods of time! So presumably there must be some homeostatic
mechanism at work to keep it constant. Only life --- he argued --- could
be responsible! Conversely, Lovelock guessed there is not life on Mars,
because its atmosphere \emph{is} in equilibrium.

Now, the methane in Titan's atmosphere is dissociated by sunlight, and
this process is irreversible, since the resulting hydrogen flies off
into space. At the rate this happens, the entire methane content of the
atmosphere would be destroyed in only 10 million years if it were not
renewed somehow. In the first article cited above, the author writes:
``For the methane we see today not to be a bizarre fluke, it must be
continuously resupplied from a surface reservoir or by cryovolcanism
(that is, volcanism where the molten `rock' is just ice).'' And this
made me wonder: where is Lovelock when we need him? Maybe \emph{life} is
responsible for this out-of-equilibrium condition.

Or maybe not. After all, it really could be something else.

Next: a world where it might rain diamonds!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  Richard A. Kerr, ``Neptune may crush methane into diamonds'',
  \emph{Science} \textbf{286} (October 1, 1999), 25.

  Laura Robin Benedetti, Jeffrey H. Nguyen, Wendell A. Caldwell,
  Hongjian Liu, Michael Kruger, and Raymond Jeanloz, ``Dissociation of
  \(\mathrm{CH}_4\) at high pressures and temperatures: diamond
  formation in giant planet interiors?'', \emph{Science} \textbf{286}
  (October 1, 1999), 100--102.
\end{enumerate}

The atmosphere of Neptune is believed to contain lots of methane when
you go 4000 kilometers or more beneath the cloud tops. And Neptune ain't
no measly moon: it's a gas giant, so the atmospheric pressure becomes
enormous as you go further in. Recently, people have been compressing
methane under ridiculously high pressures, using techniques too fiendish
to describe here. At sufficiently high pressures, it releases hydrogen
and turns into diamond crystals! --- together with lots of other crud,
like ethane and acetylene. This could happen in Neptune at a depth of
about 7000 kilometers below the cloud tops, where the pressure reaches
500,000 times that of the Earth's atmosphere. So in fact, there could be
a steady rain of diamond crystals on Neptune! By the way, all these
Science articles are available for free online here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Science Magazine, \texttt{http://www.sciencemag.org/search.dtl}
\end{enumerate}

I also want to say a bit about spin foams. Papers continue to come out
on this subject:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Alejandro Perez and Carlo Rovelli, ``A spin foam model without bubble
  divergences'', available as
  \href{https://arxiv.org/abs/gr-qc/0006107}{\texttt{gr-qc/0006107}}.
\end{enumerate}

A while ago, De Pietri, Freidel, Krasnov and Rovelli showed how to get
the Barrett-Crane model for Riemannian quantum gravity from a quantum
field theory on a product of 4 copies of \(\mathrm{SO}(4)\) --- see
\protect\hyperlink{week140}{``Week 140''}. This was based on earlier
work by Boulatov and Ooguri, who did a similar thing for BF theory. The
basic idea is to cook up a quantum field theory on a product of copies
of Lie group, with a nice Lagrangian that encodes how simplices can
stick together to form a spacetime. If you do a Feynman diagram
expansion of this quantum field theory, the Feynman diagrams can be
identified with spin foams, and the sum over Feynman diagrams becomes a
sum over spin foams.

The sum over spin foams may diverge; this paper attempts to control
those divergences. It makes some precise mathematical conjectures about
the convergence of certain sums --- mathematicians who like analysis and
representation theory should get to work on these!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Alejandro Perez and Carlo Rovelli, Spin foam model for Lorentzian
  general relativity, available as
  \href{https://arxiv.org/abs/gr-qc/0009021}{\texttt{gr-qc/0009021}}.
\end{enumerate}

This paper modifies the De Pietri-Freidel-Krasnov-Rovelli construction
to get the \emph{Lorentzian} Barrett-Crane model from quantum field
theory on a product of 4 copies of \(\mathrm{SO}(3,1)\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Alejandro Perez and Carlo Rovelli, ``3+1 spinfoam model of quantum
  gravity with spacelike and timelike components'', available as
  \href{https://arxiv.org/abs/gr-qc/0011037}{\texttt{gr-qc/0011037}}.
\end{enumerate}

In the original Lorentzian Barrett-Crane model, spacetime is made of
4-simplices whose triangular faces are space/timelike --- in other
words, like little bits of the \(xt\) plane in Minkowski spacetime. This
model also allows \(4\)-simplices whose triangular faces are
space/spacelike --- in other words, like little bits of the \(xy\)
plane. This amounts to using a different class of irreducible unitary
representations of the Lorentz group to label the triangles.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Daniele Oriti and Ruth M. Williams, ``Gluing \(4\)-simplices: a
  derivation of the Barrett-Crane spin foam model for Euclidean quantum
  gravity'', available as
  \href{https://arxiv.org/abs/gr-qc/0010031}{\texttt{gr-qc/0010031}}.
\end{enumerate}

This gives an alternate derivation of the Riemannian Barrett-Crane spin
foam model starting from the Lagrangian for Riemannian general
relativity. This is good because it gives some more intuition for the
relation between classical general relativity and the spin foam approach
to quantum gravity.

Finally, if you're hopelessly confused about spin foams and other
approaches to quantum gravity, you might enjoy the following little
history of quantum gravity. It explains how many different approaches
were tried, leading up to the research directions that people pursue
now:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Carlo Rovelli, ``Notes for a brief history of quantum gravity'',
  presented at the 9th Marcel Grossmann Meeting in Rome, July 2000.
  Available as
  \href{https://arxiv.org/abs/gr-qc/0006061}{\texttt{gr-qc/0006061}}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week161}{%
\section{December 10, 2000}\label{week161}}

I'm in the middle of reading this book, so I don't know how it ends yet,
but it's good:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Dava Sobel, \emph{Galileo's Daughter}, Penguin Books, London, 2000.
\end{enumerate}

Galileo had two daughters and a son with a beautiful woman whom never
married --- Marina Gamba of Venice. The son was a wastrel, and the
younger daughter was very shy, but the older daughter, Virginia, loved
Galileo very much and wrote him many letters. Of these, 124 have been
preserved, which serve as the basis of this book. At the age of 13 she
was sent to a convent, and she later became a nun. She took on the name
Suor Maria Celeste --- Sister Mary of the Heavens. Unfortunately, all of
Galileo's letters to her were destroyed by her abbess after his trial by
the Inquisition. Thus, what was really a dialog has come down to us as a
monolog. Nonetheless it is fascinating, especially since Sobel elegantly
fills in many of the holes using other sources.

Since I haven't read much about Galileo, I didn't know that this man,
often considered the father of experimental physics and telescope-aided
astronomy, was officially the ``Chief Mathematician of the University of
Pisa''. Now I can add him to my list of mathematicians who have done
good physics.

Two later figures standing on the border of math and physics are Kelvin
and Stokes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  David B. Wilson, \emph{Kelvin and Stokes: A Comparative Study in
  Victorian Physics}, Adam Hilger, Bristol, 1987.
\end{enumerate}

One thing I like about this book is the debunking of the popular image
of quantum mechanics and relativity as ``bolts from the blue''
shattering the complacent serenity of 19th-century physics. In physics,
the 19th century was also a century of drastic change! To quote:

\begin{quote}
Science in Victorian Britain underwent revolutionary conceptual and
institutional changes. Together, thermodynamics and the electromagnetic
theory of light, for example, transformed a bundle of only partially
linked, largely experimental sciences into a coherent, unified,
mathematical physics of energy and ether. In the 1890s one could
contemplate reducing the phenomena of matter, electricity, magnetism,
heat and light to an underlying reality of potential and kinetic energy
in an all-pervading ether. The pursuit of scientific research, largely
avocational early in the century, was a full-fledged profession by the
century's end. Science became important to university curricula, and the
universities expanded their science faculties. Institutions like the
British Association for the Advancement of Science, founded in 1831, and
Royal Society of London, reformed at mid-century, provided
organizational support for a growing community of scientists. And that
community of late-Victorian scientists resided in a community which, on
balance, was much more scientific and less religious than it had been
only two or three generations earlier. In sum late-Victorian society
endorsed the imporance of scientific knowledge and research, and
late-Victorian physics affirmed the primary significance of the ideal of
unification and the language of mathematics. In these respects, there
was an essential \emph{similarity} between late-Victorian Britain and
both the ``big science'' and the modern physics of the twentieth
century. The metamorphosis that created this state of affairs was the
context of the the careers of G. G. Stokes and William Thomson, Lord
Kelvin.
\end{quote}

Marching forwards into the 20th century, we find Einstein as another
physicist with a special tie to mathematics. Certainly he was no
mathematician, but his search for a theory of general relativity was a
curious combination of philosophical and mathematical reasoning, with
very little support from experiment. How did he really figure it out?
This book is a good place to learn the details:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Don Howard and John Stachel eds., \emph{Einstein and the History of
  General Relativity}, Birkhauser, Boston, 1989.
\end{enumerate}

There are a number of essays exploring the interesting period between
1912, when Einstein recognized that gravity was caused by spacetime
curvature, and 1915, when he found his field equations and used them to
compute the anomalous precession of the perihelion of Mercury. Why did
it take him so long? According to Einstein himself, ``The main reason
lies in the fact that it is not easy to free oneself from the idea that
co-ordinates must have an immediate metrical significance''.

Indeed, in 1913 he noticed that generally covariant field equations
could not uniquely determine the gravitational field generated by a
fixed mass distribution. The reason --- apart from the existence of
gravitational waves, which he was not concerned with here --- is that
one can take any solution, apply an arbitrary change of coordinates, and
get a new solution. This seemed to suggest a conflict between general
covariance and the principle that every effect should have a sufficient
cause.

Before he solved it, this conceptual problem aggravated the technical
problem of getting the right field equations: there aren't that many
good candidates for these equations if one demands general covariance,
but during the period when he distrusted this principle, Einstein and
his collaborator Grossman put a lot of work into other candidates. The
main one they tried gave Mercury an anomalous precession of 18" per
century instead of the correct value of 45" per century. Einstein only
discarded this theory in November, 1915.

On November 11th he tried a theory where the Ricci tensor was
proportional to the stress-energy tensory. On November 25th he tried a
better one, where what we now call the Einstein tensor is proportional
to the stress-energy tensor. He quickly used this to derive the correct
precession for Mercury. And so general relativity was born! In January
1916 he explained in letters to Ehrenfest and Besso how he had
reconciled general covariance with causality: two solutions of the field
equations that differ only by a change of coordinates should be regarded
as physically the same.

Now I'd like to switch to something else: a couple of emails I got. A
while back I wrote up a webpage about the end of the universe:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  John Baez, ``The end of the universe'',
  \texttt{http://math.ucr.edu/home/baez/end.html}
\end{enumerate}

I got a lot of the numbers out of a book I bet you've already read:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  John D. Barrow and Frank J. Tipler, \emph{The Cosmological Anthropic
  Principle}, Oxford U. Press, Oxford, 1988.
\end{enumerate}

What --- you haven't read it? Yikes! Hurry up and give it to a friend
for Christmas --- and then make them lend it to you. Regardless of what
you think about the anthropic principle, you're bound to enjoy the cool
facts this book is stuffed with! Anyway, I got an email from Barrow
saying that he's coming out with a new book. Like the previous one, it's
sure to be full of interesting things. You can tell from the title:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  John D. Barrow, \emph{The Book of Nothing}, to be published.
\end{enumerate}

My other email was from Bert Schroer, an expert on the \(C^*\)-algebraic
approach to quantum field theory. He has written a paper about the
``AdS-CFT correspondence'' which is bound to stir up controversy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Bert Schroer, ``Facts and fictions about Anti de Sitter spacetimes
  with local quantum matter'', available as
  \href{https://arxiv.org/abs/hep-th/9911100}{\texttt{hep-th/9911100}}.
\end{enumerate}

Let me just quote the beginning:

\begin{quote}
There has been hardly any problem in particle physics which has has
attracted as much attention as the problem if and in what way quantum
matter in the Anti de Sitter spacetime and the one dimension lower
conformal field theories are related and whether this could possibly
contain clues about the meaning of quantum gravity.

In more specific quantum physical terms the question is about a
conjectured (and meanwhile in large parts generically and rigorously
understood) correspondence between two quantum field theories in
different spacetime dimensions; the lower-dimensional conformal one
being the ``holographic image'' or projection of the AdS theory.

The entire globalized community of string physicists has placed this
problem in the centre of their interest and treated it as the dominating
problem of theoretical particle physics with the result that there have
been approximately around 100-150 papers per month during a good part of
1999. Even if one takes into account the increase in the number of
particle physicists during the last decades and compares it with the
relative number of participants in previous fashionable topics (the
S-matrix bootstrap, Regge theory, the \(\mathrm{SU}(6)\) --
\(\mathrm{U}(12)\) symmetric and the so-called relativistic quark
theory, to name some of them) which also led to press-conferences,
interviews and articles in the media (but not to awards and prizes), it
remains still an impressive sociological phenomenon. Just imagine
yourself working on this kind of problem and getting up every morning
turning nervously to the \texttt{hep-th} server in order to check that
nobody has beaten you to similar results. What a life in an area which
used to required a contemplative critical attitude!

This is clearly a remarkable situation in the exact sciences which
warrants an explanation. This is particularly evident to somebody old
enough to have experienced theoretical particle physics at times of
great conceptual and calculational achievements, e.g.~the derivation of
scattering theory and dispersion theory from local fields, achievements
with which the name of Harry Lehmann (to whose memory this article is
dedicated) is inexorably linked. In those times the acceptance of a
theoretical proposal in particle physics was primarily coupled to its
experimental verifiability and its conceptual standing within physics
and not yet to the beauty of its differential-geometric content. There
were also fashions, but if they did not deliver what they promised they
were allowed to die.

In the opinion of Roger Penrose, the new totalitarian attitude in
particle physics is the result of the rapid and propagandistic
communication through the new electronic media which favors speedy
calculations with no or only insufficient superficial physical
interpretation to more contemplative and not instantly profitable
conceptual investments. He cites supersymmetry and inflation cosmology
as examples of theories which achieved a kind of monopolistic dominance
despite a total lack of experimental fact (or even convincing
theoretical arguments). It seems to me that this phenomenon receives an
even stronger illustration from string theory, and I am not the only one
who thinks this way {[}here he cites a paper by I. Todorov{]}.

Leaving the final explanation of this phenomenon to historians or
sociologists of the exact sciences, I will limit myself to analyzing the
particle physics content of the so-called Anti de Sitter -- conformal
QFT correspondence from the conservative point of view of a quantum
field theorist with a 30 year professional experience who, although
having no active ambitions outside QFT, still nourishes a certain
curiosity about present activities in particle physics, e.g. string
theory or the use of noncommutative geometry. Some of the consistency
calculations one finds there are really surprising and if one could
consider them in the critical Bohr-Sommerfeld spirit as ciphers encoding
possibly new principles in fundamental physics and not as a theory (let
alone a theory of everything), these observations may have an enigmatic
use. But for this to be successful one would have to make a much more
serious attempt at confronting the new mathematical consistency
observations with local quantum physics on a more conceptual level
beyond the standard formalism. Only in this way can one be sure to
confront something new and not just a new formalism which implements the
same principles in a different way.

The AdS model of a curved spacetime has a long history as a theoretical
laboratory of what can happen with particle physics in a universe which
is the extreme opposite of globally hyperbolic in that it possesses a
self-closing time, whereas the proper de Sitter spacetime was once
considered among the more realistic models of the universe. The recent
surge of interest about AdS came from string theory and is different in
motivation and more related to the hope (or dream) to attribute a
meaning to ``Quantum Gravity'' from a string theory viewpoint.

Fortunately for the curious outsider (otherwise I would have to quit
right here), this motivation has no bearing on the conceptual and
mathematical problems posed by the would-be AdS-conformal QFT
correspondence, which turned out to be one of those properties
discovered in the setting of string theory which allow an interesting
and rigorous formulation in QFT which confirms some but not all of the
conjectured properties. The rigorous treatment however requires a
reformulation of (conformal) QFT. The standard formalism based on
pointlike ``field coordinatizations'' which underlies the Lagrangian
(and Wightman) formulations does not provide a natural setting for the
study of isomorphisms between models in different spacetime dimensions,
even though the underlying principles are the same. One would have to
introduce too many additional concepts and auxiliary tricks into the
standard framework. The important aspects in this isomorphism are
related to space and time-like (Einstein, Huyghens) causality,
localization of corresponding objects and problems of degree of freedom
counting. All these issues belong to real-time physics and in most cases
their meaning in terms of Euclidean continuation (statistical mechanics)
remains obscure; but this of course does not make them less physical.

This note is organized as follows. In the next section I elaborate on
the kinematical aspects of the
\(\mathrm{AdS}_{d+1}\)--\(\mathrm{CQFT}_d\) situation as a collateral of
the old (1974/75) compactification formalism for the
``conformalization'' of the \(d\)-dimensional Minkowski spacetime. For
this reason the seemingly more demanding problem of studying QFT
directly in AdS within a curved spacetime formalism can be bypassed. The
natural question whose answer would have led directly from
\(\mathrm{CQFT}_4\) to \(\mathrm{AdS}_5\) in the particle physics
setting (without string theory as a midwife) is: Does there exist a
quantum field theory which has the same \(\mathrm{SO}(4,2)\) symmetry
and just reprocesses the CQFT\_4 matter content in such a way that the
``conformal hamiltonian'' (the timelike generator of rotations of
conformally compactified Minkowski space) becomes the true hamiltonian?
The theory exists and is an AdS theory with a specific local matter
content computable from the CQFT matter content. The answer is unique,
but as a result of the different dimensionality one cannot describe this
unique relation between matter contents in terms of pointlike fields.
This will be treated in Section 3, where we will also compare the
content of Rehren's isomorphism with Maldacena, Witten et al conjectures
and notice some subtle but potentially serious differences. Whoever is
aware of the fact that subtle differences have often been the enigmatic
motor of progress in good physics times will not dismiss such
observations.

The last section presents some results of algebraic QFT on degrees of
freedom counting and holography. Closely connected is the idea of
``chiral scanning'', i.e.~the encoding of the full content of a higher
dimensional (massive) QFT into a finite number of copies of one chiral
theory in a carefully selected position within a common Hilbert space.
In this case the price one has to pay for this more generic holography
(light-front holography) is that some of the geometrically acting
spacetime symmetry transformations become ``fuzzy'' in the holographic
projection and some of the geometrically acting symmetries on the
holographic image are not represented by diffeomorphisms if pulled back
to the original QFT.
\end{quote}

As you can see, there is some interesting mathematical physics in here,
as well as some serious criticism of how particle physics is done these
days.

By the way, Schroer has recently written a paper about the braid group
and quantum field theory. Everyone knows how the braid group shows up in
3d quantum field theory, but this is about \emph{4d} quantum field
theory:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Bert Schroer, ``Braided structure in \(4\)-dimensional conformal
  quantum field theory'', available as
  \href{https://arxiv.org/abs/hep-th/0012021}{\texttt{hep-th/0012021}}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week162}{%
\section{December 17, 2000}\label{week162}}

Since the winter solstice is coming soon, I'll start with some gift
suggestions\ldots{} for the physicist who has everything.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  ``The Universe Map'', National Geographic Society, 2000, NSG \#602011.
\end{enumerate}

I've only seen a picture of this \(20\times31\) inch map, but I know I
want one! In a series of different 3d views, it shows the solar system,
nearby stars, the Milky Way, the Local Group and the observable universe
as a whole. I'll put it outside my office so my students can figure out
just where they stand in the grand scheme of things.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Wil Tirion and Roger W. Sinnot, \emph{Sky Atlas 2000.0}, 2nd edition,
  Cambridge U. Press, 1999.
\end{enumerate}

This is a favorite sky atlas among amateur astronomers. It comes in lots
of versions, but Kevin Kelly of Whole Earth says that the most useful is
the ``deluxe version, spiralbound''.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Lee Smolin, \emph{Three Roads to Quantum Gravity}, Weidenfeld and
  Nicholson, 2000.
\end{enumerate}

This is a nontechnical guide to quantum gravity and the different
approaches people have taken to this problem: string theory, loop
quantum gravity, and the more radical lines of thought pursued by people
whom Smolin calls ``the true heroes of quantum gravity'', like Alain
Connes, David Finkelstein, Chris Isham, Roger Penrose and Raphael
Sorkin. I haven't gotten ahold of this book, so I can't describe it in
detail yet, but it should be lots of fun.

That's enough gift suggestions. Now I want to talk about Jordan algebras
and how they show up in projective geometry, quantum logic, special
relativity and so on. I'll start by reminding you of some stuff from
\protect\hyperlink{week106}{``Week 106''} and
\protect\hyperlink{week145}{``Week 145''}. Then I'll charge ahead and
show you how a Jordan algebra built from the octonions is related to
\(10\)-dimensional Minkowski spacetime\ldots.

Projective geometry is a venerable subject that has its origins in the
study of perspective by Renaissance painters. As seen by the eye, any
pair of parallel lines --- e.g., train tracks --- appear to meet at a
``point at infinity''. Furthermore, when you change your viewpoint,
distances and angles appear to change, but points remain points and
lines remain lines. This suggests a modification of Euclidean plane
geometry based on a set of points, a set of lines, and relation whereby
a point ``lies on'' a line, satisfying the following axioms:

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\item
  For any two distinct points, there is a unique line on which they both
  lie.
\item
  For any two distinct lines, there is a unique point which lies on both
  of them.
\item
  There exist four points, no three of which lie on the same line.
\item
  There exist four lines, no three of which have the same point lying on
  them.
\end{enumerate}

Any structure satisfying these axioms is called a ``projective plane''.
But projective geometry is also interesting in higher dimensions. One
can define a ``projective space'' by the following axioms:

\begin{enumerate}
\def\labelenumi{\Alph{enumi})}
\item
  For any two distinct points \(p\) and \(q\), there is a unique line
  \(pq\) on which they both lie.
\item
  For any line, there are at least three points lying on this line.
\item
  If \(a,b,c,d\) are distinct points and there is a point lying on both
  \(ab\) and \(cd\), then there is a point lying on both \(ac\) and
  \(bd\).
\end{enumerate}

Given a projective space and a set \(S\) of points in this space, we
define the ``span'' of \(S\) to be the set of all points lying on lines
\(ab\) where \(a,b\) are distinct points in \(S\). The ``dimension'' of
a projective space is defined to be one less than the smallest number of
points that span the whole space. As you would hope, a \(2\)-dimensional
projective space is the same thing as a projective plane! It's a fun
exercise to show this straight from the above axioms. If you give up,
read this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Lynn E. Garner, \emph{An Outline of Projective Geometry}, North
  Holland, New York, 1981.
\end{enumerate}

How can we get our hands on some projective spaces? Well, if
\(\mathbb{K}\) is any field, there is an \(n\)-dimensional projective
space called \(\mathbb{KP}^n\) where the points are lines through the
origin in \(\mathbb{K}^{n+1}\), the lines are planes through the origin
in \(\mathbb{K}^{n+1}\), and the relation of ``lying on'' is inclusion.
The example relevant to perspective is the real projective plane,
\(\mathbb{RP}^2\). But it's good to follow Polya's advice:

\begin{quote}
``Be wise --- generalize!''
\end{quote}

and study \(\mathbb{KP}^n\) for any field and any \(n\). In fact, we can
define \(\mathbb{KP}^n\) even when \(\mathbb{K}\) is a mere ``skew
field'': a ring such that every nonzero element has a left and right
multiplicative inverse. We just need to be a bit careful about defining
lines and planes through the origin in \(\mathbb{K}^{n+1}\). To do this,
we just take a line through the origin to be any set
\[L = {ax \mid a\in\mathbb{K}}\] where \(x\) is nonzero element of
\(\mathbb{K}^{n+1}\), and take a plane through the origin to be any set
\[P = {ax + by \mid a,b\in\mathbb{K}}\] where \(x,y\) are elements of
\(\mathbb{K}^{n+1}\) such that \(ax + by = 0\) implies \(a\) and \(b\)
are zero.

Around now, you might be wondering whether \emph{every} projective
\(n\)-space is of the form \(\mathbb{KP}^n\) for some skew field
\(\mathbb{K}\). If so, you must have forgotten
\protect\hyperlink{week145}{``Week 145''}, where I gave the answer: yes,
but only if \(n>2\). Projective planes are more subtle! A projective
plane comes from a skew field if and only if it satisfies an extra
axiom, the ``axiom of Desargues''. I described this axiom in
\protect\hyperlink{week145}{``Week 145''} so I won't do it again here.
The main point is that a projective plane coming from a skew field has
some extra geometrical properties that a ``non-Desarguesian'' projective
plane will not.

Projective geometry was very fashionable in the 1800s, with such
worthies as Poncelet, Brianchon, Steiner and von Staudt making important
contributions. Later it was overshadowed by other forms of geometry.
However, work on the subject continued, and in 1933 Ruth Moufang
constructed a remarkable example of a non-Desarguesian projective plane
using the octonions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Ruth Moufang, ``Alternativkoerper und der Satz vom vollstaendigen
  Vierseit'', \emph{Abhandlungen Math. Sem. Hamburg} \textbf{9}, (1933),
  207--222.
\end{enumerate}

It turns out that this projective plane deserves the name
\(\mathbb{OP}^2\), where \(\mathbb{O}\) stands for the octonions.

The 1930s also saw the rise of another reason for interest in projective
geometry: quantum mechanics! Quantum theory is distressingly different
from the classical Newtonian physics we have learnt to love. In
classical mechanics, observables are described by real-valued functions.
In quantum mechanics, they are often described by hermitian
\(n\times n\) complex matrices. In both cases, observables are closed
under addition and multiplication by real scalars. However, in quantum
mechanics, observables do not form an associative algebra. Still, one
can raise an observable to any power, and from squaring one can define a
commutative product:
\[x \circ y = \frac12[(x+y)^2 - x^2 - y^2] = \frac12(xy + yx)\] This
product is not associative, but it satisfies the weaker identity
\[x\circ (y\circ x^2) = (x\circ y)\circ x^2\] In 1932, Pascual Jordan
attempted to understand this situation better by isolating the bare
minimum axioms that an ``algebra of observables'' should satisfy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Pascual Jordan, ``Ueber eine Klasse nichtassociativer hyperkomplexer
  Algebren'', \emph{Nachr. Ges. Wiss. Goettingen} (1932), 569--575.
\end{enumerate}

He invented the definition of what is now called a ``formally real
Jordan algebra'': a commutative (but not necessarily associative) unital
algebra over the real numbers such that:
\[x\circ (y\circ x^2) = (x\circ y)\circ x^2\] and also:
\[[a^2 + b^2 + c^2 + \ldots = 0] \implies [a = b = c = \ldots = 0].\]
The last condition gives our algebra a partial ordering: if we say that
\(x\) is ``less than or equal to'' \(y\) when the element \(y-x\) is a
sum of squares, this condition says that if \(x\) is less than or equal
to \(y\) and \(y\) is less than or equal to \(x\), then \(x = y\). If we
drop this last condition, we get the definition of what is now called a
``Jordan algebra''.

In 1934, one year after Moufang published her paper on
\(\mathbb{OP}^2\), Jordan published a paper with von Neumann and Wigner
classifying all formally real Jordan algebras:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Pascual Jordan, John von Neumann, Eugene Wigner, ``On an algebraic
  generalization of the quantum mechanical formalism'', \emph{Ann.
  Math.} \textbf{35} (1934), 29--64.
\end{enumerate}

Their classification is nice and succinct. An ``ideal'' in the Jordan
algebra \(A\) is a subspace \(B\) such that if \(b\) is in \(B\),
\(a\circ b\) lies in \(B\) for all \(a\) in \(A\). A Jordan algebra
\(A\) is ``simple'' if its only ideals are \(\{0\}\) and \(A\) itself.
Every formally real Jordan algebra is a direct sum of simple ones. The
simple formally real Jordan algebras consist of 4 infinite families and
one exception:

\begin{itemize}
\tightlist
\item
  The algebra of \(n\times n\) self-adjoint real matrices with the
  product \[x\circ y = \frac12(xy + yx).\]
\item
  The algebra of \(n\times n\) self-adjoint complex matrices with the
  product \[x\circ y = \frac12(xy + yx).\]
\item
  The algebra of \(n\times n\) self-adjoint quaternionic matrices with
  the product \[x\circ y = \frac12(xy + yx).\]
\item
  The algebra \(\mathbb{R}^n\oplus\mathbb{R}\) with the product
  \[(v,a) o (w,b) = (aw + bv, \langle v,w\rangle + ab)\] where
  \(\langle v,w\rangle\) is the usual inner product of vectors in
  \(\mathbb{R}^n\). This sort of Jordan algebra is called a ``spin
  factor''.
\item
  The algebra of \(3\times3\) self-adjoint octonionic matrices with the
  product \[x\circ y = \frac12(xy + yx).\] This is called the
  ``exceptional Jordan algebra''.
\end{itemize}

This classification raises some obvious questions. Why does nature
prefer the Jordan algebras \(h_n(\mathbb{C})\) over all the rest? Or
does it? Could the other Jordan algebras --- even the exceptional one
--- have some role to play in quantum physics? Despite much research,
these questions remain unanswered to this day.

The paper by Jordan, von Neumann and Wigner appears to have been
uninfluenced by Moufang's discovery of \(\mathbb{OP}^2\), but in fact
the two are related! A ``projection'' in a formally real Jordan algebra
is defined to be an element \(p\) with \(p^2 = p\). In the usual case of
\(h_n(\mathbb{C})\), these correspond to hermitian matrices with
eigenvalues \(0\) and \(1\), so they are used to describe observables
that assume only two values --- e.g., ``true'' and ``false''.

This suggests treating projections in a formally real Jordan algebra as
propositions in a kind of ``quantum logic''. The partial order helps us
do this: given projections \(p\) and \(q\), we say that \(p\)
``implies'' \(q\) if \(p\) is less than or equal to \(q\). We can then
go ahead and define ``and'', ``or'' and ``not'' in this context, and
most of the familiar rules of Boolean logic continue to hold. However,
we no longer have the distributive laws: \[
  \begin{gathered}
    \mbox{$p$ and ($q$ or $r$) = ($p$ and $q$) or ($p$ and $r$)}
  \\\mbox{$p$ or ($q$ and $r$) = ($p$ or $r$) and ($q$ or $r$)}
  \end{gathered}
\] The failure of these distributive laws is the hallmark of quantum
logic.

Now, the relation between Jordan algebras and quantum logic is already
interesting in itself:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  G. Emch, \emph{Algebraic Methods in Statistical Mechanics and Quantum
  Field Theory}, Wiley-Interscience, New York, 1972.
\end{enumerate}

\ldots{} but the real fun starts when we note that projections in the
Jordan algebra of \(n\times n\) self-adjoint complex matrices correspond
to subspaces of \(\mathbb{C}^n\). This sets up a relationship to
projective geometry, since the projections onto \(1\)-dimensional
subspaces correspond to points in \(\mathbb{CP}^n\), while the
projections onto \(2\)-dimensional subspaces correspond to lines. Even
better, we can work out the dimension of a subspace \(V\) from the
corresponding projection \(p\colon\mathbb{C}^n\to V\) using only the
partial order on projections: \(V\) has dimension \(d\) iff the longest
chain of distinct projections \[p_0 < p_1 < \ldots < p_i = p\] has
length \(i = d\). In fact, we can use this to define the ``dimension''
of any projection in \emph{any} formally real Jordan algebra. We can
then try to construct a projective space whose points are the
\(1\)-dimensional projections and whose lines are the \(2\)-dimensional
projections, with the relation of ``lying on'' given by the partial
order in our Jordan algebra.

If we try this starting with the Jordan algebra of \(n\times n\)
self-adjoint matrices with real, complex or quaternionic entries, we
succeed when \(n\) is \(2\) or more --- and we obtain the projective
spaces \(\mathbb{RP}^n\), \(\mathbb{CP}^n\) and \(\mathbb{HP}^n\),
respectively. If we try this starting with the spin factor
\(\mathbb{R}^n\oplus\mathbb{R}\) we succeed when \(n\) is \(2\) or more
--- and we obtain a series of 1-dimensional projective spaces related to
Minkowskian geometry, which I'll talk about in a minute. Finally, in
1949 Jordan discovered that if we try this construction starting with
the exceptional Jordan algebra, we get the projective plane discovered
by Ruth Moufang --- \(\mathbb{OP}^2\)!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Pascual Jordan, ``Ueber eine nicht-desarguessche ebene projektive
  Geometrie'', \emph{Abhandlungen Math. Sem. Hamburg} \textbf{16}
  (1949), 74--76.
\end{enumerate}

Physicists have tried for a long time to find some use for the quantum
logic corresponding to the exceptional Jordan algebra. So far they have
not succeeded. Jordan hoped this stuff would be related to nuclear
physics. Feza Gursey and Murat Gunaydin hoped it was related to quarks,
since \(3\times3\) hermitian octonionic matrices should describe
observables in some 3-state quantum system:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\item
  Murat Gunaydin and Feza Gursey, ``An octonionic representation of the
  Poincare group'', \emph{Lett. Nuovo Cim.} \textbf{6} (1973), 401--406.
\item
  Murat Gunaydin and Feza Gursey, ``Quark structure and octonions'',
  \emph{Jour. Math. Phys.} \textbf{14} (1973), 1615--1667.
\item
  Murat Gunaydin and Feza Gursey, ``Quark statistics and octonions'',
  \emph{Phys. Rev.} \textbf{D9} (1974), 3387--3391.
\item
  Murat Gunaydin,
  \(Octonionic Hilbert spaces, the Poincare group and \mathrm{SU}(3)\),
  \emph{Jour. Math. Phys.} \textbf{17} (1976), 1875--1883.
\item
  M. Gunaydin, C. Piron and H. Ruegg, ``Moufang plane and octonionic
  quantum mechanics'', \emph{Comm. Math. Phys.} \textbf{61} (1978),
  69--85.
\end{enumerate}

Alas, these ideas never quite worked out, so most physicists discarded
the exceptional Jordan algebra as a lost cause.

However, the exceptional Jordan algebra is secretly related to string
theory, so there's a sense in which it's still lurking in the collective
subconscious. Now, you probably want me to explain this, but I'm not
ready to. So I won't say what \(3\times3\) hermitian octonionic matrices
have to do with string theory. If you want to know that, read these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\item
  E. Corrigan and T. J. Hollowood, ``The exceptional Jordan algebra and
  the superstring'', \emph{Commun. Math. Phys.} \textbf{122} (1989),
  393. Also available at
  \href{http://projecteuclid.org/DPubS?service=UI\&version=1.0\&verb=Display\&handle=euclid.cmp/1104178468}{\texttt{http://projecteuclid.org/}}
\item
  E. Corrigan and T. J. Hollowood, ``A string construction of a
  commutative nonassociative algebra related to the exceptional Jordan
  algebra'', \emph{Phys. Lett.} \textbf{B203} (1988), 47.
\item
  G. Sierra, ``An application of the theories of Jordan algebras and
  Freudenthal triple systems to particles and strings'', \emph{Class.
  Quant. Grav.} \textbf{4} (1987), 227.
\end{enumerate}

Instead, I'll just say what \(2\times2\) hermitian octonionic matrices
have to do with \(10\)-dimensional Minkowski spacetime. Since
superstrings live in 10 dimensions, that's at least a start.

First, we need to think about spin factors.

In case you forgot, spin factors were the fourth infinite family of
simple formally real Jordan algebras on my list up there. I gave a
lowbrow definition of these guys, but now let's try a highbrow one.
Given an \(n\)-dimensional real inner product space \(V\), the ``spin
factor'' \(J(V)\) is the Jordan algebra generated by \(V\) with the
relations \[v\circ w = \langle v,w\rangle\] This should remind you of
the definition of a Clifford algebra, and indeed, they're related ---
they have the same representations! This sets up a connection to
spinors, which is why these Jordan algebras are called ``spin factors''.

But anyway: if you think about it a while, you'll see that \(J(V)\) is
isomorphic to the direct sum \(V\oplus\mathbb{R}\) equipped with the
product \[(v,a)\circ(w,b) = (aw + bv, \langle v,w\rangle + ab)\] which
is basically the lowbrow definition of a spin factor.

Though Jordan algebras were invented to study quantum mechanics, the
spin factors are also deeply related to special relativity: we can think
of \(J(V) = V\oplus\mathbb{R}\) as ``Minkowski spacetime'', with \(V\)
as space and \(\mathbb{R}\) as time. The reason is that \(J(V)\) is
naturally equipped with a dot product:
\[(v,a)\cdot(w,b) = \langle v,w\rangle - ab\] which is just the usual
Minkowski metric in slight disguise. This makes it tempting to borrow an
idea from special relativity and define the ``lightcone'' to consist of
all nonzero \(x\) in \(J(V)\) with \[x\cdot x = 0\] A \(1\)-dimensional
subspace of \(J(V)\) spanned by an element of the lightcone is called a
``light ray'', and the space of all light rays is called the ``heavenly
sphere'' \(S(V)\). We can identify the heavenly sphere with the sphere
of unit vectors in \(V\), since every light ray is spanned by an element
of \(J(V)\) of the form \((v,1)\) where \(v\) is a unit vector in \(V\).

What's the physical meaning of the heavenly sphere? Well, if you were a
resident of the spacetime \(J(V)\) and gazed up at the sky at night, the
stars would seem to lie on this sphere. If you took off in a spaceship
and whizzed along at close to the speed of light, all the constellations
would look distorted, but all \emph{angles} would be preserved, since
the Lorentz group acts as conformal transformations of the heavenly
sphere.

Now, when \(V\) is at least \(2\)-dimensional, we can build a projective
space from \(J(V)\) using the construction I described for any simple
formally real Jordan algebra. If we do this, what do we get?

Well, you can easily check that aside from the elements \(0\) and \(1\),
all projections in \(J(V)\) are of the form \(p = \frac12(v,1)\) where v
is a unit vector in V. These projections will be the points of our
projective space, but as we've seen, they also correspond to points of
the heavenly sphere. So our projective space is really just the heavenly
sphere! This is cool, because it means points on the heavenly sphere can
also be thought of as \emph{propositions} in a certain sort of quantum
logic.

Now, what does this have to do with the exceptional Jordan algebra?
Well, we have to sneak up carefully on this wild beast, so first let's
think about a smaller Jordan algebra: the \(2\times2\) hermitian
octonionic matrices. In fact, we can kill four birds with one stone, and
think about \(2\times2\) hermitian matrices with entries in any
\(n\)-dimensional normed division algebra, say \(\mathbb{K}\). There are
not that many normed division algebras, so I really just mean:

\begin{itemize}
\tightlist
\item
  the real numbers, \(\mathbb{R}\), if \(n = 1\),
\item
  the complex numbers, \(\mathbb{C}\), if \(n = 2\),
\item
  the quaternions, \(\mathbb{H}\), if \(n = 4\),
\item
  the octonions, \(\mathbb{O}\), if \(n = 8\).
\end{itemize}

The space \(\mathrm{h}_2(\mathbb{K})\) of hermitian \(2\times2\)
matrices with entries in \(\mathbb{K}\) is a Jordan algebra with the
product \[x\circ y = \frac12(xy + yx)\] Moreover, this Jordan algebra is
secretly a spin factor! There is an isomorphism
\[f\colon \mathrm{h}_2(\mathbb{K}) \to J(\mathbb{K}\oplus\mathbb{R}) = \mathbb{K}\oplus\mathbb{R}\oplus\mathbb{R}\]
which sends the hermitian matrix \[
  \left(
    \begin{array}{cc}
      a+b&k
    \\k^*&a-b
    \end{array}
  \right)
\] to the element \((k,b,a)\) in \(K\oplus\mathbb{R}\oplus\mathbb{R}\).

Furthermore, the determinant of matrices in \(\mathrm{h}_2(\mathbb{K})\)
is just the Minkowski metric in disguise, since the determinant of \[
  \left(
    \begin{array}{cc}
      a+b&k
    \\k^*&a-b
    \end{array}
  \right)
\] is \[a^2-b^2-\langle k,k\rangle.\]

These facts have a number of nice consequences. First of all, since the
Jordan algebras \(J(\mathbb{K}\oplus\mathbb{R})\) and
\(\mathrm{h}_2(\mathbb{K})\) are isomorphic, so are their associated
projective spaces. We have seen that the former space is the heavenly
sphere \(S(\mathbb{K}\oplus\mathbb{R})\); unsurprisingly, the latter is
the projective line \(\mathbb{KP}^1\). It follows that these are the
same! This shows that:

\begin{itemize}
\tightlist
\item
  \(\mathrm{h}_2(\mathbb{R})\) is 3d Minkowski spacetime, and
  \(\mathbb{RP}^1\) is the heavenly sphere \(S^1\);
\item
  \(\mathrm{h}_2(\mathbb{C})\) is 4d Minkowski spacetime, and
  \(\mathbb{CP}^1\) is the heavenly sphere \(S^2\);
\item
  \(\mathrm{h}_2(\mathbb{H})\) is 6d Minkowski spacetime, and
  \(\mathbb{HP}^1\) is the heavenly sphere \(S^4\);
\item
  \(\mathrm{h}_2(\mathbb{O})\) is 10d Minkowski spacetime, and
  \(\mathbb{OP}^1\) is the heavenly sphere \(S^8\).
\end{itemize}

Secondly, it follows that the determinant-preserving linear
transformations of \(\mathrm{h}_2(\mathbb{K})\) form a group isomorphic
to \(\mathrm{O}(n+1,1)\). How can we find some transformations of this
sort? For \(\mathbb{K}=\mathbb{R}\), it's easy: when \(g\) lies in
\(\mathrm{SL}(2,\mathbb{R})\) and \(x\) is in
\(\mathrm{h}_2(\mathbb{R})\), we have \(gxg^*\) in
\(\mathrm{h}_2(\mathbb{R})\) again, and \[\det(gxg*) = \det(x).\] This
gives a homomorphism from \(\mathrm{SL}(2,\mathbb{R})\) to
\(\mathrm{O}(2,1)\). It's easy to see that this makes
\(\mathrm{SL}(2,\mathbb{R})\) into a double cover of the Lorentz group
\(\mathrm{SO}_0(2,1)\). The exact same construction works for
\(\mathbb{K}=\mathbb{C}\), so \(\mathrm{SL}(2,\mathbb{C})\) is a double
cover of the Lorentz group \(\mathrm{SO}_0(3,1)\) --- which you probably
knew already, if you made it this far!

For the other two normed division algebras the above calculation
involving determinants breaks down, and it even becomes tricky to define
the group \(\mathrm{SL}(2,\mathbb{K})\), so we'll start by working at
the Lie algebra level. We say a \(2\times2\) matrix with entries in the
normed division algebra \(\mathbb{K}\) is ``traceless'' if the sum of
its diagonal entries is zero. Any such traceless matrix acts as a
real-linear operator on \(\mathbb{K}^2\). When \(\mathbb{K}\) is
commutative and associative, the space of operators coming from
\(2\times2\) traceless matrices with entries in \(\mathbb{K}\) is closed
under commutators, but otherwise it is not, so we'll define
\(\mathfrak{sl}(2,\mathbb{K})\) to be the Lie algebra of operators on
\(\mathbb{K}^2\) \emph{generated} by operators of this form. This Lie
algebra in turn generates a Lie group of real-linear operators on
\(\mathbb{K}^2\), which we call \(\mathrm{SL}(2,\mathbb{K})\).

Now, \(\mathfrak{sl}(2,\mathbb{K})\) has an obvious representation on
\(\mathbb{K}^2\), called the ``fundamental representation''. If we
tensor this representation with its dual we get a representation of
\(\mathfrak{sl}(2,\mathbb{K})\) on the space of \(2\times2\) matrices
with entries in \(\mathbb{K}\), which is given by
\[a\colon x \mapsto ax + xa^*\] whenever \(a\) is actually a
\(2\times2\) traceless matrix with entries in \(\mathbb{K}\). Since
\(ax + xa^*\) is hermitian whenever \(x\) is, this representation
restricts to a representation of \(\mathfrak{sl}(2,\mathbb{K})\) on
\(\mathrm{h}_2(\mathbb{K})\). This in turn gives a rep of the group
\(\mathrm{SL}(2,\mathbb{K})\). A little calculation at the Lie algebra
level shows that this action of \(\mathrm{SL}(2,\mathbb{K})\) on
\(\mathrm{h}_2(\mathbb{K})\) preserves the determinant, so we have a
homomorphism \[\mathrm{SL}(2,\mathbb{K}) \to \mathrm{SO}_0(n+1,1).\]
This is two-to-one and onto, so it follows pretty easily that:

\begin{itemize}
\tightlist
\item
  \(\mathrm{SL}(2,\mathbb{R})\) is the double cover of the Lorentz group
  \(\mathrm{SO}_0(2,1)\);
\item
  \(\mathrm{SL}(2,\mathbb{C})\) is the double cover of the Lorentz group
  \(\mathrm{SO}_0(3,1)\);
\item
  \(\mathrm{SL}(2,\mathbb{H})\) is the double cover of the Lorentz group
  \(\mathrm{SO}_0(5,1)\);
\item
  \(\mathrm{SL}(2,\mathbb{O})\) is the double cover of the Lorentz group
  \(\mathrm{SO}_0(9,1)\).
\end{itemize}

and thus:

\begin{itemize}
\tightlist
\item
  \(\mathrm{SL}(2,\mathbb{R})\) acts as conformal transformations of the
  sphere \(S^1 = \mathbb{RP}^1\);
\item
  \(\mathrm{SL}(2,\mathbb{C})\) acts as conformal transformations of the
  sphere \(S^2 = \mathbb{CP}^1\);
\item
  \(\mathrm{SL}(2,\mathbb{H})\) acts as conformal transformations of the
  sphere \(S^4 = \mathbb{HP}^1\);
\item
  \(\mathrm{SL}(2,\mathbb{O})\) acts as conformal transformations of the
  sphere \(S^8 = \mathbb{OP}^1\).
\end{itemize}

In the complex case, these conformal transformations are often called
``Moebius transformations''. For more on the octonionic case, try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\tightlist
\item
  Corinne A. Manogue and Tevian Dray, ``Octonionic Moebius
  transformations'', \emph{Mod. Phys. Lett.} \textbf{A14} (1999)
  1243--1256, available as
  \href{https://arxiv.org/abs/math-ph/9905024}{\texttt{math-ph/9905024}}.
\end{enumerate}

To round off the story, it helps to bring in spinors:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{15}
\tightlist
\item
  Anthony Sudbery, ``Division algebras, (pseudo)orthogonal groups and
  spinors'', \emph{Jour. Phys.} \textbf{A17} (1984), 939--955.
\end{enumerate}

The fundamental rep of \(\mathrm{SL}(2,\mathbb{K})\) on \(\mathbb{K}^2\)
is secretly one of the spinor reps of the double cover of the Lorentz
group \(\mathrm{SO}_0(n+1,1)\). Moreover, we can get points on the
heavenly sphere from these spinors! This has been nicely explained by
Penrose in the complex case, but it works the same way for the other
normed division algebras. It goes like this:

Suppose \[\vert\psi\rangle = (x,y)\] is a unit spinor, i.e.~an element
of \(\mathbb{K}^2\) with norm one. Then \[
  \vert\psi\rangle\langle\psi\vert =
  \left(
    \begin{array}{cc}
      xx^*&xy^*
    \\yx^*&yy^*
    \end{array}
  \right)
\] is a projection in \(\mathrm{h}_2(\mathbb{K})\) which is not \(0\) or
\(1\) --- or in other words, a point on the heavenly sphere. If we
identify the heavenly sphere with \(\mathbb{KP}^1\), this point
corresponds to the line through the origin in \(\mathbb{K}^2\)
containing the spinor \(\vert\psi\rangle\).

To go further, I would want to say more about why this connection
between quantum logic, Lorentzian geometry, and spinors is interesting,
and what you can do with it. And then I would want to take everything
we've seen about \(\mathbb{OP}^1\) and \(\mathrm{h}_2(\mathbb{O})\) and
see how it fits inside the bigger, more interesting story of
\(\mathbb{OP}^2\) and \(\mathrm{h}_3(\mathbb{O})\). But alas, I'm
running out of steam here, so I'll just give you a little reading list
about the octonionic projective plane and the exceptional Jordan
algebra:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{19}
\item
  Hans Freudenthal, ``Zur ebenen Oktavengeometrie'', \emph{Indag. Math.}
  \textbf{15} (1953), 195--200.

  Hans Freudenthal, ``Beziehungen der \(\mathfrak{e}_7\) und
  \(\mathfrak{e}_8\) zur Oktavenebene'':

\begin{verbatim}
I, II, _Indag. Math._ **16** (1954), 218--230, 363--368.

III, IV, _Indag. Math._ **17** (1955), 151--157, 277--285.

V -- IX, _Indag. Math._ **21** (1959), 165--201, 447--474.

X, XI, _Indag. Math._ **25** (1963) 453--471, 472--487.
\end{verbatim}

  Hans Freudenthal, ``Lie groups in the foundations of geometry'',
  \emph{Adv. Math.} \textbf{1} (1964), 145--190.

  Hans Freudenthal, ``Oktaven, Ausnahmegruppen und Oktavengeometrie'',
  \emph{Geom. Dedicata} \textbf{19} (1985), 7--63.
\item
  Jacques Tits, ``Le plan projectif des octaves et les groupes de Lie
  exceptionnels'', \emph{Bull. Acad. Roy. Belg. Sci.} \textbf{39}
  (1953), 309--329.
\end{enumerate}

Jacques Tits, Le plan projectif des octaves et les groupes exceptionnels
\(\mathrm{E}_6\) et \(\mathrm{E}_7\), \emph{Bull. Acad. Roy. Belg. Sci.}
\textbf{40} (1954), 29--40.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{21}
\item
  Tonny A. Springer, ``The projective octave plane, I-II'', \emph{Proc.
  Koninkl. Akad. Wetenschap.} \textbf{A63} (1960), 74--101.

  Tonny A. Springer, ``On the geometric algebra of the octave planes,
  I-III'', \emph{Proc. Koninkl. Akad. Wetenschap.} \textbf{A65} (1962),
  413--451.
\item
  J. R. Faulkner and J. C. Ferrar, ``Exceptional Lie algebras and
  related algebraic and geometric structures'', \emph{Bull. London Math.
  Soc.} \textbf{9} (1977), 1--35.
\end{enumerate}

Finally, for a really good overview of Jordan algebras and related
things like ``Jordan pairs'' and ``Jordan triple systems'', try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{23}
\tightlist
\item
  Kevin McCrimmon, ``Jordan algebras and their applications'', \emph{AMS
  Bulletin} \textbf{84} (1978), 612--627.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week163}{%
\section{December 31, 2000}\label{week163}}

If you think numbers start with the number 1, you probably think the
millennium is ending now. I think it ended last year\ldots{} but either
way, now is a good time to read this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Georges Ifrah, \emph{The Universal History of Numbers from Prehistory
  to the Invention of the Computer}, Wiley, New York, 2000.
\end{enumerate}

On the invention of zero:

\begin{quote}
Most peoples throughout history failed to discover the rule of position,
which was discovered in fact only four times in the history of the
world. (The rule of position is the principle in which a 9, let's say,
has a different magnitude depending on whether it comes in first,
second, third\ldots{} position in a numerical expression.) The first
discovery of this essential tool of mathematics was made in Babylon in
the second millennium BCE. It was then rediscovered by the Chinese
arithmeticians at around the start of the Common Era. In the third to
fifth centuries CE, Mayan astronomers reinvented it, and in the fifth
century CE it was rediscovered for the last time, in India.

Obviously, no civilization outside of these four ever felt the need to
invent zero; but as soon as the rule of position became the basis for a
numbering system, a zero was needed. All the same, only three of the
four (the Babylonians, the Mayans, and the Indians) managed to develop
this final abstraction of number; the Chinese only acquired it through
Indian influences. However, the Babylonian and Mayan zeroes were not
conceived of as numbers, and only the Indian zero had roughly the same
potential as the one we use nowadays. That is because it is indeed the
Indian zero, transmitted to us through the Arabs together with the
number-symbols that we call Arabic numerals and which are in reality
Indian numerals, with their appearance altered somewhat by time, use and
travel.
\end{quote}

Among other things, this book has wonderful charts showing the
development of each numeral. You can see, for example, how the primitive
numeral

\begin{verbatim}
                          ____
                          ____
                          ____
\end{verbatim}

slowly evolved to our modern ``3''. Hmm --- how come this doesn't feel
like progress?

Now, I usually keep my eyes firmly focused on the beauties of nature,
but once in a millennium I feel the need to engage in some politics.
So\ldots.

In \protect\hyperlink{week155}{``Week 155''} I talked a lot about
polyhedra and their 4-dimensional generalizations, and I referred to
Eric Weisstein's online math encyclopedia since it had lots of nice
pictures. Now this website has been closed down, thanks to a lawsuit by
the people at CRC Press:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Frequently asked questions about the MathWorld case,
  \texttt{http://mathworld.wolfram.com/docs/faq.html}
\end{enumerate}

Weisstein published a print version of his encyclopedia with CRC press,
but now they claim to own the rights to the online version as well. So I
urge you all to remember this: \emph{when dealing with publishers, never
sign away the electronic rights on your work unless you're willing to
accept the consequences!}

For example, suppose you write a math or physics paper and put it on the
preprint archive, and then publish it in a journal. They'll probably
send you a little form to sign where you hand over the rights to this
work --- including the electronic rights. If you're like most people,
you'll sign this form without reading it. This means that if they feel
like it, they can now sue you to make you take your paper off the
preprint archive! Journals don't do this yet, but as they continue
becoming obsolete and keep fighting ever more desperately for their
lives, there's no telling what they'll do. Corporations everywhere are
taking an increasingly aggressive line on intellectual property rights
--- as the case of Weisstein shows.

So what can you do? Simple: don't agree to it. When you get this form,
cross out any sentences you refuse to agree to, put your initials by
these deletions, and sign the thing --- indicating that you agree to the
\emph{other} stuff! Keep a copy. If they complain, ask them how much
these electronic rights are worth.

Basically, I think it's time for academics to take more responsibility
about keeping their work easily accessible.

There are lots of things you can do. One of the easiest is to stop
refereeing for ridiculously expensive journals. Journal prices bear
little relation to the quality of service they provide. For example, the
Elsevier-published journal ``\emph{Nuclear Physics B}'' costs \$12,596
per year for libraries, or \$6,000 for a personal subscription. The
comparable journal ``Advances in Theoretical and Mathematical Physics''
costs \$300 for libraries or \$80 for a personal subscription --- and
access to the electronic version is free. So when Nuclear Physics B asks
me to referee manuscripts, I now say ``Sorry, I'll wait until your
prices go down.''

In fact, I no longer referee articles for any journals published by
Elsevier, Kluwer, or Gordon \& Breach. If you've looked at their prices,
you'll know why. G\&B has even taken legal action against the American
Institute of Physics, the American Physical Society, and the American
Mathematical Society for publishing information about journal prices!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\item
  Gordon and Breach et al v. AIP and APS, brief of amici curiae of the
  American Library Association, Association of Research Libraries and
  the Special Library Association,
  \texttt{http://www.arl.org/scomm/gb/amici.html}
\item
  AIP/APS prevail in suit by Gordon and Breach, G\&B to appeal,
  \texttt{http://www.arl.org/newsltr/194/gb.html}
\end{enumerate}

Of course, the ultimate solution is to support the math and physics
preprint archives, and figure out ways to decouple the refereeing
process from the distribution process.

Okay, enough politics. I was thinking about \(4\)-dimensional polytopes,
and Eric Weisstein's now-defunct website\ldots{} but what got me going
in the first place was this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  John Stilwell, ``The story of the 120-cell'', \emph{AMS Notices}
  \textbf{48} (January 2001), 17--24.
\end{enumerate}

The 120-cell is a marvelous \(4\)-dimensional shape with 120 regular
dodecahedra as faces. I talked about it in
\protect\hyperlink{week155}{``Week 155''}, but this article is full of
additional interesting information. For example, Henri Poincare once
conjectured that every compact 3-manifold with the same homology groups
as a 3-sphere must \emph{be} a 3-sphere. He later proved himself wrong
by finding a counterexample: the ``Poincare homology 3-sphere''. This is
obtained by identifying the opposite faces of the dodecahedron in the
simplest possible way. What I hadn't known is that the fundamental group
of this space is the ``binary icosahedral group'', \(I\). This is the
120-element subgroup of \(\mathrm{SU}(2)\) consisting of all elements
that map to rotational symmetries of the icosahedron under the
two-to-one map from \(\mathrm{SU}(2)\) to \(\mathrm{SO}(3)\). Now
\(\mathrm{SU}(2)\) is none other than the 3-sphere\ldots{} so it follows
that \(\mathrm{SU}(2)/I\) is the Poincare homology 3-sphere!

When cosmologists study the possility that universe is finite in size,
they usually assume that space is a 3-sphere. In this scenario, barring
sneaky tricks, it's likely that the universe would recollapse before
light could get all the way around the universe. But there's no strong
reason to favor this topology. Some people have checked to see whether
space is a \(3\)-dimensional torus. In such a universe, light might wrap
all the way around --- so you might see the same bright quasars by
looking in various different directions! People have looked for this
effect but not seen it. This doesn't rule out a torus-shaped universe,
but it puts a limit on how small it could be.

In fact, some physicists have even considered the possibility that space
is a Poincare homology 3-sphere! Can light go all the way around in this
case? I don't know. If so, we might see bright quasars in a pretty
dodecahedral pattern.

Amusingly, Plato hinted at something resembling this in his ``Timaeus'':

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Plato, ``Timaeus'', translated by B. Jowett, in \emph{The Collected
  Dialogues}, Princeton U. Press, Princeton, 1969 (see line 55c).
\end{enumerate}

This dialog is one the first attempts at doing mathematical physics. In
it, the Socrates character guesses that the four elements earth, air,
water and fire are made of atoms shaped like four of the five Platonic
solids: cubes, octahedra, icosahedra and tetrahedra, respectively. Why?
Well, fire obviously feels hot because of those pointy little tetrahedra
poking you! Water is liquid because of those round little icosahedra
rolling around. Earth is solid because of those little cubes packing
together so neatly. And air\ldots{} well, ahem\ldots{} we'll get back to
you on that one.

\emph{But what about the dodecahedron?} On this topic, Plato makes only
the following cryptic remark: ``There was yet a fifth combination which
God used in the delineation of the universe with figures of animals.''

Huh??? I think this is a feeble attempt to connect the 12 sides of the
dodecahedron to the 12 signs of the zodiac. After all, lots of the signs
of the zodiac are animals. The word ``zodiac'' comes from the Greek
phrase ``zodiakos kuklos'', or ``circle of carved figures'' --- where
``zodiakos'' or ``carved figure'' is really the diminutive of ``zoion'',
meaning ``animal''. There may even be a connection between the
dodecahedron and the ``quintessence'': the fifth element, of which the
heavenly bodies were supposedly made. I know, this is all pretty weird,
but there seems to be some tantalizingly murky connection between the
dodecahedron and the heavens in Greek cosmology\ldots. so it would be
cool if space turned out to be a Poincare homology 3-sphere. But of
course, there's no reason to believe it is.

Okay, enough goofing around. Now let me talk a bit about the exceptional
Jordan algebra and the octonionic projective plane. I'll basically pick
up where I left off in \protect\hyperlink{week162}{``Week 162''} --- but
you might want to reread \protect\hyperlink{week61}{``Week 61''},
\protect\hyperlink{week106}{``Week 106''} and
\protect\hyperlink{week145}{``Week 145''} to prepare yourself for the
weirdness to come. Also, keep in mind the following three facts about
the number 3, which fit together in a spooky sort of synergy that makes
all the magic happen:

\begin{enumerate}
\def\labelenumi{\roman{enumi})}
\item
  An element of \(\mathrm{h}_3(\mathbb{O})\) is a \(3\times3\) hermitian
  matrix with octonionic entries, and thus consists of 3 octonions and 3
  real numbers: \[
     \left(
       \begin{array}{ccc}
         a&z^*&y^*
       \\z&b&x
       \\y&x^*&c
       \end{array}
     \right)
     \qquad\mbox{($a,b,c$ in $\mathbb{R}$, $x,y,z$ in $\mathbb{O}$.)}
   \]
\item
  The octonions arise naturally from ``triality'': the relation between
  the three \(8\)-dimensional irreps of \(\mathrm{Spin}(8)\), i.e.~the
  vector representation \(V_8\), the right-handed spinor representation
  \(S_8^+\), and the left-handed spinor representation \(S_8^-\).
\item
  The associative law \((xy)z = x(yz)\) involves 3 variables.
\end{enumerate}

Let's see how it goes.

First, if we take the 3 octonions in our element of
\(\mathrm{h}_3(\mathbb{O})\) and identify them with elements of the
three \(8\)-dimensional irreps of \(\mathrm{Spin}(8)\), we get
\[\mathrm{h}_3(\mathbb{O}) = \mathbb{R}^3\oplus V_8\oplus S_8^+\oplus S_8^-.\]
A little calculation then reveals a wonderful fact: while superficially
the Jordan product in \(\mathrm{h}_3(\mathbb{O})\) is built using the
structure of \(\mathbb{O}\) as a normed division algebra, it can
actually be defined using just the natural map
\[t\colon V_8\times S_8^+\times S_8^-\to\mathbb{R}\] and the inner
products on these 3 spaces. It follows that any element of
\(\mathrm{Spin}(8)\) gives an automorphism of
\(\mathrm{h}_3(\mathbb{O})\). Indeed, \(\mathrm{Spin}(8)\) becomes a
subgroup of \(\mathrm{Aut}(\mathrm{h}_3(\mathbb{O}))\).

So the exceptional Jordan algebra has a lot to do with geometry in 8
dimensions --- that's not surprising. What's surprising is that it also
has a lot to do with geometry in 9 dimensions! When we restrict the
spinor and vector representations of \(\mathrm{Spin}(9)\) to the
subgroup \(\mathrm{Spin}(8)\), they split as follows: \[
  \begin{aligned}
    S_9 &= S_8^+\oplus S_8^-
  \\V_9 &= \mathbb{R}\oplus V_8
  \end{aligned}
\] This gives an isomorphism
\[\mathrm{h}_3(\mathbb{O}) = \mathbb{R}^2\oplus V_9\oplus S_9\] and in
fact the product in \(\mathrm{h}_3(\mathbb{O})\) can be described in
terms of natural maps involving scalars, vectors and spinors in 9
dimensions. It follows that \(\mathrm{Spin}(9)\) is also a subgroup of
\(\mathrm{Aut}(\mathrm{h}_3(\mathbb{O}))\).

This does not exhaust all the symmetries of
\(\mathrm{h}_3(\mathbb{O})\), since there are other automorphisms coming
from the permutation group on 3 letters, which acts on \((a,b,c)\) in
\(\mathbb{R}^3\) and \((x,y,z)\) in \(\mathbb{O}^3\) in an obvious way.
Also, any matrix \(g\) in the orthogonal group \(\mathrm{O}(3)\) acts by
conjugation as an automorphism of \(\mathrm{h}_3(\mathbb{O})\); since
the entries of \(g\) are real, there is no problem with nonassociativity
here. The group \(\mathrm{Spin}(9)\) is 36-dimensional, but the full
automorphism group \(\mathrm{h}_3(\mathbb{O})\) is 52-dimensional. In
fact, it is the exceptional Lie group \(\mathrm{F}_4\)!

However, we can already do something interesting with the automorphisms
we have: we can use them to diagonalize any element of
\(\mathrm{h}_3(\mathbb{O})\). To see this, first note that the rotation
group, and thus \(\mathrm{Spin}(9)\), acts transitively on the unit
sphere in the vector representation \(V_9\). This means we can use an
automorphism in our \(\mathrm{Spin}(9)\) subgroup to bring any element
of \(\mathrm{h}_3(\mathbb{O})\) to the form \[
  \left(
    \begin{array}{ccc}
      a&z^*&y^*
    \\z&b&x
    \\y&x^*&c
    \end{array}
  \right)
\] where \(x\) is \emph{real}. The next step is to apply an automorphism
that makes \(y\) and \(z\) real while leaving \(x\) alone. To do this,
note that the subgroup of \(\mathrm{Spin}(9)\) fixing any nonzero vector
in \(V_9\) is isomorphic to \(\mathrm{Spin}(8)\). When we restrict the
representation \(S_9\) to this subgroup it splits as
\(S_8^+\oplus S_8^-\), and with some work one can show that
\(\mathrm{Spin}(8)\) acts on \(S_8^+\oplus S_8^- = \mathbb{O}^2\) in
such a way that any element \((y,z)\) in \(\mathbb{O}^2\) can be carried
to an element with both components real. The final step is to take our
element of \(\mathrm{h}_3(\mathbb{O})\) with all real entries and use an
automorphism to diagonalize it. We can do this by conjugating it with a
suitable matrix in \(\mathrm{O}(3)\).

To understand the octonionic projective plane, we need to understand
projections in \(\mathrm{h}_3(\mathbb{O})\). Here is where our ability
to diagonalize matrices in \(\mathrm{h}_3(\mathbb{O})\) via
automorphisms comes in handy. Up to automorphism, every projection in
\(\mathrm{h}_3(\mathbb{O})\) looks like one of these four guys: \[
  \begin{gathered}
    p_0 =
    \left(
      \begin{array}{ccc}
        0&0&0\\0&0&0\\0&0&0
      \end{array}
    \right)
    \qquad\qquad
    p_1 =
    \left(
      \begin{array}{ccc}
        1&0&0\\0&0&0\\0&0&0
      \end{array}
    \right)
  \\p_2 =
    \left(
      \begin{array}{ccc}
        1&0&0\\0&1&0\\0&0&0
      \end{array}
    \right)
    \qquad\qquad
    p_3 =
    \left(
      \begin{array}{ccc}
        1&0&0\\0&1&0\\0&0&1
      \end{array}
    \right)
  \end{gathered}
\]

Now, the trace of a matrix in \(\mathrm{h}_3(\mathbb{O})\) is invariant
under automorphisms, because we can define it using only the Jordan
algebra structure:
\[\operatorname{tr}(a) = \frac13 \operatorname{tr}(L_a)\] where \(L_a\)
is left multiplication by \(a\). It follows that the trace of any
projection in \(\mathrm{h}_3(\mathbb{O})\) is \(0\), \(1\), \(2\), or
\(3\).

Remember from \protect\hyperlink{week162}{``Week 162''} that the
``dimension'' of a projection \(p\) in a formally real Jordan algebra is
the largest number \(d\) such that there's a chain of projections
\[p_0<p_1<\ldots<p_d=p.\] In favorable cases, like the exceptional
Jordan algebra, the dimension-1 projections become the points of a
projective plane, while the dimension-2 projections become the lines.
But what's a practical way to compute the dimension of a projection?
Well, in \(\mathrm{h}_3(\mathbb{O})\) the dimension equals the trace.

Why?

Well, clearly the dimension is less than or equal to the trace, since
\(p < q\) implies \(\operatorname{tr}(p) < \operatorname{tr}(q)\), and
the trace goes up by integer steps. But on the other hand, the trace is
less than or equal to the dimension. To see this it suffices to consider
the four projections shown above, since both trace and dimension are
invariant under automorphisms. Since \(p_0< p_1 < p_2 < p_3\), it is
clear that for these projections the trace is indeed less than or equal
to the rank.

So: the points of the octonionic projective plane are the projections
with trace \(1\) in \(\mathrm{h}_3(\mathbb{O})\), while the lines are
projections with trace \(2\). A brutal calculation in Reese Harvey's
book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  F. Reese Harvey, \emph{Spinors and Calibrations}, Academic Press,
  Boston, 1990.
\end{enumerate}

reveals that any projection with trace 1 has the form \[
  \vert\psi\rangle\langle\psi\vert =
  \left(
    \begin{array}{ccc}
      xx^*&xy^*&xz^*
    \\yx^*&yy^*&yz^*
    \\zx^*&zy^*&zz^*
    \end{array}
  \right)
\] where \[\vert\psi\rangle = (x,y,z)\] is a unit vector in
\(\mathbb{O}^3\) for which \((xy)z = x(yz)\). This is supposed to remind
you of stuff about spinors and the heavenly sphere in
\protect\hyperlink{week162}{``Week 162''}.

On the other hand, any projection with trace \(2\) is of the form
\(1-p\) where \(p\) has trace \(1\). This sets up a one-to-one
correspondence between points and lines in the octonionic projective
plane. If we use this correspondence to think of both as trace-\(1\)
projections, the point \(p\) lies on the line \(q\) if and only if
\(p < 1 - q\). Of course, \(p < 1 - q\) iff \(q < 1 - p\). The symmetry
of this relation means the octonionic projective plane is self-dual!
This is also true of the real, complex and quaternionic projective
planes. In all cases, the operation that switches points and lines
corresponds in quantum logic to ``negation''.

Let's use \(\mathbb{OP}^2\) to stand for the set of points in the
octonionic projective plane. Given any nonzero element \((x,y,z)\) in
\(\mathbb{O}^3\) with \((xy)z = x(yz)\), we can normalize it and then
use the above formula to obtain a point of \(\mathbb{OP}^2\), which we
call \([(x,y,z)]\). We can make \(\mathbb{OP}^2\) into a smooth manifold
by covering it with three coordinate charts: one containing all points
of the form \([(x,y,1)]\), one containing all points of the form
\([(x,1,z)]\), and one containing all points of the form \([(1,y,z)]\).
Checking that this works is a simple calculation. The only interesting
part is to make sure that whenever the associative law might appear
necessary, we can either use the weaker equations \[
  \begin{aligned}
    (xx)y &= x(xy) 
  \\(xy)x &= x(yx)
  \\(yx)x &= y(xx)
  \end{aligned}
\] which still hold for the octonions, or else the fact that only
triples with \((xy)z = x(yz)\) give points \([(x,y,z)]\) in
\(\mathbb{OP}^2\).

Clearly the manifold \(\mathbb{OP}^2\) is \(16\)-dimensional. The lines
in \(\mathbb{OP}^2\) are copies of \(\mathbb{OP}^1\), and thus
8-spheres. It is also good to work out the space of lines going through
any point. Here we can use self-duality: since the space of all points
lying on any given line is a copy of \(\mathbb{OP}^1\), so is the space
of all lines on which a given point lies! So the space of lines through
a point is also an 8-sphere. Everything is very pretty.

If we give \(\mathbb{OP}^1\) the nicest possible metric, its isometry
group is \(\mathrm{F}_4\): just the automorphism group of the
exceptional Jordan algebra. However, the group of ``collineations'' ---
i.e., line-preserving transformations - is a form of the 78-dimensional
exceptional Lie group \(\mathrm{E}_6\). From stuff explained last week,
the subgroup of collineations that map a point \(p\) to itself and also
map the line \(1 - p\) to itself is isomorphic to
\(\mathrm{Spin}(9,1)\). This gives a nice embedding of
\(\mathrm{Spin}(9,1)\) in this form of \(\mathrm{E}_6\). So the
octonionic projective plane is also related to \(10\)-dimensional
\emph{spacetime} geometry.

I hope I've got that last part right\ldots. ultimately, this is supposed
to explain why various different theories of physics formulated in 10d
spacetime wind up being related to the exceptional Lie groups! But I'm
afraid that so far, I'm just struggling to understand the basic
geometry.

Happy New Year!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week164}{%
\section{January 13, 2001}\label{week164}}

What are the top ten questions for physics in this millennium? The
participants of the conference Strings 2000 chose these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Are all the (measurable) dimensionless parameters that characterize
  the physical universe calculable in principle or are some merely
  determined by historical or quantum mechanical accident and
  uncalculable?
\item
  How can quantum gravity help explain the origin of the universe?
\item
  What is the lifetime of the proton and how do we understand it?
\item
  Is Nature supersymmetric, and if so, how is supersymmetry broken?
\item
  Why does the universe appear to have one time and three space
  dimensions?
\item
  Why does the cosmological constant have the value that it has, is it
  zero and is it really constant?
\item
  What are the fundamental degrees of freedom of M-theory (the theory
  whose low-energy limit is eleven-dimensional supergravity and which
  subsumes the five consistent superstring theories) and does the theory
  describe Nature?
\item
  What is the resolution of the black hole information paradox?
\item
  What physics explains the enormous disparity between the gravitational
  scale and the typical mass scale of the elementary particles?
\item
  Can we quantitatively understand quark and gluon confinement in
  Quantum Chromodynamics and the existence of a mass gap?
\end{enumerate}

For details see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Physics problems for the next millennium,
  \texttt{http://feynman.physics.lsa.umich.edu/strings2000/millennium.html}
\end{enumerate}

I think most of these questions are pretty good if one limits physics to
mean the search for new fundamental laws, rather than interesting
applications of the laws we know. I would leave out question 7, since
it's too concerned with a particular theory, rather than the physical
world itself. I'd instead prefer to ask: ``What physics underlies the
Standard Model gauge group
\(\mathrm{SU}(3)\times\mathrm{SU}(2)\times\mathrm{U}(1)\)?''

Of course, this business of limiting ``physics'' to mean ``the search
for fundamental laws'' annoys condensed matter physicists like Philipp
Anderson, since it excludes everything they work on. He writes:

\begin{quote}
My colleagues in the fashionable fields of string theory and quantum
gravity advertise themselves as searching desperately for the 'Theory of
Everything``, while their experimental colleagues are gravid with
the''God Particle``, the marvelous Higgson which is the somewhat
misattributed source of all mass. (They are also after an understanding
of the earliest few microseconds of the Big Bang.) As Bill Clinton might
remark, it depends on what the meaning of''everything" is. To these
savants, ``everything'' means a list of some two dozen numbers which are
the parameters of the Standard Model. This is a set of equations which
already exists and does describe very well what you and I would be
willing to settle for as ``everything''. This is why, following Bob
Laughlin, I make the distinction between ``everything'' and ``every
thing''. Every thing that you and I have encountered in our real lives,
or are likely to interact with in the future, is no longer outside of
the realm of a physics which is transparent to us: relativity, special
and general; electromagnetism; the quantum theory of ordinary, usually
condensed, matter; and, for a few remote phenomena, hopefully rare here
on earth, our almost equally cut-and-dried understanding of nuclear
physics. {[}Two parenthetic remarks: 1) I don't mention statistical
mechanics only because it is a powerful technique, not a body of facts;
2) our colleagues have done only a sloppy job so far of deriving nuclear
physics from the Standard Model, but no one really doubts that they
can.{]}

I am not arguing that the search for the meaning of those two dozen
parameters isn't exciting, interesting, and worthwhile: yes, it's not
boring to wonder why the electron is so much lighter than the proton, or
why the proton is stable at least for another 35 powers of ten years, or
whether quintessence exists. But learning why can have no real effect on
our lives, spiritually inspiring as it would indeed be, even to a
hardened old atheist like myself.
\end{quote}

For the rest of his remarks, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  What questions have disappeared?, The World Question Center,
  \texttt{http://www.edge.org/documents/questions/q2001.html}
\end{enumerate}

Personally, I would be wary of asserting that a piece of knowledge ``can
have no real effect on our lives'' unless we are limiting the discussion
to short-term effects --- not the next millennium. But I don't think
physics should be construed to mean only the search for ``fundamental
laws''. That neglects too much fun stuff! It would be nice to see the
condensed matter theorists' list of problems for the next millennium,
for example.

On to something a bit more mathematical\ldots.

Careful readers of This Week's Finds will remember Diarmuid Crowley from
\protect\hyperlink{week151}{``Week 151''}. This week he visited U. C.
Riverside and talked about the topology of 7- and \(15\)-dimensional
manifolds. He also told me the following cool things.

You may recall from \protect\hyperlink{week163}{``Week 163''} that the
Poincare homology 3-sphere is a compact 3-manifold that has the same
homology groups as the ordinary 3-sphere, but is not homeomorphic to the
3-sphere. I explained how this marvelous space can be obtained as the
quotient of \(\mathrm{SU}(2) = S^3\) by a 120-element subgroup --- the
double cover of the symmetry group of the dodecahedron. Even better, the
points in \(S^3\) which lie in this subgroup are the centers of the
faces a 4d regular polytope with 120 dodecahedral faces. That's pretty
cool. But here's another cool way to get the Poincare homology sphere:

\(\mathrm{E}_8\) is the biggest of the exceptional Lie groups. As I
explained in \protect\hyperlink{week64}{``Week 64''}, the Dynkin diagram
of this group looks like this: \[
  \begin{tikzpicture}[rotate=180]
    \draw[thick] (0,0) node{$\bullet$} to (1,0) node{$\bullet$} to (2,0) node{$\bullet$} to (3,0) node {$\bullet$} to (4,0) node {$\bullet$} to (5,0) node {$\bullet$} to (6,0) node {$\bullet$};
    \draw[thick] (2,0) to (2,1) node{$\bullet$};
  \end{tikzpicture}
\] Now, make a model of this diagram by linking together 8 rings: \[
  \begin{tikzpicture}
    \begin{knot}[clip width=7]
      \strand[thick] (0,0)
        to [out=left,in=left,looseness=1.75] (0,1)
        to [out=right,in=right,looseness=1.75] (0,0);
      \strand[thick] (0.75,0)
        to [out=left,in=left,looseness=1.75] (0.75,1)
        to [out=right,in=right,looseness=1.75] (0.75,0);
      \strand[thick] (1.5,0)
        to [out=left,in=left,looseness=1.75] (1.5,1)
        to [out=right,in=right,looseness=1.75] (1.5,0);
      \strand[thick] (2.25,0)
        to [out=left,in=left,looseness=1.75] (2.25,1)
        to [out=right,in=right,looseness=1.75] (2.25,0);
      \strand[thick] (3,0)
        to [out=left,in=left,looseness=1.75] (3,1)
        to [out=right,in=right,looseness=1.75] (3,0);
      \strand[thick] (3.75,0)
        to [out=left,in=left,looseness=1.75] (3.75,1)
        to [out=right,in=right,looseness=1.75] (3.75,0);
      \strand[thick] (4.5,0)
        to [out=left,in=left,looseness=1.75] (4.5,1)
        to [out=right,in=right,looseness=1.75] (4.5,0);
      \flipcrossings{1,3,5,7,9,11}
      \strand[thick] (3,-0.8)
        to [out=left,in=left,looseness=1.75] (3,0.2);
    \end{knot}
    \begin{knot}
      \strand[thick] (3,0.2)
        to [out=right,in=right,looseness=1.75] (3,-0.8);
    \end{knot}
  \end{tikzpicture}
\] Imagine this model as living in \(S^3\). Next, hollow out all these
rings: actually delete the portion of space that lies inside them! We
now have a 3-manifold \(M\) whose boundary \(\partial M\) consists of 8
connected components, each a torus. Of course, a solid torus also has a
torus as its boundary. So attach solid tori to each of these 8
components of \(\partial M\), but do it via this attaching map:
\[(x,y) \mapsto (y,-x+2y)\] where \(x\) and \(y\) are the obvious
coordinates on the torus, numbers between \(0\) and \(2\pi\), and we do
the arithmetic \(\mod 2\pi\). We now have a new 3-manifold without
boundary\ldots{} and this is the Poincare homology sphere.

We see here a strange and indirect connection between \(\mathrm{E}_8\)
and the dodecahedron. This is not the only such connection! There's also
the ``McKay correspondence'' (see \protect\hyperlink{week65}{``Week
65''}) and a way of getting the \(\mathrm{E}_8\) root lattice from the
``icosians'' (see \protect\hyperlink{week20}{``Week 20''}).

Are these three superficially different connections secretly just
different views of the same grand picture? I'm not sure. I think I'd
know the answer to part of this puzzle if I better understood the
relation between ADE theory and singularities.

But Diarmuid Crowley told me much more. The Poincare homology sphere is
actually the boundary of a 4-manifold, and it's not hard to say what
this 4-manifold is. I just gave you a recipe for cutting out 8 solid
tori from the 3-sphere and gluing them back in with a twist. Suppose we
think of 3-sphere as the boundary of the 4-disk \(D^4\), and think of
each solid torus as part of the boundary of a copy of
\(D^2 \times D^2\), using the fact that
\[\partial(D^2\times D^2) = S^1\times D^2 + D^2\times S^1.\] Then the
same recipe can be seen as instructions for gluing 8 copies of
\(D^2\times D^2\) to the 4-ball along part of their boundary, getting a
new 4-manifold with boundary. If you ponder it, you'll see that the
boundary of this 4-manifold is the Poincare homology 3-sphere.

Now, this is actually no big deal, at least for folks who know some
3-dimensional topology. But Crowley likes higher-dimensional topology,
and what he told me is this: the whole story generalizes to higher
dimensions! Instead of starting with this picture of linked 1-spheres in
the 3-sphere: \[
  \begin{tikzpicture}
    \begin{knot}[clip width=7]
      \strand[thick] (0,0)
        to [out=left,in=left,looseness=1.75] (0,1)
        to [out=right,in=right,looseness=1.75] (0,0);
      \strand[thick] (0.75,0)
        to [out=left,in=left,looseness=1.75] (0.75,1)
        to [out=right,in=right,looseness=1.75] (0.75,0);
      \strand[thick] (1.5,0)
        to [out=left,in=left,looseness=1.75] (1.5,1)
        to [out=right,in=right,looseness=1.75] (1.5,0);
      \strand[thick] (2.25,0)
        to [out=left,in=left,looseness=1.75] (2.25,1)
        to [out=right,in=right,looseness=1.75] (2.25,0);
      \strand[thick] (3,0)
        to [out=left,in=left,looseness=1.75] (3,1)
        to [out=right,in=right,looseness=1.75] (3,0);
      \strand[thick] (3.75,0)
        to [out=left,in=left,looseness=1.75] (3.75,1)
        to [out=right,in=right,looseness=1.75] (3.75,0);
      \strand[thick] (4.5,0)
        to [out=left,in=left,looseness=1.75] (4.5,1)
        to [out=right,in=right,looseness=1.75] (4.5,0);
      \flipcrossings{1,3,5,7,9,11}
      \strand[thick] (3,-0.8)
        to [out=left,in=left,looseness=1.75] (3,0.2);
    \end{knot}
    \begin{knot}
      \strand[thick] (3,0.2)
        to [out=right,in=right,looseness=1.75] (3,-0.8);
    \end{knot}
  \end{tikzpicture}
\] start with an analogous pattern of 8 \(n\)-spheres linked in the
\((2n+1)\)-sphere. Do all the same stuff, boosting the dimensions
appropriately\ldots{} and you'll get an interesting (2n+1)-dimensional
manifold \(\partial M\) which is the boundary of a (2n+2)-dimensional
manifold M.

When n is \emph{odd} and greater than 1, this manifold \(\partial M\) is
actually an ``exotic sphere''. In other words, it's homeomorphic but not
diffeomorphic to the usual sphere of dimension 2n+1.

Now, exotic spheres of a given dimension form an abelian group G under
connected sum (see \protect\hyperlink{week141}{``Week 141''}). This
group consists of two parts: the easy part and the hard part. The easy
part is a normal subgroup \(N\) consisting of the exotic spheres that
bound parallelizable smooth manifolds. The size of this subgroup can be
computed in terms of Bernoulli numbers and stuff like that. The hard
part is the quotient group \(G/N\). This is usually the cokernel of a
famous gadget called the ``\(J\)-homomorphism''. I say ``usually''
because this is known to be true in most dimensions, but in certain
dimensions it remains an open question.

Anyway: the easy part \(N\) is always a finite cyclic group, and this is
\emph{generated} by the exotic sphere \(\partial M\) that I just
described!

For example:

In dimension 7 we have \(G = N = \mathbb{Z}/28\), so there are 28 exotic
spheres in this dimension (up to orientation-preserving diffeomorphism),
and they are all connected sums of the exotic 7-sphere \(\partial M\)
formed by the above construction.

In dimension 11 we have \(G = N = \mathbb{Z}/992\), so there are 992
exotic spheres, and they are all connected sums of the exotic 11-sphere
\(\partial M\) formed by the above construction.

In dimension 15 we no longer have \(G = N\). Instead we have
\(N = \mathbb{Z}/8128\) and \(G = \mathbb{Z}/8128\oplus \mathbb{Z}/2\).
There are thus 16256 exotic spheres in this dimension, only half of
which are connected sums of the exotic 15-sphere \(\partial M\) formed
by the above construction.

And so on.

While we're on the subject of exotic 15-spheres, I can't resist
mentioning this. I explained in \protect\hyperlink{week141}{``Week
141''} how to construct a bunch of exotic 7-spheres (24 of them,
actually) using the quaternions. Once you understand this trick, it's
natural to wonder if you can construct exotic 15-spheres the same way,
but using octonions instead of quaternions. Well, you can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Nobuo Shimada, ``Differentiable structures on the 15-sphere and
  Pontrjagin classes of certain manifolds'', \emph{Nagoya Math. Jour.}
  \textbf{12} 1957, 59--69.
\end{enumerate}

I should also explain what I really like about the above stuff. In
topological quantum field theory, people like to get 3-manifolds by
``surgery on framed links''. The idea is to start with a framed link in
the 3-sphere, use the framing to thicken each component to an embedded
solid torus, cut out these solid tori, and reattach them ``the other
way'', using the fact that \(S^1\times S^1\) is the boundary of both
\(S^1\times D^2\) and \(D^2\times S^1\). We can get any compact oriented
3-manifold this way.

The above construction of the Poincare homology sphere was just an
example of this, where the link was \[
  \begin{tikzpicture}
    \begin{knot}[clip width=7]
      \strand[thick] (0,0)
        to [out=left,in=left,looseness=1.75] (0,1)
        to [out=right,in=right,looseness=1.75] (0,0);
      \strand[thick] (0.75,0)
        to [out=left,in=left,looseness=1.75] (0.75,1)
        to [out=right,in=right,looseness=1.75] (0.75,0);
      \strand[thick] (1.5,0)
        to [out=left,in=left,looseness=1.75] (1.5,1)
        to [out=right,in=right,looseness=1.75] (1.5,0);
      \strand[thick] (2.25,0)
        to [out=left,in=left,looseness=1.75] (2.25,1)
        to [out=right,in=right,looseness=1.75] (2.25,0);
      \strand[thick] (3,0)
        to [out=left,in=left,looseness=1.75] (3,1)
        to [out=right,in=right,looseness=1.75] (3,0);
      \strand[thick] (3.75,0)
        to [out=left,in=left,looseness=1.75] (3.75,1)
        to [out=right,in=right,looseness=1.75] (3.75,0);
      \strand[thick] (4.5,0)
        to [out=left,in=left,looseness=1.75] (4.5,1)
        to [out=right,in=right,looseness=1.75] (4.5,0);
      \flipcrossings{1,3,5,7,9,11}
      \strand[thick] (3,-0.8)
        to [out=left,in=left,looseness=1.75] (3,0.2);
    \end{knot}
    \begin{knot}
      \strand[thick] (3,0.2)
        to [out=right,in=right,looseness=1.75] (3,-0.8);
    \end{knot}
  \end{tikzpicture}
\] and each component had two twists in the framing as we go around, as
compared to the standard ``blackboard'' framing. This is why there was
that mysterious number ``2'' in my formula for the attaching map.

Whenever we describe a 3-manifold using ``surgery on framed links'' this
way, there's an important matrix where the entry in the \(i\)th row and
\(j\)th column is the linking number of the \(i\)th component and the
\(j\)th component of our framed link, with the diagonal entries standing
for the ``self-linking'' numbers of the components, that is, the number
of twists their framings have. This matrix is important because it also
describes the ``intersection form'' on the 2nd homology group of a
simply-connected 4-manifold \(M\) whose boundary \(\partial M\) is the
3-manifold we're describing.

For example, in the case of the Poincare homology sphere, this matrix is
called the \(\mathrm{E}_8\) Cartan matrix: \[
  \left(
    \begin{array}{rrrrrrrr}
      2&-1&0&0&0&0&0&0
    \\-1&2&-1&0&0&0&0&0 
    \\0&-1&2&-1&0&0&0&0 
    \\0&0&-1&2&-1&0&0&0 
    \\0&0&0&-1&2&-1&0&-1
    \\0&0&0&0&-1&2&-1&0
    \\0&0&0&0&0&-1&2&0 
    \\0&0&0&0&-1&0&0&2
    \end{array}
  \right)
\] The Dynkin diagram simply summarizes this matrix in pictorial form. I
already described the 4-manifold \(M\) whose boundary is the Poincare
homology sphere; now you know its intersection form.

Anyway, what I find exciting is that all this stuff generalizes to
higher dimensions if we restrict attention to manifolds that have
trivial homotopy groups up to a certain point! For example, it works for
compact oriented smooth 7-manifolds that have trivial \(\pi_1\) and
\(\pi_2\). Any such manifold can be obtained by doing surgery on some
framed 3-spheres embedded in \(S^7\). Just as 1-spheres can link in 3d
space since 1+1 is one less than 3, 3-spheres can link in 7d space since
3+3 is one less than 7. We again get a matrix of linking numbers. As
before, this matrix is also an intersection form: namely, the
intersection form on the 4th homology group of an 8-manifold M whose
boundary \(\partial M\) is the 7-manifold we're describing. Moreover,
this matrix is symmetric in both the 3-manifold example and the
7-manifold example, since it describes an intersection pairing on an
\emph{even-dimensional} homology group.

Even better, all the same stuff happens in manifolds with enough trivial
homotopy groups in dimension 11, and dimension 15\ldots{} and all
dimensions of the form \(4n-1\). And what's \emph{really} neat is that
these higher-dimensional generalizations are in some ways simpler than
the 3d story. The reason is that a 1-sphere can be knotted in 3-space in
really complicated ways, but the higher-dimensional generalizations do
not involve such complicated knotting. The framing aspects can be more
complicated, since there's more to framing an embedded sphere than just
an integer, but it's not all \emph{that} complicated.

So maybe I can learn some more 3d topology by first warming up with the
simpler 7d case\ldots.

Finally, I'd like to list a few articles that I've been meaning to read,
but haven't gotten around to. I hope to read them sometime \emph{this}
millennium! I'll quote the abstracts and make a few comments.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Jack Morava, ``Cobordism of symplectic manifolds and asymptotic
  expansions'', a talk at the conference in honor of S.P. Novikov's 60th
  birthday, available as
  \href{https://arxiv.org/abs/math.SG/9908070}{\texttt{math.SG/9908070}}.
\end{enumerate}

\begin{quote}
The cobordism ring of symplectic manifolds defined by V.L. Ginzburg is
shown to be isomorphic to the Pontrjagin ring of complex-oriented
manifolds with free circle actions. This suggests an interpretation of
the formal group law of complex cobordism, in terms of a composition-law
on semiclassical expansions. An appendix discusses related questions
about cobordism of toric varieties.
\end{quote}

I started trying to explain the relation between formal group laws and
complex oriented cohomology theories in
\protect\hyperlink{week150}{``Week 150''}, because I'm quite puzzled
about the deep inner meaning of this relation. This paper might be the
key to this mystery!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Detlev Buchholz, ``Current trends in axiomatic quantum field theory'',
  available as
  \href{https://arxiv.org/abs/hep-th/9811233}{\texttt{hep-th/9811233}}.
\end{enumerate}

\begin{quote}
In this article a non-technical survey is given of the present status of
Axiomatic Quantum Field Theory and interesting future directions of this
approach are outlined. The topics covered are the universal structure of
the local algebras of observables, their relation to the underlying
fields and the significance of their relative positions. Moreover, the
physical interpretation of the theory is discussed with emphasis on
problems appearing in gauge theories, such as the revision of the
particle concept, the determination of symmetries and statistics from
the superselection structure, the analysis of the short distance
properties and the specific features of relativistic thermal states.
Some problems appearing in quantum field theory on curved spacetimes are
also briefly mentioned.
\end{quote}

I've been falling behind on new developments in axiomatic quantum field
theory. Lots of cool stuff is happening, I hear. This might help me
catch up.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Matt Visser, ``The reliability horizon'', available as
  \href{https://arxiv.org/abs/gr-qc/9710020}{\texttt{gr-qc/9710020}}.
\end{enumerate}

\begin{quote}
The ``reliability horizon'' for semi-classical quantum gravity
quantifies the extent to which we should trust semi-classical quantum
gravity, and gives a handle on just where the ``Planck regime'' resides.
The key obstruction to pushing semi-classical quantum gravity into the
Planck regime is often the existence of large metric fluctuations,
rather than a large back-reaction.
\end{quote}

This seems like a very sensible enterprise: determining just where
semiclassical calculations are likely to break down, and quantum gravity
effects to become important. Why haven't I read this? It's obviously
worthwhile!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Bianca Letizia Cerchiai and Julius Wess, ``\(q\)-Deformed Minkowski
  Space based on a \(q\)-Lorentz Algebra'', available as
  \href{https://arxiv.org/abs/math.QA/9801104}{math.QA/9801104}.
\end{enumerate}

\begin{quote}
The Hilbert space representations of a non-commutative \(q\)-deformed
Minkowski space, its momenta and its Lorentz boosts are constructed. The
spectrum of the diagonalizable space elements shows a lattice-like
structure with accumulation points on the light-cone.
\end{quote}

The \(q\)-deformed Lorentz algebra plays a role in quantum gravity with
nonzero cosmological constant, but it also shows up in noncommutative
geometry. Are the two roles related? I don't know! This is on my list of
puzzles to ponder.

The people applying the \(q\)-deformed Lorentz algebra to noncommutative
geometry want to develop the theory of \(q\)-deformed Minkowski space,
see if it makes the infinities in quantum field theory go away, and see
what physical predictions it makes. It makes spacetime discrete in a
very pretty way; that I know from Julius Wess' talk in Schladming a few
years back (see \protect\hyperlink{week129}{``Week 129''}). But I should
learn more about this, and not just because Bianca Letizia Cerchiai is a
very nice person who invited my girlfriend and I to lunch at her
parents' apartment in Milan\ldots. oh, now I'm feeling \emph{terribly}
guilty for not reading her paper! How nasty of me! I'd better print it
out and read it as soon as I go into the office!

In fact, now that I think of it, I've had at least \emph{some} dealings
with \emph{all} the authors of these papers. And now I'm publicly
admitting I haven't read some of their most interesting papers! Ugh! At
least this admission may shame me into reading them now\ldots{}

Bye.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

On \texttt{sci.physics.research}, Aaron Bergman clarified something
about these millennial physics problems:

\begin{quote}
John Baez wrote:
\end{quote}

\begin{quote}
\begin{quote}
Aaron Bergman (abergman@Princeton.EDU) wrote:
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
John Baez wrote:
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
Of course, this business of limiting ``physics'' to mean ``the search
for fundamental laws'' annoys condensed matter physicists like Philipp
Anderson, since it excludes everything they work on.
\end{quote}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
One should note that Gross explicitly says --- there's a Realaudio of
the talk online --- that this is a very narrowminded list that excludes
fundamental questions in other fields. It's not really intended to be a
universal list.
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
Good! It's too bad the text of the webpage doesn't make that clearer.
I'm appending your comment to the version of ``week164'' on my website,
assuming you don't object.
\end{quote}
\end{quote}

\begin{quote}
Sure. Or you can just refer them to the transparencies and the talk. For
those who don't want to bother listening to the whole thing, start
listening at about 7:30 mins into the RealAudio stream:

http://feynman.physics.lsa.umich.edu/cgi-bin/s2ktalk.cgi?questions

It's on transparency 4 which is why I mentioned,
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
And Witten is coming back.
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
You mean he's not staying in LA? Can't take the winters out here?
\end{quote}
\end{quote}

\begin{quote}
I won't speculate on the reasons, but his grad students have said that
he's coming back to the Institute.

Aaron

--- Aaron Bergman
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week165}{%
\section{March 14, 2001}\label{week165}}

A few weeks ago I went to the University of Wisconsin at Milwaukee to
give some talks at their Center for Gravitation and Cosmology. They have
a group of 8 people working on data analysis for the LIGO experiment. As
you probably know, LIGO will use laser interferometry to look for
gravitational waves. It consists of two detectors, one near Livingston,
Louisiana, and one near Hanford, Washington. Each one is shaped like an
L, with each arm of the L consisting of a 4-kilometer-long evacuated
pipe with a laser beam running down it. A typical gravitational wave
might stretch one of the arms by \(10^{-16}\) centimeters --- one
hundred-millionth of the diameter of a hydrogen atom. It will be quite
exciting if they can actually get this level of precision. They're not
there yet, but already they can tell when wind-blown tumbleweeds pile up
along the pipe at the Hanford site, because their gravitational pull
bends the beam and messes things up!

In Milwaukee, it's a time of preparation and anticipation. The first
data should start coming in by September, but right now they're busy
writing software and assembling a ``Beowulf cluster''. This is a
parallel computer formed from a bunch of commercially available
processors, all running Linux. I'd heard about these before, because my
friend Dan Christensen is planning to do calculations in spin foam
models of quantum gravity on a Beowulf cluster over at the University of
Western Ontario. The cluster at Milwaukee will have 128 processors, each
with at least 1 gigaflop peak performance, and a total of 19 terabytes
of distributed disk memory.

You can learn more about this at their homepage:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  University of Wisconsin at Milwaukee, Center for Gravitation and
  Cosmology home page, \texttt{http://www.gravity.phys.uwm.edu/}
\end{enumerate}

For a nice popular account of the LIGO experiment, try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Marcia Bartusiak, \emph{Einstein's Unfinished Symphony: Listening to
  the Sounds of Space-Time}, Joseph Henry Press, Washington D.C., 2000.
\end{enumerate}

My host was at Milwaukee was John Friedman. I was surprised and pleased
to find that he was one of the people who discovered how to make
spin-\(1/2\) particles out of topological defects in spacetime!
Theoretically speaking, that is. I'd heard about this trick, but I never
knew where it came from:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  J. Friedman and R. Sorkin, ``Spin \(1/2\) from gravity'', \emph{Phys.
  Rev.~Lett.} \textbf{44} (1980), 1100.
\end{enumerate}

I was more familiar with a recent implementation of it in the framework
of loop quantum gravity, as mentioned in
\protect\hyperlink{week128}{``Week 128''}.

Friedman and Sorkin's trick was based on the idea of ``dyons''. I'd
never understood dyons, but Friedman explained them to me, and now the
idea seems so simple that I can't resist telling everyone.

To make a ``dyon'', just take a charged particle and a magnetic monopole
and tape them together with high-quality duct tape. You can buy all
these materials at your local hardware store\ldots{} though mine was out
of monopoles when I last checked.

Now, rotate your dyon. As you move the charged particle around the
monopole, it picks up a phase, thanks to the magnetic field.
Alternatively, as you move the monopole around charged particle, it
picks up a phase thanks to the electric field! Either way, you get the
same phase when you move one of these guys all the way around the other
--- and this phase has to be \(1\) or \(-1\) for well-known topological
reasons. If the phase is \(1\), your dyon is a boson. But if the phase
is \(-1\), your dyon is a fermion!

In short, this is a strange and interesting way to build fermions out of
components that are not themselves fermionic.

In Milwaukee, I gave a talk where I tried to explain the meaning of
Einstein's equation in simple English. There are a lot of books that
give simple explanations of curved spacetime, geodesics and so on.
Unfortunately, most of them don't explain the real meat of general
relativity: Einstein's equation. This bugs me, especially since it's not
so hard. If you're interested, take a look at this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  John Baez, ``The meaning of Einstein's equation'', available at
  \href{https://arxiv.org/abs/gr-qc/0103044}{\texttt{gr-qc/0103044}}.
\end{enumerate}

Since my Milwaukee trip I've become really busy writing notes on the
quantum gravity seminar here at Riverside. Toby Bartels and I have been
writing them up in the form of a rather silly dialog, and my student
Miguel Carrion-Alvarez has been been writing them in a more traditional
format. Eventually they will be put together in the form of a book, but
it's a lot of work. That's the main reason This Week's Finds has been
dormant lately. You can see all these notes here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  John Baez, Toby Bartels and Miguel Carrion, \emph{Quantum Gravity
  Seminar}, \texttt{http://math.ucr.edu/home/baez/qg.html}
\end{enumerate}

The ultimate goal is to describe spin foam models of 4d quantum gravity,
but we're only gradually working our way to that point.

There are a lot of other things I'd like to talk about, but I don't have
time to do them all justice. For example, there's a nice new book of
essays on quantum gravity:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Craig Callender and Nick Huggett, eds., \emph{Physics Meets Philosophy
  at the Planck Scale: Contemporary Theories in Quantum Gravity},
  Cambridge U. Press, Cambridge, 2001.
\end{enumerate}

It has articles by Chris Isham, Carlo Rovelli, Ed Witten and other
folks. I found Gordon Belot and John Earman's ``Pre-Socratic Quantum
Gravity'' to be a particularly clear-headed account of the so-called
``problem of time'' in quantum gravity. I wish it had existed when I was
first struggling to understand this subject! Everyone trying to
understand quantum gravity should read this.

Over on the more technical end, Martin Bojowald has written a bunch of
papers applying loop quantum gravity to the big bang, which I want to
catch up with:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\item
  Martin Bojowald, ``Loop Quantum Cosmology I: Kinematics'',
  \emph{Class. Quant. Grav.} \textbf{17} (2000), 1489--1508, also
  available at
  \href{https://arxiv.org/abs/gr-qc/9919103}{\texttt{gr-qc/9919103}}

  ``Loop Quantum Cosmology II: Volume Operators'', \emph{Class. Quant.
  Grav.} \textbf{17} (2000), 1509--1526, also available at
  \href{https://arxiv.org/abs/gr-qc/9910104}{\texttt{gr-qc/9910104}}.

  ``Loop Quantum Cosmology III: Wheeler-DeWitt Operators'', \emph{Class.
  Quant. Grav.} \textbf{18} (2001), 1055--1070, also available at
  \href{https://arxiv.org/abs/gr-qc/0008052}{\texttt{gr-qc/0008052}}.

  ``Loop Quantum Cosmology IV: Discrete Time Evolution'', \emph{Class.
  Quant. Grav.} \textbf{18} (2001) 1071--1088, also available at
  \href{https://arxiv.org/abs/gr-qc/0008053}{\texttt{gr-qc/0008053}}.

  ``Absence of Singularity in Loop Quantum Cosmology'', available at
  \href{https://arxiv.org/abs/gr-qc/0102069}{\texttt{gr-qc/0102069}}.
\end{enumerate}

The really interesting ones are the last two, whose titles explain why
they're interesting --- but they're based on the framework developed in
the earlier papers.

And then there's \(n\)-category theory! Two of Martin Hyland's students
have been making interesting progress on this subject. Tom Leinster has
been studying operads, their generalizations, their relation to homotopy
theory, and their application to \(n\)-categories. He's even given a new
definition of ``weak \(n\)-category'', thus adding to the profusion of
competing candidates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\item
  Tom Leinster, ``General operads and multicategories'', available as
  \href{https://arxiv.org/abs/math.CT/9810053}{\texttt{math.CT/9810053}}.

  \emph{Structures in higher-dimensional category theory}, Ph.D.~thesis,
  available at
  \texttt{http://www.dpmms.cam.ac.uk/\textasciitilde{}leinster/shdctabs.html}

  ``Up-to-homotopy monoids'', available as
  \href{https://arxiv.org/abs/math.QA/9912084}{\texttt{math.QA/9912084}}.

  ``Homotopy algebras for operads'', available as
  \href{https://arxiv.org/abs/math.QA/0002180}{\texttt{math.QA/0002180}}.

  ``Operads in higher-dimensional category theory'', available as
  \href{https://arxiv.org/abs/math.CT/0011106}{\texttt{math.CT/0011106}}
\end{enumerate}

Eugenia Cheng, on the other hand, seems to be working to \emph{reduce}
the number of different definitions of weak \(n\)-category, by laying
the groundwork for connecting various existing definitions --- mainly
those based on ``opetopes'' and related shapes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\item
  Eugenia Cheng, ``The relationship between the opetopic and multitopic
  approaches to weak \(n\)-categories'', available at
  \texttt{http://www.dpmms.cam.ac.uk/\textasciitilde{}elgc2/}

  ``Equivalence between approaches to the theory of opetopes'',
  available at
  \texttt{http://www.dpmms.cam.ac.uk/\textasciitilde{}elgc2/}
\end{enumerate}

I'm glad these energetic young folks are stepping in to help out the
older folks like me who have become completely exhausted from thinking
about \(n\)-categories.

Finally, everyone who wants to understand M-theory and its relation to
matrix models should first read this review article by Nicolai and
Helling:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Hermann Nicolai and Robert Helling, ``Supermembranes and M(atrix)
  theory'', available as
  \href{https://arxiv.org/abs/hep-th/9809103}{\texttt{hep-th/9809103}}.
\end{enumerate}

and then this new review article by Wati Taylor:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Washington Taylor, ``M(atrix) theory: matrix quantum mechanics as a
  fundamental theory'', available as
  \href{https://arxiv.org/abs/hep-th/0101126}{\texttt{hep-th/0101126}}.
\end{enumerate}

They're both pretty cool. How does a theory of matrices wind up acting
like a theory of membranes? That's what you'll understand if you study
this stuff.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week166}{%
\section{March 27, 2001}\label{week166}}

Do you know this number?
\[2.685452001065306445309714835481795693820382293994462953051152\ldots\]
They say that mathematics is not really about numbers, and they're
right. But sometimes it's fun to play around with the darn things!

Given any positive number you can work out its continued fraction
expansion, like this:
\[\sqrt{2} = 1+\frac{1}{2+\frac{1}{2+\frac{1}{2+_{\ldots}}}}\] But
normally it won't look so pretty! A number is rational if and only if
the continued fraction stops after finitely many steps. If its continued
fraction expansion eventually repeats, like this:
\[\sqrt{3} = 1+\frac{1}{1+\frac{1}{2+\frac{1}{1+_{\ldots}}}}\] then it
satisfies a quadratic equation with integer coefficients. So the
continued fraction expansion of e can't ever repeat\ldots{} but it's
cute nonetheless:
\[e = 2+\frac{1}{1+\frac{1}{2+\frac{1}{1+\frac{1}{1+\frac{1}{4+\frac{1}{1+\frac{1}{1+\frac{1}{6+_{\ldots}}}}}}}}}\]
It continues on predictably after that initial hiccup. The number
\(\pi\), on the other hand, gives a random-looking mess. This is a hint
that \(\pi\) is number-theoretically more complicated than \(e\), which
is also apparent when you compare the proofs that \(e\) and \(\pi\) are
transcendental --- the proof for \(e\) is much easier.

Pondering all this, it's natural to ask about the ``average'' behavior
of the continued fraction expansion of a number. What's the average
behavior of the series \(a_1, a_2, a_3, \ldots\) that we get this way:
\[x=a_1+\frac{1}{a_2+\frac{1}{a_3+\frac{1}{a_4+_{\ldots}}}}\] It turns
out that if we take the geometric mean of the first \(n\) terms and then
let \(n\) approach \(\infty\), the mean almost always converges to
``Khinchin's constant'' --- the number at the beginning of this article!
Here by ``almost always'' I mean that the set of exceptions has measure
zero. One can prove this using some ideas from ergodic theory.

Now, there is much more to say about continued fraction expansions, but
my real goal is simply to point out that there are lots of interesting
constants in mathematics besides \(\pi\), \(e\), the golden ratio, and
Euler's number. Where can you read about them? Here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Steven Finch, ``MathSoft Constants'',
  \texttt{http://pauillac.inria.fr/algo/bsolve/constant/constant.html}
\end{enumerate}

This is a great place to learn about Khinchin's constant, Feigenbaum's
number, Madelung's constant, Artin's constant, Grothendieck's constant,
and many other fun numbers!

Speaking of fun websites, here's another:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  The Mathematics Genealogy Project,
  \texttt{http://hcoonce.math.mankato.msus.edu/}
\end{enumerate}

My advisor's advisor's advisor's advisor's advisor's advisor's advisor's
advisor was Gauss. If you think I'm showing off, you're right! But I
couldn't have done it without this website, and if you're a
mathematician, there's a good chance you use it to track down
\emph{your} academic lineage. And if you can't, you can at least add
your information to the database.

Before Demian Cho showed me this site, I'd gotten stuck 3 generations
back in my attempts to discover my academic ancestors. Now I can go back
11 generations. I know it's annoying, but I'm gonna tell you the whole
story:

My advisor was Irving Segal, the guy who helped prove the
Gelfand-Naimark-Segal theorem. This is a basic result about
\(C^*\)-algebras, a kind of gadget he invented to formalize the notion
of an ``algebra of observables'' in quantum theory. The GNS theorem
implies that every \(C^*\)-algebra sits inside the algebra of all
bounded operators on some Hilbert space, so it's a kind of justification
for using Hilbert spaces in quantum physics. But even better, it gives a
procedure for representing a \(C^*\)-algebra as operators on a Hilbert
space starting from a ``state'' on the \(C^*\)-algebra. The upshot is
that while Hilbert spaces are important, the right Hilbert space to use
can depend on the state of the system you're studying. At first people
thought Segal was nuts for saying this, but by now it's well-accepted.

Segal also did work on quantum field theory, nonlinear partial
differential equations, and other topics at the borderline between
physics and functional analysis. His students include Isadore Singer and
Bertram Kostant, whose work on geometric quantization generalized
Segal's ideas on the ``Bargmann-Segal representation''. I worked with
Segal because I liked analysis and wanted to understand quantum field
theory in a rigorous way.

Segal's advisor was Einar Hille, the guy who helped prove the
Hille-Yosida theorem. Hille did a lot of work on integral and
differential equations, but later he became interested in functional
analysis: the study of infinite-dimensional vector spaces equipped with
nice topologies, such as Hilbert spaces, Banach spaces and the like. At
the time, he was rather special in his emphasis on applying these
abstract ideas to concrete problems. In his book ``Methods in Classical
and Functional Analysis,'' he wrote:

\begin{quote}
If the book has a thesis, it is that a functional analyst is an analyst,
first and foremost, and not a degenerate species of a topologist. His
problems come from analysis and his results should throw light on
analysis\ldots.
\end{quote}

The Hille-Yosida theorem shows how to write a large class of
one-parameter semigroups of linear operators on Banach spaces in the
form \(\exp(-tH)\). These so-called ``contraction semigroups'' naturally
come from the heat equation and its relatives. Segal was fond of this
idea, and he generalized it to semigroups of nonlinear operators, which
arise naturally from \emph{nonlinear} partial differential equations. He
used this idea to prove global existence of solutions for various
nonlinear classical field theories.

Hille's advisor was Marcel Riesz, the guy who didn't prove the Riesz
representation theorem. Marcel's brother Frigyes was the guy who did
that. Marcel worked on functional analysis, partial differential
equations, and mathematical physics --- even Clifford algebras and
spinors!

The advisor of Marcel Riesz was Lipot Fejer, the guy who discovered the
Fejer kernel. This shows up when you sum Fourier series. If you just
naively sum the Fourier series of a continuous function on the circle,
it may not converge uniformly. However, if you use a trick called Cesaro
summation, which amounts to averaging the partial sums, you get uniform
convergence. The average of the first \(n\) partial sums of the Fourier
series of your function is equal to its convolution with the Fejer
kernel. Fejer also worked on conformal mappings. His students included
Paul Erdos and Gabor Szego.

Fejer's advisor was Karl Herman Amandus Schwarz, the guy who helped
prove the Cauchy-Schwarz inequality. That's a wonderful inequality which
everyone should know! But Schwarz also worked on minimal surfaces and
complex analysis: for example, conformal mappings from polyhedra into
the sphere, and also the Dirichlet problem. Don't mix him up with
Laurent Schwartz, the guy who invented distributions.

(Actually, Lipot Fejer's name was originally Leopold Weiss. He changed
it to seem more Hungarian. This was a common practice at the time in
Hungary, but when he did it, his advisor Schwarz stopped speaking to
him!)

Schwarz's advisor was Karl Weierstrass, the guy who proved the
Weierstrass theorem. This theorem says that every continuous real-valued
function on the unit interval is a uniform limit of polynomials.
Weierstrass also has a function named after him: the Weierstrass
elliptic function, which I explained in
\protect\hyperlink{week13}{``Week 13''}. But his real claim to fame is
how he made analysis more rigorous! For example, he discovered the
importance of uniform convergence, and found a continuous function with
no derivative at any point. Besides Schwarz, his students include
Frobenius, Killing, and Kowalevsky.

Now, Weierstrass doesn't have an advisor listed in the mathematics
genealogy. However, by using this website full of mathematician's
biographies, I can go back further:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  John J. O'Connor and Edmund F. Robertson, ``The MacTutor History of
  Mathematics Archive'',
  \texttt{http://www-groups.dcs.st-andrews.ac.uk/\textasciitilde{}history/index.html}
\end{enumerate}

According to this, Weierstrass had an erratic career as a student: his
father tried to make him study finance instead of math, so he spent his
undergraduate years fencing and drinking. He learned a lot of math on
his own, and got really interested in elliptic functions from the work
of Abel and Jacobi. I can't tell if he ever had an official dissertation
advisor. However, in 1839 he went to the Academy at Muenster to study
under Christoph Gudermann, who worked on elliptic functions and
spherical geometry. Gudermann strongly encouraged Weierstrass in his
mathematical studies. Weierstrass asked for a question on elliptic
functions, and wound up writing a paper which Gudermann assessed
``\ldots{} of equal rank with the discoverers who were crowned with
glory.'' (When Weierstrass heard this, he commended Gudermann's
generosity, since he had strongly criticized Gudermann's methods.)

Given all this, and the fact that Weierstrass seems to have had no
\emph{other} mentor, I'll declare Gudermann to be his advisor, de facto
even if not officially.

But who was Gudermann? He's the guy they named the ``gudermannian''
after! That's this function:
\[\mathrm{gd}(u) = 2 \arctan(\exp(u)) - \frac\pi2.\] Now, if you're
wondering why such a silly function deserves a name, you should work out
its inverse function: \[\mathrm{gd}^{-1}(x) = \ln(\sec(x) + \tan(x)).\]
And if you don't recognize \emph{this}, you probably haven't taught
freshman calculus lately! It's the integral of \(\sec(x)\), which is one
of the hardest of the basic integrals you teach in that kind of course.
But it's not just hard, it's historically important: a point at latitude
\(\mathrm{gd}(u)\) has distance \(u\) from the equator in a Mercator
projection map. If you think about it a while, this is precisely what's
needed to make the projection be a conformal transformation --- that is,
angle-preserving. And that's just what you want if you're sailing a ship
in a constant direction according to a compass and you want to know
where you'll wind up.

If you don't see how this works, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Wikipedia, \texttt{http://en.wikipedia.org/wiki/Mercator\_projection}
\end{enumerate}

Gudermann's advisor was Carl Friedrich Gauss, the guy they named
practically \emph{everything} after! Poor Gudermann, who was content to
mess around with special functions and spherical geometry, seems to have
been one of Gauss' worst students. But that's not so bad, since three of
the other four were Bessel, Dedekind and Riemann.

Gauss' advisor was Johann Pfaff, the guy they named the ``Pfaffian''
after. If the matrix A is skew-symmetric, we can write
\[\det(A) = \operatorname{Pf}(A)^2\] where \(\operatorname{Pf}(A)\) is
also a polynomial in the entries of \(A\). Pfaffians now show up in the
study of fermionic wavefunctions. Pfaff worked on various things,
including the integrability of partial differential equations, where the
concept of a ``Pfaffian system'' is important. Unfortunately I've never
gotten around to understanding these.

Pfaff's advisor was Abraham Kaestner. I'd never heard of him before now.
He wrote a 4-volume history of mathematics, but his most important work
was on axiomatic geometry. His interest in the parallel postulate
indirectly got Gauss, Bolyai and Lobachevsky interested in that topic:
we've already seen that he taught Gauss' advisor, but he also taught
Bolyai's father, as well as Lobachevsky's teacher, one J. M. C. Bartels.
In fact, Kaestner was still teaching when Gauss went to school, but
Gauss didn't go to Kaestner's courses, because he found them too
elementary. Gauss said of him, ``He is the best poet among
mathematicians and the best mathematician among poets''. Perhaps this
faint praise refers to Kaestner's knack for aphorisms.

At this point I got stuck until my student Miguel Carrion-Alvarez helped
out. It appears that Kaestner's advisor was one Christian A. Hausen.
He's the guy they named the Hausen crater after --- a lunar crater
located at 65.5 S, 88.4 W. He did his thesis on theology in 1713, but
became a professor of mathematics in Leipzig. He worked on
electrostatics, but made no memorable discoveries.

At this point the trail disappears into mist. For some conjectures, see
this page:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Anthony M. Jacobi, ``Academic Family Tree'',
  \texttt{http://www.staff.uiuc.edu/\%7Ea-jacobi/tree.html}
\end{enumerate}

It's interesting how the same themes keep popping up in this genealogy.
For example, Weierstrass invented uniform convergence and proved that
the limit of a uniformly convergent series of continuous functions is
continuous. The Fejer kernel shows up when you're trying to write
functions on the circle as a uniformly convergent sum of complex
exponentials. Segal's \(C^*\)-algebras generalize the notion of uniform
convergence to operator algebras. I guess these things just go from
generation to generation\ldots.

A little while ago John McKay visited me and told me about all sorts of
wonderful things: relations between subgroups of the Monster group,
exceptional Lie groups, and modular forms\ldots{} a presentation of the
Monster group with 2 generators, a way to build the Leech lattice from 3
copies of the \(\mathrm{E}_8\) lattice\ldots{} a way to get ahold of the
Monster group starting with a diagram with 26 nodes\ldots.

Unfortunately, I'm having trouble finding references for some of these
things! It's possible that the last two items are really these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\item
  Robert L. Griess, ``Pieces of eight: semiselfdual lattices and a new
  foundation for the theory of Conway and Mathieu groups''. \emph{Adv.
  Math.} \textbf{148} (1999), 75--104.
\item
  John H. Conway, Christopher S. Simons, ``26 implies the Bimonster'',
  \emph{Jour. Algebra} \textbf{235} (2001), 805--814.
\end{enumerate}

Anyway, I need to read about this stuff.

Speaking of exceptionology: in \protect\hyperlink{week163}{``Week 163''}
I explained how \(\mathrm{Spin}(9)\) sits inside the Lie group
\(\mathrm{F}_4\), thanks to the fact that \(\mathrm{Spin}(9)\) is the
automorphism group of Jordan algebra of \(2\times2\) hermitian
octonionic matrices, and \(\mathrm{F}_4\) is the automorphism group of
the Jordan algebra of \(3\times\) hermitian matrices. But in fact, since
there are different ways to think of \(2\times2\) matrices as special
\(3\times\) matrices, there are actually 3 equally good ways to stuff
\(\mathrm{Spin}(9)\) in \(\mathrm{F}_4\). Since I'd been hoping this
might be important in particle physics, it was nice to discover that
Pierre Ramond, a real expert on this stuff, has had similar thoughts. In
fact he's written two papers on this! Let me just quote the abstracts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Pierre Ramond, ``Boson-fermion confusion: the string path to
  supersymmetry'', available at
  \href{https://arxiv.org/abs/hep-th/0102012}{\texttt{hep-th/0102012}}.
\end{enumerate}

\begin{quote}
Reminiscences on the string origins of supersymmetry are followed by a
discussion of the importance of confusing bosons with fermions in
building superstring theories in 9+1 dimensions. In eleven dimensions,
the kinship between bosons and fermions is more subtle, and may involve
the exceptional group \(\mathrm{F}_4\).
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  T. Pengpan and Pierre Ramond, M(ysterious) patterns in
  \(\mathrm{SO}(9)\), Phys. Rep.~315 (1999) 137-152, also available as
  \href{https://arxiv.org/abs/hep-th/9808190}{\texttt{hep-th/9808190}}.
\end{enumerate}

\begin{quote}
The light-cone little group, \(\mathrm{SO}(9)\), classifies the massless
degrees of freedom of eleven-dimensional supergravity, with a triplet of
representations. We observe that this triplet generalizes to four-fold
infinite families with the quantum numbers of massless higher spin
states. Their mathematical structure stems from the three equivalent
ways of embedding \(\mathrm{SO}(9)\) into the exceptional group
\(\mathrm{F}_4\).
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{quote}
\emph{``This is why we are here,'' said Teacher, ``to be good and kind
to other people.''}

Pippi stood on her head on the horse's back and waved her legs in the
air. ``Heigh-ho,'' said she, ``then why are the other people here?''

--- Astrid Lingren, \emph{Pippi Goes on Board}
\end{quote}



\hypertarget{week167}{%
\section{March 30, 2001}\label{week167}}

I'm now visiting the Center for Gravitational Physics and Geometry at
Penn State, and I have all sorts of exciting stuff to report. First I'll
talk about fundamental limitations in measuring distances due to quantum
gravity and then I'll say a bit about Martin Bojowald's new work, which
uses loop quantum gravity to tackle the question ``what came before the
big bang?''

Theoretical physicists sometimes look longingly back to the early 20th
century as the heyday of thought experiments --- Einstein and his
elevator, the famous Bohr-Einstein debate at the 1927 Solvay conference,
and so on. But thought experiments are most important when you're
struggling to do something really new and haven't yet hammered out a
mathematical formalism. The declining importance of thought experiments
in later years is mainly a reflection of the tremendous success of
quantum mechanics and general relativity,

But what about when QM and GR meet?

Here we need all the help we can get. For example: does it make any
sense to do experiments looking for quantum fluctuations in the geometry
of spacetime, or are they far too puny to detect with present
technology? A precise answer would require a full-fledged theory of
quantum gravity, which we don't have. But a rough answer is all we need!
Here's where thought experiments come in handy. However, one must be
careful\ldots{} verbal reasoning easily conceals many pitfalls! Let me
present an argument that puts a lower bound on how accurately we can
measure distances:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Y. Jack Ng and H. van Dam, ``Measuring the foaminess of space-time
  with gravity-wave interferometers'', \emph{Found. Phys.} \textbf{30}
  (2000) 795--805, also available as
  \href{https://arxiv.org/abs/gr-qc/9906003}{\texttt{gr-qc/9906003}}
\end{enumerate}

You can decide if it's right or not.

First: how accurate can a clock be? One limitation is that any clock has
some position uncertainty. This translates into time uncertainty when we
read the clock by having it send photons to us.

Let's work this out, ignoring factors of \(2\) and small stuff like
that. Suppose our clock has mass \(m\) and starts out with a position
uncertainty equal to \(D\). Then the uncertainty of our clock's momentum
is at least \(\hbar/D\), so its velocity is uncertain by at least
\(\hbar/mD\). After a time \(T\), its position uncertainty will grow to
about \[dx > D + \frac{\hbar t}{mD}.\]

This is minimized when \[D = \left(\frac{\hbar t}{m}\right)^{\frac12}\]
which gives \[dx > \left(\frac{\hbar t}{m}\right)^{\frac12}.\]

This position uncertainty translates into an uncertainty of
\[dt = \frac{dx}{c}\] in the time we read off the clock, so we have
\[c dt > \left(\frac{\hbar t}{m}\right)^{\frac12}.\] Thus, to keep time
with an accuracy \(dt\) over a span of time equal to \(t\), our clock
must have mass \[m > \frac{\hbar t}{c^2 dt^2}.\]

This part of the argument actually goes back to Wigner:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  Eugene P. Wigner, ``Relativistic invariance and quantum phenomena'',
  \emph{Rev.~Mod. Phys.} \textbf{29} (1957), 255--268.

  H. Salecker and E. P. Wigner, ``Quantum limitations of the measurement
  of space-time distances'', \emph{Phys. Rev.} \textbf{109}, (1958),
  571--577. Also available at
  \texttt{http://fangio.magnet.fsu.edu/\textbackslash{}\textasciitilde{}vlad/pr100/100\ yrs/html/chap14\_toc.htm}
\end{enumerate}

Next: how accurate can a distance measurement be? Suppose we measure the
distance between two clocks by timing how long it takes light to go from
one to the other (or make a round trip, if you prefer). If our clocks
keep time with accuracy \(dt\), the uncertainty in the distance
measurement is \[dx = c dt\] Of course, our clocks must keep time this
accurately long enough for light to get from one to the other, so their
masses must satisfy \[m > \frac{\hbar t}{c^2 dt^2}\] or
\[m > \frac{\hbar t}{dx^2}.\]

If \(x\) is the distance between the clocks, we have \[x = c t\] so this
gives \[m > \frac{\hbar x}{c dx^2}.\tag{$\star$}\] In short, to measure
distances accurately this way, our clocks must be heavy.

We've used quantum mechanics. Now let's put gravity into the picture! If
our clocks are \emph{too} heavy they'll collapse into a black hole,
ruining the experiment. This puts a limit on our ability to measure
distances accurately.

To get somewhere with this idea, let's assume the distance \(x\) is
basically the size of our whole experimental apparatus. This must exceed
the Schwarzschild radius for the mass \(m\), or we'll get a black hole,
so we need: \[x > \frac{G m}{c^2}.\] Plugging this into the right-hand
side of (\(\star\)), we get \[m > \frac{\hbar G m}{c^3 dx^2}\] or
\[dx > \left(\frac{\hbar G}{c^3}\right)^{\frac12} = L\] where \(L\) is
the Planck length. So we can't measure distances more accurately than
the Planck length.

Whoops! The last paragraph here is not the argument due to Ng and van
Dam! It's something I came up just now while trying to copy their
argument. Their actual argument is different. They assume the
uncertainty \(dx\) must exceed the Schwarzschild radius of a black hole
of mass \(m\), so that \[dx > \frac{G m}{c^2}.\] If we plug this into
(\(\star\)) and fiddle around, we get \[dx > x^{\frac13} L^{\frac23}.\]
This is much more exciting, because it says that the uncertainty due to
quantum gravity gets bigger when we measure long distances!

Now, the way I've presented Ng and van Dam's argument, the obvious weak
spot is their assumption that the uncertainty in position measurement is
greater than the radius of a black hole with mass equal to that of the
experimental apparatus. Where does this assumption come from? They get
it by saying the clocks ``tick'' once each time light bounces back and
forth between them. If the clocks' accuracy is limited by their tick
rate, we have \(dt = t\) and thus \(dx = x\), so my assumption
\[x > \frac{G m}{c^2}\] turns into their stronger assumption
\[dx > \frac{G m}{c^2}\]

But to me it seems artificial, even circular, to measure distances using
clocks that work this way!

For further criticism of this argument, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Ronald J. Adler, Ilya M. Nemenman, James M. Overduin, David I.
  Santiago, ``On the detectability of quantum spacetime foam with
  gravitational-wave interferometers'', \emph{Phys. Lett.} \textbf{B477}
  (2000) 424--428, also available at
  \href{https://arxiv.org/abs/gr-qc/9909017}{\texttt{gr-qc/9909017}}.
\end{enumerate}

For their response, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Y. Jack Ng and H. van Dam, ``On Wigner's clock and the detectability
  of spacetime foam with gravitational-wave interferometers'',
  \emph{Phys. Lett.} \textbf{B477} (2000) 429--435, also available at
  \href{https://arxiv.org/abs/gr-qc/9911054}{\texttt{gr-qc/9911054}}.
\end{enumerate}

For an argument that claims an even larger value of the position
uncertainty, namely \[dx > x^{\frac12} L^{\frac12},\] see these papers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  G. Amelino-Camelia, ``Quantum theory's last challenge'', \emph{Nature}
  \textbf{408} (2000) 661--664.

  ``Testable scenario for relativity with minimum length'', available at
  \href{https://arxiv.org/abs/hep-th/0012238}{\texttt{hep-th/0012238}}
\end{enumerate}

Let's do a little number-crunching to compare these calculations. An
gravitational wave detector like LIGO is basically just a device that
bounces a laser between mirrors to carefully measure the distance
between them. The goal of LIGO is to measure a 4-kilometer distance with
a precision of \(10^{-18}\) meters. If we believe the fundamental
uncertainty in distance measurements is about the Planck length, LIGO
has no chance of bumping into this limit, since the Planck length is
about \(10^{-35}\) meters. If we believe Ng and van Dam's thought
experiment, we get an uncertainty of about \(10^{-22}\) meters. If we
believe Amelino-Camelia's argument, we get a figure of about
\(10^{-16}\) meters\ldots{} which would be very noticeable at LIGO!

Unfortunately, I'm pretty sure the Planck length figure is about right.
For another derivation of this figure, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Ronald J. Adler and David I. Santiago, ``On gravity and the
  uncertainty principle'', \emph{Mod. Phys. Lett.} \textbf{A14} (1999)
  1371, also available at
  \href{https://arxiv.org/abs/gr-qc/9904026}{\texttt{gr-qc/9904026}}.
\end{enumerate}

What other ways might we detect quantum gravity effects? One is to look
for dispersion of light as it passes through the vacuum. Maxwell's
equations say that in the vacuum the speed of light is independent of
its wavelength. But if spacetime is ``grainy'' at short distance scales,
this might not be exactly correct. If the velocity were
frequency-dependent, a pulse of radiation would get slightly smeared out
as it travels along through empty space.

There are calculations in both string theory and loop quantum gravity
which raise this as a possibility:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\item
  J. Ellis, N.E. Mavromatos and D. V. Nanopoulos, ``Search for quantum
  gravity'', \emph{Gen.~Rel. Grav.} \textbf{31} (1999) 1257--1262, also
  available as
  \href{https://arxiv.org/abs/gr-qc/9905048}{\texttt{gr-qc/9905048}}.
\item
  Jorge Pullin and Rodolfo Gambini, ``Nonstandard optics from quantum
  spacetime'', \emph{Phys. Rev.} \textbf{D59} (1999) 124021, also
  available as
  \href{https://arxiv.org/abs/gr-qc/9809038}{\texttt{gr-qc/9809038}}.
\end{enumerate}

These calculations are quite controversial. For one thing, they require
a breaking of Lorentz invariance, since there's no way to get the speed
of light to depend on its wavelength without picking out a special rest
frame. This makes some people's hair stand on end.

But never mind: suppose we were looking for this effect. Nobody has seen
it yet, so it must be tiny if it exists at all. To detect it we'd want
our light to travel a long distance\ldots{} say, 10 billion light years.
And we'd like a source that emitted a pulse of light whose variation in
time we can detect with good resolution\ldots{} say, less than a
millisecond.

Hmm. How can we arrange this? Use \(\gamma\)-ray bursters! We don't have
to build them; nature has seen to that, so we can use these rascals to
put limits on this dispersion effect. For more details, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  J. Ellis, K. Farakos, N.E. Mavromatos, V. Mitsou and D.V. Nanopoulos,
  ``Astrophysical probes of the constancy of the velocity of light'',
  \emph{Astrophys. J.} \textbf{535} (2000) 139--151, also available as
  \href{https://arxiv.org/abs/astro-ph/9907340}{\texttt{astro-ph/9907340}}.
\end{enumerate}

So far, nobody has seen quantum gravity effects this way.

Okay\ldots{} let me wrap things up with a word about Martin Bojowald's
work on quantum cosmology. I listed his papers in
\protect\hyperlink{week165}{``Week 165''}, but didn't get around to
discussing them.

From an outsider's viewpoint, the exciting thing about this work is that
it uses loop quantum gravity to study what happened before the big bang.
And the answer is simple: there was a big crunch! In other words,
Bojowald can extrapolate the quantum version of the big bang cosmology
back before \(t = 0\), without encountering any singularity, and he gets
a collapsing universe which shrinks down to zero volume at \(t = 0\)
before re-expanding in a big bang.

From an insider's perspective, the exciting thing is that he's using
loop quantum gravity to study dynamics. Since loop quantum gravity is
background-free, there's no Hamiltonian, just a Hamiltonian constraint.
This means that any study of dynamics must confront the thorny ``problem
of time'': how to do physics without a god-given external clock that's
outside the system you're studying. And this problem makes it hard to
tell which formula for the Hamiltonian constraint is ``right''. Thiemann
came up with a candidate for the Hamiltonian constraint back in 1996
(see \protect\hyperlink{week85}{``Week 85''}), and the field has
struggled ever since to make up it's collective mind about this formula,
without much success so far.

Bojowald's progress comes from looking at ``minisuperspace models'',
where we assume the universe is highly symmetrical --- as people often
do in cosmology. This allows him to tackle the problem of time by
treating the volume of the universe as a notion of time. It's like
having one aspect of the system you're studying be the clock that you
use to see how other things change. This idea per se is not new; what's
new is carrying it out in the framework of loop quantum gravity. In loop
quantum gravity volume is discrete\ldots{} so Bojowald's ``clock'' ticks
in discrete steps. By adapting Thiemann's formula for the Hamiltonian
constaint to this highly symmetrical context, he can write it as an
evolution equation saying how other observables change as a function of
the volume of the universe. Since volume is discrete, this equation is a
difference equation rather than a differential equation.

He can solve this equation on the computer\ldots{} and he finds that
even when the universe is very small, on the order of the Planck length,
it closely mimics the classically expected behavior. However, there is
no singularity at \(t = 0\), or more precisely, at zero volume.

Here's where things get technical, in a way that tickles me pink, but
may bore you to tears:

A funny feature of the volume operator in loop quantum gravity is that
it's expressed in terms of the square root of the absolute value of a
certain quantity. We can think of this quantity as a sort of ``volume
squared'' operator, but with both positive and negative eigenvalues.
This always used to puzzle me, and I've put a lot of thought into this
issue. Renate Loll has also written a paper about it. I'm delighted to
find that in Bojowald's setup, it becomes a real \emph{virtue} of loop
quantum gravity, since it allows us to extrapolate our quantum cosmology
to negative times --- or more precisely, negative ``volume squared''!

How can you visualize this? Crudely speaking, negative-volume-squared
states of the universe can be thought of as ``inside-out versions'' of
positive-volume-squared ones. So the way I visualize Bojowald's result
is like this: the universe shrinks to nothing as you rewind history back
to the big bang, and then expands again ``inside out'' as you go to
negative times.

Anyway, regardless of how we visualize it, loop quantum gravity is now
at the stage of making dynamical predictions about serious physics
questions. Ashtekar and Bojowald are now working to determine what
happens at the singularity of a black hole\ldots{} so stay tuned!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Now the thing about time is that time isn't really real. It's just
your point of view, how does it feel for you? Einstein said he could
never understand it all.} --- James Taylor



\hypertarget{week168}{%
\section{May 31, 2001}\label{week168}}

It's been about two months since the last issue of This Week's Finds,
and I apologize for this. I've been very busy, and my limited writing
energy has all gone into finishing up a review article on the octonions.
I'm dying to talk about that\ldots{} but first things first!

When I left off I was at Penn State, learning about the latest
developments in quantum gravity. I told you how Martin Bojowald was
using loop quantum gravity to study what came before the big
bang\ldots{} but I didn't mention that he'd written a nice little book
on the subject:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Martin Bojowald, \emph{Quantum Geometry and Symmetry}, Shaker Verlag,
  Aachen, 2000. Available at
  \texttt{http://www.shaker.de/Online-Gesamtkatalog/Details.asp?ISBN=3-8265-7741-8}
\end{enumerate}

This does not cover his most recent work, in which his program is really
starting to pay off\ldots{} but it will certainly help you
\emph{understand} his recent work. He's doing lots of great stuff these
days. In fact, he just came out with a paper yesterday:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Martin Bojowald, ``The semiclassical limit of loop quantum
  cosmology'', available at
  \href{https://arxiv.org/abs/gr-qc/0105113}{\texttt{gr-qc/0105113}}.
\end{enumerate}

This explains how his new approach to quantum cosmology is related to
the old ``minisuperspace'' approach. In the old approach, you just take
some limited class of cosmologies satisfying the equations of general
relativity and think of this class as a classical mechanics problem with
finitely many degrees of freedom: for example, the size of the universe
together with various numbers describing its shape. Then you quantize
this classical system.

In this approach, you don't see any hint of spacetime discreteness on
the Planck scale. But in Bojowald's approach, you do! What gives? He
still starts with a limited class of cosmologies and quantizes that, but
he does so using ideas taken from loop quantum gravity. This makes all
the difference: now areas and volumes have discrete spectra of
eigenvalues, and this saves us from the horrors of the singularity at
the big bang. In fact, we can go back \emph{before} the big bang, and
find a time-reversed expanding universe on the other side!

But what's the relation between this new approach and the old one,
exactly? Well, in loop quantum gravity, space is described using ``spin
networks'', and area is quantized. Each edge of a spin network is
labelled by some spin \(j = 0, 1/2, 1, \ldots\), and when a spin-\(j\)
edge punctures a surface, it gives that surface an area equal to
\[8\pi\gamma\sqrt{j(j+1)}\] times the Planck length squared. Here
\(\gamma\) is a constant called the ``Immirzi parameter'' --- see
\protect\hyperlink{week112}{``Week 112''} and
\protect\hyperlink{week148}{``Week 148''} for more about that. Bojowald
shows that you can recover the old approach to quantum cosmology from
his new one by taking a limit in which the Immirzi parameter approaches
zero while the spins labelling spin network edges go to infinity. In
this limit, the spacings between the above areas go to zero --- so the
discrete spectrum of the ``area operator'' becomes continuous! Thus we
lose the discrete geometry which is typical of loop quantum gravity.

I'm also excited by what's going on with spin foams lately. For one, my
friend Dan Christensen is starting to do numerical calculations with the
Riemannian Barrett-Crane model. I've discussed this model in
\protect\hyperlink{week113}{``Week 113''},
\protect\hyperlink{week120}{``Week 120''}, and
\protect\hyperlink{week128}{``Week 128''}, so I won't bore you with the
details yet again. For now, let me just say that it's a theory of
quantum gravity in which spacetime is a triangulated \(4\)-dimensional
manifold. There is also a Lorentzian version of this model, which is
more physical, but it's trickier to compute with, so Dan has wisely
decided to start by tackling the Riemannian version.

As you probably know, in quantum field theory, as in statistical
mechanics, the partition function is king. So Dan Christensen is
starting out by using a supercomputer to numerically calculate the
partition function of a triangulated 4-sphere. He has some students
helping him, and he's also gotten some help from Greg Egan\ldots.

Anyway: this partition function is a sum over all ways of labelling
triangles by spins --- but it's not obvious that the sum converges! For
this reason Dan has begun by imposing a ``cutoff'', that is, an upper
bound on the allowed spins. Physically this would be called an
``infrared cutoff'', since big spins mean big triangles. The question
is: what happens as you let this cutoff approach infinity? Does the
partition function converge or not?

Now, what's cool is that in November of last year, a fellow named
Alejandro Perez claimed to have proven that it \emph{does} converge:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Alejandro Perez, ``Finiteness of a spin foam model for euclidean
  quantum general relativity'', \emph{Nucl. Phys.} \textbf{B599} (2001)
  427--434. Also available at
  \href{https://arxiv.org/abs/gr-qc/0011058}{\texttt{gr-qc/0011058}}.
\end{enumerate}

I say ``claimed'', not because I doubt his proof, but because I still
haven't checked it, and I should. But the great thing is: now we have
both numerical and analytic ways of studying this spin foam model, and
we can play them off against each other! This helps a lot when you're
trying to understand a complicated problem.

Of course, the skeptics among you will say ``Fine, but this is just
Riemannian quantum gravity, not the Lorentzian theory. We're still not
talking about the real world.'' And you'd be right! But luckily, there
has also been a lot of progress on the Lorentzian Barrett-Crane model.

This version of the Barrett-Crane model is based on the Lorentz group
instead of the rotation group. Because the representations of the
Lorentz group are parametrized in a continuous rather than discrete way,
in this version one computes the partition function as as an
\emph{integral} over ways of labelling the triangles by nonnegative real
numbers. These numbers represent areas, so it seems that area is not
quantized in this theory --- but I should warn you, this is a hotly
debated issue! We need to better understand how this model relates to
loop quantum gravity, where area is quantized.

Anyway, when Barrett and Crane proposed the Lorentzian version of their
model, it wasn't obvious that this integral for the partition function
converged. Even worse, it wasn't clear that the integrand was
well-defined! The basic ingredient in the integrand is the so-called
``Lorentzian \(10j\) symbol'', which describes the amplitude for an
individual \(4\)-simplex to have a certain geometry, as specified by the
areas of its 10 triangular faces. Barrett and Crane wrote down an
explicit integral for the Lorentzian \(10j\) symbol, but they didn't
show this integral converges.

Last summer, in a fun-filled week of intense calculation, John Barrett
and I showed that the integral defining the Lorentzian \(10j\) symbols
\emph{does} in fact converge:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  John Baez and John W. Barrett, ``Integrability for relativistic spin
  networks'', available at
  \href{https://arxiv.org/abs/gr-qc/0101107}{\texttt{gr-qc/0101107}}.
\end{enumerate}

It took us until this January to write up those calculations. By April,
Louis Crane, Carlo Rovelli, and Alejandro Perez had written a paper
extending our methods to show that the partition function converges:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Louis Crane, Alejandro Perez, Carlo Rovelli, ``A finiteness proof for
  the Lorentzian state sum spin foam model for quantum general
  relativity'', available as
  \href{https://arxiv.org/abs/gr-qc/0104057}{\texttt{gr-qc/0104057}}.
\end{enumerate}

So now we have a well-defined quantum gravity theory for a
\(4\)-dimensional spacetime with a fixed triangulation, and we can start
studying it! The big question is whether it mimics general relativity at
distance scales much larger than the Planck scale.

But enough of that. Now: octonions!

I've finally finished writing a survey of the octonions and their
connections to Clifford algebras and spinors, Bott periodicity,
projective and Lorentzian geometry, Jordan algebras, the exceptional Lie
groups, quantum logic, special relativity and supersymmetry:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  John Baez, ``The octonions'',
  \texttt{http://math.ucr.edu/home/baez/octonions/}. Also available at
  \href{http://www.arXiv.org/abs/math.RA/0105155}{\texttt{math.RA/0105155}}.
\end{enumerate}

Let me just sketch some of the main themes. For details and precise
statements, read the paper!

Octonions arise naturally from the interaction between vectors and
spinors in \(8\)-dimensional Euclidean space, but in superstring theory
and other physics applications, what matters most is their relation to
10-dimensional Lorentzian spacetime. This is part of a pattern:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  spinors in 1d Euclidean space are real numbers (\(\mathbb{R}\)).
\item
  spinors in 2d Euclidean space are complex numbers (\(\mathbb{C}\)).
\item
  spinors in 4d Euclidean space are quaternions (\(\mathbb{H}\)).
\item
  spinors in 8d Euclidean space are octonions (\(\mathbb{O}\)).
\end{enumerate}

(These numbers are just the dimensions of \(\mathbb{R}\),
\(\mathbb{C}\), \(\mathbb{H}\) and \(\mathbb{O}\).)

Also:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  points in 3d Minkowski spacetime are \(2\times2\) hermitian real
  matrices
\item
  points in 4d Minkowski spacetime are \(2\times2\) hermitian complex
  matrices
\item
  points in 6d Minkowski spacetime are \(2\times2\) hermitian
  quaternionic matrices
\item
  points in 10d Minkowski spacetime are \(2\times2\) hermitian
  octonionic matrices
\end{enumerate}

(These numbers are 2 more than the dimensions of \(\mathbb{R}\),
\(\mathbb{C}\), \(\mathbb{H}\) and \(\mathbb{O}\).)

The octonions are also what lie behind the 5 exceptional simple Lie
groups. The exceptional group \(\mathrm{G}_2\) is just the symmetry
group of the octonions. The other four exceptional groups, called
\(\mathrm{F}_4\), \(\mathrm{E}_6\), \(\mathrm{E}_7\) and
\(\mathrm{E}_8\), are symmetry groups of ``projective planes'' over:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  the octonions, \(\mathbb{O}\)
\item
  the complexified octonions or ``bioctonions'',
  \(\mathbb{C}\otimes\mathbb{O}\)
\item
  the quaternionified octonions or ``quateroctonions'',
  \(\mathbb{H}\otimes\mathbb{O}\)
\item
  the octonionified octonions or ``octooctonions'',
  \(\mathbb{O}\otimes\mathbb{O}\)
\end{enumerate}

respectively.

Warning: I put the phrase ``projective planes'' in quotes here because
the last two spaces are not projective planes in the usual axiomatic
sense (see \protect\hyperlink{week145}{``Week 145''}). This makes the
subject a bit tricky.

Now, it is no coincidence that:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  spinors in \(9\)-dimensional Euclidean space are pairs of octonions.
\item
  spinors in \(10\)-dimensional Euclidean space are pairs of
  bioctonions.
\item
  spinors in \(12\)-dimensional Euclidean space are pairs of
  quateroctonions.
\item
  spinors in \(16\)-dimensional Euclidean space are pairs of
  octooctonions.
\end{enumerate}

(These numbers are 8 more than the dimensions of \(\mathbb{R}\),
\(\mathbb{C}\), \(\mathbb{H}\) and \(\mathbb{O}\).)

This sets up a relation between spinors in these various dimensions and
the projective planes over \(\mathbb{O}\),
\(\mathbb{C}\otimes\mathbb{O}\), \(\mathbb{H}\otimes\mathbb{O}\) and
\(\mathbb{O}\otimes\mathbb{O}\). The upshot is that we get a nice
description of \(\mathrm{F}_4\), \(\mathrm{E}_6\), \(\mathrm{E}_7\) and
\(\mathrm{E}_8\) in terms of the Lie algebras \(\mathfrak{so}(n)\) and
their spinor representations where \(n = 9, 10, 12, 16\), respectively.

It's all so tightly interlocked --- I can't believe it's not trying to
tell us something about physics! Just to whet your appetite for more,
Just to whet your appetite for more, let me show you 7 quateroctonionic
descriptions of the Lie algebra of \(\mathrm{E}_7\): \[
  \begin{aligned}
    \mathfrak{e}_7
    &= \mathfrak{isom}((\mathbb{H}\otimes\mathbb{O})\mathbb{P}^2)
  \\&= \mathfrak{der}(\mathrm{h}_3(\mathbb{O}))\oplus\mathrm{h}_3(\mathbb{O})^3
  \\&= \mathfrak{der}(\mathbb{O})\oplus\mathfrak{der}(\mathrm{h}_3(\mathbb{H}))\oplus(\Im(\mathbb{O})\otimes\mathrm{sh}_3(\mathbb{H}))
  \\&= \mathfrak{der}(\mathbb{H})\oplus\mathfrak{der}(\mathrm{h}_3(\mathbb{O}))\oplus(\Im(\mathbb{H})\otimes\mathrm{sh}_3(\mathbb{O}))
  \\&= \mathfrak{der}(\mathbb{O})\oplus\mathfrak{der}(\mathbb{H})\oplus\mathrm{sa}_3(\mathbb{H}\otimes\mathbb{O})
  \\&= \mathfrak{so}(\mathbb{O}\oplus\mathbb{H})\oplus\Im(\mathbb{H})\oplus(\mathbb{H}\otimes\mathbb{O})^2
  \\&= \mathfrak{so}(\mathbb{O})\oplus\mathfrak{so}(\mathbb{H})\oplus\Im(\mathbb{H})\oplus(\mathbb{H}\otimes\mathbb{O})^3
  \end{aligned}
\] I explain why these are true in the paper, but for now, let me just
say what all this stuff means:

\begin{itemize}
\tightlist
\item
  ``\(\mathfrak{isom}\)'' means the Lie algebra of the isometry group,
\item
  \((\mathbb{H}\otimes\mathbb{O})\mathbb{P}^2\) means the
  quateroctonionic projective plane with its god-given Riemannian
  metric,
\item
  ``\(\mathfrak{der}\)'' means the Lie algebra of derivations,
\item
  \(\mathrm{h}_3(\mathbb{O})\) is the exceptional Jordan algebra,
  consisting of \(3\times3\) hermitian octonionic matrices,
\item
  \(\mathrm{h}_3(\mathbb{H})\) is the Jordan algebra of \(3\times3\)
  hermitian quaternionic matrices,
\item
  \(\Im(\mathbb{O})\) is the \(7\)-dimensional space of imaginary
  octonions,
\item
  \(\Im(\mathbb{H})\) is the \(3\)-dimensional space of imaginary
  quaternions,
\item
  \(\mathrm{sh}_3(\mathbb{O})\) is the traceless \(3\times3\) hermitian
  octonionic matrices,
\item
  \(\mathrm{sh}_3(\mathbb{H})\) is the traceless \(3\times3\) hermitian
  quaternionic matrices,
\item
  \(\mathrm{sa}_3(\mathbb{H}\otimes\mathbb{O})\) is the traceless
  \(3\times3\) antihermitian quateroctonionic matrices.
\item
  \(\mathfrak{so}(V)\) is the rotation group Lie algebra associated to
  the real inner product space \(V\).
\end{itemize}

It is fun to compute the dimension of \(\mathrm{E}_7\) using each of
these 7 formulas and see that you get 133 each time!

I also give 6 bioctonionic descriptions of \(\mathrm{E}_6\). Alas, I
could not find 8 octooctonionic descriptions of \(\mathrm{E}_8\),
probably because this group is more symmetrical and in a curious sense
simpler than the others.

Time for dinner.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{``Don't take life too serious, it ain't nohow permanent.''} ---
Walt Kelly, Pogo



\hypertarget{week169}{%
\section{July 4, 2001}\label{week169}}

When I write This Week's Finds as rarely as I do these days, so much
stuff builds up that I completely despair of ever getting to all of
it\ldots{} so I'll just randomly mention a few cool things that are on
the top of my mind right now.

First of all, here's a great new review article on spin foams. If you're
trying to understand spin foam models of quantum gravity, this is the
place to start:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Daniele Oriti, ``Spacetime geometry from algebra: spin foam models for
  non-perturbative quantum gravity'', \emph{Rep.~Prog. Phys.}
  \textbf{64} (2001), 1489--1544. Also available at
  \href{https://arxiv.org/abs/gr-qc/0106091}{\texttt{gr-qc/0106091}}.
\end{enumerate}

You'll learn how spin foam models naturally show up in all sorts of
different approaches to quantum gravity: loop quantization, path
integral approaches, lattice field theory, matrix models, and
category-theoretic approaches.

Secondly, here's a great introduction to \(n\)-categories and topology:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Tom Leinster, ``Topology and higher-dimensional category theory: the
  rough idea'', available at
  \href{https://arxiv.org/abs/math.CT/0106240}{\texttt{math.CT/0106240}}.
\end{enumerate}

As he says, this is a ``Friday-afternoonish description of some of the
dreams people have for higher-dimensional category theory and its
interactions with topology''. Much more readable than the
Monday-morningish papers where people put in all the details!

And next, here is some stuff I have been thinking about lately.

As you're probably sick to death of hearing, I'm interested in category
theory and also normed division algebras: the real numbers, complex
numbers, quaternions and octonions. There's no instantly obvious
relationship between these topics, but naturally I've tried to find one,
since this would let me unify two of my obsessions into one big
super-obsession. I recently made a bunch of progress, thanks to finding
these papers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\item
  Markus Rost, ``On the dimension of a composition algebra'',
  \emph{Documenta Mathematica} \textbf{1} (1996), 209--214. Available at
  \texttt{http://www.mathematik.uni-bielefeld.de/DMV-J/vol-01/10.html}
\item
  Dominik Boos, ``Ein tensorkategorieller Zugang zum Satz von Hurwitz (A
  tensor-categorical approach to Hurwitz's theorem)'',
  \emph{Diplomarbeit ETH Zurich}, March 1998, available at
  \texttt{http://www.mathematik.uni-bielefeld.de/\textasciitilde{}rost/data/boos.pdf}
\end{enumerate}

I'd like to explain what the problem is and how these papers solve it.

Part of the fun of category theory is that it lets you take mathematical
arguments and generalize them to their full extent by finding the proper
context for them: that is, by figuring out in exactly what sort of
category you can carry out the argument. Out of laziness and ignorance,
people usually work in the category of sets as a kind of ``default
setting''. This category has many wonderful features --- it's like a
machine that chops, slices, dices, grates, liquefies and purees --- but
usually you don't need \emph{all} these features to carry out a
particular task. So, one job of a category theorist is to figure out
what features are actually needed in a given situation, and isolate the
kind of category that has those features.

A ``kind of category'' is sometimes called a ``doctrine''. I believe
this term was invented by Lawvere. It must have some technical
definition, but luckily I don't know it, so I will not be restrained by
it here. I'll just talk in a sloppy way about this question: ``in what
doctrine can we define the concept of a normed division algebra?'' It'll
get technical for a while, so most of you may want to leave, but then
some pretty pictures will show up, so make sure to come back then.

First think a minute about ``algebras''. Here by an ``algebra'' I mean a
finite-dimensional real vector space with a not-necessarily-associative
bilinear product and an element that's both the left and right unit for
this product. We can define algebras like this using the category
\(\mathsf{Vect}\) consisting of real vector spaces and linear operators,
without resorting to full power of the category of sets --- as long as
we use the tensor product in \(\mathsf{Vect}\). We start by saying an
algebra is an object \(A\) in \(\mathsf{Vect}\) together with a product
\[m\colon A \otimes A \to A\] and unit \[i\colon I \to A\] where \(I\)
is the unit object for the tensor product --- that is, the real numbers.
In case you're confused: the map \(i\) here is just the linear operator
sending the real number \(1\) to the unit element of \(A\); we're using
a standard trick for expressing \emph{elements} as \emph{maps}. Given
this stuff, we can write the left and right unit laws by saying this
diagram commutes: \[
  \begin{tikzcd}
    I\otimes A
      \dar[swap,"i\otimes1_A"]
    & A
      \lar \rar
      \dar["1_A" description]
    & A\otimes I
      \dar["1_A\otimes i"]
  \\A\otimes A
      \rar[swap,"m"]
    & A
    & A\otimes A
      \lar["m"]
  \end{tikzcd}
\] where the unlabelled arrows are some obvious isomorphisms coming from
the fact that \(I\) is the unit for the tensor product.

Now, this definition could have been stated in \emph{any} category with
tensor products; or more technically, any ``monoidal category''. So the
right doctrine for talking about algebras of this sort is the doctrine
of monoidal categories.

What's the right doctrine for defining \emph{associative} algebras?
Well, we can write down another commutative diagram to state the
associative law: \[
  \begin{tikzcd}[column sep=small,row sep=huge]
    (A\otimes A)\otimes A
      \ar[rr]
      \dar[swap,"m\otimes1_A"]
    && A\otimes(A\otimes A)
      \dar["1_A\otimes m"]
  \\A\otimes A
      \drar[swap,"m"]
    && A\otimes A
      \dlar["m"]
  \\&A&
  \end{tikzcd}
\] where again the unlabelled arrow is the obvious isomorphism. This
works fine in any monoidal category, so the right doctrine is again that
of monoidal categories. But instead of speaking of an ``associative
algebra'' in a monoidal category, folks usually call a gadget of this
sort a ``monoid object'' --- see \protect\hyperlink{week89}{``Week 89''}
for more on this. The reason is that if we take our monoidal category to
be \(\mathsf{Set}\), a monoid object boils down to a ``monoid'': a set
with an associative product and unit element.

Lots of people like groups more than monoids. What's the right doctrine
for defining groups? This time it's definitely NOT the doctrine of
monoidal categories. The reason is that the equational laws satisfied by
inverses in a group: \[
  \begin{aligned}
    g g^{-1} &= 1
  \\g^{-1} g &= 1
  \end{aligned}
\] have duplicated and deleted arguments --- the ``\(g\)'' shows up
twice on the left side and not at all on the right! This is different
from the associative law \[g (h k) = (g h) k\] where each argument shows
up once on each side of the equation.

In a monoidal category we can't ``duplicate'' or ``delete'' arguments:
if \(X\) is an object in a monoidal category, there's no god-given map
from \(X\) to \(X\otimes X\), or from \(X\) to \(1\). This means we
can't use commutative diagrams in a monoidal category to express
equational laws that duplicate or delete arguments.

However, we \emph{can} duplicate and delete arguments if we're in a
``category with finite products'' --- a nice sort of monoidal category
where we \emph{do} have maps from \(X\) to \(X\otimes X\) and from \(X\)
to \(1\). The best example of this is the category of sets, where the
``tensor product'' is just the usual Cartesian product. This is why we
can easily define groups in the category of sets! More generally, we can
define ``group objects'' in any category with finite products.

So, the right doctrine for talking about groups --- or more precisely,
group objects --- is the doctrine of categories with finite products.

By the way, if you think this stuff is too abstract to be useful, take a
peek at \protect\hyperlink{week54}{``Week 54''} and
\protect\hyperlink{week115}{``Week 115''}, where I described how group
objects show up in algebraic topology. But beware: back then I was
engaging in a bit of overkill, and working in the doctrine of
``categories with finite limits''. This more powerful doctrine also lets
you define gadgets with partially defined operations, like ``category
objects''. But for group objects, finite products are all we really
need.

Gradually getting to the point, let us now ask: what's the right
doctrine for talking about \emph{division} algebras? It's definitely
\textbf{not} the doctrine of monoidal categories. It's not even the
doctrine of categories with finite products! The problem is that a
division algebra is defined to be an algebra such that \(xy = 0\)
implies \(x = 0\) or \(y = 0\). This condition is not even an equational
law: it doesn't say some equation holds, it says ``this equation implies
this one or that one''. To express such fancier conditions as
commutative diagrams, we need a more powerful doctrine.

I'm too lazy to figure out exactly what we need, but certainly the
doctrine of ``topoi'' will do. If you don't know what a topos is, give
yourself 40 lashes and read this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  John Baez, ``Topos theory in a nutshell'',
  \texttt{http://math.ucr.edu/home/baez/topos.html}
\end{enumerate}

However, there are lots of reasons to avoid working in such a powerful
doctrine --- basically, it greatly limits the generality with which one
can discuss a subject.

So it's very interesting to see how much better we can do if we're
interesed in \emph{normed} division algebras. These are algebras
equipped with a norm such that \[|xy| = |x| |y|\] and if we're working
in the category of real vector spaces, the only examples are the real
numbers, the complex numbers, the quaternions and the octonions. These
have all sorts of important applications in physics, so it's good to see
what doctrine we need to talk about them.

The problem is that the norm is nothing like a linear map. To get around
this, it's better to work with the inner product, which is related to
the norm by \[|x|^2 = \langle x,x\rangle\] The inner product is
bilinear, so have a chance of talking about it in the doctrine of
monoidal categories. Unfortunately, there are a couple of problems:

First of all, it's tough to state the positive definiteness of the inner
product:
\[\mbox{if $x$ is nonzero, then $\langle x,x\rangle$ is greater than $0$.}\]
The easiest way around this is to relax a bit, and instead of demanding
that our algebra have an inner product \(\langle x,y\rangle\), simply
demand that it have a nondegenerate bilinear form \(g(x,y)\). Believe it
or not, this condition can be stated in any monoidal category. It's
easiest to do this using pictures --- not commutative diagrams, but an
equivalent approach using pictures that look a bit like Feynman
diagrams. These days, lots of mathematical physicists use pictures like
this to do calculations in monoidal categories. There are lots of places
to learn this stuff, but if you want something online, it's easiest for
me to point you to my notes on quantum gravity:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  John Baez, Toby Bartels, and Miguel Carrion, ``Quantum gravity
  seminar'', \texttt{http://math.ucr.edu/home/baez/qg.html}
\end{enumerate}

Okay. Now that you've read those notes, you know what to do! We assume
our algebra \(A\) is equipped with maps \[g\colon A\otimes A \to I\] and
\[h\colon I \to A\otimes A\] which we draw as \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to [out=down,in=down,looseness=2] (1,0);
    \end{knot}
    \node[label=below:{$g$}] at (0.5,-0.6) {$\bullet$};
  \end{tikzpicture}
\] and \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to [out=up,in=up,looseness=2] (1,0);
    \end{knot}
    \node[label=above:{$h$}] at (0.5,0.57) {$\bullet$};
  \end{tikzpicture}
\] respectively. We demand that \[
  \begin{tikzpicture}
    \begin{scope}[xscale=-1,shift={(-2,0)}]
      \begin{knot}
        \strand[thick] (0,0)
        to (0,1)
        to [out=up,in=up,looseness=2] (1,1)
        to [out=down,in=down,looseness=2] (2,1)
        to (2,2);
      \end{knot}
      \node[label=above:{$h$}] at (0.5,1.57) {$\bullet$};
      \node[label=below:{$g$}] at (1.5,0.4) {$\bullet$};
    \end{scope}
    \node at (3,1) {$=$};
    \begin{scope}[shift={(4,0)}]
      \begin{knot}
        \strand[thick] (0,0) to (0,2);
      \end{knot}
    \end{scope}
    \node at (5,1) {$=$};
    \begin{scope}[shift={(6,0)}]
      \begin{knot}
        \strand[thick] (0,0)
        to (0,1)
        to [out=up,in=up,looseness=2] (1,1)
        to [out=down,in=down,looseness=2] (2,1)
        to (2,2);
      \end{knot}
      \node[label=above:{$h$}] at (0.5,1.57) {$\bullet$};
      \node[label=below:{$g$}] at (1.5,0.4) {$\bullet$};
    \end{scope}
  \end{tikzpicture}
\] which says that the bilinear form \(g\) is nondegenerate. To get
further, we'll also demand that \[
  \begin{tikzpicture}
    \begin{knot}[clip width=7]
      \strand[thick] (0,0)
        to [out=down,in=up] (1,-2)
        to [out=down,in=down,looseness=2] (0,-2);
      \strand[thick] (0,-2)
        to [out=up,in=down] (1,0);
      \flipcrossings{1}
    \end{knot}
    \node[label=below:{$g$}] at (0.5,-2.6) {$\bullet$};
    \node at (2,-1.5) {$=$};
    \begin{knot}
      \strand[thick] (3,0)
        to (3,-2)
        to [out=down,in=down,looseness=2] (4,-2)
        to (4,0);
    \end{knot}
    \node[label=below:{$g$}] at (3.5,-2.6) {$\bullet$};
  \end{tikzpicture}
\] This says that the bilinear form \(g\) is symmetric, that is:
\[g(x,y) = g(y,x).\] But we can only state this equation if we're in a
monoidal category where we can ``switch arguments'', which in pictures
goes like this: \[
  \begin{tikzpicture}
    \begin{knot}[clip width=7]
      \strand[thick] (0,0)
        to [out=down,in=up] (1,-2);
      \strand[thick] (0,-2)
        to [out=up,in=down] (1,0);
      \flipcrossings{1}
    \end{knot}
  \end{tikzpicture}
\] A monoidal category with this feature is called a ``symmetric
monoidal category'' (or more generally a ``braided monoidal category'',
but I don't want to get into those complications here).

So far, so good! The second problem is figuring out how to state the
condition \(|xy| = |x| |y|\). If we translate this into a condition on
our bilinear form \(g\), we get \[g(xy,xy) = g(x,x) g(y,y)\] An algebra
with a nondegenerate bilinear form having this property is called a
``composition algebra''. Hurwitz showed that such an algebra must have
dimension 1, 2, 4, or 8. However, there are examples other than the
famous four, coming from bilinear forms \(g\) that aren't positive
definite. For example, there are the ``split quaternions'' in dimension
4, or the ``split octonions'' in dimension 8.

Now, the problem with the above equational law is that it involves
duplication of arguments. But we can get around this problem by a
standard trick called ``polarization'', which people use a lot in
quantum mechanics.

First let's polarize the argument \(x\). To do this, note that we have
\[
  \begin{aligned}
    g(xy,xy) &= g(x,x) g(y,y)
  \\g(x'y,x'y) &= g(x',x') g(y,y)
  \end{aligned}
\] and also \[g((x+x')y,(x+x')y) = g(x+x',x+x') g(y,y).\] Subtracting
the first two equations from the last and then dividing by \(2\), we get
\[g(xy,x'y) = g(x,x') g(y,y).\] See? We've eliminated the duplication of
the argument \(x\). This new equation obviously implies the original
one.

Next we polarize the argument \(y\). We have \[
  \begin{aligned}
    g(xy,x'y) &= g(x,x') g(y,y)
  \\g(xy',x'y') &= g(x,x') g(y',y')
  \end{aligned}
\] and also \[g(x(y+y'),x'(y+y')) = g(x,x') g(y+y',y+y').\] Subtracting
the first two equations from the last one, we get
\[g(xy,x'y') + g(xy',x'y) = 2 g(x,x') g(y,y')\] Now there is no
duplication of arguments. We've paid a price, though: now our equation
involves addition, so we can only write it down if our category has the
extra feature that we can add morphisms. For this, we want our category
to be ``additive''.

So: the right doctrine in which to define composition algebras is the
doctrine of symmetric monoidal additive categories!

(Technical note: here we want the monoidal and additive structures to
get along nicely: tensoring of morphisms should be bilinear.)

Let me summarize by giving all the details. A ``composition object'' is
an object \(A\) in a symmetric monoidal additive category which is
equipped with morphisms \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to [out=down,in=up] (0.5,-1)
        to (0.5,-2);
      \strand[thick] (1,0)
        to [out=down,in=up] (0.5,-1);
    \end{knot}
    \node[label=left:{$m$}] at (0.5,-0.95) {$\bullet$};
    \node (s) at (3,0) {$A\otimes A$};
    \node (t) at (3,-2) {$A$};
    \draw[->] (s) to node[label=left:{$m$}]{} (t);
    \node at (1.75,-2.75) {``multiplication''};
  \end{tikzpicture}
  \qquad\qquad
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to (0,-2);
    \end{knot}
    \node[label=left:{$i$}] at (0,0) {$\bullet$};
    \node (s) at (2,0) {$I$};
    \node (t) at (2,-2) {$A$};
    \draw[->] (s) to node[label=left:{$i$}]{} (t);
    \node at (1,-2.75) {``unit''};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to (0,-1)
        to [out=down,in=down,looseness=2] (1,-1)
        to (1,0);
    \end{knot}
    \node[label=below:{$g$}] at (0.5,-1.6) {$\bullet$};
    \node (s) at (3,0) {$A\otimes A$};
    \node (t) at (3,-2) {$I$};
    \draw[->] (s) to node[label=left:{$g$}]{} (t);
    \node at (1.75,-2.75) {``bilinear form''};
  \end{tikzpicture}
  \qquad\qquad
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,-2)
        to (0,-1)
        to [out=up,in=up,looseness=2] (1,-1)
        to (1,-2);
    \end{knot}
    \node[label=above:{$h$}] at (0.5,-0.43) {$\bullet$};
    \node (s) at (3,0) {$I$};
    \node (t) at (3,-2) {$A\otimes A$};
    \draw[->] (s) to node[label=left:{$h$}]{} (t);
    \node at (1.75,-2.75) {``inverse bilinear form''};
  \end{tikzpicture}
\] satisfying the equations already shown: \[
  \begin{tikzpicture}
    \begin{scope}[xscale=-1,shift={(-2,0)}]
      \begin{knot}
        \strand[thick] (0,0)
        to (0,1)
        to [out=up,in=up,looseness=2] (1,1)
        to [out=down,in=down,looseness=2] (2,1)
        to (2,2);
      \end{knot}
      \node[label=above:{$h$}] at (0.5,1.57) {$\bullet$};
      \node[label=below:{$g$}] at (1.5,0.4) {$\bullet$};
    \end{scope}
    \node at (3,1) {$=$};
    \begin{scope}[shift={(4,0)}]
      \begin{knot}
        \strand[thick] (0,0) to (0,2);
      \end{knot}
    \end{scope}
    \node at (5,1) {$=$};
    \begin{scope}[shift={(6,0)}]
      \begin{knot}
        \strand[thick] (0,0)
        to (0,1)
        to [out=up,in=up,looseness=2] (1,1)
        to [out=down,in=down,looseness=2] (2,1)
        to (2,2);
      \end{knot}
      \node[label=above:{$h$}] at (0.5,1.57) {$\bullet$};
      \node[label=below:{$g$}] at (1.5,0.4) {$\bullet$};
    \end{scope}
  \end{tikzpicture}
\] and \[
  \begin{tikzpicture}
    \begin{knot}[clip width=7]
      \strand[thick] (0,0)
        to [out=down,in=up] (1,-2)
        to [out=down,in=down,looseness=2] (0,-2);
      \strand[thick] (0,-2)
        to [out=up,in=down] (1,0);
      \flipcrossings{1}
    \end{knot}
    \node[label=below:{$g$}] at (0.5,-2.6) {$\bullet$};
    \node at (2,-1.5) {$=$};
    \begin{knot}
      \strand[thick] (3,0)
        to (3,-2)
        to [out=down,in=down,looseness=2] (4,-2)
        to (4,0);
    \end{knot}
    \node[label=below:{$g$}] at (3.5,-2.6) {$\bullet$};
  \end{tikzpicture}
\] together with the left and right unit laws: \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0.5) to (0,0);
      \strand[thick] (1,1.5) to (1,0);
      \strand[thick] (0,0)
        to [out=down,in=up] (0.5,-1)
        to (0.5,-2);
      \strand[thick] (1,0)
        to [out=down,in=up] (0.5,-1);
    \end{knot}
    \node[label=left:{$i$}] at (0,0.5) {$\bullet$};
    \node[label=left:{$m$}] at (0.5,-0.95) {$\bullet$};
    \node at (2,-0.25) {$=$};
    \begin{knot}
      \strand[thick] (3,1.5) to (3,-2);
    \end{knot}
    \node at (4,-0.25) {$=$};
    \begin{scope}[xscale=-1,shift={(-6,0)}]
      \begin{knot}
        \strand[thick] (0,0.5) to (0,0);
        \strand[thick] (1,1.5) to (1,0);
        \strand[thick] (0,0)
          to [out=down,in=up] (0.5,-1)
          to (0.5,-2);
        \strand[thick] (1,0)
          to [out=down,in=up] (0.5,-1);
      \end{knot}
      \node[label=right:{$i$}] at (0,0.5) {$\bullet$};
      \node[label=left:{$m$}] at (0.5,-0.95) {$\bullet$};
    \end{scope}
  \end{tikzpicture}
\] and best of all, the equation
\[g(xy,x'y') + g(xy',x'y) = 2 g(x,x') g(y,y')\] translated into pictures
like this: \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to [out=down,in=up] (0.5,-1)
        to (0.5,-1.5);
      \strand[thick] (1,0)
        to [out=down,in=up] (0.5,-1);
      \strand[thick] (1.5,0)
        to [out=down,in=up] (2,-1)
        to (2,-1.5);
      \strand[thick] (2.5,0)
        to [out=down,in=up] (2,-1);
      \strand[thick] (0.5,-1.5)
        to [out=down,in=down,looseness=2] (2,-1.5);
    \end{knot}
    \node[label=left:{$m$}] at (0.5,-0.95) {$\bullet$};
    \node[label=right:{$m$}] at (2,-0.95) {$\bullet$};
    \node[label=below:{$g$}] at (1.25,-2.4) {$\bullet$};
    \node at (3.5,-1.5) {$+$};
    \begin{scope}[shift={(4.5,0)}]
      \begin{knot}[clip width=7]
        \strand[thick] (0,0)
          to (0,-1)
          to [out=down,in=up] (1.25,-2);
        \strand[thick] (0.75,0)
          to [out=down,in=up] (1.25,-1)
          to [out=down,in=up] (0,-2)
          to [out=down,in=down,looseness=2] (1.25,-2);
        \strand[thick] (1.75,0)
          to [out=down,in=up] (1.25,-1);
        \strand[thick] (2.5,0) to (2.5,-1)
          to [out=down,in=up] (1.25,-2);
        \flipcrossings{1}
      \end{knot}
      \node[label=left:{$m$}] at (1.25,-0.95) {$\bullet$};
      \node[label=right:{$m$}] at (1.25,-1.95) {$\bullet$};
      \node[label=below:{$g$}] at (0.625,-2.74) {$\bullet$};
    \end{scope}
    \node at (8,-1.5) {$=$};
    \node at (9,-1.5) {$2\,\,\times$};
    \begin{scope}[shift={(9.7,-1.1)}]
      \begin{knot}[clip width=7]
        \strand[thick] (0,0)
          to [out=down,in=down,looseness=2] (1.5,0);
        \strand[thick] (1,0)
          to [out=down,in=down,looseness=2] (2.5,0);
      \end{knot}
      \node [label=below:{$g$}] at (0.75,-0.88) {$\bullet$};
      \node [label=below:{$g$}] at (1.75,-0.88) {$\bullet$};
    \end{scope}
  \end{tikzpicture}
\]

Now, given all this stuff, we can define the ``dimension'' of our
composition algebra to be the value of this morphism from \(I\) to
\(I\): \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
        to [out=up,in=up,looseness=2] (1,0)
        to [out=down,in=down,looseness=2] (0,0);
    \end{knot}
    \node[label=above:{$h$}] at (0.5,0.57) {$\bullet$};
    \node[label=below:{$g$}] at (0.5,-0.6) {$\bullet$};
  \end{tikzpicture}
\] This reduces to the usual dimension of the algebra \(A\) when we're
in the category \(\mathsf{Vect}\). Of course, only in certain categories
is this dimension bound to be a \emph{number} --- namely, those
categories where every morphism from \(I\) to \(I\) is some number times
the identity morphism.

By making an extra assumption like this, Boos is able to give a
``picture proof'' that in a large class of symmetric monoidal additive
categories, every composition object has dimension 1, 2, 4 or 8. This is
great, because it means we can talk about things like real, complex,
quaternionic and octonionic objects in a wide variety of categories! He
doesn't prove such objects exist, but I think this should be easy, at
least with some extra assumptions which would allow us to construct them
``by hand'', mimicking standard constructions of the normed division
algebras.

But now I must warn you of some things. Boos doesn't state his result
the way I would! Instead of working with ``composition objects'' (which
appear to be my own invention), he works with ``vector product
algebras''. These are modelled, not after the normed division algebras
themselves, but after their ``imaginary parts''. These have both an
inner product and a ``vector product''.

For example, the imaginary quaternions form a \(3\)-dimensional vector
product algebra with vector product given by
\[a\times b = \frac12(ab - ba).\] This is just the usual cross product!
The same formula makes the imaginary octonions into a \(7\)-dimensional
vector product algebra, the imaginary complex numbers into a boring
\(1\)-dimensional one\ldots{} and the imaginary real numbers into an
even more boring 0-dimensional one.

Boos writes down the axioms for a vector product algebra using pictures
much like I just did for a composition object, and he shows that under
some pretty mild conditions you can freely go back and forth between the
two concepts.

I think you can summarize his theorem on vector product algebras as
follows: in all symmetric monoidal \(R\)-linear categories where \(R\)
is a commutative ring containing \(\mathbb{Z}[\frac12]\) and \(I\) is a
simple object, vector product algebras must have dimension 0, 1, 3, or
7. He doesn't state his result quite this way, but I'm pretty sure
that's what it boils down to. As for the jargon: a category is
``\(R\)-linear'' if the homsets are \(R\)-modules and composition of
morphisms is bilinear; for monoidal categories we also want tensoring
morphisms to be bilinear. The ring \(\mathbb{Z}[\frac12]\) consists of
all fractions with a power of 2 in the denominator --- Boos needs this
because he needs to divide by \(2\) at some point in his argument. For
an \(R\)-linear category, an object \(I\) is ``simple'' if
\(\operatorname{Hom}(I,I) = R\). This allows us to interpret the
dimension of our vector product algebra as an element of \(R\) --- which
Boos shows is actually one of the integers 0, 1, 3, or 7.

Let me conclude by showing you Boos' main axiom for vector product
algebras, written in terms of pictures: \[
  \begin{tikzpicture}
    \begin{knot}[clip width=0]
      \strand[thick] (0,0)
        to (0.25,-0.75)
        to (0,-1.5);
      \strand[thick] (1,0)
        to (0.75,-0.75)
        to (1,-1.5);
      \strand[thick] (0.25,-0.75) to (0.75,-0.75);
    \end{knot}
    \node at (1.75,-0.75) {$+$};
    \begin{scope}[shift={(2.5,0)}]
      \begin{knot}[clip width=0]
        \strand[thick] (0,0)
          to (0.5,-0.5)
          to (0.5,-1)
          to (0,-1.5);
        \strand[thick] (1,0)
          to (0.5,-0.5)
          to (0.5,-1)
          to (1,-1.5);
      \end{knot}
    \end{scope}
    \node at (4.25,-0.75) {$=$};
    \node at (5.25,-0.75) {$2\,\,\times$};
    \begin{scope}[shift={(5.75,0)}]
      \begin{knot}[clip width=7]
        \strand[thick] (0,0) to (1,-1.5);
        \strand[thick] (1,0) to (0,-1.5);
        \flipcrossings{1}
      \end{knot}
    \end{scope}
    \node at (7.5,-0.75) {$-$};
    \begin{scope}[shift={(8.25,0)}]
      \begin{knot}
        \strand[thick] (0,0)
          to (0.25,-0.75)
          to (0,-1.5);
        \strand[thick] (1,0)
          to (0.75,-0.75)
          to (1,-1.5);
      \end{knot}
    \end{scope}
    \node at (10,-0.75) {$-$};
    \begin{scope}[shift={(10.75,0)}]
      \begin{knot}
        \strand[thick] (0,0)
          to (0.25,-0.5)
          to (0.75,-0.5)
          to (1,0);
        \strand[thick] (0,-1.5)
          to (0.25,-1)
          to (0.75,-1)
          to (1,-1.5);
      \end{knot}
    \end{scope}
  \end{tikzpicture}
\] Ain't it cool? Fans of knot theory will be struck by the resemblance
to various ``skein relations''. Fans of physics will be reminded of
Feynman diagrams. But what is the secret inner meaning?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{``The perplexity of life arises from there being too many
interesting things in it for us to be interested properly in any of
them.''} --- G. K. Chesterton, 1909



\hypertarget{week170}{%
\section{August 8, 2001}\label{week170}}

I've been travelling around a lot lately. For a couple of weeks I was in
Turkey, resisting the lure of the many internet cafes. I urge you all to
visit Istanbul when you get a chance! Fascinating music fills the
streets. There are a lot of nice bookstore-cafes on Istiklal Caddesi
near Taksim Square, and a huge number of musical instrument shops at the
other end of this street, down near Tunel Square. I bought a nice
doumbek at one of these shops, and looked at lots of ouzes, sazes and
neys, none of which I can play. It's also imperative to check out the
Grand Bazaar, the mosques, and the Topkapi Palace --- the harem there
has most beautiful geometric tiling patterns I've ever seen. I'm not
sure why that's true; perhaps this is where the sultans spent most of
their time.

The mathematics of tilings is a fascinating subject, but that's not what
I'm going to talk about. After my trip to Turkey, I went to a conference
at Stanford:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Conference on Algebraic Topological Methods in Computer Science,
  Stanford University, \texttt{http://math.stanford.edu/atmcs/index.htm}
\end{enumerate}

There were lots of fun talks, but I'll just mention two.

The talk most related to physics was the one by my friend Dan
Christensen, who spoke on ``Spin Networks, Spin Foams and Quantum
Gravity'', describing a paper he is writing with Greg Egan on efficient
algorithms for computing Riemannian \(10j\) symbols. Dan is a homotopy
theorist at the University of Western Ontario, and Greg is my favorite
science fiction writer. They're both interested in quantum gravity, and
they're both good at programming. Together with some undergraduate
students of Dan's, the three of us are starting to study the Riemannian
and Lorentzian Barrett-Crane models of quantum gravity with the help of
computer simulations. But to get anywhere with this, we need to get good
at computing ``\(10j\) symbols''.

Huh? ``\(10j\) symbols''??

Well, as with any quantum field theory, the key to the Barrett-Crane
model is the partition function. In the Riemannian version of this
theory, you compute the partition function as follows. First you take
your \(4\)-dimensional manifold representing spacetime and triangulate
it. Then you label all the triangles by spins
\(j = 0, 1/2, 1, 3/2, \ldots\). Following certain specific formulas you
then calculate a number for each 4-simplex, a number for each
tetrahedron, and a number for each triangle, using the spin labellings.
Then you multiply all these together. Finally you sum over all
labellings to get the partition function. The only tricky part is the
convergence of this sum, which was proved by Perez:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Alejandro Perez, ``Finiteness of a spin foam model for euclidean
  quantum general relativity'', \emph{Nucl. Phys.} \textbf{B599} (2001)
  427--434. Also available as
  \href{https://arxiv.org/abs/gr-qc/0011058}{\texttt{gr-qc/0011058}}.
\end{enumerate}

The most interesting aspect of all this is the formula giving numbers
for \(4\)-simplices. A \(4\)-simplex has 10 triangular faces all of
which get labelled by spins, and the formula says how to compute a
number from these 10 spins --- the so-called ``\(10j\) symbol''.

How do you compute \(10j\) symbols? One approach involves representation
theory, or in lowbrow terms, multiplying a bunch of matrices.
Unfortunately, if you go about this in the most simple-minded obvious
fashion, when the spins labelling your triangles are all about equal to
\(j\), you wind up needing to work with matrices that are as big as
\(N\times N\), where \[N = (2j+1)^{12}.\] If you do this, already for
\(j = 1/2\) you are dealing with square matrices that are \(2^{12}\) by
\(2^{12}\). This is too big to be practical!

In computer science lingo, this algorithm sucks because it uses
\(\mathcal{O}(j^{12})\) time and also \(\mathcal{O}(j^{12})\) space. You
might think it was \(\mathcal{O}(j^{24})\), but it's not that
bad\ldots{} however, it's still very bad!

Luckily, Dan and Greg have figured out a much more efficient algorithm,
which uses only \(\mathcal{O}(j^6)\) time and \(\mathcal{O}(j)\) space.
Alternatively, with more caching of data, they can get
\(\mathcal{O}(j^5)\) time and \(\mathcal{O}(j^3)\) space, or maybe even
better. Using an algorithm of this sort, Dan can compute the \(10j\)
symbol for spins up to 55. For all spins equal to 55, the calculation
took about 10 hours on a normal desktop computer. However, for computing
partition functions it appears that small spins are much more important,
and then the computation takes milliseconds.

(Actually, for computing partition functions, Dan is not using a
desktop: he is using a Beowulf cluster, which is a kind of supercomputer
built out of lots of PCs. This works well for partition functions
because the computation is highly parallelizable.)

John Barrett has also figured out a very different approach to computing
\(10j\) symbols:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  John W. Barrett, ``The classical evaluation of relativistic spin
  networks'', \emph{Adv. Theor. Math. Phys.} \textbf{2} (1998),
  593--600. Also available as
  \href{https://arxiv.org/abs/math.QA/9803063}{\texttt{math.QA/9803063}}.
\end{enumerate}

In this approach one computes the \(10j\) symbols by doing an integral
over the space of geometries of a \(4\)-simplex --- or more precisely,
over a product of 5 copies of the 3-sphere, where a point on one of
these 3-spheres describes the normal vector to one of the 5 tetrahedral
faces of the \(4\)-simplex.

Dan and Greg have also written programs that calculate the \(10j\)
symbols by doing these integrals. The answers agree with their other
approach.

We've already been getting some new physical insights from these
calculations. If you write down the integral formula for the Riemannian
\(10j\) symbols, a stationary phase argument due to John Barrett and
Ruth Williams suggests that, at least in the limit of large spins, the
dominant contribution to the integral for the \(10j\) symbol comes from
4-simplices whose face areas are the 10 spins in your \(10j\) symbols:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  John W. Barrett and Ruth M. Williams, ``The asymptotics of an
  amplitude for the \(4\)-simplex'', \emph{Adv. Theor. Math. Phys.}
  \textbf{3} (1999), 209--215. Also available as
  \href{https://arxiv.org/abs/gr-qc/9809032}{\texttt{gr-qc/9809032}}.
\end{enumerate}

However, Dan and Greg's calculations suggest instead that the dominant
contribution comes from certain ``degenerate'' configurations. Some of
these correspond to points on the product of 5 copies of the 3-sphere
that are close to points of the form \((v,v,v,v,v)\) --- or roughly
speaking, 4-simplices whose 5 normal vectors are all pointing the same
way. Others come from sprinkling minus signs in this list of vectors.
Heuristically, we can think of these degenerate configurations as
extremely flattened-out \(4\)-simplices.

For simplicity, we have concentrated so far on studying the \(10j\)
symbols in the case when all 10 spins are equal. In this case we can
show that the only nondegenerate \(4\)-simplex with these spins as face
areas is the regular \(4\)-simplex (all of whose faces are congruent
equilateral triangles). Greg used stationary phase to compute the
contribution of this regular \(4\)-simplex to Barrett's integral formula
for the \(10j\) symbols, and it turned out that asymptotically, for
large \(j\), this contribution decays like \(j^{-9/2}\). On the other
hand, Dan's numerical computations of the \(10j\) symbol suggests that
it goes like \(j^{-2}\). This suggests that for large \(j\), the
contribution of the regular \(4\)-simplex is dwarfed by that of the
degenerate \(4\)-simplices.

Greg has gotten more evidence for this by studying the integral formula
for the \(10j\) symbols and estimating the contribution due to
degenerate 4-simplices. This estimate indeed goes like \(j^{-2}\) for
large \(j\).

There is a lot more to be understood here, but plunging ahead
recklessly, we can ask what all this means for the physics of the
Barrett-Crane model. For example: is the dominant contribution to the
partition function going to come from spacetime geometries with lots of
degenerate \(4\)-simplices?

I think that's a premature conclusion, because we already have evidence
that 4 -simplices with large face areas are not contributing that much
compared to those with small face areas when we compute the partition
function as a sum over spin foams. In other words, it seems that in the
Riemannian Barrett-Crane model, spacetime is mostly made of lots of
small \(4\)-simplices, rather than a few giant ones. If so, the tendency
for the giant ones to flatten out may not be so bad.

Of course the really important thing will be to study these questions
for the Lorentzian theory, but it's good to look at the Riemannian
theory too.

Another talk on a subject close to my heart was given by Noson Yanofsky.
It was based on these papers of his, especially the last:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Noson S. Yanofsky, ``Obstructions to coherence: natural noncoherent
  associativity'', \emph{Jour. Pure Appl. Alg.} \textbf{147} (2000),
  175--213. Also available at
  \href{https://arxiv.org/abs/math.QA/9804106}{\texttt{math.QA/9804106}}.

  ``The syntax of coherence''. To appear in \emph{Cahiers Top. Geom.
  Diff.}. Also available at
  \href{https://arxiv.org/abs/math.CT/9910006}{\texttt{math.CT/9910006}}.

  ``Coherence, homotopy and 2-theories''. To appear in \emph{K-Theory}.
  Also available at
  \href{https://arxiv.org/abs/math.CT/0007033}{\texttt{math.CT/0007033}}.
\end{enumerate}

One of the cool things Yanofsky has done is to study what happens when
we categorify Lawvere's concept of an ``algebraic theory''. I've already
explained this idea of ``algebraic theory'' in
\protect\hyperlink{week53}{``Week 53''} and
\protect\hyperlink{week136}{``Week 136''}, so I'll just quickly recap it
here:

The notion of ``algebraic theory'' is just a slick way to study sets
equipped with extra algebraic structure. We call a category
\(\mathcal{C}\) with finite products an ``algebraic theory'' if its
objects are all of the form \(1, X, X^2, X^3, \ldots\) for some
particular object \(X\). We call a product-preserving functor
\(F\colon\mathcal{C}\to\mathsf{Set}\) a ``model'' of the theory. And we
call a natural transformation between such functors a ``homomorphism''
between models. This gives us a category \(\mathsf{Mod}(\mathcal{C})\)
consisting of models and homomorphisms between them, and it turns out
that many categories of algebraic gadgets are of this form: the category
of monoids, the category of groups, the category of abelian groups, and
so on.

Since algebraic theories are good for studying sets with extra algebraic
structure, we might hope that by categorifying, we could obtain a
concept of ``algebraic 2-theories'' which is good for studying
\emph{categories} with extra algebraic structure. And it's true! In
1974, John Gray defined an ``algebraic 2-theory'' to be a \(2\)-category
\(\mathcal{C}\) with finite products, all of whose objects are of the
form \(1, X, X^2, X^3,\ldots\) for some particular object \(X\). Define
a ``model'' of this 2-theory to be a product-preserving 2-functor
\(F\colon\mathcal{C}\to\mathsf{Cat}\). And define a ``homomorphism''
between models to be a pseudonatural transformation between such
2-functors.

Huh? ``Pseudonatural''??

Sorry, now things are getting a bit technical: the right thing going
between 2-functors is not a natural transformation but something a bit
weaker called a ``pseudonatural transformation'', where the usual
commuting squares in the definition of a natural transformation are
required to commute only up to certain specified 2-isomorphisms, which
in turn satisfy some coherence laws described here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  G. Maxwell Kelly and Ross Street, \emph{Review of the elements of
  \(2\)-categories}, Springer Lecture Notes in Mathematics \textbf{420},
  Berlin, 1974, pp.~75--103.
\end{enumerate}

However, you don't need to understand the details right now. There is
also something going between pseudonatural transformations called a
``modification'', and this gives us ``2-homomorphisms'' between
homomorphisms between models of our algebraic theory. Thanks to these
there is a \(2\)-category \(\mathsf{Mod}(\mathcal{C})\) consisting of
models of our 2-theory homomorphisms between those, and 2-homomorphisms
between those.

Some examples might help! For example, there's a 2-theory
\(\mathcal{C}\) called the ``theory of weak monoidal categories''.
Models of \(\mathcal{C}\) are weak monoidal categories, homomorphisms
are monoidal functors, and 2-homomorphisms are natural transformations,
so \(\mathsf{Mod}(\mathcal{C})\) is the usual \(2\)-category of monoidal
\(2\)-categories. There's a similar 2-theory \(\mathcal{C}'\) called
``the theory of strict monoidal categories'', for which
\(\mathsf{Mod}(\mathcal{C}')\) is the usual \(2\)-category of strict
monoidal categories.

(Hyper-technical note for \(n\)-category mavens only: in both examples
here, monoidal functors are required to preserve unit and tensor product
only \emph{up to coherent natural isomorphism}. This nuance is what we
get from working with pseudonatural rather than natural transformations.
Without this nuance, some of the stuff I'm about to say would be false.)

Now, whenever we have a product-preserving 2-functor between 2-theories,
say \(F\colon\mathcal{C}\to\mathcal{C}'\), we get an induced 2-functor
going the other way,
\[F^*\colon\mathsf{Mod}(\mathcal{C}')\to\mathsf{Mod}(\mathcal{C}).\] For
example, there's a product-preserving 2-functor from the theory of weak
monoidal categories to the theory of strict monoidal categories, and
this lets us turn any strict monoidal category into a weak one.

Now in this particular example, \(F^*\) is a biequivalence, which is the
nice way to say that the \(2\)-categories \(\mathsf{Mod}(C)\) and
\(\mathsf{Mod}(C')\) are ``the same'' for all practical purposes. And in
fact, saying that this particular \(F^*\) is a biequivalence is really
just an ultra-slick version of Mac Lane's theorem --- the theorem we use
to turn weak monoidal categories into strict ones.

Now, Mac Lane's theorem is the primordial example of a ``strictification
theorem'' --- a theorem that lets us turn ``weak'' algebraic structures
on categories into ``strict'' ones, where lots of isomorphisms, like the
associators in the monoidal category example, are assumed to be
equations. This suggests that lots of coherence theorems can be stated
by saying that 2-functors of the form \(F^*\) are biequivalences.

So: is there a super-general strictification theorem where we can start
from any 2-theory \(\mathcal{C}\) and get a ``strictified'' version
\(\mathcal{C}'\) together with an \(F\colon\mathcal{C}\to\mathcal{C}'\)
such that \(F^*\) is a biequivalence?

As a step in this direction, Yanofsky has cooked up a model category of
algebraic 2-theories, in which \(F\colon\mathcal{C}\to\mathcal{C}'\) is
a weak equivalence precisely when \(F^*\) is a biequivalence.

Huh? ``Model category''??

Well, if you don't know what a ``model category'' is, you're in serious
trouble now! They're a concept invented by Quillen for generalizing the
heck out of homotopy theory. Try reading his book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Daniel G. Quillen, \emph{Homotopical Algebra}, Springer Lecture Notes
  in Mathematics, vol.~\textbf{43}, Springer, Berlin, 1967.
\end{enumerate}

or for something newer:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Mark Hovey, \emph{Model Categories}, American Mathematical Society
  Mathematical Surveys and Monographs, vol \textbf{63}, Providence,
  Rhode Island, 1999.
\end{enumerate}

or else:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Paul G. Goerss and John F. Jardine, \emph{Simplicial Homotopy Theory},
  Birkhauser, Boston, 1999.
\end{enumerate}

(By the way, Jardine was one of the organizers of this Stanford
conference, along with Gunnar Carlsson. He told me he had created a
hypertext version of this book, but has not been able to get the
publisher interested in it. Sad!)

Anyway, in the framework of model categories, the problem of
``strictifying'' an algebraic structure on categories then amounts to
finding a ``minimal model'' of a given 2-theory \(\mathcal{C}\) ---
roughly speaking, a weakly equivalent 2-theory with as little flab as
possible. The concept of ``minimal model'' is important in homotopy
theory, but apparently Yanofsky is the first to have given a general
definition of this concept applicable to any model category. Yanofsky
has not shown that every algebraic 2-theory admits a minimal model, but
this seems like a fun and interesting question.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{all ignorance toboggans into know and trudges up to ignorance
again.} --- e.e.cummings, 1959



\hypertarget{week171}{%
\section{October 10, 2001}\label{week171}}

There isn't a Nobel prize for mathematics. You've probably heard why:
Alfred Nobel was annoyed that the famous mathematician Mittag-Leffler
had an affair with his wife. Well, that's what they say, anyway. It
makes a great story. The only problem is, Nobel was never married! So
it's just another urban legend. For more details, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Urban legends reference pages, ``The Prize's Rite'',
  \texttt{http://www.snopes2.com/science/nobel.htm}
\end{enumerate}

More likely, Nobel just didn't consider mathematics sufficiently
practical. In any event, mathematicians have always felt a bit grumpy
about this slight. Their adoption of the Fields Medal as a kind of
substitute has never been completely satisfying. For one thing, the
Fields Medal is only for work done before the age of 40 --- a condition
that seems ever more silly with the wisdom of age. For another, the
Fields prize gives you a measly 15,000 Canadian dollars, while the Nobel
prize keeps going up: this year, it was 10 million Swedish crowns, or
almost a million bucks.

Anyway, now there may be a better substitute: the Abel Prize.

\begin{itemize}
\tightlist
\item
  ``Norway Establishes Abel Prize in Mathematics'',
  \texttt{http://www.maa.org/news/abel\_prize.html}
\end{itemize}

It even almost rhymes with Nobel! Abel, of course, was a famous
Norwegian mathematician, and this prize will be awarded annually by the
government of Norway, starting in 2003. It will have a value of about
\$500,000, at least initially. Even better, it will be awarded on a
first-come, first-serve basis\ldots{} so send in your application now.

When I was in Cambridge this summer, I visited Tom Leinster and Eugenia
Cheng, who showed me around the new mathematics buildings. The Cambridge
system is too Byzantine for a mere American to understand, but there are
two main things resembling a ``mathematics department'': DPMSS, the
Department of Pure Mathematics and Mathematical Statistics, and DAMTP,
the Department of Applied Mathematics and Theoretical Physics. They used
to be in separate dilapidated buildings downtown on Silver Street, but
now they occupy two towers in a huge complex near the Newton Institute,
on the outskirts of town.

The new setup is pretty cool. Parts of it are still under construction,
but you can get the idea already. Different breeds of mathematicians
will be housed in different towers, all surrounding a central building
resembling an airplane hanger, which is actually an enormous cafeteria.
The univeral human interest in food will lure otherwise aloof
specialists to mingle and chat. I even saw Hawking there one day.
However, there is also a separate coffee lounge at the base of each
tower, so the different groups can have slightly more private chats.
Futuristic light sensors lower curtains in the cafeteria whenever the
sun comes out, to enhance the visitor's impression that it's always
cloudy in England. But the really cool thing is that every tower has a
door on the second floor which opens out to the \emph{roof} of the
cafeteria. The roof is covered with grass, like a little park! Finally,
people working on fluid dynamics are kept in the basement, which gurgles
mysteriously with the sound of experiments.

Leinster and Cheng are both students of Martin Hyland, and they both
work on \(n\)-categories. I've talked about their work before in
\protect\hyperlink{week165}{``Week 165''}. Leinster has just come out
with a nice paper on \(n\)-categories:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Tom Leinster, ``A survey of definitions of \(n\)-category'', available
  at
  \href{https://arxiv.org/abs/math.CT/0107188}{\texttt{math.CT/0107188}}.
\end{enumerate}

By now, there are lots of definitions of ``weak \(n\)-category'', and
our job is to understand how they're related. This paper is required
reading for anyone interested in this business: it goes through 10
different definitions, giving each definition in two pages and then
using two more pages to show how it works for \(n\) less than or equal
to 2. It also has a nice annotated bibliography giving some of the
history of the subject.

While I'm talking about review articles, here are some review articles
on quantum gravity:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Steve Carlip, ``Quantum gravity: a progress report'', \emph{Rep.~Prog.
  Phys.} \textbf{64} (2001) 885--942, also available at
  \href{https://arxiv.org/abs/gr-qc/0108040}{\texttt{gr-qc/0108040}}.
\end{enumerate}

This is an excellent \emph{long} description of where we stand on
quantum gravity, with a strong focus on the big conceptual problems.
Again, it's required reading for anyone in this field. It doesn't do
justice to string theory, which is a mammoth subject in its own. For
that, you might try this article which I bumped into in the same
journal:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Ulf Daniellson, ``Introduction to string theory'', \emph{Rep.~Prog.
  Phys.} \textbf{64} (2001) 51-96.
\end{enumerate}

It seems to do a pretty good job of the impossible --- explaining all of
string theory in less than 50 pages. Of course, if you want to get
serious, you'll eventually have to read some of the string theory
textbooks listed in \protect\hyperlink{week124}{``Week 124''} and
elsewhere.

There is also a new introduction to loop quantum gravity available
online. It's more of a book than an article:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Thomas Thiemann, \emph{Introduction to modern canonical quantum
  general relativity}, 301 pages, available at
  \href{https://arxiv.org/abs/gr-qc/0110034}{\texttt{gr-qc/0110034}}.
\end{enumerate}

This is really \emph{the} place to go if you want to catch up on the
last 15 years of work on loop quantum gravity. It's truly impressive.
It'll make fairly substantial demands on the average physicist's
mathematical know-how: for example, not just differential geometry,
which everyone into gravity must know, but also functional analysis.
Luckily, it has an appendix over 40 pages long which explains much of
the needed math. For the would-be grad student or postdoc, a very
helpful feature is the list of institutions where loop quantum gravity
is studied, in the Introduction.

Speaking of loop quantum gravity, here are a few interesting new papers
on that subject:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Rodolfo Gambini and Jorge Pullin, ``Consistent discretizations for
  classical and quantum general relativity'', available as
  \href{https://arxiv.org/abs/gr-qc/0108062}{\texttt{gr-qc/0108062}}.
\item
  Luca Bombelli, ``Statistical geometry of random weave states'',
  available as
  \href{https://arxiv.org/abs/gr-qc/0101080}{\texttt{gr-qc/0101080}}.
\item
  Michael Seifert, ``Angle and volume studies in quantized space'', 85
  pages, available as
  \href{https://arxiv.org/abs/gr-qc/0108047}{\texttt{gr-qc/0108047}}.
\end{enumerate}

The paper by Gambini and Pullin argues that good spin foam models will
come from quantizing ``consistent'' discretizations of general
relativity, that is, those where the discretized equations of motion
preserve the constraints on initial data, and where the solutions
converge to solutions of the continuum equations in the limit where the
discretization is made ever more fine.

The paper by Bombelli presents a proposal for states of loop quantum
gravity that should be good approximations to classical geometries. The
idea is to take a Riemannian manifold, sprinkle points on it randomly
form the corresponding Voronoi diagram, and label the edges with spins
in a certain way to get a spin network. If we then average over all
possible ways of randomly sprinkling these points, we get Bombelli's
``random weave state'' --- a kinematical state of quantum gravity that
approximates of the Riemannian geometry we started with.

I don't know if that made sense to you. Do you at least know what a
Voronoi diagram is? To explain that, a picture is worth a thousand
words, so I won't explain the concept --- I'll just urge you to play
with this applet:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Paul Chew, Voronoi/Delaunay Applet,
  \texttt{http://www.cs.cornell.edu/Info/People/chew/Delaunay.html}
\end{enumerate}

If you click the mouse to sprinkle the rectangle with points, you'll see
a bunch of edges appear, which intersect in vertices, forming a graph
called the Voronoi diagram. By epxerimenting a bit you can figure out
how it works --- or else you can cheat and read the text. You'll see
that generically the vertices of this graph are trivalent: they have
three edges coming out of them. If you click on the button that says
``Delaunay Triangulation'', you'll see the dual graph, which generically
consists of a bunch of triangles. Each edge of these triangles
intersects exactly one edge of the Voronoi diagram.

In the theory of quantum gravity where space is just \(2\)-dimensional
(a toy model), we can take the Voronoi diagram and label its edges by
spins \(j = 0, 1/2, 1, \ldots\) which match, as well as possible, the
lengths of the edge of the Delaunay triangulation which it intersects.
This will give us a spin network. Averaging over all ways of sprinking
the points, we then get Bombelli's ``random weave state''. The same sort
of idea works in higher dimensions, too.

Finally, Michael Seifert's paper is an excellent undergraduate thesis on
loop quantum gravity, done with the help of Seth Major. After a nice
review of the basics, it studies some operators that act on the Hilbert
space of states of a single spin network vertex: in particular, the
volume operator and some less familiar operators that measure the angles
between spin network edges. He proves some nice things about these, and
also gets some interesting numerical results --- which someone should
make into theorems. The relation between 3d geometry and the
representation theory of \(\mathrm{SU}(2)\) still has unexplored
wrinkles!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week172}{%
\section{October 29, 2001}\label{week172}}

I recently went to a conference on ``Discrete Random Geometries and
Quantum Gravity'', organized by Renate Loll:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Discrete Random Geometries and Quantum Gravity,
  \texttt{http://www1.phys.uu.nl/Symposion/EUWorkshop.htm}
\end{enumerate}

She was one of the people who first gave me the courage to work on
quantum gravity. I'd been interested in it for a long time, but I didn't
like how string theory relied on supersymmetry and a background metric,
so I didn't know any approach that looked promising until I saw her give
a talk on loop quantum gravity at a conference in Seattle in the early
1990s. She was interested in numerical simulation of quantum gravity
models even back then, and by now she's one of the top experts on this
subject. But it's extremely hard to get permanent positions in quantum
gravity, especially in Europe, so I was happy when she recently got a
job at the University of Utrecht. To kick off her stay there, she threw
this conference!

I like to read ``Wired'' magazine when I'm on long airplane trips. On my
flight to Amsterdam, I found this interesting article:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Wil McCarthy, ``Ultimate alchemy'', \emph{Wired}, October 2001, 150.
\end{enumerate}

It's about people are using ``quantum dots'' to make ``artificial
atoms''. A quantum dot is a tiny speck of conductive material that can
be used as a potential well holding one or more electrons in a bound
state. Such bound states are a lot like atoms! However, the ones people
have made so far are about 50 times bigger than actual atoms, because
they are more loosely bound. This also means that they ionize more
easily, so they need to be kept very cold.

However, they can have more electrons than normal atoms, since they
aren't limited by the tendency of large nuclei to undergo radioactive
decay, or ultimately, somewhere around element 137, the tendency of
strong electric fields to ``spark the vacuum'' by creation of
particle-antiparticle pairs --- a quantum field theory effect that's not
included in the bare-bones Schroedinger equation. So, someday we may
learn how the periodic table goes up to, say, element 500! I've
sometimes imagined decadent future chemists studying such elements on
the computer, just for the fun of it\ldots{} but now perhaps they'll do
it with ``artificial atoms''.

Now, McCarthy is a science fiction writer, so he imagines more dramatic
applications of quantum dots, like ``programmable matter'' --- a gadget
whose surface can, say, turn from lead to gold at the flick of a switch.
Personally I don't see how to get these tricks to work at room
temperature until we make artificial atoms almost as small as real ones,
which I don't see how to do without them being\ldots{} atoms! But even
so, I believe there will be some cool technological applications of
quantum dots.

For more on quantum dots by experts on the subject, try these papers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\item
  Marc Kastner, ``Artificial atoms'', \emph{Physics Today} \textbf{46}
  (1993), 24. Also available at
  \texttt{http://web.mit.edu/physics/people/marc\_kastner.htm}
\item
  Leo Kouwenhoven and Charles Marcus, ``Quantum dots'', \emph{Physics
  World}, June 1998. Also available at
  \texttt{http://marcuslab.harvard.edu/}
\end{enumerate}

Unfortunately I didn't have access to these papers on my flight from Los
Angeles to Amsterdam. It takes 10 hours, so I had to read a lot more to
keep from going insane with boredom. Even the latest news about
bioterrorism and bombings was not enough to keep me entertained. (By the
way, I predict that a highly contagious virus will sweep the United
States and kill about 20,000 people within the next few months. It's
called ``influenza'', and that's the average number of Americans who die
from it each year. I plan to call the FBI and warn them about this.)

So, I had to hit the serious mathematical physics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Terry Gannon, ``Monstrous moonshine and the classification of CFT'',
  in \emph{Conformal Field Theory: New Non-Perturbative Methods in
  String and Field Theory}, Yavuz Nutku, Cihan Saclioglu and Teoman
  Turgut, eds., Perseus Publishing, 2000.
\end{enumerate}

This is a very pleasant 66-page review article on ``monstrous
moonshine'', which is what people call the relation between the Monster
group and modular forms. Someday I'll have to say a lot more about this;
for now see \protect\hyperlink{week66}{``Week 66''} if you have no idea
what I'm talking about. Gannon's article is full of juicy mathematical
tidbits and pieces of wisdom. He even gives a new explanation of why the
number 24 is so important throughout mathematics and string theory. If
\(x^2 = 1 \mod n\), then \(x\) must be relatively prime to \(n\)\ldots{}
and 24 is the largest integer for which the converse holds! Alas, Gannon
does not explain how this relates to the other magic properties of this
number, some of which are listed in \protect\hyperlink{week124}{``Week
124''}. Does anyone see the connection?

At the conference, one of my favorite talks was by Sergeui Dorogovtsev,
on ``Geometry of Evolving Random Networks''. A directed graph is a bunch
of nodes connected by edges with little arrows on them. A nice example
is the world-wide web, where the nodes are webpages and the edges are
links. Various people have noticed that in naturally evolving directed
graphs, the number of edges to or from a given node is distributed
roughly according to a power law. For example, on the World-Wide Web,
the number of sites having \(n\) links \emph{to} them is roughly
proportional to \[n^{-2.1}\] while the number of sites having \(n\)
links coming \emph{from} them is roughly proportional to \[n^{-2.7}\]
This differs from the simple models of random graphs most studied by
mathematicians, for which these quantities often follow a Poisson
distribution. But recently people have been coming up with new models of
evolving graphs that have this power-law behavior. The trick is to take
into account the fact that ``popularity is attractive''. The simplest
model uses undirected graphs: keep adding new nodes one at a time, and
let the probability that your new node has an edge to any existing node
be proportional to the number of edges already attached to the existing
node. Following this rule, you'll build up a big random graph with the
power law behavior \[n^{-3}.\] For more details see this fascinating
paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Sergeui N. Dorogovtsev and J.F.F. Mendes, ``Evolving networks'',
  available at
  \href{https://arxiv.org/abs/cond-mat/0106144}{\texttt{cond-mat/0106144}}.
\end{enumerate}

I really love the chart on page 11! It shows the general structure of a
typical naturally arising large directed graph such as the World-Wide
Web. The picture is worth a thousand words, but let me try to explain
it:

First, a large fraction of the nodes lie in the ``giant strongly
connected component'', or GSCC. This is the biggest set of nodes where
you can get between any two by following a sequence of edges and going
forwards along the arrows. For example, in 1999, the entire Web had 203
million webpages, and of these, 56 million were in the GSCC.

Even bigger than the GSCC is the ``giant weakly connected component'',
or GWCC. This is the set of all nodes from which you can get to the GSCC
by following a sequences of edges either forwards or backwards. In 1999,
186 million webpages were in the GWCC. That's 91\% of all webpages!

We can also define the ``giant in-component'' or GIN to be the set of
all nodes from which you can get \emph{into} the GSCC by following edges
forward. Similarly, the ``giant out-component'' or GOUT is the set of
nodes that you can get to by going \emph{out of} the GSCC, following
edges forward. In 1999, both the GIN and the GOUT of the Web contained
about 99 million webpages.

Besides these structures, there are also ``tendrils'' leading out of the
GIN and into the GOUT. More precisely, ``tendrils'' consist of nodes in
the GWCC but in neither the GIN nor the GOUT. In 1999, 44 million
webpages lay in these tendrils.

Finally, there are a bunch of smaller components not reachable from the
GSCC by edges pointing either forwards or backwards; in 1999 these
accounted for 17 million webpages.

Of course, the main reason I'm interested in randomly evolving graphs is
not because I surf the Web, but because I work on spin foam models of
quantum gravity. Here the nodes and edges are labelled by spins, and
instead of a probabilistic evolution rule one has a quantum-mechanical
rule. So things are pretty different, though there are tantalizing
similarities.

I gave a review of spin foam models and an introduction to the following
new papers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\item
  John Baez and J. Daniel Christensen, ``Positivity of spin foam
  amplitudes'', available at
  \href{https://arxiv.org/abs/gr-qc/0110044}{\texttt{gr-qc/0110044}}.
\item
  J. Daniel Christensen and Greg Egan, ``An efficient algorithm for the
  Riemannian \(10j\) symbols'', available at
  \href{https://arxiv.org/abs/gr-qc/0110045}{\texttt{gr-qc/0110045}}.
\end{enumerate}

The Riemannian \(10j\) symbols are a function of ten spins that serves
as the amplitude for a spin foam vertex in the Barrett-Crane model of
Riemannian quantum gravity --- by which I mean the theory where we do a
real-time path integral over Riemannian metrics. This is different from
so-called ``Euclidean quantum gravity'', where we do an imaginary-time
path integral over Riemannian metrics. As far as I can tell, Riemannian
quantum gravity is only important insofar as it's a useful warmup for
Lorentzian quantum gravity.

In their paper, Christensen and Egan describe an algorithm that computes
the Riemannian \(10j\) symbols using \(\mathcal{O}(j^5)\) operations and
\(\mathcal{O}(j^2)\) space, as well as an algorithm that uses
\(\mathcal{O}(j^6)\) operations and a constant amount of space. This is
in contrast to the most obvious methods, which use \(\mathcal{O}(j^9)\)
operations and \(\mathcal{O}(j^2)\) or more space. Perhaps most
importantly to the practical-minded among us, their paper includes a
link to some code in C that implements this algorithm.

In our paper, Christensen and I show that the Riemannian \(10j\) symbols
are real, and that when they are nonzero, they are positive (resp.
negative) when the sum of the ten spins is an integer (resp.
half-integer). The proof is a nice exercise in spin network theory. We
also show that for a closed spin foam of the type appearing in the
Barrett-Crane model, the minus signs cancel when we take the product of
Riemannian \(10j\) symbols over all the spin foam vertices. It follows
that in both the original Riemannian Barrett-Crane model, and also the
modified version due to Perez and Rovelli, the amplitudes of spin foams
are \emph{nonnegative}.

This is interesting because, as Lee Smolin has often emphasized, it's
hard to simulate spin foams on the computer unless the amplitudes are
nonnegative. Nonnegative amplitudes allows us to use ideas from
statistical mechanics, like the Metropolis algorithm. This is one reason
lattice gauge theory people prefer imaginary-time path integrals to
real-time ones. Of course, in lattice gauge theory, we can do Wick
rotation to get real physics from imaginary-time path integrals. In
quantum gravity, Wick rotation is more problematic, though Renate and
others have considered situations where it's justified. It thus comes as
a pleasant surprise to find that sometimes spin foam amplitudes are
nonnegative \emph{without} doing Wick rotation.

Of course, so far I've only been talking about the Riemannian
Barrett-Crane model! Here the gauge group is
\(\mathrm{Spin}(4) = \mathrm{SU}(2) \times \mathrm{SU}(2)\), and if you
examine our proof, you'll see that the positivity result comes from the
way this group ``factors'' into two copies of \(\mathrm{SU}(2)\). We
can't prove positivity of spin foam amplitudes in the more physical
Lorentzian case, where the group is
\(\mathrm{Spin}(3,1) = \mathrm{SL}(2,\mathbb{C})\).

However, even though we can't prove it, it may be true! Dan has written
a number of programs which compute the Lorentzian \(10j\) symbols, and
while they are very slow and we haven't computed many values, all the
values we've computed so far seem to be positive. We include the results
we have so far in our paper.

In a paper that will come out later, ``Partition function of the
Riemannian Barrett-Crane model'', by Dan Christensen, Tom Halford, David
Tsang and myself, we'll discuss the qualitative behavior of various
versions of the Riemannian Barrett-Crane model. In order to write this
paper, we needed to numerically simulate the Barrett-Crane model using
the Metropolis algorithm and the efficient algorithm for Riemannian
\(10j\) symbols.

Actually, in this conference there were \emph{lots} of talks about
different models of quantum gravity involving discrete random
geometries. But right now I'll just discuss something called the IKKT
matrix model. This was proposed in the following paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  N. Ishibashi, H. Kawai, Y. Kitazawa and T. Tsuchiya, ``A large-\(N\)
  reduced model as superstring'', \emph{Nucl. Phys.} \textbf{B498}
  (1997) 467--491. Also available as
  \href{https://arxiv.org/abs/hep-th/9612115}{\texttt{hep-th/9612115}}.
\end{enumerate}

The idea is to provide something like a background-free formulation of
type IIB string theory. But I don't understand how that's supposed to
work yet, so my own attaction to this theory mainly comes from the fact
that it's very simple and pretty. Let me describe it to you!

I'll assume you know that the Lagrangian for \(\mathrm{SU}(N)\)
Yang-Mills theory coupled to spinors looks like this:
\[\operatorname{tr}(F\wedge *F) + \overline{\psi} D \psi\] where \(F\)
is the curvature of the gauge field, \(\psi\) is a spinor field
transforming under some representation of \(\mathrm{SU}(N)\), and \(D\)
is the covariant Dirac operator. If we write this out a bit more
explicitly, it's
\[\operatorname{tr}((dA + [A,A]) \wedge *(dA + [A,A]) + \overline{\psi}^i (d_a+A_a) \Gamma^a_{ij} \psi^j\]
where \(A\) is the gauge field. But now let's assume \(A\) and \(\psi\)
are constant as functions on space, and that \(\psi\) transforms in the
adjoint representation of \(\mathfrak{su}(N)\). This amounts to saying
that \(A\) lies in \(\mathfrak{su}(N)\otimes\mathbb{R}^n\), where \(n\)
is the dimension of spacetime, and that \(\psi\) lies in
\(\mathfrak{su}(N)\) tensored with the space of spinors\ldots{} where we
use some sort of spinors suitable for \(n\)-dimensional spacetime. Then
the above Lagrangian becomes
\[\operatorname{tr}([A_a,A_b] [A^a,A^b]) + \overline{\psi}^i [A_a, \Gamma^a_{ij}\psi^j]\]
which is the Lagrangian for the IKKT model.

Now the idea is that as \(N \to \infty\), this sort of theory can reduce
to string theory on some \(n\)-dimensional spacetime manifold\ldots{}
but not necessarily any fixed manifold.

It will be no surprise to readers of \protect\hyperlink{week93}{``Week
93''} and \protect\hyperlink{week104}{``Week 104''} that this model is
supersymmetric when the spacetime dimension is 3, 4, 6, or 10. The
reason is that in these dimensions both vectors and spinors have a nice
description in terms of the real numbers, complex numbers, quaternions
or octonions, respectively. The \(10\)-dimensional octonionic version is
the one that string theorists hope is related to the type IIB
superstring. In this case, we can think of both \(A\) and \(\psi\) as
big fat matrices of octonions!

There were a few different talks about the IKKT matrix model. John
Wheater gave a talk about results saying that the path integral
converges for this model in certain cases. In particular, it converges
if \(n = 4\), \(6\), or \(10\). For more details try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Peter Austing and John F. Wheater, ``Convergent Yang-Mills matrix
  theories'', \emph{JHEP} \textbf{0104} (2001) 019. Also available as
  \href{https://arxiv.org/abs/hep-th/0103159}{\texttt{hep-th/0103159}}.
\end{enumerate}

Bengt Petersson spoke about computer simulations of the IKKT model:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{10}
\tightlist
\item
  Z. Burda, B. Petersson, J. Tabaczek, ``Geometry of reduced
  supersymmetric 4D Yang-Mills integrals'', \emph{Nucl. Phys.}
  \textbf{B602} (2001) 399--409. Also available as
  \href{https://arxiv.org/abs/hep-lat/0012001}{\texttt{hep-lat/0012001}}.
\end{enumerate}

Also, Graziano Vernizzi spoke on work still in progress attempting to
see the compactification of spacetime from 10 to 4 dimensions in
superstring theory as a natural consequence of a matrix model.

For more on the IKKT model, try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{11}
\tightlist
\item
  A. Konechny and A. Schwarz, ``Introduction to M(atrix) theory and
  noncommutative geometry'', available at
  \href{https://arxiv.org/abs/hep-th/0012145}{\texttt{hep-th/0012145}}.
\end{enumerate}

There were a lot more talks, but on my way back home I started reading
some papers about Tarski's ``high school algebra problem'', so now let
me talk about that. This is more like mathematical logic than
mathematical physics\ldots{} at least at first. If you follow it through
long enough, it turns out to be related to stuff like Feynman diagrams,
but I doubt I'll have the energy to go that far this week.

So:

Once upon a time, the logician Tarski posed the following question. Are
there any identities involving addition, multiplication, exponentiation
and the number \(1\) that don't follow from the identities we all
learned in high school? In case you forgot, these are:

\begin{itemize}
\tightlist
\item
  \(x + y = y + x\)
\item
  \((x + y) + z = x + (y + z)\)
\item
  \(xy = yx\)
\item
  \((xy)z = x(yz)\)
\item
  \(1x=x\)
\item
  \(x^1 = x\)
\item
  \(1^x = 1\)
\item
  \(x(y + z) = xy + xz\)
\item
  \(x^{y + z} = x^y x^z\)
\item
  \((xy)^z = x^z y^z\)
\item
  \(x^{yz} = (x^y)^z\)
\end{itemize}

A bit more precisely, are there equational laws in the language
\((+,\,\cdot,\,\mbox{\textasciicircum},\,1)\) that hold for the positive
natural numbers but do not follow from the above axioms using
first-order logic?

Remarkably, in 1981 it turned out the answer is YES:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{12}
\tightlist
\item
  A. J. Wilkie, ``On exponentiation --- a solution to Tarski's high
  school algebra problem'', to appear in \emph{Quaderni di Matematica}.
  Also available at
  \texttt{http://www.maths.ox.ac.uk/\textasciitilde{}wilkie/}
\end{enumerate}

Here is Wilkie's counterexample: \[
  \begin{aligned}
    &[(x + 1)^x + (x^2 + x + 1)^x]^y  [(x^3 + 1)^y + (x^4 + x^2 + 1)^y]^x
  \\= &[(x + 1)^y + (x^2 + x + 1)^y]^x  [(x^3 + 1)^x + (x^4 + x^2 + 1)^x]^y
  \end{aligned}
\]

You might enjoy showing this holds for all positive natural numbers
\(x\) and \(y\). You can do it by induction, for example. You just can't
show it by messing around with the ``high school algebra'' axioms listed
above.

Wilkie's original proof was rather subtle, but in 1985 Gurevic gave a
more simple-minded proof: he constructed a finite set equipped with
addition, multiplication, exponentiation and \(1\) satisfying the high
school algebra axioms but not Wilkie's identity. This clearly shows that
the former don't imply the latter! His counterexample had 59 elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{13}
\tightlist
\item
  R. Gurevic, ``Equational theory of positive numbers with
  exponentiation'', \emph{Proc. Amer. Math. Soc.} \textbf{94} (1985),
  135--141.
\end{enumerate}

Later, various mathematicians enjoyed cutting down the number of
elements in this counterexample. As far as I can tell, the current
record-holder is Marcel Jackson, who constructed one with only 14
elements. He also showed that none exists with fewer than 8 elements:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\tightlist
\item
  Marcel G. Jackson, ``A note on HSI-algebras and counterexamples to
  Wilkie's identity'', \emph{Algebra Universalis} \textbf{36} (1996),
  528--535. Also available at
  \texttt{http://www.latrobe.edu.au/mathstats/Staff/Marcel/details/publications.html}
\end{enumerate}

I have no idea what these small counterexamples are good for, though
Jackson proves some nice things in the process of studying them.

More important, in my opinion, is a 1990 result of Gurevic: no finite
set of axioms in first-order logic is sufficient to prove all the
identities involving addition, multiplication, exponentiation and \(1\)
that hold for the positive natural numbers. You can find this here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{15}
\tightlist
\item
  R. Gurevic, ``Equational theory of positive numbers with
  exponentiation is not finitely axiomatizable'', \emph{Ann. Pure. Appl.
  Logic} \textbf{49} (1990), 1--30.
\end{enumerate}

In other words, Wilkie's identity is but one of an infinite set of
logically independent axioms of this type!

But the real fun starts when we \emph{categorify} Tarski's high school
algebra problem. I learned about this from Marcelo Fiore, a computer
scientist whom I met in Cambridge this summer. The idea here is to
realize that the high school identities all hold as \emph{isomorphisms}
between finite sets if we interpret addition as disjoint union,
multiplication as Cartesian product, \(x^y\) as the set of functions
from the finite set \(y\) to the finite set \(x\), and \(1\) as your
favorite one-element set. The point here that the set of natural numbers
is just a dumbed-down version of the category of finite sets, with all
these arithmetic operations coming from things we can do with finite
sets. I explained this in \protect\hyperlink{week121}{``Week 121''}.

From this viewpoint it's very natural to include some extra axioms
involving \(0\), which corresponds to the empty set:

\begin{itemize}
\tightlist
\item
  \(0 + x = x\)
\item
  \(0x = 0\)
\item
  \(x^0 = 1\)
\end{itemize}

Note that this gives \(0^0 = 1\), which is ``correct'' in that there's
one function from the empty set to the empty set. The only reason people
often formulate Tarski's problem in terms of \emph{positive} natural
numbers is that they're afraid to say \(0^0 = 1\), having been scared
silly by their high school math teachers. In analysis \(0^0\) is a
dangerous thing, but not in the arithmetic of natural numbers. All the
aforementioned results on the high school algebra problem still hold if
we include 0 and throw in the above extra axioms --- except the results
on smallest possible counterexamples.

The reason why it's so nice to include \(0\) is that then the high
school identities correspond closely to what holds in any ``biCartesian
closed category'' --- a good example being the category of finite sets.
A Cartesian category is one with binary products and a terminal object;
these act like ``multiplication'' and ``\(1\)''. In a Cartesian
\emph{closed} category we also require that the operation of taking the
product with any object has a right adjoint; this gives
``exponentiation''. Finally, in a biCartesian closed category we also
have binary coproducts and an initial object, which act like
``addition'' and ``\(0\)'', and we require that products distribute over
coproducts.

There are lots of examples of biCartesian closed categories: for
example, the category of finite sets, or sets, or sets on which some
group acts, or more generally presheaves on any category, or still more
generally, any topos!

Anyway, Fiore has solved the following categorified version of Tarski's
high school algebra problem, posed by Roberto di Cosmo: are there any
natural isomorphisms in the category of finite sets between expressions
built from addition, multiplication, exponentiation, \(0\) and \(1\)
that don't hold in a general biCartesian closed category? I'm posing
this a bit vaguely, so I hope you can guess what I mean. Anyway, the
answer is again YES, and a similar sort of counterexample does this job.

To tackle this problem it's useful to consider the \emph{free}
biCartesian closed category on some set of objects, because this has the
fewest isomorphisms. Now, the real reason I'm interested in this stuff
is that James Dolan and Toby Bartels have been thinking about various
similar categories, like the free Cartesian closed category on one
object, or the free symmetric monoidal closed category on one object, or
the free symmetric monoidal compact category on one object\ldots{} and
the last-mentioned of these is closely related to the theory of Feynman
diagrams!

But alas, just as I suspected, I don't have the energy to go into this
now. So I'll stop here, hopefully leaving you more tantalized than
baffled.

(Thanks go to Michael Barr, Noam Elkies, Dave Rusin and Bruce Smith for
catching mistakes in the original error-ridden version of this issue.)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Postscript --- A friend of mine interested in nanotechnology made the
following comments on Wil McCarthy's article:

\begin{quote}
From your comments I can't tell if you were ``fooled'' by his misleading
impression in the article that (1) the specific physical atoms of our
periodic table could be ``found'' analogously in quantum dots containing
the corresponding numbers of electrons; or the weaker (but still false)
(2) there could be a ``periodic table of quantum-dot artificial atoms''
indexed by their number of electrons. (2) is the most obviously false,
and he even says why in the article --- the shape of the dot (and for
that matter the material it's made of) also influence its properties.
But, basically for exactly this reason, (1) is also false --- there's no
reason to expect \emph{any} quantum dot and number of electrons in it to
be able to imitate a specific kind of physical atom.

So it's misleading to say that a material could be ``switched from lead
to gold''. It could not be exactly ``lead'', and it could not be exactly
``gold'', and it could not even be in states which would justify making
an analogy to those specific elements, unless you carefully selected the
properties you wanted to compare -- e.g. color. But selecting color you
might say ``it's like gold'', whereas selecting conductivity you might
choose a different element (or something different from any element) to
compare it to.

However, effects almost as interesting might be true (though I don't
know enough to judge critically whether they \emph{really} might be
true), e.g.~a material whose various physical properties could be
quickly changed over wide ranges, ``programmed'' in various uncommon
useful combinations, and reconfigured in tiny detail. It seems almost
certainly true that an advanced nanotech would include important
technological uses for these kinds of effects. Whether they can be
useful in these ``chemistry-like ways'' before we have advanced nanotech
(for building the dots precisely) is doubtful to me --- their properties
are likely to be highly dependent on their \emph{precise} shape and
composition, which I doubt we can control well enough without building
them atom-by-atom. (However, they'll probably be quite useful in other
ways, not analogous to ``atoms'', which depend much less on their
precise shape \& composition. I think this has already happened.)

It's too bad he gave the false impressions in the article, since it
obscures the true and amazing stuff --- it makes me unclear on how much
of what he says is actually plausible.

One other thing he implied, which is false, is that ``regular'' nanotech
couldn't give us anything like ``programmable matter''. In fact, if you
\emph{really} want a surface that switches from lead to gold at the
flick of a switch, just make lots of little cubes or plates with gold on
one side and lead on the other side, and have them all get turned over
by little motors when you flick the switch.

This kind of ``mechanical reconfiguration'' method (generalized/extended
a lot) could be fast enough to let big buildings change shape faster
than water can flow, and with feasible expenditure of energy and
generation of waste heat. So the main thing added to this by the
possibility of ``artificial atoms in quantum dots'' would be a wider
variety of electronic/optical/magnetic materials properties (I doubt the
mechanical properties will be very much affected), and the ability to
switch those in picoseconds (that's a guess) rather than merely
milliseconds, and to do so for much less energy.

I.e. mainly important for technological uses rather than something that
has a biq qualitative effect on ``human experience'', which will already
include all effects that he listed, just from ``regular'' nanotech.

\begin{quote}
\ldots But even so, I believe there will be some cool technological
applications of quantum dots.
\end{quote}

Yep!
\end{quote}

Also, here are some comments by Noam Elkies about the number 24:

\begin{quote}
John Baez wrote:

\begin{quote}
{[}\ldots.{]}
\end{quote}

\begin{quote}
Gannon's article is full of juicy mathematical tidbits and pieces of
wisdom. He even gives a new explanation of why the number 24 is so
important throughout mathematics and string theory. If
\(x^2 = 1 \mod n\), then \(x\) does not divide \(n\)\ldots{} and 24 is
the largest integer for which the converse holds!
\end{quote}

This cannot be right: for any \(n\), the only factors \(x|n\) such that
\(x^2\) is \(1 \mod n\) are \(x=1\) and \(x=-1\). You must mean that
\(n|24\) if and only if \(x^2-1\) is a multiple of \(n\) for every
integer \(x\) that's \emph{coprime} to \(n\). But is this connection
really new? I remember observing this some time back, and can't believe
I was the first either\ldots{}

\begin{quote}
Alas, Gannon does not explain how this relates to the other magic
properties of this number, some of which are listed in
\protect\hyperlink{week124}{``Week 124''}. Does anyone see the
connection?
\end{quote}

Here's one not-immediately-obvious consequence. Consider the group
\(\Gamma_0(n^2)\), consisting of \(2\times2\) integer matrices of
determinant \(1\) whose bottom left entry is a multiple of \(n^2\). When
is the matrix
\[T(n) = \left(\begin{array}{cc}1&\frac1n\\0&1\end{array}\right)\] in
the normalizer of this group? The conjugate of \([a, b; n^2 c, d]\) by
this matrix has integer diagonal entries and bottom left entry \(n^2c\);
so it's in \(\Gamma_0(n^2)\) if and only if the top right entry is an
integer. Well, the top right entry is \(b-c + (d-a)/n\). This is an
integer provided \(d\) is congruent to \(a \mod n\). But all that
restricts \((a,d)\mod n\) is the condition that \(ad-n^2bc=1\), and thus
that \(ad=1\mod n\). So, this should entail \(a=d\mod n\), which it does
if and only if every integer coprime to \(n\) is its own multiplicative
inverse \(\mod n\) !

So, the integers \(n\) for which this holds are precisely those for
which the normalizer of \(\Gamma_0(n^2)\) contains \(T(n)\).

Another way to say this is: conjugate \(\Gamma_0(n^2)\) by the matrix
\[\left(\begin{array}{cc}n&0\\0&\frac1n\end{array}\right)\] This yields
all integer matrices of determinant \(1\) whose off-diagonal matrices
are multiples of \(n\). Reducing mod \(n\), we get the group of scalar
matrices if and only if each unit in \(\mathbb{Z}/n\mathbb{Z}\) is a
square root of \(1\) --- in which case we have a normal subgroup of
\(\mathrm{SL}_2(\mathbb{Z})\) {[}the group of \(2\times2\) integer
matrices of determinant \(1\){]}, so in particular the corresponding
conjugate \[\left(\begin{array}{cc}1&1\\0&1\end{array}\right)\] of
\(T(n)\) is in the normalizer.

What has all this to do with moonshine? I'm no moonshine expert, so I
can't say for sure; but moonshine certainly involves coefficients of
modular forms and functions for congruence subgroups of
\(\mathrm{SL}_2(\mathbb{Z})\). If \(T(n)\) is in the normalizer of
\(\Gamma_0(n^2)\) then \(T(n)\) acts on the spaces of modular
forms/functions by linear transformations whose \(n\)-th power is the
identity (since \(T(n)^n\) is in \(\Gamma_0(n^2)\)). The eigenspaces of
these transformations are the modular forms/functions whose coefficients
are supported on arithmetic progressions mod \(n\). So, we get to
isolate the different arithmetic progressions mod \(n\) precisely when n
satisfies the \(n|x^2-1\) condition. This should explain the special
role played by these integers \(n\), which as we know are 24 and its
factors.

--Noam D. Elkies
\end{quote}

And here is some more by Noam Elkies:

\begin{quote}
\begin{verbatim}
John Baez wrote:
 
\end{verbatim}

\begin{quote}
{[}\ldots{]} He then uses this to explain why even self-dual lattices
occur only in dimensions that are multiples of 8, which is nice, but he
doesn't connect up with any appearances of the number 24.\\
Your remarks go much further in this direction --- thanks!
\end{quote}

Glad to be of help. I mention the use of modular forms to explain this
divisibility by 8 in my paper ``A characterization of the
\(\mathbb{Z}^n\) lattice'' (\emph{Math Research Letters} \textbf{2}
(1995), 321--6 =
\href{https://arxiv.org/abs/math.NT/9906019}{\texttt{math.NT/9906019}},
and again in the first part of my expository article ``Lattices, Linear
Codes, and Invariants'' (\emph{AMS Notices} \textbf{27} (2000), pages
1238--1245 =
\texttt{http://www.ams.org/notices/200010/fea-elkies-1.pdf}; see the
footnote on page 1243).

\begin{quote}
To me, one basic reason for the appearance of the number 24 in the
theory of modular forms is the fact that of all lattices in the plane,
the square one and the ``equilateral triangle'' one have more symmetry
--- 4-fold symmetry and 6-fold symmetry, respectively. It's related to
the fact that the abelianization of \(\mathrm{SL}(2,\mathbb{Z})\) has 12
elements. But I don't see an immediate connection between these simple
things and the above number-theoretic property of 24.
\end{quote}

I don't see a complete explanation either. However, there is this:

The group of units in \(\mathbb{Z}/n\mathbb{Z}\) is known to be the
Galois group over \(\mathbb{Q}\) of the \(n\)-th cyclotomic field (the
field obtained from \(\mathbb{Q}\) by adjoining the \(n\)-th roots of
unity).

The condition: \((x,n)=1\) iff \(n|x^2-1\) is equivalent to the
requirement that every element of this group be its own inverse, and
thus that this group be isomorphic to \((\mathbb{Z}/2\mathbb{Z})^r\).

By Galois theory, this is equivalent to requirement that the \(n\)-th
cyclotomic field be the compositum of \(r\) quadratic extensions. For
instance, the 24th cyclotomic field is the compositum of
\(\mathbb{Q}(i)\), \(\mathbb{Q}(\sqrt{-3})\), and
\(\mathbb{Q}(\sqrt{-2})\).

Now if a lattice \(L\) in \(\mathbb{C}\) has extra symmetries, then its
ring of complex endomorphisms (the complex numbers \(z\) such that
\(zL\) is contained in \(L\)) is an imaginary quadratic field generated
by these symmetries. It is thus one of the two cyclotomic fields of
degree 2 over \(\mathbb{Q}\).

So this explains at least why 4 and 6 (as in fourfold and sixfold
symmetry) are factors of the number 24. It doesn't explain 24 entirely,
because 12 suffices to get both 4 and 6. But then 12 is also a good
number for this kind of game; see Poonen and Rodriguez-Villegas's paper
\href{www.math.berkeley.edu/~poonen/papers/lattice12.ps}{(www.math.berkeley.edu/\textasciitilde poonen/papers/lattice12.ps)}
on ``Lattice polygons and the number 12''.

NDE
\end{quote}

Finally, Marcelo Fiore tells me that there are some extra axioms for
\(0\) which automatically arise when you decategorify a biCartesian
closed category, for example:

\begin{itemize}
\tightlist
\item
  \(x\cdot 0^x=0\) (logically: \(x\) and \(\operatorname{not}(x)\) is
  false)
\item
  \(0^{0^{0^x}}=0^x\) (logically:
  \(\operatorname{not}(\operatorname{not}(\operatorname{not}(x)))\) iff
  \(\operatorname{not}(x)\))
\end{itemize}

and probably at least one more. I guess I should have added these as
axioms in my description of the Tarski high school algebra in the
version where we include \(0\). I'm a bit confused about this\ldots.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week173}{%
\section{November 25, 2001}\label{week173}}

Did you see the Leonid meteor shower last Tuesday? I watched them from
1:30 to 3 in the morning from my back yard. They were great! Near the
end I saw several a minute and sensed many more, too dim to stand out in
the light-polluted Riverside sky, like near-subliminal pinpricks grazing
the surface of consciousness. There are some Leonids every November as
the Earth passes through the debris in the orbit of comet Tempel-Tuttle,
but activity peaks about once every 33 years, when the timing is best.
They were really good in 1966, and really good this year.

If you missed them, try these pictures:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Favorite Leonid images found posted on the net,
  \texttt{http://leonids.arc.nasa.gov/image\_favorites.html}
\end{enumerate}

Anyway, this week I'm in the mood for math, so I'll start with a bit of
stuff about the octonionic projective plane and linear lattices, and
then talk about categories and homotopy theory, in a kind of
continuation of The Tale of \(n\)-Categories.

Three of my favorite dimensions are 8, 11, and 24. Why?

Well, 8 is the dimension of the octonions, which are related to special
properties of rotations in \(8\)-dimensional space, and also Bott
periodicity: a magical phenomenon relating rotations, spinors and the
like in n dimensions to the corresponding things in \(n+8\) dimensions.
The ``Cayley integral octonions'' form a marvelous lattice which happens
to give the densest lattice packing of spheres in 8 dimensions: each
sphere has 240 nearest neighbors. This is also the root lattice of the
group \(\mathrm{E}_8\), which has dimension \(248 = 240+8\), and is the
symmetry group of the projective plane over the octooctonions: the
octonions tensored with themselves!

In short, all sorts of beautiful madness breaks loose in dimension 8.
But this madness is \emph{tripled} in dimension 24. In this dimension,
spinors are pairs of octooctooctonions: the octonions tensored with
themselves thrice! But more importantly, this is the dimension where
Monstrous Moonshine lives. While bosonic string theory works best in
26-dimensional spacetime, two of those dimensions really come from the
fact that a string worldsheet is a 2d surface, so the real magic comes
from secret relations between \(2\)-dimensional stuff (complex analysis)
and the number 24.

Some of this boils down to the fact that the only specially symmetric
lattices in 2 dimensions are the square lattice and the hexagonal one,
and \(4 \times 6 = 24\). But there's a lot more going on! For example,
there's a marvelous lattice in 24 dimensions called the Leech lattice,
which gives the densest lattice packing of spheres in that dimension. It
also gives rise to a lattice in \(26\)-dimensional spacetime, and if we
cleverly use this to compactify 26d spacetime and do bosonic string
theory there, we get a string theory whose symmetry group is the
Monster: the largest sporadic finite simple group! The dimensions of the
irreducible representations of the Monster are closely connected to the
coefficients of an important function in complex analysis, called the
\(j\)-function - this connection is known as Monstrous Moonshine.

I've said all this stuff more carefully and in much more detail in
previous Weeks, so don't mind if it went by in a blur this time. Right
now I'm just trying to remind you of how cool these dimensions are!

11 dimensions is more mysterious, at least to me. String theorists
believe it's the right dimension for M-theory, their favorite candidate
for the Theory of Everything. I'm still struggling to understand the
math that makes this dimension special. Luckily, someone sent me a paper
which provides a tiny tantalizing clue --- a relation between the
numbers 8, 11, and 24:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Thomas Püttmann and A. Rigas, ``Isometric actions on the projective
  planes and embedded generators of homotopy groups''. Available at
  \texttt{http://www.ruhr-uni-bochum.de/mathematik8/puttmann/index.html}.
\end{enumerate}

The simple idea standing behind their work is that
\[\pi_{11}(S^8) = \mathbb{Z}/24.\] In other words: the 11th homotopy
group of the 8-sphere is the group of integers \(\mod 24\). This is just
a reflection of the fact that the \[\pi_{n+3}(S^n) = \mathbb{Z}/24\]
whenever \(n\) is big enough. I touched upon the importance of this for
string theory in \protect\hyperlink{week102}{``Week 102''}.

But it gets cooler. \(S^8\) is just the octonionic projective line
\(\mathbb{OP}^1\). The octonionic projective plane, \(\mathbb{OP}^2\),
is formed from \(\mathbb{OP}^1\) by gluing on some extra stuff. However,
this extra stuff is sufficiently high-dimensional that it doesn't affect
the 11th homotopy group, so we get
\[\pi_{11}(\mathbb{OP}^2) = \mathbb{Z}/24.\] Now, what Püttman and Rigas
do is find an 11-sphere \emph{embedded} in the octonionic projective
plane that generates the group \(\mathbb{Z}/24\). In fact, it's a
minimal surface: there's no way to wiggle it a bit to make the ``area''
less! It's the analogue for \(\mathbb{OP}^2\) of the 2-sphere in
\(\mathbb{CP}^2\) defined by the equation \(x^2 + y^2 + z^2 = 0\).
(Püttman and Rigas also describe an analogous 5-sphere in the
quaternionic projective plane that generates
\(\pi_5(\mathbb{HP}^2) = \mathbb{Z}/2\).)

Could this geometrical fact have some application to M-theory? I bet it
will. Could it be a useful clue to the math linking these special
dimensions? We'll see.

Now for something a bit less flashy, but related:

Back in \protect\hyperlink{week145}{``Week 145''}, when I was trying to
understand the octonionic projective plane, I explained Desargues'
theorem. This is a cute theorem about a pair of triangles which holds in
real, complex or quaternionic projective geometry, but not for the
octonionic projective plane. Earlier, in
\protect\hyperlink{week106}{``Week 106''}, I explained how projective
geometries give quantum logics. The basic idea is that we think of
points, lines, planes and higher-dimensional subspaces as propositions.
If the subspace \(P\) is contained in the subspace \(Q\), we say \(P\)
``implies'' \(Q\).

Mathematicians call the resulting structure a ``lattice'': technically,
this is a partially ordered set where every finite set of elements has a
greatest lower bound and least upper bound. Don't worry if you don't
understand the terminology! If we think in terms of geometry, the
greatest lower bound of two subspaces is just their intersection: the
biggest subspace contained in either of them. Their least upper bound is
their ``span'': the smallest subpsace containing both of them. For
example: \[
  \begin{tikzpicture}
    \draw[thick] (-1,0) to (2,0) node[label=right:{$P$}]{};
    \draw[thick] (-0.25,-0.7) to (1,1.5) node[label=above:{$Q$}]{};
    \node at (0.15,-0.01) {$\bullet$};
  \end{tikzpicture}
\] Here the intersection of \(P\) and \(Q\) is a point, and their span
is a plane.

If we think in terms of logic, the greatest lower bound of \(P\) and
\(Q\) is called ``\(P\) and \(Q\)'': the weakest proposition implying
either of them. Similarly, their least upper bound is called ``\(P\) or
\(Q\)'': the strongest proposition implied by both of them.

If we do this starting with complex projective space, we get the lattice
of propositions for an ordinary sort of quantum theory, based on the
complex numbers. The same sort of thing works in the real, quaternionic
and octonionic cases --- though for the octonions, you can't go above
the octonionic projective \emph{plane}.

Translating the statement of Desargues' theorem from geometry to logic,
we can reinterpret it as a \emph{law of logic} which holds in real,
complex and quaternionic quantum theory --- but not octonionic! If I
could grok what this law said, I might understand how octonionic quantum
theory was different from the others. Unfortunately, it's pretty
complicated. Here's what it says: if we have 6 propositions \(x\),
\(y\), \(z\), \(x'\), \(y'\), \(z'\), then \[
  \begin{gathered}
    \{x \operatorname{and} (x' \operatorname{or} \{(y \operatorname{or} y') \operatorname{and} (z \operatorname{or} z')\})\}
  \\\implies
  \\\{y \operatorname{or} (\{x' \operatorname{or} y'\} \operatorname{and} \{(\{x \operatorname{or} z\} \operatorname{and} \{x' \operatorname{or} z'\}) \operatorname{or} (\{y \operatorname{or} z\} \operatorname{and} \{y' \operatorname{or} z'\}) \}
  \end{gathered}
\] where I have used two flavors of parentheses in a feeble attempt to
make these expressions easier to parse. If you look at
\protect\hyperlink{week145}{``Week 145''}, you can sort of see where
this weird stuff is coming from: Desargues' theorem is about two
triangles \(xyz\) and \(x'y'z'\). But comprehending it as a law of
\emph{logic} still seems very tough.

(In case you're tempted to massage the above expressions using other
laws of logic, beware: you're not allowed to use the distributivity of
``and'' over ``or'' and vice versa in quantum logic --- that's a very
\emph{classical} law, and it's not allowed here. But you might try using
it anyway, just for fun, to see what happens!)

Anyway, I found it interesting to discover that Desargues' theorem is
just of one of many laws that hold in all ``linear lattices'':

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Matteo Mainetti and Catherine Huafei Yan, ``Arguesian identities in
  linear lattices'', \emph{Adv. Math.} \textbf{144} (1999), 50--93.
\end{enumerate}

But what's a linear lattice? Back when I was at MIT, Gian-Carlo Rota
occasionally tried to get me interested in these, and he'd always say,
his eyes sparkling mischievously: ``A linear lattice is just a lattice
of commuting equivalence relations!'' Unfortunately, I could never quite
parse that sentence. Luckily, by reading this paper by people whom he
\emph{did} manage to interest, I finally figured out what he meant.

First of all, we can partially order the relations on a given set by
saying the relation \(R\) ``implies'' the relation \(S\) iff \(xRy\)
implies \(xSy\) for all \(x,y\). This makes relations into a lattice,
and equivalence relations become a sublattice.

Second, we can compose relations. Given relations \(R\) and \(S\), the
relation \(RS\) is defined by:
\[\mbox{$xRSz$ iff $xRy$ and $ySz$ for some $y$.}\] We say the relations
\(R\) and \(S\) commute if \(RS = SR\). For example, if \(R\) is
``father of'' and \(S\) is ``mother of'', then \(R\) and \(S\) do not
commute, since \(RS\) is ``maternal grandfather of'' and \(SR\) is
``paternal grandmother of''. Here's a cute fact whose proof I leave as a
puzzle: two equivalence relations \(R\) and \(S\) commute if and only if
\(RS\) is an equivalence relation.

Now hopefully it makes sense when I tell you that a linear lattice is a
lattice of equivalence relations on some set, all of which commute. But
to see why this is cool, you need some examples.

The classic example is the lattice of subspaces of a vector space! Any
subspace \(S\) determines an equivalence relation on our vector space,
which by abuse of language we also call \(S\), given by letting \(xSy\)
iff \(x-y\) is in \(S\). All these equivalence relations commute,
because addition of vectors commutes, as shown by the ``parallelogram
law'': \[
  \begin{tikzpicture}
    \node (bl) at (0,0) {$x$};
    \node (br) at (2,0) {$y$};
    \node (tl) at (0.75,1.5) {$y'$};
    \node (tr) at (2.75,1.5) {$z$};
    \draw[thick] (bl) to (tl) to (tr) to (br) to (bl);
  \end{tikzpicture}
\] So
\[\mbox{$xRSz$ iff $x-y$ is in $R$ and $y-z$ is in $S$ for some $y$,}\]
while
\[\mbox{$xSRz$ iff $x-y'$ is in $S$ and $y'-z$ is in $R$ for some $y'$.}\]
but the picture shows these are equivalent!

If we start with a vector space over the reals, complexes or
quaternions, the lattice we get this way is exactly the same as the
lattice we get starting from the corresponding projective space, so
Desargues' theorem in this case is just a corollary of the fact that
Desargues' theorem holds for all linear lattices.

On the other hand, since the lattice associated to the octonionic
projective plane does \emph{not} satisfy Desargues' theorem, it's not a
linear lattice. Maybe someday I'll use these ideas to understand what's
weird about octonionic quantum mechanics.

But another cool thing is that Mark Haiman has cooked up a set of
deduction rules that let you derive precisely all the implications that
hold in all linear lattices. Even better, there's a way to draw pictures
of these deduction rules, which makes them look a bit like tricks for
rewiring electrical circuits! You can learn about this in the above
paper, or Haiman's original paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Mark Haiman, ``Proof theory for linear lattices'', \emph{Adv. Math.}
  \textbf{58} (1985), 209--242.
\end{enumerate}

or this followup:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  D. Finberg, M. Mainetti and G.-C. Rota, ``The logic of commuting
  equivalence relations'', in \emph{Logic and Algebra}, eds.~A. Ursini
  and P. Agliano, Lecture Notes in Pure and Applied Mathematics,
  vol.~\textbf{180}, Decker, New York 1996.
\end{enumerate}

To finish up, let me add that there are lots of linear lattices. For
example, we can try generalizing the above trick from vector spaces to
groups! Given any group \(G\), each subgroup \(H\) determines an
equivalence relation on \(G\), which by abuse of language I'll call
\(H\), such that \(xHy\) iff \(xy^{-1}\) is in \(H\). If \(G\) is
abelian all these equivalence relations commute, so the lattice of
subgroups of \(G\) becomes a linear lattice. If \(G\) is nonabelian this
trick breaks down unless we use \emph{normal} subgroups.

I should also add that nobody has figured out whether the collection of
linear lattices can be characterized by identities\ldots{} though they
satisfy lots of interesting identities, like the famous ``modular law'':
\[x \operatorname{and} (y \operatorname{or} (x \operatorname{and} z)) = (x \operatorname{and} y) \operatorname{or} (x \operatorname{and} z)\]
This is one reason Haiman's proof theory is interesting.

Now, on to some category theory!

Michael Mueger has written some excellent papers on the relation between
quantum field theory, category theory, and topology:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Michael Mueger, ``Conformal field theory and Doplicher-Roberts
  reconstruction'', available at
  \href{https://arxiv.org/abs/math-ph/0008027}{\texttt{math-ph/0008027}}.
\end{enumerate}

``From subfactors to categories and topology I: Frobenius algebras in
and Morita equivalence of tensor categories'', available at
\href{https://arxiv.org/abs/math.CT/0111204}{\texttt{math.CT/0111204}}.

``From subfactors to categories and topology II: The quantum double of
tensor catgories and subfactors'', available at
\href{https://arxiv.org/abs/math.CT/0111205}{\texttt{math.CT/0111205}}.

I can't possibly do justice to these, but I'd like to discuss a very
pretty idea from his paper on Frobenius algebras. This will give me a
good chance to continue some themes from my earlier issues on
\(n\)-categories and homotopy theory.

In \protect\hyperlink{week83}{``Week 83''} I talked about adjoint
functors, and more generally, adjunctions in any \(2\)-category. If you
don't understand this stuff, you're a goner now, but let me just remind
you of the definitions. Suppose \(a\) and \(b\) are objects in a
\(2\)-category. Then we say the morphism \[L\colon a \to b\] is a ``left
adjoint'' of the morphism \[R\colon b \to a\] (and \(R\) is a ``right
adjoint'' of \(L\)) if there are \(2\)-morphisms called the ``unit''
\[i: 1a \Rightarrow LR\] and ``counit'' \[e: RL \Rightarrow 1b\]
satisfying the ``triangle equations'', which say that these vertical
composites are both identity \(2\)-morphisms:
\[L = 1_aL \xRightarrow{i\cdot1_L} LRL \xRightarrow{1_L\cdot e} L1_a = L\]
and
\[R = R1_b \xRightarrow{1_R\cdot i} RLR \xRightarrow{e\cdot1_R} 1_bR = R\]
where \(\cdot\) denotes horizontal composition. The whole setup
\((a,b,L,R,e,i)\) is then called an ``adjunction''.

There are some important variations on this theme. For example, if \(e\)
and \(i\) are invertible, but we drop the triangle equations, we call
the setup an ``equivalence''. It's morally correct to consider two
objects \(a\) and \(b\) in a \(2\)-category ``the same for all practical
purposes'' if they take part in an equivalence. A special case is when
they are \emph{equal} --- since then we can take \(L,R,e,i\) to be
identities. Another special case is when they are \emph{isomorphic} -
since then we can take \(L\) to be an isomorphism, \(R\) its inverse,
and \(e\) and \(i\) to be identities. But in general we only need \(L\)
and \(R\) to be isomorphisms ``up to 2-isomorphism''.

So, the notion of equivalence is better than equality, because it
follows the fundamental principle of \(n\)-category theory: everything
is only true up to something!

If \(e\) and \(i\) are invertible and we \emph{keep} the triangle
equations, we call the setup an ``adjoint equivalence''. In other words,
an adjoint equivalence is an adjunction that is also an equivalence.
This is a bit better than an equivalence. Recently on the category
theory mailing list Paul Levy asked exactly how much better. The first
answer is: not much, because given any equivalence we can cook up an
adjoint equivalence by just fiddling with either the unit or counit in a
standard way, using only the material at hand: \((a,b,R,L,i,e)\). I
leave this as a fun exercise\ldots.

But the second answer, which James Dolan and I worked out this Friday,
goes like this:

First, consider the ``Platonic idea of an equivalence''. By this, I mean
the \(2\)-category \(\mathsf{Equiv}\) which is freely generated by
objects \(a\) and \(b\), morphisms \(L\colon a \to b\) and
\(R\colon b \to a\), and isomorphisms \(i\colon 1_b \Rightarrow RL\) and
\(e\colon LR \Rightarrow 1_a\). Why do I call this the ``Platonic idea
of an equivalence''? Well, any equivalence in any \(2\)-category
\(\mathcal{C}\) is just the same as a 2-functor
\[F\colon \mathsf{Equiv} \to \mathcal{C}\] The functor \(F\) turns the
``abstract'' equivalence in \(\mathsf{Equiv}\) into a ``concrete''
equivalence in \(\mathcal{C}\)! This is reminiscent of Plato's theory of
ideas and how they get manifested in concrete situations. We can think
of \(\mathsf{Equiv}\) as the unadorned idea of an adjunction without any
contamination by accidental extra features.

I should add that James, less of an intellectual snob than I, calls
\(\mathsf{Equiv}\) the ``walking equivalence''. After all, if someone
has really big bushy eyebrows, so that when you see him walking down the
street you first notice his eyebrows and only later realize there's a
person attached, you call him a ``walking pair of eyebrows''. The person
is basically just the life support system for the eyebrows! Similarly,
in \(\mathsf{Equiv}\) we have a \(2\)-category which is just the life
support system for an adjunction: no more and no less.

Anyway, the walking equivalence is a weak 2-groupoid: a \(2\)-category
where every \(2\)-morphism is invertible and every morphism is
invertible up to 2-isomorphism. Weak 2-groupoids are secretly the same
thing as homotopy 2-types: roughly speaking, topological spaces whose
homotopy groups vanish above dimension 2. And there's a pretty easy way
to turn a weak 2-groupoid into a homotopy 2-type. First you turn it into
a simplicial set, called its ``nerve'', and then you take the geometric
realization of that.

Eh? Well, I talked about geometric realization in part E of
\protect\hyperlink{week116}{``Week 116''}, and I talked about the nerve
of a \(1\)-category in part J of \protect\hyperlink{week117}{``Week
117''}, so the only thing I need to do is say a bit about the nerve of a
\(2\)-category. This is a simplicial set where the 0-simplices
correspond to objects: \[x\] the \(1\)-simplices correspond to
morphisms: \[x\xrightarrow{F}Y\] the \(2\)-simplices correspond to
\(2\)-morphisms: \[
  \begin{tikzpicture}
    \node (x) at (0,0) {$x$};
    \node (y) at (1,1.7) {$y$};
    \node (z) at (2,0) {$z$};
    \draw[thick,->] (x) to node[fill=white]{$F$} (y);
    \draw[thick,->] (x) to node[fill=white]{$H$} (z);
    \draw[thick,->] (y) to node[fill=white]{$G$} (z);
    \draw[double,double equal sign distance,-implies] (y) to (1,0.2);
    \node[fill=white] at (1,0.6) {$a$};
    \node at (4,0.85) {$
      \begin{aligned}
        F\colon x&\to y
      \\G\colon x&\to z
      \\H\colon y&\to z
      \\a\colon FG&\Rightarrow H
      \end{aligned}
    $};
  \end{tikzpicture}
\] and the higher-dimensional simplices correspond to equations,
``equations between equations'', and so on.

Anyway, if you use this trick to turn the walking equivalence into a
space, what space do you get?

The 2-sphere!

It's pretty easy to see\ldots{} I'd draw it for you on paper if I could,
but you'll have to do it yourself. It helps if you have a globe:

\begin{itemize}
\tightlist
\item
  \(a\) is the North Pole,
\item
  \(b\) is the South Pole,
\item
  \(L\colon a \to b\) is the Greenwich Meridian running from north to
  south,
\item
  \(R\colon b \to a\) is the International Date Line running from south
  to north,
\item
  \(i\colon 1_a \Rightarrow LR\) is the Eastern Hemisphere, and
\item
  \(e\colon RL \Rightarrow 1_b\) is the Western Hemisphere!
\end{itemize}

(More precisely, we just get the 2-sphere up to homotopy equivalence:
there is a whole bunch of higher-dimensional flab which I'm ignoring
here. But that's okay, since we're doing homotopy theory.)

We can also play this game for the ``walking adjoint equivalence'',
\(\mathsf{AdEquiv}\). This is just like the walking equivalence, except
we put in extra relations: the triangle equations. How does this affect
the space we get?

It's very beautiful: the extra equations fill in the 2-sphere to give us
a 3-ball! (At least up to homotopy equivalence.)

Now, the 3-ball is contractible, so as a homotopy type it's really the
same as a point. And a point is exactly the space we'd get from playing
the same game starting with the ``walking object'': the \(2\)-category
with one object, its identity morphism, and the identity \(2\)-morphism
of that.

To the eyes of a homotopy theorist, a point and 3-ball are the same, but
the 2-sphere is not. Similarly, to the eyes of an \(n\)-category
theorist, the walking object and the walking adjoint equivalence are
``the same'', but the walking equivalence is not!

We could make this very precise with a suitable notion of ``sameness''
for \(2\)-categories. But instead, let's jump straight to the punchline:
having an adjoint equivalence in a \(2\)-category is ``the same'' as
having an object\ldots. but having an equivalence is not!

There's even more fun to be had here. Since every adjoint equivalence is
an equivalence, there's a 2-functor
\[I\colon \mathsf{Equiv} \to \mathsf{AdEquiv}\] But I also said every
equivalence can be massaged to obtain an adjoint equivalence! In fact, I
said it could be done in two equally good ways. Either of these gives a
2-functor \[P\colon \mathsf{AdEquiv} \to \mathsf{Equiv}\] Now, we can
ask what these become when we turn them into maps between spaces\ldots.

It turns out that \(I\) is just the inclusion of the 2-sphere into the
3-ball, while \(P\) is the map that squashes the 3-ball down to either
the eastern or western hemisphere of the sphere!

By the way, it is irresistible to predict generalizations to higher
dimensions. For any \(n\), we will have weak \(n\)-groupoids called
\(\mathsf{Equiv}\), the ``walking \(n\)-equivalence'', and
\(\mathsf{AdEquiv}\), the ``walking adjoint n-equivalence''. The
geometric realization of the nerve of \(\mathsf{Equiv}\) will be
homotopy equivalent to the \(n\)-sphere, while that of
\(\mathsf{AdEquiv}\) will be homotopy equivalent to the \((n+1)\)-ball.

(Note that for \(n = 1\), \(\mathsf{Equiv}\) will be the category with
objects \(a\) and \(b\) and isomorphisms \(L\colon a \to b\),
\(R\colon b \to a\). In \(\mathsf{AdEquiv}\), there will be extra
relations saying that \(R\) is the inverse of \(L\). In this sense, it
is really an adjoint equivalence rather than an equivalence which is the
proper generalization of an isomorphism!)

Okay. Believe it or not, I still haven't gotten to the stuff Michael
Mueger was talking about! I got distracted. I talked about the walking
equivalence and the walking adjoint equivalence, but next week, I'll
talk about the walking adjunction\ldots{} and finally the walking
``biadjunction'', which is where Mueger comes in.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Postscript --- Keith Harbaugh writes:

\begin{quote}
Since you're back on Desargues again, just thought I'd mention (in case
you haven't already noticed this) that if you look up Desargues in
``Categories, Allegories'' by Freyd and Scedrov, you'll find that they
(probably really Freyd) have a neat proof of Desargues in the context of
their ``allegories'' (\(2\)-categories with structure modeled on the
bicategory of relations).
\end{quote}

Linus Kramer writes:

\begin{quote}
I'd like to comment on the interesting paper by Thomas Püttmann and A.
Rigas, Isometric actions on the projective planes and embedded
generators of homotopy groups, available at

\texttt{http://www.ruhr-uni-bochum.de/mathematik8/puttmann/index.html}

which is mentioned in Baez' article.

As Baez writes, the authors construct an embedding of the 11-sphere into
the Cayley plane \(\mathbb{OP}^2\). This embedding is closely related to
a polarity (a polarity of a projective plane is an involution which maps
points to lines and vice versa, and which preserves incidence).

The simplest example is the elliptic polarity over the reals. Take the
standard inner product on R\^{}3 and consider the map which sends a
subspace to its perp. Now the points of the real projective plane are
the \(1\)-dimensional subspaces, and the lines are the \(2\)-dimensional
subspaces. It is fairly easy to see that this map `take the perp' is a
polarity.

Now there is also a different polarity: take a Minkowski-like metric on
\(\mathbb{R}^3\), (\(++-\)). In exactly the same way as above, one
obtains a polarity, the hyperbolic polarity of the real projective
plane. This polarity has absolute elements, i.e.~elements which are
incident with their image under the polarity: this happens with all
1-dim. subspaces which are `light-like', i.e.~on which the metric
vanishes. The set of all absolute points in \(\mathbb{RP}^2\) is a
1-sphere.

One can prove that up to automorphisms, these two are the only
polarities for the real projective plane \(\mathbb{RP}^2\). Notice the
associated motion groups \(\mathrm{SO}_3(\mathbb{R})\) and
\(\mathrm{SO}_{2,1}(\mathbb{R})\) (the motion group consists of all
collineations which commute with the polarity).

Similar polarities can be defined for the complex, the quaternionic and
the octonionic projective planes. One obtains elliptic (no absolute
points) and hyperbolic (many absolute points) polarities. In the second
case, the set of absolute points are spheres of dimensions 3,7,15,
respectively.

But for these latter projective planes, there are more polarities! There
is one more polarity (called `planar polarity' by some authors) which
has a different kind of absolute points. For these polarities, one
obtains spheres of dimension 2,5,11, respectively for the absolute
points.

These semi-classical embeddings were (re)discovered by the authors. The
corresponding motion groups are by the way simple; they are
\(SO_{3,1}(\mathbb{R})\), \(SU_{3,1}(\mathbb{C})\) and
\(SU_{3,1}(\mathbb{H})=\mathrm{Sp}_{3,1}\). If one looks only for
isometric motions (as the authors do) (i.e.~motions which centralize at
the same time the elliptic polarity) one obtains the compact groups
mentioned in the article.

Of course, the main point of the authors is that they obtain generators
of the 11th homotopy group, and this is certainly a new and beautiful
result. I just wanted to mention some related `classical' results from
projective geometry.

A good source here is, as always, Salzmann et al., Compact Projective
Planes, de Gruyter 1995, p.~127.

Regards, Linus Kramer
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week174}{%
\section{November 28, 2001}\label{week174}}

Groups are how mathematicians and physicists talk about symmetry, and
Lie groups are how they talk about \emph{continuously varying}
symmetries, like rotations, translations and the like. Sophus Lie helped
start the subject of Lie groups in the late 1800s, and it's been in
constant growth ever since. I spend lots of time studying it, and I
probably will all my life --- there's a lot to learn! To really
understand it, it helps to know the history. And for that, this is the
book to read:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Thomas Hawkins, \emph{The Emergence of the Theory of Lie Groups: an
  Essay in the History of Mathematics, 1869--1926}, Springer, New York,
  2000.
\end{enumerate}

You have to know your Lie groups pretty well to enjoy this book, but if
you do, you'll find it's full of interesting facts. For example: folks
often complain about Wilhelm Killing's original classification of simple
Lie algebras --- it wasn't rigorous, he made some mistakes, and so on.
Elie Cartan came along later and cleaned it up, and many people applaud
Cartan's work and sneer at poor old Killing, even though he was the one
who came up with the original ideas. But in this book, it becomes clear
that Killing was pretty much \emph{pushed} into publishing his ideas in
a half-baked state by mathematicians who were dying to know his results!
Now I feel even more sorry for him.

There's also a lot of interesting stuff about Hermann Weyl's approach to
representation theory via tensors and Young diagrams, and why he liked
it better than Cartan's approach via roots and weights. Basically, Weyl
liked his approach because it stuck closer to Felix Klein's original
``Erlanger program'' --- a program for understanding geometry via
symmetry groups. But it's interesting to see how Weyl studied and
respected Cartan's approach, and tried to bridge the gap between the
two.

Okay\ldots{} so much for gossip! Now I'm going to dive in and pick up
right where I left off in my discussion of the ideas behind this paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Michael Mueger, ``From subfactors to categories and topology I:
  Frobenius algebras in and Morita equivalence of tensor categories'',
  available at
  \href{https://arxiv.org/abs/math.CT/0111204}{\texttt{math.CT/0111204}}.
\end{enumerate}

My ultimate goal is to take you to an elegant understanding of Frobenius
algebras by means of a \(2\)-category called the ``walking ambidextrous
adjunction'', but first I'll play around a bit with a simpler but more
famous \(2\)-category called the ``walking adjunction''. This may sound
scary, but if you can stick with it, you'll see that I'm really just
using these \(2\)-categories to describe fun games that you can play
with certain \(2\)-dimensional pictures. Even if you don't read the
words, please stare at the pictures --- I spend my Thanksgiving weekend
drawing them, and I don't want that work to go to waste!

Category theorists love to talk about adjoint functors, but
\(2\)-category theorists know that these are just a special example of
an ``adjunction''. An adjunction is something that makes sense in any
\(2\)-category; if we take the \(2\)-category to be \(\mathsf{Cat}\) we
get adjoint functors. There are lots of other nice examples that make
this generalization worthwhile. For example, in
\protect\hyperlink{week83}{``Week 83''} I explained how a pair of dual
vector spaces is also an example of an adjunction.

To study adjunctions, it suffices to study the ``walking adjunction''.
This is a little \(2\)-category containing exactly the stuff any
adjunction in any \(2\)-category must have: not a jot more, not a tiddle
less! It was first studied by Schanuel and Street:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Stephen Schanuel and Ross Street, ``The free adjunction'', \emph{Cah.
  Top. Geom. Diff.} \textbf{27} (1986), 81--83.
\end{enumerate}

In a bit more detail, the walking adjunction is the \(2\)-category
freely generated by two objects: \[\mbox{$a$ and $b$,}\] two morphisms:
\[\mbox{$L\colon a \to b$ and $R\colon b \to a$,}\] and two
\(2\)-morphisms, called the ``unit'' and ``counit'':
\[\mbox{$i\colon 1_a \Rightarrow LR$ and $e\colon RL \Rightarrow 1_b$}\]
satisfying two relations, called the ``triangle equations''.

I wrote down these equations already last week, but let me do it again
using ``string diagrams'', as explained in
\protect\hyperlink{week79}{``Week 79''} and
\protect\hyperlink{week92}{``Week 92''}. In a \(2\)-categorical string
diagram, objects are denoted by 2d regions in the plane, morphisms are
denoted by 1d edges, and \(2\)-morphisms are denoted by 0d points. If
the dimensions look sort of upside-down, you're right --- that's exactly
the point!

Instead of explaining the whole theory, I'll just plunge in with the
example at hand. The unit \(i\) looks like this: \[
  \begin{tikzpicture}[yscale=-1]
    \begin{knot}
      \strand[thick] (0,0)
      to (0,-0.5)
      to [out=down,in=down,looseness=2] (1.5,-0.5)
      to (1.5,0);
    \end{knot}
    \node[fill=white] at (0,-0.45) {$L$};
    \node[fill=white] at (1.5,-0.45) {$R$};
    \node[label={[label distance=-1mm]above:{$i$}}] at (0.75,-1.39) {$\bullet$};
    \node at (0.75,-0.75) {$b$};
    \node at (-0.45,-1) {$a$};
    \node at (1.95,-1) {$a$};
  \end{tikzpicture}
\] while the counit \(e\) looks like this: \[
  \begin{tikzpicture}
    \begin{knot}
      \strand[thick] (0,0)
      to (0,-0.5)
      to [out=down,in=down,looseness=2] (1.5,-0.5)
      to (1.5,0);
    \end{knot}
    \node[fill=white] at (0,-0.45) {$L$};
    \node[fill=white] at (1.5,-0.45) {$R$};
    \node[label={[label distance=-1mm]below:{$e$}}] at (0.75,-1.39) {$\bullet$};
    \node at (0.75,-0.75) {$a$};
    \node at (-0.45,-1) {$b$};
    \node at (1.95,-1) {$b$};
  \end{tikzpicture}
\] Note that as you cross a line labelled ``\(L\)'' from left to right,
you go from region \(a\) to region \(b\), which is our way of saying
that \(L\colon a\to b\). Similarly, as you cross a line labelled
``\(R\)'' from left to right, you go from region \(b\) to region \(a\),
since \(R\colon b\to a\).

In terms of string diagrams, the triangle equations just say that we can
straighten out a zig-zag: \[
  \begin{tikzpicture}
    \begin{scope}
      \begin{knot}
        \strand[thick] (0,0)
        to (0,1)
        to [out=up,in=up,looseness=2] (1,1)
        to [out=down,in=down,looseness=2] (2,1)
        to (2,2);
      \end{knot}
      \node at (-0.5,1.5) {$a$};
      \node[fill=white] at (0,0.5) {$L$};
      \node[label={[label distance=-1mm]above:{$i$}}] at (0.5,1.57) {$\bullet$};
      \node[fill=white] at (1,1) {$R$};
      \node[label={[label distance=-1mm]below:{$e$}}] at (1.5,0.4) {$\bullet$};
      \node[fill=white] at (2,1.5) {$L$};
      \node at (2.5,0.5) {$b$};
    \end{scope}
    \node at (3.5,1) {$=$};
    \begin{scope}[shift={(5,2)}]
      \node at (-0.5,-1) {$a$};
      \draw[thick] (0,0) to node[fill=white]{$L$} (0,-2);
      \node at (0.5,-1) {$b$};
    \end{scope}
  \end{tikzpicture}
\] or a zag-zig: \[
  \begin{tikzpicture}
    \begin{scope}[xscale=-1,shift={(-2,0)}]
      \begin{knot}
        \strand[thick] (0,0)
        to (0,1)
        to [out=up,in=up,looseness=2] (1,1)
        to [out=down,in=down,looseness=2] (2,1)
        to (2,2);
      \end{knot}
      \node at (-0.5,1.5) {$a$};
      \node[fill=white] at (0,0.5) {$R$};
      \node[label={[label distance=-1mm]above:{$i$}}] at (0.5,1.57) {$\bullet$};
      \node[fill=white] at (1,1) {$L$};
      \node[label={[label distance=-1mm]below:{$e$}}] at (1.5,0.4) {$\bullet$};
      \node[fill=white] at (2,1.5) {$R$};
      \node at (2.5,0.5) {$b$};
    \end{scope}
    \node at (3.5,1) {$=$};
    \begin{scope}[shift={(5,2)}]
      \node at (-0.5,-1) {$b$};
      \draw[thick] (0,0) to node[fill=white]{$R$} (0,-2);
      \node at (0.5,-1) {$a$};
    \end{scope}
  \end{tikzpicture}
\] We can build any \(2\)-morphism in the walking adjunction by
vertically and horizontally composing units and counits, which
corresponds to sticking together string diagrams in a vertical or
horizontal way. Thus, a typical \(2\)-morphism looks like this:

\begin{verbatim}
      \     \   a   /   \   a   /      /               |
       \     R     L     R     L      /       i        |
        \     \   /       \   /      /       / \       L
         \     \ /         \ /      /   a   /   R      |    b
          \     e           e      /       /     \     |
    a      L                      R        \      \   / 
            \         b          /     i    \      \ / 
             \                  /     / \    L      e
              \                /     L   R    \       
               \              /     /  b  \    \  
\end{verbatim}

By the triangle equations, we could straighten out the zig-zag without
changing the \(2\)-morphism.

As you may know, the word ``anaranjado'' means ``orange'' in Spanish ---
there was no word in English for ``orange'' before people in England
started importing oranges from Spain. And this is a nice mnemonic,
because if we take the above picture and paint the regions labelled
``\(a\)'' orange, and paint the regions labelled ``\(b\)'' black, the
above picture has a roughly tiger-striped appearance. In fact, these
tiger stripes tell you everything you need to know about the
\(2\)-morphism! For example, starting from just this:

\begin{verbatim}
      \     \   a   /   \   a   /      /               |
       \     \     /     \     /      /       _        |
        \     \   /       \   /      /       / \       |
         \     \_/         \_/      /   a   /   \      |    b
          \                        /       /     \     |
    a      \                      /        \      \   / 
            \         b          /     _    \      \_/ 
             \                  /     / \    \      
              \                /     /   \    \       
               \              /     /  b  \    \  
\end{verbatim}

you can figure out where everything else should go.

By the way, note that orange stripes can disappear as we go down the
page, and they can split, but they can't appear or merge. Black stripes
can appear or merge, but they can't disappear or split. As a result,
there can never be any orange or black \emph{spots}. We'll change these
rules later, when we talk about the walking ``ambidextrous adjunction''.

Okay, so we've got this \(2\)-category, the walking adjunction: let's
call it \(\mathsf{Ad}\) for short. It's pretty simple. How can we
understand it better?

Well, for any two objects \(a\) and \(b\) in a \(2\)-category we get a
``hom-category'' \(\operatorname{Hom}(a,b)\), whose objects are the
morphisms from \(a\) to \(b\), and whose morphisms are the
\(2\)-morphisms between those. If we work out these hom-categories in
\(\mathsf{Ad}\), we get some cool stuff.

First let's look at the hom-category \(\operatorname{Hom}(a,a)\). In
this category, the objects are \[1_a, LR, LRLR, LRLRLR, \ldots\] and all
the morphisms are built by sticking these two basic generators together
vertically or horizontally:

\begin{verbatim}
                     \  \    a    /  /  
                      \  \       /  /
                       L  R     L  R
                        \  \   /  /
                  a      \  \ /  /      a
                          \  e  /
                           \   /
                           | b |
                           |   |
                           L   R
                           |   |
                           |   |   
\end{verbatim}

and

\begin{verbatim}
                              i
                             / \
                     a      |   |    a
                            | b |     
                            |   |
                            L   R   
                            |   |
                            |   |
\end{verbatim}

In tiger language, we're talking about pictures of black stripes on an
orange background. The two basic generators are the merging of two black
stripes and the appearance of a black stripe.

If you read \protect\hyperlink{week89}{``Week 89''}, you'll know another
way to describe this! Our ability to stick together pictures vertically
and horizontally makes \(\operatorname{Hom}(a,a)\) into a ``monoidal
category''. \(LR\) is a ``monoid object'', with merging of two black
stripes being ``multiplication'', and the appearance of a black stripe
being the ``multiplicative identity''. Being a ``monoid object'' simply
means that these operations satisfy the left unit law:

\begin{verbatim}
                                 / /                 | |
                                / /                  | |
                               / /                   | |
                    /\        / /                    | |
                    \ \      / /                     | |
                     \ \    / /                      | |
                      \ \  / /                  a    | |
                       \ \/ /                        |b|
                        |  /          =              | |
             a          | |                          | |      a
                        | |                          | |
                        |b|                          | |
                        | |     a                    | |
                        | |                          | |
                        | |                          | |
                        | |                          | |
\end{verbatim}

and its mirror image, called the right unit law, together with the
associative law:

\begin{verbatim}
            \ \  a / /    / /      \ \    \ \  a / /
             \ \  / /  a / /        \ \  a \ \  / /
              \ \/ /    / /          \ \    \ \/ /
               \  /    / /            \ \    \  /
                \ \   / /              \ \   / /
                 \ \_/ /                \ \_/ /
                  \   /                  \   /
                   | |                    | |
              a    | |   a            a   | |   a
                   | |          =         | |
                   |b|                    |b|
                   | |                    | |
                   | |                    | |
                   | |                    | |
                   | |                    | |
\end{verbatim}

There aren't any other laws, so \(\operatorname{Hom}(a,a)\) is the
``free monoidal category on a monoid object'', or if you prefer, the
``walking monoid''!

I touched upon the immense consequences of this fact for algebraic
topology in \protect\hyperlink{week117}{``Week 117''} and
\protect\hyperlink{week118}{``Week 118''}. They mainly rely on another
way of thinking about \(\operatorname{Hom}(a,a)\): it's the category of
order-preserving maps between finite ordinals!

For example, these black tiger stripes on an orange background:

\begin{verbatim}
         0          1           2                     3
    --------------------------------------------------------
   |  \     \   a |   |  a  /      /               |    |   |
   |   \     \    |   |    /      /       _        |    |   |
   |    \     \   |   |   /      /       / \       |    |   |
   |     \     \_/     \_/      /   a   /   \      |    |   |
   |      \                    /        \    \     |    |   |
   | a     \                  /          \    \   /    /    |
   |        \       b        /     _      \    \_/    /     |
   |         \              /     / \      \         /      |
   |          \            /     / b \      \   b   /   a   |
   |           \          /     /     \      \     |        |
    --------------------------------------------------------
                     0             1            2
\end{verbatim}

correspond to the order-preserving map
\[f\colon \{0,1,2,3\} \to \{0,1,2\}\] with
\[f(0) = 0,\quad f(1) = 0,\quad f(2) = 0,\quad f(3) = 2.\] Just read the
stripes down!

A more geometrical way to say the same thing is to call
\(\operatorname{Hom}(a,a)\) the category of ``simplices'', usually
denoted \(\Delta\). Here the object
\[\underbrace{LRLR\ldots LR}_{\mbox{$n+1$ of them}}\] corresponds to the
\(n\)-simplex, and these morphisms: \[
  \begin{tikzcd}[column sep=huge]
    1_a
      \rar["i" description]
    & LR
      \rar[shift left=5,"i\cdot LR" description]
      \rar["LR\cdot i" description]
    & LRLR
      \rar[shift left=10,"i\cdot LRLR" description]
      \rar[shift left=5,"LR\cdot i\cdot LR" description]
      \rar["LRLR\cdot i" description]
      \lar[shift left=5,"L\cdot e\cdot R" description]
    & LRLRLR
      \lar[shift left=5,"L\cdot e\cdot RLR" description]
      \lar[shift left=10,"LRL\cdot e\cdot R" description]
      \rar
    &\ldots
  \end{tikzcd}
\]

\begin{verbatim}
                                 -i.LRLR-->
                 --i.LR->        -LR.i.LR->
1a  --i-->  LR  --LR.i->  LRLR  -LRLR.i-->  LRLRLR ...
                 <-L.e.R-        <-L.e.RLR-
                                 <-LRL.e.R-
\end{verbatim}

are the basic ``face'' and ``degeneracy'' maps between simplices, which
you'll find in any book on algebraic topology. The \(n\)-simplex is a
face of the \((n+1)\)-simplex in n+1 ways, and there are n basic
degenerate ways to map the \((n+1)\)-simplex down to the \(n\)-simplex.
These aren't \emph{all} the morphisms; just enough to generate all the
rest by composition --- i.e., sticking together pictures vertically, but
\emph{not} horizontally.

Perhaps I should explain the notation here a bit more. Readers of
\protect\hyperlink{week80}{``Week 80''} will know that I use a dot to
denote horizontal composition of \(2\)-morphisms. For example, when we
have a couple of \(2\)-morphisms like this:

\begin{verbatim}
                      f           f'
                  ---->----   ---->----  
                 /   ||    \ /   ||    \              S: f \Rightarrow g
                x    || S   y    || T   z             T: f' \Rightarrow g'
                 \   \/    / \   \/    /
                  ---->----   ---->----
                      g           g'
\end{verbatim}

we get a \(2\)-morphism like this:

\begin{verbatim}
                         ff'
                  -------->-------
                 /       ||       \
                x        || S.T    z                S.T: ff' \Rightarrow gg'
                 \       \/       /
                  -------->-------
                         gg'
\end{verbatim}

But sometimes we can also horizontally compose a morphism and a
2-morphism! We can do it whenever our morphism \(f\) looks like a little
``whisker'' \(f\) sticking out of the \(2\)-morphism \(T\):

\begin{verbatim}
                                  f'
                              ---->----  
                      f      /   ||    \              
                x----->-----y    || T   z             T: f' \Rightarrow g'
                             \   \/    /
                              ---->----
                                  g'
\end{verbatim}

and what we get is a \(2\)-morphism \(f\cdot S\) like this:

\begin{verbatim}
                         ff'
                  -------->-------
                 /       ||       \
                x        || f.T    z                f.T: ff' \Rightarrow fg'
                 \       \/       /
                  -------->-------
                         fg'
\end{verbatim}

This process, called ``whiskering'', is not really a new operation.
\(f\cdot S\) is really just the horizontal composite of these
\(2\)-morphisms:

\begin{verbatim}
                      f           f'
                  ---->----   ---->----  
                 /   ||    \ /   ||    \              
                x    ||1_f  y    || S   z             
                 \   \/    / \   \/    /
                  ---->----   ---->----
                      f           g'
\end{verbatim}

Similarly we can define \(T\cdot f\) in this sort of situation:

\begin{verbatim}
                      f'           
                  ---->----   
                 /   ||    \      f                   T: f' \Rightarrow g'
                x    || T   y----->-----z             T.f: f'f \Rightarrow g'f
                 \   \/    /
                  ---->---- 
                      g'     
\end{verbatim}

Anyway, once you're an expert on this \(2\)-categorical yoga, you can
easily see that these morphisms in \(\operatorname{Hom}(a,a)\), which
are really 2-morphisms in \(\mathsf{Ad}\):

\begin{verbatim}
                                 -i.LRLR-->
                 --i.LR->        -LR.i.LR->
1a  --i-->  LR  --LR.i->  LRLR  -LRLR.i-->  LRLRLR ...
                 <-L.e.R-        <-L.e.RLR-
                                 <-LRL.e.R-
\end{verbatim}

are obtained by taking our basic tiger stripe operations --- the
``merging of two black stripes'', or \(L\cdot e\cdot R\), and the
``appearance of a black stripe'', or \(i\) --- and drawing some extra
black stripes on both sides. That's what those \(LR\)'s are for. After
all, no tiger is complete without whiskers!

Okay. Now, having understood \(\operatorname{Hom}(a,a)\) in all these
ways, let's turn to \(\operatorname{Hom}(b,b)\). Luckily, this is very
similar! Here the objects are
\[1_b,\quad RL,\quad RLRL,\quad RLRLRL,\quad \ldots\] and morphisms are
pictures of \emph{orange} stripes on a \emph{black} background:

\begin{verbatim}
           \   a   /   \   a   /      /               |
            \     /     \     /      /       _        |
             \   /       \   /      /       / \       |
              \_/         \_/      /   a   /   \      |    b
                                  /       /     \     |
                                 /        \      \   / 
       b                        /     _    \      \_/ 
                               /     / \    \      
                              /     /   \    \       
                             /     /  b  \    \  
\end{verbatim}

These orange stripes can only split:

\begin{verbatim}
                           |   |
                           |   |   
                           R   L
                           |   |
                           | a |
                           /   \                           
                          /  i  \
                  b      /  / \  \      b
                        /  /   \  \
                       R  L     R  L
                      /  /       \  \
                     /  /    b    \  \ 
\end{verbatim}

or disappear:

\begin{verbatim}
                            |   |    
                     b      | a |     b 
                            |   |
                            R   L   
                            |   |
                            |   |
                             \ /
                              e
\end{verbatim}

as we march down the page. This means is that
\(\operatorname{Hom}(b,b)\) is \(\Delta^{\mathrm{op}}\): the
\emph{opposite} of the category of simplices, the \emph{opposite} of the
category of finite ordinals, or the walking \emph{comonoid} --- which is
just like a monoid, only upside down!

Here is another picture of \(\operatorname{Hom}(b,b)\):

\begin{verbatim}
                                  --R.i.LRL->
                 --R.i.L->        --RLR.i.L->
1b  <--e--  RL  <--e.RL--  RLRL  <--e.RLRL--  RLRLRL ...
                 <--RL.e--        <--RL.e.RL-
                                  <--RLRL.e--
\end{verbatim}

If you're a devoted reader of This Week's Finds, you'll know I secretly
drew this category already in section N of
\protect\hyperlink{week118}{``Week 118''}. There I was talking about
specific adjoint functors instead of the walking adjunction, so as not
to prematurely blow your mind. I was also writing horizontal composites
backwards, for certain old-fashioned reasons. But the idea is exactly
the same! The morphisms above give the usual ``face and degeneracy
maps'' we always have in a simplicial set, since a simplicial set is a
functor \[F\colon \Delta^{\mathrm{op}} \to \mathsf{Set}.\] By the way,
you may have noticed that to get from \(\operatorname{Hom}(a,a)\) to
\(\operatorname{Hom}(b,b)\), we had to switch the colors orange and
black AND read the pictures upside-down. The reason is that if we turn
around all the \(1\)-morphisms AND \(2\)-morphisms in the walking
adjunction, we get the walking adjunction again. Ponder that!

We can summarize what we've learned so far using the ``Platonic idea''
jargon I introduced last week:

\begin{quote}
The Platonic idea of a monoid and the Platonic idea of a comonoid are
the hom-categories \(\operatorname{Hom}(a,a)\) and
\(\operatorname{Hom}(b,b)\) sitting inside the Platonic idea of an
adjunction!
\end{quote}

(By the way, to round this off we should really describe
\(\operatorname{Hom}(a,b)\) and \(\operatorname{Hom}(b,a)\), too. I
think \(\operatorname{Hom}(a,b)\) is the Platonic idea of ``an object
with a left action of a monoid and a right coaction of a comonoid, in a
compatible way''. If so, \(\operatorname{Hom}(b,a)\) would be the
Platonic idea of ``an object with a right action of a monoid and a left
coaction of a comonoid, in a compatible way''. By ``compatible'' I'm
saying that we can act on one side and coact on the other side in either
order, and get the same thing. Filling in the details requires concepts
I'm not eager to discuss right now, so I leave this as an exercise for
the highly energetic reader. The less energetic reader can just study
the tiger-stripe descriptions of these categories.)

Finally, here's Mueger's new twist on all these ideas! Better than an
adjunction is an ``ambidextrous'' adjunction. This has some extra
structure, which turns out to explain all sorts of fancy-sounding stuff
people look at in the study of subfactors and TQFTs and the like\ldots.

But what's an ``ambidextrous adjunction''?

A ambidextrous adjunction is where you have a morphism
\[L\colon a \to b\] in a \(2\)-category that is both left and right
adjoint to \[R\colon b \to a.\] More precisely, it is a setup
\[(a,b,L,R,i,e,j,f)\] where \[(a,b,L,R,i,e)\] and \[(b,a,R,L,j,f)\] are
both adjunctions.

In terms of string diagrams, our generating \(2\)-morphisms look like
this:

\begin{verbatim}
                  i                             j
                 / \                           / \
                L   R                         R   L
               /     \                       /     \
           a  /   b   \  a               b  /   a   \  b




           b  \   a   /  b               a  \   b   /  a
               R     L                       L     R
                \   /                         \   /
                 \ /                           \ /
                  e                             f
\end{verbatim}

and the triangle equations say all possible zig-zags can be straightened
out.

Now let's study the ``walking ambidextrous adjunction'',
\(\mathsf{AmbAd}\). As before, \(2\)-morphisms in \(\mathsf{AmbAd}\) can
be described using pictures with orange and black stripes --- but now
\emph{both} kinds of stripes can appear, disappear, merge or split as we
march down the page:

\begin{verbatim}
  -------------------------------------------------------
 |   \     \   a |   |  a  /      /             |       |
 |    \     \    |   |    /      /              |       |
 |     \     \__/     \__/      /      a        |       |
 |      \        _____         /     _____      |       |
 |       \      /  a  \       /     /     \     |       |
 |  a    /     /  ___  \     /     /       \   /        |
 |      /     /  /   \  \   /     /    __   \_/         |
 |     /     /   \ b /  /  /     /    /  \              |
 |    /  b   \    \_/  /  /     /    / a  \  b          |
 |   /        \       /  /     /    /      \            |
  -------------------------------------------------------
\end{verbatim}

This allows for quite arbitrary ways of cutting up a rectangle into
regions of orange and black, with piecewise linear boundaries, subject
to the condition that each vertical border has the same color all along
it. The triangle equations and the rules for \(2\)-categories say that
we can warp such a picture around without changing the \(2\)-morphism
that it defines\ldots{} I don't want to be too precise here, since it
would be boring. Hopefully you get the idea: AmbAd has a purely
topological description!

Now for the punchline: in \(\mathsf{AmbAd}\), what is the category
\(\operatorname{Hom}(a,a)\) like? As in \(\mathsf{Ad}\), the objects are
\[1_a,\quad LR,\quad LRLR,\quad LRLRLR,\quad \ldots\] but now the object
LR is equipped not only with multiplication:

\begin{verbatim}
                     \  \    a    /  /  
                      \  \       /  /
                       L  R     L  R
                        \  \   /  /
                  a      \  \ /  /      a      
                          \  e  /                     multiplication:
                           \   /                     L.e.R: LRLR \Rightarrow LR 
                           | b |
                           |   |
                           L   R
                           |   |
                           |   |   
\end{verbatim}

and multiplicative identity:

\begin{verbatim}
                             i
                            / \
                    a      |   |    a                 multiplicative
                           | b |                         identity:
                           |   |                        i: 1a \Rightarrow LR
                           L   R   
                           |   |
                           |   |
\end{verbatim}

but also a ``comultiplication'':

\begin{verbatim}
                           |   |
                           |   |   
                           L   R
                           |   |
                           | b |
                           /   \                           
                          /  j  \                    comultiplication:
                  a      /  / \  \      a            L.j.R: LR \Rightarrow LRLR
                        /  /   \  \
                       L  R     L  R
                      /  /       \  \
                     /  /    b    \  \ 
\end{verbatim}

and ``comultiplicative coidentity'':

\begin{verbatim}
                            |   |    
                     a      | b |     a 
                            |   |                    comultiplicative
                            L   R                       coidentity:
                            |   |                      f: LR \Rightarrow 1a
                            |   |
                             \ /
                              f
\end{verbatim}

which make it into a monoid object \emph{and} a comonoid object. Even
better, there are some extra relations between the multiplication and
comultiplication, which make LR into a so-called ``Frobenius object''!

In short, \(\operatorname{Hom}(a,a)\) is the walking Frobenius object!
So is \(\operatorname{Hom}(b,b)\), since there is no real asymmetry
between the objects \(a\) and \(b\) in an ambidextrous adjunction, as
there was with an adjunction. I haven't thought much about
\(\operatorname{Hom}(a,b)\) and \(\operatorname{Hom}(b,a)\) yet, but one
obvious thing is that they're isomorphic.

Next time I'll talk about examples of Frobenius objects and why they are
so important in subfactors, TQFTs and the like. This is what Mueger is
really interested in. Right now, I want to wrap up by saying exactly
what it means to say \(LR\) is a ``Frobenius object''. What are the
extra relations between multiplication and comultiplication?

There are various ways of describing these relations. Mueger uses a pair
of equations that are popular in the TQFT literature:

\begin{verbatim}
               \ \     / /                | |        | |
                \ \   / /                 | |        | |
                 \ \_/ /                  | |        | |
                  \   /                   |  \   a   | |
                   | |                    |   \      | |
              a    | |   a           a    | |\ \     | |   a
                   | |                    | | \ \    | |
                   |b|                    | |  \ \   | |
                   | |          =         | |   \ \  | |
                   | |                    | |    \ \ | |
                   | |                    | |  a  \ | |
                   | |                    | |      \   |
                  / _ \                   | |       \ b|
                 / / \ \                  | |        | |
                / /   \ \                 | |        | | 
               / /     \ \                | |        | |
\end{verbatim}

and its mirror image. People sometimes call these the ``\(I = N\)''
equations, for the obvious reason. So: one definition of a ``Frobenius
object'' in a monoidal category is that it's a monoid object / comonoid
object satisfying the \(I = N\) equations.

Where can you read about this? Well, besides Mueger's paper, there are
these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\item
  Frank Quinn, ``Lectures on axiomatic quantum field theory'', in
  \emph{Geometry and Quantum Field Theory}, Amer. Math. Soc.,
  Providence, RI, 1995.
\item
  Lowell Abrams, ``Two-dimensional topological quantum field theories
  and Frobenius algebras'', \emph{J. Knot Theory and its Ramifications}
  \textbf{5} (1996), 569--587.
\end{enumerate}

A ``Frobenius algebra'' is just a Frobenius object in the category of
vector spaces. I seem to recall that this is equivalent to what Quinn
calls an ``ambialgebra''. For any TQFT in any dimension, the vector
space associated to the sphere is a commutative Frobenius algebra. The
proof consists of playing with pictures very much like the ones above,
but in higher dimensions.

The \(I = N\) equations are cute, but personally I prefer a more
conceptual description of a Frobenius object. This may be a bit
mindblowing to the uninitiated, so if you're just barely hanging on,
please stop now.

Hmm! If you're still reading this, you must be brave! Okay --- don't say
I didn't warn you. Let's start by pondering \(LR\) a bit more. This guy
is its own adjoint, with the unit and counit as follows:

\begin{verbatim}
                      _
                a    / \      
                    |   |                     
                    |   |                      unit for LR =
                    | b |           multiplicative identity composed with
                   /  _  \                    comultiplication                
                  /  / \  \
                 /  /   \  \
                /  /  a  \  \



                \  \  a  /  /
                 \  \   /  /                 
                  \  \_/  /                   counit for LR =
                   \     /              multiplication composed with 
               a    | b |                comultiplicative coidentity
                    |   |
                    |   |
                     \_/
\end{verbatim}

It's easy to check the triangle equations by straightening out the
relevant zig-zags.

Now, whenever a monoid object has a right or left adjoint, that right or
left adjoint automatically becomes a comonoid object, by the magic of
duality. But if a monoid object is its \emph{own} adjoint, it becomes a
comonoid object in \emph{two} ways, because it is both its own left
\emph{and} right adjoint! So, our guy \(LR\) is a comonoid object in
\emph{three} ways! Huh? Well, we already knew \(LR\) was a comonoid
object before this devilish paragraph began, but since \(LR\) is its own
adjoint, it becomes a comonoid object in two other ways. Amazingly, the
\(I = N\) equations are equivalent to the fact that all three comonoid
structures agree! I leave this as an exercise for the insanely energetic
reader\ldots{} I've worked it out before, and I rechecked it this
morning in bed. I don't know if a proof exists in the literature, but
from what Mueger writes, I suspect maybe you can catch glimpses of it in
Appendix A3 of this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  L. Kadison, \emph{New Examples of Frobenius Extensions}, University
  Lecture Series \#\textbf{14}, Amer. Math. Soc., Providence RI, 1999.
\end{enumerate}

Anyway, the upshot is that we can equivalently define a Frobenius object
in a monoidal category as follows: it's a monoid object / comonoid
object which becomes its own adjoint by letting

\begin{itemize}
\tightlist
\item
  unit = multiplicative identity composed with comultiplication
\item
  counit = multiplication composed with comultiplicative coidentity
\end{itemize}

and has the property that the resulting 3 comonoid structures agree.

Or, equivalently, that the resulting 3 monoid structures agree!

There is much more to say about this, but let's stop here.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Postscript --- Oswald Wyler had this correction to make:

\begin{quote}
The walking adjunction is much older than the 1986 paper by Schanuel and
Street. Back in 1970, Pumplün published a paper: ``Eine Bemerkung über
Monaden und adjungierte Funktoren'', \emph{Math. Annalen} \textbf{185}
(1970), 329--377. The small bicategory ``walking adjunction'' definitely
was in that paper, but I don't recall whether it was explicitly
formulated or not.
\end{quote}

Andree Ehresmann added:

\begin{quote}
On the ``walking adjunction''

I don't know the Pumplun's paper cited by Wyler. But there is another
reference at about the same time; indeed, the ``walking adjunction'' has
been explicitly constructed and studied in the paper of Auderset:

\begin{quote}
``Adjonction et monade au niveau des \(2\)-categories''
\end{quote}

published in \emph{Cahiers de Top. et Geom. Diff.} \textbf{XV-1} (1974),
3--20.

More formally it could also be called ``the 2-sketch of an adjunction''
in the terminology in my paper with Charles Ehresmann:

\begin{quote}
``Categories of sketched structures'', in the \emph{Cahiers}
\textbf{XIII-2} (1972),
\end{quote}

reprinted in ``Charles Ehresmann: Oeuvres completes et commentees'' Part
\textbf{IV-2}.
\end{quote}

Bill Lawvere added:

\begin{quote}
\textbf{ONE MORE HISTORICAL CITATION}

The Pumplun paper cited by Wyler as well as the Auderset paper cited by
Mme Ehresmann illustrate that the study of generic structures in
\(2\)-categories has been going on for some time. My own paper ORDINAL
SUMS AND EQUATIONAL DOCTRINES, SLNM 80 (1969) 141--155 shows that the
augmented simplicial category \(\Delta\) serves as the generic monad,
but moreover goes on to actually apply this to show that the Kleisli
construction is a tensor product left-adjoint to the Eilenberg- Moore
construction which is an enriched Hom. The Hom/tensor formalism
appropriate to the case of strict monoid objects is all that is required
here, as I will explain below.

\textbf{AN EXTENSION AND A RESTRICTION}

The important special case of FROBENIUS monads is explicitly
characterized in three ways in my paper. Concerning the IDEMPOTENT case
discussed a few days ago by Grandis and Johnstone, note that the
publication of Schanuel and Street proves among other things that the
monoid \(\Delta\) in \(\mathsf{Cat}\) has very few quotients (see below
for significance of the monoid structure).

\mbox{}%
\hypertarget{the-general-homtensor-formalism-and-a-very-particular-monoid}{%
\paragraph{THE GENERAL HOM/TENSOR FORMALISM AND A VERY PARTICULAR
MONOID}\label{the-general-homtensor-formalism-and-a-very-particular-monoid}}

In any cartesian-closed category with finite limits and co-limits, a
non-linear version of the Cartan-Eilenberg Hom/tensor formalism applies
to actions and biactions of monoid objects. In Cat, \(\Delta\) is a
(strict) monoid and its actions are precisely monads on arbitrary
categories. A crucial part of the formalism is that categories of
actions are automatically enriched in the basic cartesian-closed
category, which in this case is Cat. There is a particular biaction of
\(\Delta\), which I called \(\Delta\) plus, with the property that the
enriched Hom of it into an arbitrary \(\Delta\)-action is exactly the
Eilenberg-Moore category of ``algebras'', automatically equipped with
its structure as a \(\Delta^{\mathrm{op}}\) action (co-monad). The
left-adjoint tensor assigns to any category equipped with a co-monad its
Kleisli category, as a category with monad. Not only are the
calculations in this particular case quite explicit, but the enriched
Hom tensor formalism has a lot of content which is still
under-exploited.

\textbf{SKETCHES VERSUS PLATONISM}

The often repeated slander that mathematicians think ``as if'' they were
``platonists'' needs to be combatted rather than swallowed. What
mathematicians and other scientists use is the objectively developed
human instrument of general concepts. (The plan to misleadingly use that
fact as a support for philosophical idealism may have been an honest
mistake by Plato, or it may have been part of his job as disinformation
officer for the Athenian CIA organization; it probably would not have
survived until now had it not been for the special efforts of Cosimo de'
Medici.) It seems that a general concept has two related aspects, as I
began to realize more explicitly in connection with my paper
``Adjointness in foundations'', \emph{Dialectica} vol. \textbf{23}
(1969), pp.~281--296; I later learned that some philosophers refer to
these two aspects as ``abstract general vs.~concrete general''. For
example, there is the algebraic theory of rings vs.~the category of all
rings, or a particular abstract group vs.~the category of all
permutation representations of the group. While it is ``obvious'' that,
at least in mathematics, a concrete general should have the structure of
a category, because all the instances embody the same abstract general
and hence any two instances can be compared in preferred ways, by
contrast it was not until the late fifties that one realized that an
abstract general can also be construed as a category in its own right.
That realization essentially made explicit the fact that substitution is
a logical operation and indeed is the most fundamental logical
operation.

Thus an abstract general is essentially a special algebraic structure
indeed a category with additional structure such as finite limits or
still richer doctrines. As with other algebraic structures there are
again two aspects, the structures themselves and their presentations
which are closely related, yet quite distinct; for example, more than
one presentation may be needed for efficient calculations determining
features of the same algebraic structure. What is meant by a
presentation depends on the doctrine: for example \(\Delta\) as a mere
category has an infinite presentation used in topology, but as a strict
monoidal category it has a finite presentation.

The notion of SKETCH is the most efficient scheme yet devised for the
general construction of PRESENTATIONS OF ABSTRACT GENERALS. The fact
that particular abstract generals and the idea of sketches exist within
the historically developed objective science does not mean that they
somehow always existed; to call them ``platonic'' seems to detract from
the honor of their actual discoverers.

Bill Lawvere
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week175}{%
\section{December 29, 2001}\label{week175}}

I spent this Christmas in Greenwich, England. Over repeated visits to
England I have discovered many fascinating things of which many
Americans are unaware. For example: while in traffic one must drive on
the left side of the road, in escalators one must stand on the right.
You flip switches down to turn on lights. Camels and zebras have escaped
from the Royal Zoo and mated, and their hybrids roam the English
countryside. On the roadside you will occasionally see signs for
``humped zebra crossings''. Also, the Royal Observatory in Greenwich
fires a powerful green laser each night to mark the Prime Meridian ---
zero degrees longitude.

Four of the last five sentences are true. In particular, you really
\emph{can} see a green laser beam shining due north from the Royal
Observatory, across the Thames, past the Citigroup Building and out into
the night. And speaking of longitude, the day before Christmas I visited
this observatory and had a wonderful time learning how John Harrison
solved the longitude problem.

The longitude problem? Ah, how soon we forget! It's pretty easy to tell
your latitude by looking at the sun or the stars. However, it's pretty
hard to tell your longitude, unless you have a clock that keeps good
time. After all, if you know what time it is in a fixed place, like
Greenwich, you can figure out how far east or west you've gone by
comparing the time you see the sun rise to the time it would rise there.
Unfortunately, until the late 1700's, pendulum clocks didn't work well
at sea, due to the rocking waves. This was a real problem! Ships would
lose track of their longitude, go astray, and sometimes even run
aground, killing hundreds of sailors.

Since England was a big maritime power, in 1714 they set up the Board of
Longitude, which offered a prize of 20,000 pounds to anyone who could
solve this problem. Newton and Halley favored a solution which involved
measuring the angle between the moon and nearby stars and then
consulting a bunch of tables. This was a complicated system that could
only work with the help of an accurate star atlas and a detailed
understanding of the motion of the moon. Newton set to work on the
necessary calculations. John Flamsteed was made the royal astronomer of
England, and he set to work on the star atlas. He moved into the Royal
Observatory, and stayed up each night making observations with the help
of his wife.

However, before this ``lunar distance method'' came online, the
watchmaker John Harrison invented the first of a series of ingenious
clocks that worked well despite rocking waves and fluctuations of
temperature. All these can still be seen at the Royal Observatory ---
they're very beautiful! In the process, Harrison developed a whole bunch
of cool technology like ball bearings and the bimetallic strip used in
thermostats.

Alas, the Board refused to pay up even when Harrison built a clock that
was accurate to within .06 seconds a day, which was certainly good
enough. Finally King George III persuaded the board to give him the
prize --- but by then he was an old man. Luckily, I get the feeling
Harrison was really more interested in building clocks than winning the
prize money. He loved his work\ldots{} one of the keys to a happy life.

Here's a book that tells his story in more detail:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Dava Sobel, \emph{Longitude}, Fourth Estate Ltd., London, 1996.
\end{enumerate}

I found it in the gift shop of the Observatory. It's a fun read, but for
the technical reader it's frustratingly vague on the technical details
of how Harrisons' clocks actually work.

I also bought this book there:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  E. G. Richards, \emph{Mapping Time: The Calendar and its History},
  Oxford U. Press, Oxford, 1998.
\end{enumerate}

Since it's almost New Year's Day, let me tell you a bit what I learned
about calendars!

Mathematical physics has deep roots in astronomy, which may have been
the first exact science. Thanks to astrology, the ancient theocratic
states put a lot of resources into precisely tracking and predicting the
motion of the sun, moon and planets. For example, by 700 BC the
Babylonians had measured the length of the year to be 365.24579 days,
with an error of only .00344 days. Two hundred years later, they had
measured the length of the month to be 29.53014 days --- an error of
only 2.6 seconds.

If there were 360 days in a year, 30 days in a month, and 12 months in a
year, the ancients would have been happy, since they loved numbers with
lots of divisors. But alas, there aren't! These whole numbers come
tantalizingly close, but not close enough, so the need for accurate
calendars, balanced by the desire for simplicity, kept pushing the
development of mathematics and astronomy forward.

There are also lots of complications I haven't mentioned. I've been
talking about the ``mean solar day'', the ``mean synodic month'' and the
``tropical year'', but in fact the length of the day and month vary
substantially due to the tilt of the earth's axis, the tilt of the
moon's orbit, and other effects --- so actually there are several
different definitions of day, month and year. This was enough to keep
the astronomer-priests in business for centuries. For more on the
physics of it all, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  John Baez, ``The wobbling of the earth and other curiosities'',
  \texttt{http://math.ucr.edu/home/baez/wobble.html}
\end{enumerate}

Unfortunately, the Romans, whose calendar we inherit, were real
goofballs when it came to calendrics. Their system was run by a body of
``pontifices'' headed by the Pontifex Maximus. In 450 BC these guys
adopted a calendar in which odd-numbered years had 12 months and 355
days, while even-numbered years had 13 months and alternated between 377
and 378 days. The extra month, called Mercedonius, was stuck smack in
the middle of February. Even worse, this system gave an average of 366
and \(1/4\) days per year --- one too many --- so it kept drifting out
of kilter with the seasons. The pontifices were authorized to fix things
on an ad hoc basis as needed, but power corrupts, so they started taking
bribes to suddenly advance or postpone the start of the year.

As a result, by the time Julius Caesar became dictator, the calendar was
three months in advance of the seasons! After consulting with the
Alexandrian astronomer Sosigenes, he decided to institute reforms. To
straighten things out, the year 46 BC was made 445 days long. This was
known as the Last Year of Confusion. It featured an extra long
Mercedonius as well as two extra months after December, called
Undecimber and Duodecimber.

The new so-called ``Julian calendar'' featured 12 months and 365 days,
with an extra day in February every fourth year. The months alternated
nicely between 31 and 30 days, except for February, which only had 30 on
leap years. Unfortunately, Caesar was assassinated in 44 BC before this
system fully took hold. The pontifices ineptly interpreted his orders
and stuck in an extra day every \emph{third} year. This didn't get fixed
until 9 BC, Augustus stopped this practice and decreed that the next 3
leap years be skipped to make up for the extra ones the pontifices had
inserted.

From then on, things went more smoothly, except for a lot of
name-grabbing. When Julius Caesar was assassinated, the Senate took the
month of Quintilis and renamed it ``Iulius'' in his honor, giving us
July. Augustus followed suit, naming the month of Sextilis after himself
--- giving us August. More annoyingly, he stole the last day from
February and stuck it on his own month to make it 31 days long, and did
some extra reshuffling so the months next to his had only 30 --- giving
us our current messy setup.

The Senate offered to name a month after the next emperor, Tiberius, but
he modestly declined. The next one, Caligula, was not so modest: he
renamed June after his father Germanicus. Then Claudius renamed May
after himself, and Nero grabbed April. Later, Domitian took October and
Antonius took September. The vile Commodus tried to rename all twelve
months, but that didn't stick. Then Tacitus snatched September away from
Antonius\ldots{} but luckily, all these later developments have been
forgotten!

This is only a tiny fraction of the fascinating lore in Richards' book.
Ever wonder why there are 7 days in a week? That's pretty easy: they're
named after the 7 planets --- in the old sense of ``planets'', meaning
heavenly bodies visible by eye that don't move with the stars. But
here's a harder puzzle! Why are the 7 planets are listed in this order?

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
Sun & (Sunday --- \emph{Dies Solis})\tabularnewline
Moon & (Monday --- \emph{Dies Lunae})\tabularnewline
Mars & (Tuesday --- \emph{Dies Martis})\tabularnewline
Mercury & (Wednesday --- \emph{Dies Mercurii})\tabularnewline
Jupiter & (Thursday --- \emph{Dies Iovis})\tabularnewline
Venus & (Friday --- \emph{Dies Veneris})\tabularnewline
Saturn & (Saturday --- \emph{Dies Saturnis})\tabularnewline
\bottomrule
\end{longtable}

There's actually a nice explanation. However, I won't give it away here.
Can you guess it?

Since ancient science was closely tied to numerology, I can't resist
mentioning some fun facts relating the calendar and the deck of cards.
As you probably know, playing cards come in 4 suits of 13 cards each,
for a total of 52. 52 is also the number of weeks in a year. The 4
suites correspond to the 4 seasons, so there are 13 weeks in each
season, just as there are 13 cards in each suite.

Even better, if we add up the face values of all the cards in the deck,
counting an ace as 1, a deuce as 2, and so on up to 13, we get
\[(1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12 + 13) \times 4 = 364,\]
which is one less than the number of days in a year! The remaining day
corresponds to the ``joker'', a card which does not belong to any suite.

Many calendars contain ``epagomenal days'' not included in any month.
For example, the Egyptians had 5 epagomenal days, leaving 360 which they
could split up neatly into 12 months. In a system with one epagomenal
day --- the ``joker'' --- the remaining 364 days can be divided not only
as \[(30 + 30 + 31) \times 4,\] which allows for two 30-day calendar
months and one 31-day calendar month per season, but also as
\[13 \times 28\] which allows for 13 anomalistic months of 28 days each
--- where an ``anomalistic month'' is the time it takes for the moon to
come round to its perigee, where it's as close to the earth as possible.

Putting it all together, we see that the number 364 factors as
\[13 \times 4 \times 7,\] which corresponds to 13 months, each
containing 4 weeks, each containing 7 days --- or alternatively to 4
seasons, each containing 13 weeks, each containing 7 days --- or to 4
suites, each containing 13 cards, with an average face value of 7.

Cute, eh? I'm not sure how much of this stuff is coincidence and how
much was planned out by the mysterious mystics who invented playing
cards. Of course we can't take these whole numbers too seriously --- for
example, the anomalistic month is actually 27.55455 days long, not 28.
However, a 364-day year \emph{is} mentioned in the the Book of Enoch, a
pseudepigrapical Hebrew text which was found, among other places, in the
Dead Sea Scrolls. In fact, a year of this length was used in Iceland as
late as 1940. The idea of having one epagomenal day and dividing each
season into months with 30, 30 and 31 days has also been favored by many
advocates of calendar reform.

Of course, numerology should always be left to competent mathematicians
who don't actually believe in it.

Here's another nice book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Alain Connes, Andre Lichnerowicz and Marcel Paul Schutzenberger,
  \emph{A Triangle of Thoughts}, AMS, Providence, 2000.
\end{enumerate}

This consists of polished-up transcripts of dialogues (or should I say
trialogues?) among these mathematicians. I wish more good scientists
would write this sort of thing; it's much less strenuous to learn stuff
by listening to people talk than by reading textbooks! It's true that
textbooks are necessary when you want to master the details, but for the
all-important ``big picture'', conversations can be much better.

This book focuses on mathematical logic and physics, with a strong touch
of philosophy\ldots{} but it wanders all over the map in a pleasant way
--- from Bernoulli numbers to game theory! The conversation is dominated
by Connes, whose name appears on the title in bigger letters than the
other two authors, perhaps because they others are now dead.

There is only one mistake in this book that I would like to complain
about. Following Roger Penrose, Connes takes quasicrystals as evidence
for some mysterious uncomputability in the laws of nature. The idea is
that since there's no algorithm for deciding when a patch of Penrose
tiles can be extended to a tiling of the whole plane, nature must do
something uncomputable to produce quasicrystals of this symmetry. The
flaw in this reasoning seems obvious: when nature gets stuck, it feels
free to insert a \emph{defect} in the quasicrystal. Quasicrystals do not
need to be perfect to produce the characteristic diffraction patterns by
which we recognize them.

But that's a minor nitpick: the book is wonderful! Read it!

In case you don't know: Alain Connes is a Fields medalist, who won the
prize mainly for two things: his work on Von Neumann algebras, and his
work on noncommutative geometry. Now I'll talk a bit about von Neumann
algebras, since you'll need to understand a bit about them to follow the
rest of my description of the paper by Michael Mueger that I have been
slowly explaining throughout \protect\hyperlink{week173}{``Week 173''}
and \protect\hyperlink{week174}{``Week 174''}.

So: what's a von Neumann algebra? Before I get technical and you all
leave, I should just say that von Neumann designed these algebras to be
good ``algebras of observables'' in quantum theory. The simplest example
consists of all \(n\times n\) complex matrices: these become an algebra
if you add and multiply them the usual way. So, the subject of von
Neumann algebras is really just a grand generalization of the theory of
matrix multiplication.

But enough beating around the bush! For starters, a von Neumann algebra
is a \(*\)-algebra of bounded operators on some Hilbert space of
countable dimension --- that is, a bunch of bounded operators closed
under addition, multiplication, scalar multiplication, and taking
adjoints: that's the \(*\) business. However, to be a von Neumann
algebra, our \(*\)-algebra needs one extra property! This extra property
is cleverly chosen so that we can apply functions to observables and get
new observables, which is something we do all the time in physics.

More precisely, given any self-adjoint operator \(A\) in our von Neumann
algebra and any measurable function \(f\colon\mathbb{R}\to\mathbb{R}\),
we want there to be a self-adjoint operator \(f(A)\) that again lies in
our von Neumann algebra. To make sure this works, we need our von
Neumann algebra to be ``closed'' in a certain sense. The nice thing is
that we can state this closure property either algebraically or
topologically.

In the algebraic approach, we define the ``commutant'' of a bunch of
operators to be the set of operators that commute with all of them. We
then say a von Neumann algebra is a \(*\)-algebra of operators that's
the commutant of its commutant.

In the topological approach, we say a bunch of operators \(T_i\)
converges ``weakly'' to an operator \(T\) if their expectation values
converge to that of \(T\) in every state, that is,
\[\langle\psi, T_i\psi \rangle \to \langle\psi, T\psi\rangle\] for all
unit vectors \(\psi\) in the Hilbert space. We then say a von Neumann
algebra is an \(*\)-algebra of operators that is closed in the weak
topology.

It's a nontrivial theorem that these two definitions agree!

While classifying all \(*\)-algebras of operators is an utterly hopeless
task, classifying von Neumann algebras is almost within reach --- close
enough to be tantalizing, anyway. Every von Neumann algebra can be built
from so-called ``simple'' ones as a direct sum, or more generally a
``direct integral'', which is a kind of continuous version of a direct
sum. As usual in algebra, the ``simple'' von Neumann algebras are
defined to be those without any nontrivial ideals. This turns out to be
equivalent to saying that only scalar multiples of the identity commute
with everything in the von Neumann algebra.

People call simple von Neumann algebras ``factors'' for short. Anyway,
the point is that we just need to classify the factors: the process of
sticking these together to get the other von Neumann algebras is not
tricky.

The first step in classifying factors was done by von Neumann and
Murray, who divided them into types \(\mathrm{I}\), \(\mathrm{II}\), and
\(\mathrm{III}\). This classification involves the concept of a
``trace'', which is a generalization of the usual trace of a matrix.

Here's the definition of a trace on a von Neumann algebra. First, we say
an element of a von Neumann algebra is ``nonnegative'' if it's of the
form \(xx^*\) for some element \(x\). The nonnegative elements form a
``cone'': they are closed under addition and under multiplication by
nonnegative scalars. Let \(P\) be the cone of nonnegative elements. Then
a ``trace'' is a function \[\operatorname{tr}\colon P \to [0, +\infty]\]
which is linear in the obvious sense and satisfies
\[\operatorname{tr}(xy) = \operatorname{tr}(yx)\] whenever both \(xy\)
and \(yx\) are nonnegative.

Note: we allow the trace to be infinite, since the interesting von
Neumann algebras are infinite-dimensional. This is why we define the
trace only on nonnegative elements; otherwise we get
``\(\infty minus \infty\)'' problems. The same thing shows up in the
measure theory, where we start by integrating nonnegative functions,
possibly getting the answer \(+\infty\), and worry later about other
functions.

Indeed, a trace very much like an integral, so we're really studying a
noncommutative version of the theory of integration. On the other hand,
in the matrix case, the trace of a projection operator is just the
dimension of the space it's the projection onto. We can define a
``projection'' in any von Neumann algebra to be an operator with
\(p^* = p\) and \(p^2 = p\). If we study the trace of such a thing,
we're studying a \emph{generalization of the concept of dimension}. It
turns out this can be infinite, or even nonintegral!

We say a factor is type \(\mathrm{I}\) if it admits a nonzero trace for
which the trace of a projection lies in the set
\(\{0,1,2,\ldots,+\infty\}\). We say it's type \(I_n\) if we can
normalize the trace so we get the values \(\{0,1,\ldots,n\}\).
Otherwise, we say it's type \(I_\infty\), and we can normalize the trace
to get all the values \(\{0,1,2,\ldots,+\infty\}\).

It turn out that every type \(I_n\) factor is isomorphic to the algebra
of \(n\times n\) matrices. Also, every type \(I_\infty\) factor is
isomorphic to the algebra of all bounded operators on a Hilbert space of
countably infinite dimension.

Type \(\mathrm{I}\) factors are the algebras of observables that we
learn to love in quantum mechanics. So, the real achievement of von
Neumann was to begin exploring the other factors, which turned out to be
important in quantum field theory.

We say a factor is type \(\mathrm{II}_1\) if it admits a trace whose
values on projections are all the numbers in the unit interval
\([0,1]\). We say it is type \(\mathrm{II}_\infty\) if it admits a trace
whose value on projections is everything in \([0,+\infty]\).

Playing with type \(\mathrm{II}\) factors amounts to letting dimension
be a continuous rather than discrete parameter!

Weird as this seems, it's easy to construct a type \(\mathrm{II}_1\)
factor. Start with the algebra of \(1\times1\) matrices, and stuff it
into the algebra of \(2\times2\) matrices as follows:
\[x\mapsto\left(\begin{array}{cc}x&0\\0&x\end{array}\right)\] This
doubles the trace, so define a new trace on the algebra of \(2\times2\)
matrices which is half the usual one. Now keep doing this, doubling the
dimension each time, using the above formula to define a map from the
\(2^n\times2^n\) matrices into the \(2^{n+1}\times2^{n+1}\) matrices,
and normalizing the trace on each of these matrix algebras so that all
the maps are trace-preserving. Then take the \emph{union} of all these
algebras\ldots{} and finally, with a little work, complete this and get
a von Neumann algebra!

One can show this von Neumann algebra is a factor. It's pretty obvious
that the trace of a projection can be any fraction in the interval
\([0,1]\) whose denominator is a power of two. But actually, \emph{any}
number from \(0\) to \(1\) is the trace of some projection in this
algebra --- so we've got our paws on a type \(\mathrm{II}_1\) factor.

This isn't the only \(\mathrm{II}_1\) factor, but it's the only one that
contains a sequence of finite-dimensional von Neumann algebras whose
union is dense in the weak topology. A von Neumann algebra like that is
called ``hyperfinite'', so this guy is called ``the hyperfinite
\(\mathrm{II}_1\) factor''.

It may sound like something out of bad science fiction, but the
hyperfinite \(\mathrm{II}_1\) factor shows up all over the place in
physics!

First of all, the algebra of \(2^n\times2^n\) matrices is a Clifford
algebra, so the hyperfinite \(\mathrm{II}_1\) factor is a kind of
infinite-dimensional Clifford algebra. But the Clifford algebra of
\(2^n\times2^n\) matrices is secretly just another name for the algebra
generated by creation and annihilation operators on the fermionic Fock
space over \(\mathbb{C}^{2n}\). Pondering this a bit, you can show that
the hyperfinite \(\mathrm{II}_1\) factor is the smallest von Neumann
algebra containing the creation and annihilation operators on a
fermionic Fock space of countably infinite dimension.

In less technical lingo --- I'm afraid I'm starting to assume you know
quantum field theory! --- the hyperfinite \(\mathrm{II}_1\) factor is
the right algebra of observables for a free quantum field theory with
only fermions. For bosons, you want the type \(I_\infty\) factor.

There is more than one type \(\mathrm{II}_\infty\) factor, but again
there is only one that is hyperfinite. You can get this by tensoring the
type \(I_\infty\) factor and the hyperfinite \(\mathrm{II}_1\) factor.
Physically, this means that the hyperfinite \(\mathrm{II}_\infty\)
factor is the right algebra of observables for a free quantum field
theory with both bosons and fermions.

The most mysterious factors are those of type \(\mathrm{III}\). These
can be simply defined as ``none of the above''! Equivalently, they are
factors for which any nonzero trace takes values in \(\{0,\infty\}\). In
a type \(\mathrm{III}\) factor, all projections other than \(0\) have
infinite trace. In other words, the trace is a useless concept for these
guys.

As far as I'm concerned, the easiest way to construct a type
\(\mathrm{III}\) factor uses physics. Now, I said that free quantum
field theories had different kinds of type \(\mathrm{I}\) or type
\(\mathrm{II}\) factors as their algebras of observables. This is true
if you consider the algebra of \emph{all} observables. However, if you
consider a free quantum field theory on (say) Minkowski spacetime, and
look only at the observables that you can cook from the field operators
on some bounded open set, you get a subalgebra of observables which
turns out to be a type \(\mathrm{III}\) factor!

In fact, this isn't just true for free field theories. According to a
theorem of axiomatic quantum field theory, pretty much all the usual
field theories on Minkowski spacetime have type \(\mathrm{III}\) factors
as their algebras of ``local observables'' --- observables that can be
measured in a bounded open set.

Okay, so much for the crash course on von Neumann algebras! Next time
I'll hook this up to Mueger's work on \(2\)-categories.

In the meantime, here are some references on von Neumann algebras in
case you want to dig deeper. For the math, try these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Masamichi Takesaki, \emph{Theory of Operator Algebras I}, Springer,
  Berlin, 1979.
\item
  Richard V. Kadison and John Ringrose, \emph{Fundamentals of the Theory
  of Operator Algebras}, 4 volumes, Academic Press, New York,
  1983--1992.
\item
  Shoichiro Sakai, \emph{\(C^*\)-algebras and \(W^*\)-algebras},
  Springer, Berlin, 1971.
\end{enumerate}

A \(W^*\)-algebra is basically just a von Neumann algebra, but defined
``intrinsically'', in a way that doesn't refer to a particular
representation as operators on a Hilbert space.

For applications to physics, try these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\item
  Gerard G. Emch, \emph{Algebraic Methods in Statistical Mechanics and
  Quantum Field Theory}, Wiley-Interscience, New York, 1972.
\item
  Rudolf Haag, \emph{Local Quantum Physics: Fields, Particles,
  Algebras}, Springer, Berlin, 1992.
\item
  Ola Bratelli and Derek W. Robinson, \emph{Operator Algebras and
  Quantum Statistical Mechanics}, 2 volumes, Springer, Berlin,
  1987--1997.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Postscript:

For more about the measurement of time, Theo Buehler recommends this
lecture:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{10}
\tightlist
\item
  John B. Conway,
  \texttt{http://www.math.utk.edu/\textasciitilde{}conway/Time.html}
\end{enumerate}

For technical information on John Harrison's clocks, Nigel Seeley
recommends this book, which also has a bunch of nice pictures:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{11}
\tightlist
\item
  William J. H. Andrewes, editor, \emph{The Quest for Longitude: The
  Proceedings of the Longitude Symposium, Harvard University, Cambridge,
  Massachusetts, November 4--6, 1993}. Harvard University Collection of
  Historical Scientific Instruments, Cambridge Massachusetts, 1996.
\end{enumerate}

Nigel Seeley and Julian Gilbey also recommend the following book on
calendrics:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{12}
\tightlist
\item
  Edward M. Reingold, and Nachum Dershowitz, \emph{Calendrical
  Calculations: The Millennium Edition}, Oxford U. Press, Oxford, 1997.
  268 pages.
\end{enumerate}

Finally, here's a correction and the answer to the puzzle I gave above:

\begin{quote}
Derek Wise wrote:
\end{quote}

\begin{quote}
\begin{quote}
JB wrote:
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\ldots.{[}Augustus{]} stole the last day from February and stuck it on
his own month to make it 31 days long, and did some extra reshuffling so
the months next to his had only 30 --- giving us our current messy
setup.
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
In the modern calendar, July has 31 days and is adjacent to August.
\end{quote}
\end{quote}

Yeah --- I only remembered that a few days ago, after writing that issue
of This Week's Finds. As a kid I refused to remember how many days were
in each month, since it seemed hopelessly arbitrary and ugly --- an
all-too-human invention, rather than something intrinsic to the
universe. Also, I was never fond of the mnemonic

\begin{quote}
Thirty days hath September

All the rest I don't remember \ldots.
\end{quote}

mainly because so many months end in ``-ember'' that this mnemonic would
need a mnemonic of its own for me to recall it. It was only much later
that I learned the ``knuckles and spaces'' method for keeping track of
this information. For some reason I tried this a few days ago, and then
I said ``Hey! There's a month with 31 days next to August! What gives?''
I meant to look up the facts in Richards' book \emph{Mapping Time}, but
I forgot. Thanks for reminding me!

Anyway, here's the deal: the calendar reform of Julius Caesar gave the
months these numbers of days:

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
Januarius & 31\tabularnewline
Februarius & 29/30\tabularnewline
Martius & 31\tabularnewline
Aprilis & 30\tabularnewline
Maius & 31\tabularnewline
Iunius & 30\tabularnewline
Iulius & 31\tabularnewline
Sextilis & 30\tabularnewline
September & 31\tabularnewline
October & 30\tabularnewline
November & 31\tabularnewline
December & 30\tabularnewline
\bottomrule
\end{longtable}

A nice systematic alternation, though you might why \emph{February} gets
picked on; this is because the earlier Roman calendar had a short
February, and a month called Mercedonius stuck in the middle of February
now and then.

Augustus screwed it up as follows:

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
Januarius & 31\tabularnewline
Februarius & 29/30\tabularnewline
Martius & 31\tabularnewline
Aprilis & 30\tabularnewline
Maius & 31\tabularnewline
Iunius & 30\tabularnewline
Iulius & 31\tabularnewline
Augustus & 31\tabularnewline
September & 30\tabularnewline
October & 31\tabularnewline
November & 30\tabularnewline
December & 31\tabularnewline
\bottomrule
\end{longtable}

In short: he took the month of Sextilis, renamed it after himself, gave
it an extra day, and switched the alternating pattern of 30 and 31 after
that month.

By the way, Richard Bullock gave the ``right'' answer to my puzzle about
why the 7 planets are listed in the order they are as names of days of
the week. By this I mean he gives the same answer that Richards does in
\emph{Mapping Time}. Astrologers like to list the planets in order of
decreasing orbital period, counting the sun as having period 365 days,
and the moon as period 29 days:

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
Saturn & (29 years)\tabularnewline
Jupiter & (12 years)\tabularnewline
Mars & (687 days)\tabularnewline
Sun & (365 days)\tabularnewline
Venus & (224 days)\tabularnewline
Mercury & (88 days)\tabularnewline
Moon & (29.5 days)\tabularnewline
\bottomrule
\end{longtable}

For the purposes of astrology they wanted to assign a planet to each
hour of each day of the week. They did this in a reasonable way: they
assigned Saturn to the first hour of the first day, Jupiter to the
second hour of the first day, and so on, cycling through the list of
planets over and over, until each of the \(7 \times 24 = 168\) hours was
assigned a planet. Each day was then named after the first hour in that
day. Since \(24 \mod 7\) equals \(3\), this amounts to taking the above
list and reading every third planet in it (\(\mod 7\)), getting:

\begin{itemize}
\tightlist
\item
  Saturn (Saturday)
\item
  Sun (Sunday)
\item
  Moon (Monday)
\item
  Mars (Tuesday)
\item
  Mercury (Wednesday)
\item
  Jupiter (Thursday)
\item
  Venus (Friday)
\end{itemize}

I don't think anyone is \emph{sure} that this is how the days got the
names they did; the earliest reference for this scheme is the Roman
historian Dion Cassius (AD 150--235), who came long after the days were
named. However, Dion says the scheme goes back to Egypt. In the
\emph{Moralia} of Plutarch (AD 46--120) there was an essay entitled
``Why are the days named after the planets reckoned in a different order
from the actual order?'' Unfortunately this essay has been lost and only
the title is known.

To bring the subject back to physics: we should see all these attempts
to bring order to time as part of a gradual process of developing ever
more precise and logical coordinate systems for the spacetime manifold
we call our universe. We may laugh at how the Roman pontifices took
bribes to start the year a day early; our descendants may laugh at how
we add or subtract leap seconds from Coordinated Universal Time (UTC) to
keep it in step with the irregular rotation of that lumpy ball of rock
we call Earth (or more precisely, the time system called UT2, based on
the Earth's rotation). How precise will we get? Will we someday be
worrying about leap attoseconds? Leap Planck times?

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week176}{%
\section{February 8, 2002}\label{week176}}

A team of astronomers has found evidence that a dwarf galaxy near the
Milky Way is surrounded by an enormous halo of dark matter, which may be
200 times heavier than all the stars in the galaxy itself:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Jan T. Kleyna, Mark I. Wilkinson, N. Wyn Evans and Gerard Gilmore,
  ``First clear signature of an extended dark matter halo in the Draco
  dwarf spheroidal'', \emph{Astrophysical Journal Letters} \textbf{563}
  (2001), L115--118. Also available at
  \href{https://arxiv.org/abs/astro-ph/0111329}{\texttt{astro-ph/0111329}}.
\end{enumerate}

This just emphasizes a well-known fact: ``dark matter'' is one of the
biggest mysteries in physics today. Unless we're mixed up, which is
always possible, most of the energy density of the universe is made of
some invisible stuff about which we know almost nothing! To add insult
to injury, after dark matter the second biggest constituent of the
mass/energy appears to be ``dark energy''. All other forms of matter ---
mainly hydrogen --- come a distant third.

Perhaps I should say a word about the difference between dark matter and
dark energy, since this is awfully confusing to the uninitiated.

The main reason people believe in ``dark matter'' is that galaxies and
clusters of galaxies seem to have a lot more mass than can be accounted
for by all the stuff we understand: stars, gas, and so forth. It's
fairly easy to measure this mass using gravity, by seeing how fast
things orbit around each other --- stars around galaxies, or galaxies
around each other. The hard part is guessing how much stuff is in the
galaxies. Could there be lots of faint stars we don't see? Black holes,
maybe? People have thought about all sorts of possibilities, but they
just don't seem to add up. So, people postulate mysterious extra stuff:
``dark matter''.

``Dark energy'', on the other hand, is basically just a fashionable name
for the cosmological constant: that is, the built-in energy density of
the vacuum. Einstein noticed that you can tinker with general relativity
by making this nonzero, but only by making the pressure nonzero too, and
of opposite sign, but with exactly the same magnitude in units where
\(c = G = 1\). This is very different from normal matter --- or even
dark matter, as far as we can tell --- where both the energy density and
pressure are positive.

This is important because the expansion of the universe is governed both
by energy density and pressure. More precisely, a calculation using
general relativity shows that the expansion of the universe decelerates
at a rate proportional to the energy density plus 3 times the pressure.
(In case you're wondering, the number 3 comes from the fact that space
is \(3\)-dimensional.)

If you think about what I've told you, this means that normal matter
makes the expansion decelerate --- but a positive cosmological constant
makes the expansion \emph{accelerate}, since the effects of negative
pressure dominate those of positive energy density, thanks to that
factor of 3.

Starting around 1995, convincing evidence started to build up that the
expansion of the universe is accelerating. The simplest way to explain
this is to posit a positive cosmological constant --- or in other words,
dark energy!

In case you're dreaming up alternative theories as I speak, let me
assure you that hundreds of papers have been written about this subject,
probing all sorts of possibilities. Perhaps the cosmological constant
isn't really constant: maybe the negative pressure is due to a new form
of matter called ``quintessence''. Perhaps general relativity is wrong:
that's what people working on ``modified Newtonian dynamics'' believe. I
don't have the energy or expertise to talk about all these ideas, so I'm
just telling you the current conventional wisdom.

But if dark matter really exists, what could it be? There are lots of
options. It could be an excess of familiar stuff that's somehow slipped
through our bookkeeping, or MACHOs (massive compact halo objects), or
WIMPs (weakly interacting massive particles), or\ldots{} something else!

If you're trying to figure out the mystery of dark matter, you should
first study all the hoops your theory must succesfully jump through.
Besides getting galaxies and clusters to rotate faster than they
otherwise would, dark matter should collapse under its own gravity early
in the history of the universe. Why? Otherwise, people seem unable to
explain why galaxies formed as soon as they did! In the early universe,
the ordinary matter was very hot gas. The hotter a ball of gas is, the
bigger it must be before it collapses under its own gravity, since this
happens when the escape velocity exceeds the average speed of the atoms.
Without something to help it out, it seems that ordinary matter in the
early universe could not collapse under its own gravity to form
galaxy-sized lumps, but only much bigger lumps. But it seems galaxies
formed quite early! This dilemma would go away if there were ``cold dark
matter'' which clumped up under its own gravitation early on, seeding
galaxy formation.

The new observation of this dwarf galaxy is further evidence that cold
dark matter is real and plays an important role in galaxy formation.
There are in fact 9 ``dwarf spheroidal galaxies'' near the Milky Way;
the one studied is about 250,000 light years away from us in the
constellation of Draco. Many astronomers believe that big galaxies like
ours were formed from the accretion of such dwarfs.

Physicists are actually doing experiments to look for dark matter.
Galaxy formation and everything else would work quite nicely if dark
matter consisted of some sort of weakly interacting massive particle
with a mass of about 100 GeV. The dark matter density near us seems to
be roughly \(5\times 10^{-24}\) grams per cubic centimeter, which would
mean about 3 WIMPs per thousand cubic centimeters. That's not much, but
since these WIMPs would be moving in random orbits in the gravitational
potential well of the galaxy, they should be zipping past us at an
average of 300 kilometers per second. This gives a flux of about
\(10^5\) WIMPs per square centimeter per second!

The problem is that, like neutrinos, most of these guys would pass
through matter undetected. If you pick some specific theory concerning
these WIMPs --- for example that they're some sort of ``neutralino'' in
the minimal supersymmetric extension of the Standard Model --- and make
some plausible assumptions about various numbers, you'd guess that about
10 WIMPs per year would interact with a 1-kilogram lump of matter. Of
course the actual number could easily be many orders of magnitude
different, but the point is: this is within the realm of what we might
actually detect!

One way to go about it is to use sodium iodide crystals as scintillation
detectors. When a WIMP smacks into one of these, it should emit a flash
of light. The problem is to eliminate other causes such as cosmic rays
and natural radioactivity from the surroundings. To get away from cosmic
rays, it's good to go down into a mine. To get away from radioactivity
it's good to use shielding made from high-purity copper or aged lead.
The UK Dark Matter Collaboration has done just this, placing several
1--10 kilogram sodium iodide crystals 1100 meters below ground in the
Boulby salt mine in Yorkshire. They've been taking data since 1997, and
they've seen a number of anomalous events:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  UK Dark Matter Collaboration (UKDMC) homepage,
  \texttt{http://hepwww.rl.ac.uk//UKDMC/}
\end{enumerate}

The DAMA group --- that's short for ``dark matter'' --- has found even
more fascinating results. This collaboration involves Italian and
Chinese physicists who are using nine 9.7-kilogram sodium iodide
crystals in a laboratory 1400 meters below ground, off of a tunnel on a
highway near Rome. The idea behind this experiment is not just to
\emph{detect} WIMPs --- but to look for seasonal variations in the
\emph{rate} of their detection!

This may sound crazy, but it's based on sound logic. The sun orbits the
galaxy at 232 kilometers/second, but also the earth orbits the sun at 30
kilometers/second in a plane that lies at a 60-degree angle to the
galactic plane. As a result the earth is going through the galaxy faster
when these motions add up, in June, than when they're pointing in
opposite directions, in December. So, if WIMPs are more or less randomly
orbiting the galaxy in all directions, we should thus see a higher flux
of WIMPs through the earth in summer than in winter!

The DAMA group has been collecting data for four years, and claims to
have actually seen such a ``annual modulation signature''. You can see a
graph of their data here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  DAMA collaboration, ``Searching for the WIMP annual signature by the
  \textasciitilde100 kg NaI(Tl) set-up'',
  \texttt{http://www.lngs.infn.it/lngs/htexts/dama/dama39.html}
\end{enumerate}

For more information, try their homepage:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Dark Matter (DAMA) experiment home page,
  \texttt{http://www.lngs.infn.it/lngs/htexts/dama/welcome.html}
\end{enumerate}

Unfortunately, their result is controversial, because the Cryogenic Dark
Matter Search (CDMS) was unable to replicate it. This experiment works a
different way: it uses germanium and silicon crystals cooled to a
hundredth of a degree above absolute zero. The idea is to detect the
phonons --- that is, quantized sound waves --- produced when a WIMP
smacks into an atomic nucleus.

The original CDMS experiment was done at Stanford, only 10 meters below
the ground; this meant it had to distinguish WIMPs from a background of
cosmic rays. Now they are redoing the experiment in an abandoned mine in
Minnesota, which should give more accurate results.

For more on the CDMS experiment, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Cryogenic Dark Matter Search (CDMS) home page,
  \texttt{http://cdms.berkeley.edu/}
\end{enumerate}

In short, the situation is still murky. Luckily, a bunch more dark
matter detectors are coming online as we speak, which should help
straighten things out. You can find websites for these dark matter
experiment and also conference here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Frederic Mayet, ``Dark Matter Portal'',
  \texttt{http://isnwww.in2p3.fr/ams/fred/dm.html}
\end{enumerate}

Finally, here are some things to read if you want to learn more. First,
some general introductions to cosmology, in roughly increasing order of
difficulty:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\item
  Edward R. Harrison, \emph{Cosmology, the Science of the Universe},
  Cambridge University Press, Cambridge, 1981.
\item
  M. Berry, \emph{Cosmology and Gravitation}, Adam Hilger, Bristol,
  1986.
\item
  John A. Peacock, \emph{Cosmological Physics}, Cambridge University
  Press, Cambridge, 1999.
\end{enumerate}

Second, a nice easy review article on dark matter:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Shaaban Khalil and Carlos Munoz, ``The enigma of the dark matter'', to
  appear in \emph{Contemp. Phys.}, also available at
  \href{https://arxiv.org/abs/hep-ph/0110122}{\texttt{hep-ph/0110122}}.
\end{enumerate}

Third, two articles surveying candidates for what dark matter might be:
neutralinos, axions, axinos, gravitinos, MACHOs --- you name it!

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{10}
\item
  Leszek Roszkowski, ``Non-baryonic dark matter'', available as
  \href{https://arxiv.org/abs/hep-ph/0102327}{\texttt{hep-ph/0102327}}.
\item
  B. J. Carr, ``Recent developments in the search for baryonic dark
  matter'', available as
  \href{https://arxiv.org/abs/astro-ph/0102389}{\texttt{astro-ph/0102389}}.
\end{enumerate}

Okay, now on to something more mathematical\ldots.

I've been having fun lately learning about ``teleparallel'' theories
gravity from Simon Clark, Chris Hillman and Stephen Speicher on
\texttt{sci.phyics.research}. This is a good introduction:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{12}
\tightlist
\item
  V. C. de Andrade, L. C. T. Guillen and J. G. Pereira, ``Teleparallel
  gravity: an overview'', available at
  \href{https://arxiv.org/abs/gr-qc/0011087}{\texttt{gr-qc/0011087}}.
\end{enumerate}

In ordinary general relativity, you describe the gravitational field
using a ``metric'': a field that lets you measure times, distances and
angles. In teleparallel gravity, you instead use a field that allows you
to decide whether two vectors at two points of spacetime are ``the
same''. This notion of unambiguously comparing vectors at different
points of spacetime is called ``distant parallelism'', hence the term
``teleparallel''.

At first the idea of distant parallelism seems antithetical to general
relativity. After all, in the usual formalism of general relativity, you
can only compare vectors at different points of a curved spaceteim
\emph{after} you pick a path from one to the other! The wonderful thing
is that you can formulate theories of teleparallel gravity that are
equivalent to general relativity for all practical purposes. The
philosophy is completely different: for example, in general relativity
you shouldn't think of gravity as a ``force'' that ``accelerates''
particles, but in teleparallel gravity you can. However, the physical
predictions are the same for a huge class of situations.

Here's a sketch of how it works. I'm afraid I'll have to turn on the
differential geometry now.

It's easiest to start with the so-called Palatini formulation of general
relativity. Here we take spacetime to be an orientable smooth
\(4\)-manifold \(M\) and pick a vector bundle \(T\) that is isomorphic
to the tangent bundle \(TM\). We equip \(T\) with a Lorentzian metric
and orientation. A good name for \(T\) would be the ``fake tangent
bundle'', but physicists usually call its fiber the ``internal space''.
The trick is then to describe a Lorentzian metric on \(M\) by means of a
vector bundle map \[e\colon TM \to T\] which we call a ``coframe
field''. We can use this to pull the metric on \(T\) back to the tangent
bundle. If \(e\) is an isomorphism, this gives a Lorentzian metric on
\(M\). If it's not, we get something like a metric, but with degenerate
directions. You can think of the Palatini formulation as extending
general relativity to allow such ``degenerate metrics'', and this
becomes really important in quantum gravity, but for now let's only
consider the case where \(e\) is an isomorphism.

The coframe field is one of the two basic fields in the Palatini
formulation. The other is a metric-compatible connection on \(T\). This
connection is usually denoted \(A\) and called a ``Lorentz connection''.
Its curvature is denoted \(F\).

The Lagrangian for the Palatini formulation of general relativity looks
like this: \[\operatorname{tr}(e\wedge e\wedge *F)\] This takes a bit of
explaining! First of all, the curvature \(F\) is an
\(\operatorname{End}(T)\)-valued \(2\)-form, but using the metric on
\(T\) we get an isomorphism between \(T\) and its dual, so we can also
think of the curvature as a \(2\)-form taking values in \(T \otimes T\).
However, if we do this, the fact that \(A\) is metric-compatible means
that \(F\) is skew-symmetric: it takes in the second exterior power of
\(T\), \(\bigwedge^2(T)\).

Since \(T\) has a metric and orientation, we can define a Hodge star
operator on the exterior algebra \(\bigwedge(T)\) just as we normally do
for differential forms on a manifold with metric and orientation. We
call this the ``internal'' Hodge star operator. Using this we can define
\(*F\), which is again a \(2\)-form taking values in \(\bigwedge^2(T)\).

Whew! It takes some work making sense of that terse formula above! We're
not done yet, either. Of course, all these verbal descriptions can be
avoided by writing down formulas packed with indices. That's what
working physicists do. And when they've got two different vector bundles
around, like \(T\) and the tangent bundle \(TM\) they use two different
fonts for their indices: for example, Latin letters for the ``internal
indices'' associated to \(T\), and Greek letters for the ``spacetime
indices'' associated to \(TM\). Once you get used to this, it's really
efficient. It's only mathematicians who would rather read a paragraph of
complicated verbiage than a fancy equation. The equation helps you
compute, but the verbiage helps you \emph{understand} --- at least if
you follow it! If you don't know enough geometry, the verbiage probably
seems more confusing than helpful.

Okay. Next, note that the coframe field e can be thought of as a
\(T\)-valued \(1\)-form. This allows us to define the wedge product
\(e\wedge e\) as a \(\bigwedge^2(T)\)-valued \(2\)-form. Note that this
is the same sort of gadget as the curvature \(F\) and its internal Hodge
dual \(*F\). This means we can take the wedge product of the
differential form parts of \(e\wedge e\) and \(*F\) while using the
metric on \(T\) to pair together their \(\bigwedge^2(T)\) parts and get
a number. The result is a plain old \(4\)-form, which we call
\(\operatorname{tr}(e\wedge e\wedge *F)\). This is our Lagrangian!

If you work out the equations of motion coming from this Lagrangian,
they say \(A\) that pulls back via \(e\) to a \emph{torsion-free}
metric-compatible connection on the tangent bundle: the Levi-Civita
connection! It follows that \(F\) pulls back to the curvature of the
Levi-Civita connection: the Riemann tensor! Finally, it turns out that
\(\operatorname{tr}(e\wedge e\wedge *F)\) is just the Ricci scalar
curvature times the volume form on \(M\)\ldots{} so we were doing
general relativity all along!

This may seem convoluted, but one advantage of this approach is that it
describes gravity as a kind of gauge theory. From the viewpoint of field
theory, the metric is a rather curious beast: it's a section of a
bundle, but it's required to satisfy \emph{inequalities} saying that it
is nondegenerate and has a certain signature. Here we have tamed this
beast --- or at least locked it up safely inside the formalism of
differential forms and connections. As a spinoff, we don't get those
nasty factors of ``the square root of the determinant of the metric''
which plague the old-fashioned approach to general relativity. The
reason is that the coframe field acts like a ``square root'' of the
metric.

Physicists have spent a lot of time trying to recast gravity as a gauge
theory If you read old journals, you'll see endless arguments about what
\emph{gauge group} to use. It turns out there are a lot of right
answers. The gauge group for the Palatini formulation of general
relativity is the Lorentz group, but we can also cook up formulations
where the gauge group is the Poincare group or the translation group
\(\mathbb{R}^4\). I'd known about the Poincare group version --- I'll
explain that in a minute --- but I hadn't known you could get away with
using just the translation group! That's where teleparallel gravity
comes in. It all fits together in a beautiful big picture\ldots.

The Poincare group is the semidirect product of the Lorentz group
\(\mathrm{SO}(3,1)\) and the translation group \(\mathbb{R}^4\). This
means that a Poincare group connection can be written as a Lorentz group
connection plus a part related to the translation group. We know the
Palatini formalism involves a Lorentz connection. What about the other
part? This is just the coframe field! To see this, note that since each
fiber of \(T\) looks just like Minkowski spacetime, we can use \(T\) to
create a principal bundle over \(M\) whose gauge group is the Poincare
group. A connection on this principal bundle works out to be exactly the
same as a Lorentz connection \(A\) together with a \(T\)-valued
\(1\)-form \(e\).

So, without lifting a finger, we can reinterpret the Palatini formalism
as a theory in which the only field is a Poincare group connection. Like
the Poincare group itself, the curvature of this connection can be
chopped into two pieces. The Lorentz group part is our old friend, the
\(\bigwedge^2(T)\)-valued \(2\)-form \[F = dA + A\wedge A.\] The
translation group part is a \(T\)-valued \(2\)-form:
\[t = de + A\wedge e.\] Using \(e\colon TM \to T\) we can pull all this
stuff back to the tangent bundle, where its meaning becomes evident. The
metric on \(T\) pulls back to a metric on the tangent bundle, \(A\)
pulls back to a metric-compatible connection on the tangent bundle,
\(F\) pulls back to the curvature of this connection, and \(t\) pulls
back to the \emph{torsion} of this connection! As already hinted, one of
the equations of motion says that \(t\) vanishes, so \(A\) really pulls
back to a \emph{torsion-free} metric-compatible connection: the
Levi-Civita connection.

Finally, let's see how to get rid of the Lorentz connection \(A\) and
formulate gravity using just the coframe field \(e\), which we'll
interpret as a translation group connection. It seems the teleparallel
gravity crowd only knows how to pull this stunt when the tangent bundle
of \(M\) is trivializable. But this is not as bad as it sounds: every
orientable \(3\)-manifold \(S\) has a trivializable tangent bundle, so
the same is true of every orientable \(4\)-manifold of the form
\(\mathbb{R}\times S\).

So: suppose \(M\) is a \(4\)-manifold with trivializable tangent bundle.
This means we can take \(T\) to be the trivial bundle
\(M\times\mathbb{R}^4\). The usual Minkowski metric on \(\mathbb{R}^4\)
puts a Lorentzian metric on \(T\), and the trivialization gives this
bundle a flat metric-compatible connection \(A\).

We've seen a connection like this \(A\) before, but this time it won't
be one of the dynamical fields in our theory: it'll be a ``fixed
background structure'', cast in iron. It's so boring it looks just like
``\(0\)'' when we do calculations using our trivialization of \(T\), but
I prefer to give a name to it nonetheless.

The only dynamical field in teleparallel gravity is the coframe field
\(e\). We can think of this as a \(T\)-valued \(1\)-form, or if you
prefer, a ``translation group connection'': a connection on the bundle
\(T\) regarded as a principal bundle with gauge group \(\mathbb{R}^4\).
The curvature of this connection is a \(T\)-valued \(2\)-form which
we'll again call \(t\). As before we have \[t = de + A\wedge e\] but
using our trivialization of \(T\) this formula boils down to \[t = de.\]
As before, we can use \(e\) to pull stuff from \(T\) back to the tangent
bundle \(TM\). The metric on \(T\) pulls back to a metric on \(TM\), the
connection \(A\) pulls back to a metric-compatible connection \(W\) on
\(TM\), and \(t\) pulls back to a \(TM\)-valued \(2\)-form which is just
the torsion of \(W\). In this setup there's no reason for \(t\) to
vanish, so the connection \(W\) will have torsion. On the other hand,
\(A\) has no curvature, so neither will \(W\).

Folks call \(W\) the ``Weitzenboeck connection''. Of course when \(e\)
is an isomorphism there's another connection on \(TM\), too: the
Levi-Civita connection, \(L\). Both these are metric-compatible, but
they're very different. The Weitzenbock connection has torsion but no
curvature; the Levi-Civita connection has curvature but no torsion!

Andrade and company give a nice explanation for what's going on here.

\begin{quote}
According to general relativity, curvature is used to \emph{geometrize}
spacetime, and in this way successfully describe the gravitational
interaction. Teleparallelism, on the other hand, attributes gravitation
to torsion, but in this case torsion accounts for gravitation not by
geometrizing the interaction, but by acting as a \emph{force}. This
means that, in the teleparallel equivalent of general relativity, there
are no geodesics, but force equations quite analogous to the Lorentz
force equation of electrodynamics. Thus, we can say that the
gravitational interaction can be described \emph{alternatively} in terms
of curvature, as is usually done in general relativity, or in terms of
torsion, in which case we have the so-called teleparallel gravity.
Whether gravity requires a curved or torsioned spacetime, therefore,
turns out to be a matter of convention.
\end{quote}

The difference of the Weitzenboeck and Levi-Civita connections,
\[K = W - L,\] goes by the charming name of the ``contorsion'', since it
says how much the coframe field twists around as measured by the
Levi-Civita connection.

The review article by Andrade et al gives a nice formula for the
contorsion in terms of the torsion of the Weitzenboeck connection. This
means we can express the Levi-Civita connection completely in terms of
the Weitzenboeck connection and its torsion. And \emph{that} means we
can express the Ricci scalar curvature in terms of the Weitzenboeck
connection and its torsion. Great --- so we can write down the
Lagrangian for general relativity in this new lingo! Ultimately, we can
express it purely in terms of the coframe field \(e\).

Unfortunately, I haven't smoothed down the calculations to the point
where you'd actually want to see them here. The prettiest formula for
the Lagrangian shows up in this paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{13}
\tightlist
\item
  Yakov Itin, ``Energy-momentum current for coframe gravity'', available
  as \href{https://arxiv.org/abs/gr-qc/0111036}{\texttt{gr-qc/0111036}}.
\end{enumerate}

Up to a constant factor, it looks like this:
\[2(e^i\wedge de_i)\wedge *(e^j\wedge de_j) - (e^i\wedge de^j)\wedge *(e_i\wedge de_j)\]
where \(i\) and \(j\) are internal indices, but \(*\) is the usual
``spacetime'' Hodge star operator.

By now I've probably lost everyone except people who understand this
stuff already, so I'll stop here. If you read the references, you'll
find a nice equation for how a freely falling particle moves in
teleparallel gravity, a nice formula for the gravitational
energy-momentum pseudotensor in teleparallel gravity, and so on. Itin's
paper also considers versions of teleparallel gravity with more general
Lagrangians built from the coframe field, which are not necessarily
equivalent to general relativity.

Now for something completely different! Here's the final episode of my
description of this paper by Michael Mueger:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{14}
\tightlist
\item
  ``From subfactors to categories and topology I: Frobenius algebras in
  and Morita equivalence of tensor categories'', available as
  \href{http://www.arXiv.org/abs/math.CT/0111204}{math.CT/0111204}.
\end{enumerate}

In \protect\hyperlink{week174}{``Week 174''} I talked about Frobenius
algebras and \(2\)-categories; in \protect\hyperlink{week175}{``Week
175''} I said a bit about subfactors; now it's time for me to say
something about how Mueger puts these together! This will be very
sketchy, I'm afraid.

First, it's worth noting that lots of mathematical gadgets form not just
categories but also \(2\)-categories. For example, we all know the
category of groups, where the objects are groups and the morphisms are
homomorphisms. But there is also a \(2\)-category lurking around here!
Between any morphisms \[f,f'\colon  G \to  H\] we can define a
\(2\)-morphism \[a\colon f \Rightarrow f'\] to be an element of \(H\)
with the property that
\[af(g) = f'(g)a    \quad\mbox{for all $g$ in $G$.}\] This just says
that \(f'\) is \(f\) conjugated by an element of \(H\), so we could call
these \(2\)-morphisms ``conjugations''.

This definition may seem forced, but it's actually quite natural if you
remember that a group is a special sort of category with one object and
with all morphisms being invertible. Functors between these special
categories are just group homomorphisms, and natural transformations
between these functors are just conjugations! If you don't follow this,
check out \protect\hyperlink{week73}{``Week 73''} --- you'll see the
above equation is just a special case of the definition of ``natural
transformation''.

For fans of group theory, one nice thing about this \(2\)-category is
that it explains where ``inner automorphisms'' fit into the grand
\(n\)-categorical scheme of things. It also explains why conjugations
become important in algebraic topology when you're playing around with
the ``fundamental group'': this is actually a \(2\)-functor from the
\(2\)-category of

\begin{itemize}
\tightlist
\item
  spaces with basepoint,
\item
  base-point-preserving maps, and
\item
  not-necessarily-basepoint-preserving homotopies
\end{itemize}

to the \(2\)-category of

\begin{itemize}
\tightlist
\item
  groups,
\item
  group homomorphisms, and
\item
  conjugations.
\end{itemize}

We can also cook up a \(2\)-category of rings which works in a similar
way; the objects are rings, the morphisms are ring homomorphisms, and
the \(2\)-morphisms are conjugations, defined by the same formula as
above.

Mueger's work uses this \(2\)-category, or more precisely, a
sub-\(2\)-category where we use not \emph{all} rings, but only certain
specially nice type III factors, and not \emph{all} homomorphisms, but
only certain specially nice \(*\)-homomorphisms. He gives a nice simple
condition for a morphism in this \(2\)-category to have a ``two-sided
adjoint'' --- meaning precisely that it's part of what I called an
``ambidextrous adjunction'' in \protect\hyperlink{week174}{``Week
174''}. And as we saw back then, any ambidextrous adjunction gives a
Frobenius object! So, he gets lots of Frobenius objects from the theory
of factors. But more importantly, he shows that a whole lot of concepts
beloved by folks who study von Neumann algebras are really concepts from
\(2\)-category theory, applied to this situation!

This is cool, because there are \emph{already} deep connections between
\(n\)-categories and quantum theory --- see
\protect\hyperlink{week78}{``Week 78''} for an introduction to these
ideas. Since von Neumann algebras are the basic ``algebras of
observables'' in quantum theory, we should \emph{expect} them to be
deeply \(n\)-categorical in nature. And now, thanks to the work of
Mueger, it's becoming a lot clearer just how. But I don't think we're
anywhere near the bottom of it yet --- at least, not me!

By the way, it's taken me so long to explain Mueger's last paper that
he's already written another:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{15}
\tightlist
\item
  Michael Mueger, ``On the structure of modular categories'', available
  as \href{http://www.arXiv.org/abs/math.CT/0201017}{math.CT/0201017}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{``I admire the elegance of your method of computation; it must be
nice to ride through these fields upon the horse of true mathematics
while the like of us have to make our way laboriously on foot.''} ---
Einstein to Levi-Civita



\hypertarget{week177}{%
\section{February 24, 2002}\label{week177}}

This week I want to talk about some new developments in quantum gravity.
But first, here's a little taste of Greg Egan's new novel:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Greg Egan, Schild's Ladder, Eos, May 2002. Synopsis available at
  \texttt{http://www.netspace.net.au/\textasciitilde{}gregegan/SCHILD/SCHILD.html}
\end{enumerate}

\begin{quote}
Kusnanto Sarumpaet had lived on Earth at the turn of the third
millennium, when a group of physicists and mathematicians scattered
across the planet --- now known universally as the
\href{http://jdc.math.uwo.ca/spin-foams/sultans.html}{Sultans of Spin}
--- had produced the first viable offspring of general relativity and
quantum mechanics. To merge the two descriptions of nature, you needed
to replace the precise, unequivocal geometry of classical spacetime with
a quantum state that assigned amplitudes to a whole range of possible
geometries. One way to do this was to imagine carrying a particle such
as an electron around a loop, and computing the amplitude for its
direction of spin being the same at the end of the journey as when it
first set out. In flat space, the spins would always agree, but in
curved space the result would depend on the detailed geometry of the
region through which the particle had travelled. Generalising this idea,
criss-crossing space with a whole network of paths taken by particles of
various spins, and comparing them all at the junctions where they met,
led to the notion of \emph{spin network}. Like the harmonics of a wave,
these networks comprised a set of building blocks from which all quantum
states of geometry could be constructed.
\end{quote}

Apart from the first sentence, all this is a perfectly factual, lucid
account of the state of loop quantum gravity at the turn of the third
millennium. Unlike so many SF writers, Egan really knows his physics -
and can explain it more clearly than either the physicists or the
science journalists!

But this is just the start. The tale goes on to sketch how Sarumpaet
found a ``theory of everything'' which goes by the name of Quantum Graph
Theory:

\begin{quote}
``It's simple, it's elegant, and it's consistent with all observations
to date.'' That handful of words sounded glib, but other people had
quantified all of these criteria long ago: QGT as a descriptionof the
dynamics of the universe with the minimum possible algorithmic
complexity; QGT as a topological re-description of some basic results in
category theory --- a mathematical setting in which the Sarumpaet rules
appeared as natural and inevitable as the rules of arithmetic; QGT as
the most probable underlying system of physical laws, given any
substantial database of experimental results that spanned both nuclear
physics and cosmology.
\end{quote}

And then, much farther in the future, along comes someone who wants to
do a novel experiment which will test these rules in a more stringent
way than ever before. And then --- not to give too much away --- all
hell breaks loose!

There's more in this novel than just physics. Fans of Egan's
``Diaspora'' (see \protect\hyperlink{week115}{``Week 115''}) will
recognize this world, but there are many new twists, too. Technophiles
will enjoy the depiction of a time when virtual reality is commonplace,
death and gender are things of the past, and everybody except a few
``anachronauts'' is fully backed up and fitted with a device that
prevents their mind from splitting into different Everett branches when
making decisions. Thoughtful readers will be interested to see what
people \emph{worry} about in a world like this --- though I wish Egan
had given more of a sense of everyday life. Finally, those of us who
like math will enjoy reading of a world where people give theorems as
presents --- since everything else is too easy.

Would you like to see \(\mathrm{SO}(4)\) as a principal
\(\mathrm{SO}(3)\)-bundle over \(S^3\), dear?

I should admit this is a wholly biased review of Egan's novel, since
we're collaborating on a physics paper, and he cites my work at the end
of his book. So you may want to take it with a grain of salt when I say:
\emph{Read this!}

If ``Schild's Ladder'' gets you hungry to learn more about what loop
quantum gravity was like at the beginning of the third millennium, try
these review articles by Ashtekar:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  Abhay Ashtekar, ``Quantum geometry and gravity: recent advances'',
  available as
  \href{https://arxiv.org/abs/gr-qc/0112038}{\texttt{gr-qc/0112038}}.

  Abhay Ashtekar, ``Quantum geometry in action: big bang and black
  holes'', available as
  \href{https://arxiv.org/abs/math-ph/0202008}{\texttt{math-ph/0202008}}.
\end{enumerate}

They're not too technical, and they show how the theory is going beyond
``kinematical'' results like the quantization of area and a tentative
explanation of black hole entropy in terms of microstates of the
horizon, towards ``dynamical'' results like a theory of the big bang.

In case you're wondering, ``kinematics'' in loop quantum gravity means
the description of the geometry of \emph{space} at ultra-short distance
scales, taking quantum effects into account, while ``dynamics'' means a
description of the geometry of \emph{spacetime}. Loop quantum gravity
has a much easier time with the former than the latter, basically
because it's a form of ``canonical quantization'' --- more jargon, which
means that at the very start of the day one chops spacetime into space
and time. Only recently have people like Martin Bojowald made progress
on using loop quantum gravity to answer interesting dynamical questions
--- and even now, this work is fraught with difficulties.

To understand dynamics better in loop quantum gravity, people have tried
to develop a form of ``covariant quantization'' that goes hand-in-hand
with the canonical approach. Covariant quantization doesn't chop
spacetime into space and time; it's very popular in particle physics,
where it gives rise to the much-beloved Feynman diagrams. A Feynman
diagram describes a ``quantum history'' in which particles zip hither
and thither along edges, interacting at vertices. A theory of particle
physics gives a rule for computing the probability --- or more
precisely, the amplitude --- of any such history, and to figure out the
probability that something happens, you need to sum over these
histories, weighted by their amplitudes.

In loop quantum gravity the analogue of a Feynman diagram is called a
``spin foam'', because it looks a bit like a foam of soap bubbles. A
spin foam has \(2\)-dimensional faces in addition to the
\(1\)-dimensional edges and \(0\)-dimensional vertices of a Feynman
diagram. Again, these spin foams describe ``quantum histories'', and
again we want to compute their amplitudes --- but now these are
histories for \emph{spacetime itself}, rather than particles moving
around in spacetime. Of course we eventually want to describe particles
as well as spacetime, and it's unlikely that we'll get very far until we
combine both aspects into a unified description, but work on that is
just beginning:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\item
  Aleksandar Mikovic, ``Spin foam models of matter coupled to gravity'',
  \href{https://arxiv.org/abs/hep-th/0108099}{\texttt{hep-th/0108099}}.

  Aleksandar Mikovic, ``Quantum field theory of open spin networks and
  new spin foam models'', available as
  \href{https://arxiv.org/abs/gr-qc/0202026}{\texttt{gr-qc/0202026}}.
\end{enumerate}

As usual, the hard part is deciding how much effort to put in going
after the big enchilada, versus straightening out all sorts of details -
details that could prove fatal if not handled properly. For example, it
would be a real pity if the work on canonical quantum gravity weren't
firmly bolted to the new work on spin foams. The best paper so far on
this is by Arnsdorf, building on work by Rovelli and others:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Matthias Arnsdorf, ``Relating covariant and canonical approaches to
  triangulated models of quantum gravity'', available as
  \href{https://arxiv.org/abs/gr-qc/0110026}{\texttt{gr-qc/0110026}}.
\end{enumerate}

This shows how, in principle, one can go back and forth between a recipe
for computing spin foam amplitudes and a formula for the ``Hamiltonian
constraint'' --- the basic description of dynamics in canonical quantum
gravity. Unfortunately, attempts to relate the most popular spin foam
models to the most popular formulas for the Hamiltonian constrant are
going slower. In particular, it's hard to see how Thiemann's formulas
for the Hamiltonian constraint (see \protect\hyperlink{week85}{``Week
85''}) could arise naturally from a spin foam model. A tentative step in
this direction has been made by Gambini and Pullin:

5)Rodolfo Gambini and Jorge Pullin, ``A finite spin-foam-based theory of
three and four dimensional quantum gravity'',
\href{https://arxiv.org/abs/gr-qc/0111089}{\texttt{gr-qc/0111089}}.

However, their theory is admittedly just a toy model, since it only
handles a certain restricted class of solutions of Thiemann's
constraint.

In a different direction, there has also been some good work lately on
clarifying the inner workings of the spin foam formalism:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\item
  Robert Oeckl, ``Generalized lattice gauge theory, spin foams and state
  sum invariants'', available as
  \href{https://arxiv.org/abs/hep-th/0110259}{\texttt{hep-th/0110259}}.

  Florian Girelli, Robert Oeckl and Alejandro Perez, ``Spin foam
  diagrammatics and topological invariance'', available as
  \href{https://arxiv.org/abs/gr-qc/0111022}{\texttt{gr-qc/0111022}}.
\end{enumerate}

Mathematicians will especially like the second paper, since it gives a
slick way to prove the triangulation-independence of the Turaev-Viro
model which avoids complicated calculations involving \(6j\) symbols.
Physicists, however, need to understand triangulation-dependent models;
there is more about these in the first paper.

As for me, I've been spending the last half year working with Greg Egan,
Dan Christensen, and two students of his trying to compare various spin
foam models by means of computer simulations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  John C. Baez, J. Daniel Christensen, Thomas R. Halford and David C.
  Tsang, ``Spin foam models of Riemannian quantum gravity'',
  \href{https://arxiv.org/abs/gr-qc/0202017}{\texttt{gr-qc/0202017}}.
\end{enumerate}

Riemannian quantum gravity is a toy model where the gauge group is the
4d rotation group rather than the Lorentz group. The reason we've been
studying this instead of the real thing is that we don't yet have
efficient ways of computing spin foam amplitudes in the Lorentzian
theory. In the Riemannian case, Egan and Christensen developed an
efficient algorithm that serves as the workhorse for the above paper -
see \protect\hyperlink{week172}{``Week 172''} for more on that. Without
this algorithm, we'd be dead in the water!

In essence, what we did is take the simplest compact \(4\)-dimensional
manifold and triangulate it in the simplest possible way: the
\(4\)-sphere, triangulated as the boundary of a \(5\)-simplex. Then we
compared various recipes for computing the amplitudes of spin foams that
fit neatly into this triangulation. In Riemannian quantum gravity, a
spin foam living in this triangulation simply amounts to a way of
labelling each triangle with a spin \(j = 0, 1/2, 1, 3/2,\ldots\) which
describes its area. More precisely, the area is proportional to
\(\sqrt{j(j+1)}\) --- a formula familiar from other contexts in quantum
mechanics.

The job of a spin foam model is to compute an amplitude from all these
spins. If the amplitudes we get are biggest when lots of the spins are
large, we'll know the model favors quantum histories where the discrete
geometry of spacetime is visible at large scales. If the amplitudes are
biggest when most of the spins are small, it means the discreteness is
visible only at very small scales. This is just step down the long road
towards seeing whether a model reduces to general relativity at large
distance scales.

However, when you do these calculations, at first you get amplitudes
that aren't normalized. To normalize them, you must divide by the sum of
these unnormalized amplitudes over all spin foams, which is called the
``partition function''. So, one of the very first questions to ask about
a specific model is whether this sum converges!

The models we compared were all variants of the Riemannian Barrett-Crane
model (see \protect\hyperlink{week128}{``Week 128''} and the previous
issues referred to there). Barrett and Crane left some aspects of their
model unspecified, and different ways of filling in the details turn out
to give drastically different results. The first people to tackle this
were De Pietri, Freidel, Krasnov and Rovelli:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Roberto De Pietri, Laurent Freidel, Kirill Krasnov, and Carlo Rovelli,
  ``Barrett-Crane model from a Boulatov-Ooguri field theory over a
  homogeneous space'', preprint available as
  \href{https://arxiv.org/abs/hep-th/9907154}{\texttt{hep-th/9907154}}.
\end{enumerate}

Our calculations show that the partition function diverges very rapidly
in their model. In fact, when we summed the amplitudes of spin foams
with all triangles labelled by spins less than or equal to \(J\), we got
the following results:

\begin{longtable}[]{@{}ll@{}}
\toprule
spin cutoff & cutoff partition function\tabularnewline
\midrule
\endhead
\(J = 0\) & \(1.000\)\tabularnewline
\(J = 1/2\) & \(3.722\times 10^5\)\tabularnewline
\(J = 1\) & \(7.812\times 10^9\)\tabularnewline
\(J = 3/2\) & \(2.128\times 10^{13}\)\tabularnewline
\(J = 2\) & \(1.345\times 10^{16}\)\tabularnewline
\bottomrule
\end{longtable}

Barring various loopholes which we discuss in our paper, this seems to
make it difficult to get sensible physics from this model: spacetime
discreteness always appears on the largest length scale you let it!

In fact, Perez and Rovelli had already suspected problems with a
divergent partition function in this model. They came up with an elegant
variant in which they could show the partition function converges:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\item
  Alejandro Perez and Carlo Rovelli, ``A spin foam model without bubble
  divergences'', \emph{Nucl. Phys.} \textbf{B599} (2001), 255--282. Also
  available as
  \href{https://arxiv.org/abs/gr-qc/0006107}{\texttt{gr-qc/0006107}}.

  Alejandro Perez, ``Finiteness of a spin foam model for Euclidean
  quantum general relativity'', \emph{Nucl. Phys.} \textbf{B599} (2001),
  427--434. Also available as
  \href{https://arxiv.org/abs/gr-qc/0011058}{\texttt{gr-qc/0011058}}.

  Alejandro Perez, ``Group quantum field theories and spin foam models
  for quantum gravity'', to appear.
\end{enumerate}

The funny thing is, our calculations show the partition function
converges \emph{really fast} in this model. Taking the same
triangulation of the \(4\)-sphere, we got these results:

\begin{longtable}[]{@{}ll@{}}
\toprule
spin cutoff & cutoff partition function\tabularnewline
\midrule
\endhead
\(J = 0\) & \(1.000000000000\)\tabularnewline
\(J = 1/2\) & \(1.000014319178\)\tabularnewline
\(J = 1\) & \(1.000014323656\)\tabularnewline
\(J = 3/2\) & \(1.000014323670\)\tabularnewline
\(J = 2\) & \(1.000014323670\)\tabularnewline
\bottomrule
\end{longtable}

Now it seems that all spin foams except the one with all zero-area
triangles contribute only a tiny amount to the partition function! A
more detailed analysis shows that for a larger triangulated manifold,
the sum over spin foams would be dominated by those where all triangles
have zero area except for small, widely separated ``islands'' of
higher-spin triangles. The simplest such island has four spin-\(1/2\)
triangles arranged as the faces of a tetrahedron; compared to tetrahedra
labelled by spin zero, the amplitude for this to occur works out to be
\(2^{-20}\).

It's hard to be sure that this ``spin-zero dominance'' is a bad thing,
but at the very least, it makes computer simulations a bit dull.
Eventually we started trying to come up with a model that darts between
the Scylla of a divergent partition function and the Charybdis of
spin-zero dominance. This turns out to be quite tricky, at least if one
wants a theory that's neatly expressed in the language of category
theory --- which is what underlies spin foam models. But eventually we
found one! And amusingly, it was the very simplest, prettiest model of
all\ldots{} for some silly reason we'd overlooked it until we were
really desperate.

Here is what our calculations gave for this model:

\begin{longtable}[]{@{}ll@{}}
\toprule
spin cutoff & cutoff partition function\tabularnewline
\midrule
\endhead
\(J = 0\) & \(1.000000000000\)\tabularnewline
\(J = 1/2\) & \(2.342658607645\)\tabularnewline
\(J = 1\) & \(3.378038633798\)\tabularnewline
\(J = 3/2\) & \(3.966290480574\)\tabularnewline
\(J = 2\) & \(4.293589340364\)\tabularnewline
\(J = 5/2\) & \(4.480621474940\)\tabularnewline
\bottomrule
\end{longtable}

From this data, it's not completely clear whether the partition function
converges or not. It seems to be poised right on the brink of
convergence. You might wonder why we didn't try higher cutoffs. The
reason is simple: already for \(J = 5/2\), the sum over spin foams
involved approximately 3.6 trillion terms! Dan did it with the help of
the SHARCNet supercomputer at the University of Western Ontario, and it
occupied 28 CPUs for 23 hours.

To get more information on whether the partition function converges, one
has to use a sneakier method: the Metropolis algorithm. This is a
technique widely used in statistical mechanics and quantum field theory.
In our case, it amounts to designing a random walk that samples spin
foams with a frequency equal to their amplitude. This only works thanks
to a special property of the Barrett-Crane model which we proved in an
earlier paper: the amplitudes are nonnegative! See
\protect\hyperlink{week172}{``Week 172''} for details.) One can't use
the Metropolis algorithm to compute the partition function, but one can
use it to compute expectation values of observables. We proved that a
very simple observable --- the average area of a triangle --- can only
have a finite expectation value if the partition function converges.
Then we used the Metropolis algorithm to compute the expectation value
of this observable\ldots{} and it came out nice and finite: in fact,
close to \(0.401507\).

So, we feel quite sure the partition function converges in our new model
--- at least for this particular triangulated \(4\)-manifold. We also
came up with an argument that should apply more generally, but it has
some holes in it, which we'll try to plug in our next paper, with Greg
Egan.

Anyway, it's fun seeing actual numbers coming out of spin foam models,
and seeing computer calculations lead to new questions and even new
theories. I think this sort of interaction between theory and
``experiment'' is a good thing, especially since we can't do \emph{real}
quantum gravity experiments yet. I hope more people working on quantum
gravity do some numerical calculations, instead of focusing solely on
analytically solvable problems, which is very limiting, especially for
nonperturbative work.

Indeed, over in string theory there have already been some interesting
calculations done in the IKKT matrix model --- see
\protect\hyperlink{week172}{``Week 172''} for references on that. These
are actually quite similar to our spin foam calculations: you take a
manifold, triangulate it, label it in various ways and compute an
amplitude for each labelling\ldots.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week178}{%
\section{March 22, 2002}\label{week178}}

A ``homotopy'' is a way of bending or stretching something without
adding or getting rid of any holes: if you've ever heard the joke about
how a topologist is someone who can't tell the difference between a
doughnut and a coffee cup, it's a bit like that. Homotopy theory is
closely related to \(n\)-categories, because in both subjects you need
to develop special skills to speak precisely about how things are ``the
same in a way'' despite not being equal. I recently visited the
University of Chicago to give some talks on \(n\)-categories to a bunch
of homotopy theorists. I knew I was in the right place because after my
talk we went to the math department lounge for coffee, and they dipped
all their coffee mugs in their doughnuts!

I was invited by Peter May, who is a well-known practitioner of homotopy
theory. He has recently become interested in \(n\)-categories, even
proposing his own definition of this concept:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  J. Peter May, ``Operadic categories, \(A_\infty\)-categories and
  \(n\)-categories'', writeup of a talk given in Morelia, Mexico, May
  25, 2001. Available with other papers at his homepage,
  \texttt{http://www.math.uchicago.edu/\textasciitilde{}may/}
\end{enumerate}

However, his real ambition is not to add to the glut of definitions, but
to systematize the subject. Right now there are over a dozen definitions
of ``\(n\)-category'', and your only guide through the jungle is this
paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Tom Leinster, ``A survey of definitions of \(n\)-category'', available
  at
  \href{https://arxiv.org/abs/math.CT/0107188}{\texttt{math.CT/0107188}}.
\end{enumerate}

Luckily, a lot of people want to use ideas from homotopy theory to prove
all these definitions are ``the same in a way''. Here's one strategy:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Carlos Simpson, ``Some properties of the theory of \(n\)-categories'',
  available at
  \href{https://arxiv.org/abs/math.CT/0110273}{\texttt{math.CT/0110273}}.
\end{enumerate}

It will take a lot of work, but the final answer will probably be really
nice.

Meanwhile, homotopy theory is beginning to creep into lots of subjects,
so more people are trying to learn about it. Physicists are getting
interested in applying techniques borrowed from homotopy theory to
string theory and deformation quantization:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Martin Markl, Steve Shnider and Jim Stasheff, \emph{Operads in
  Algebra, Topology and Physics}, AMS, Providence, 2002.
\end{enumerate}

Algebraic geometers, on the other hand, have been trying to learn
homotopy theory ever since Vladimir Voevodksy used ideas from it to
crack a famous open problem:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  F. Morel, ``Voevodsky's proof of Milnor's conjecture'', \emph{Bull.
  Amer. Math. Soc.} \textbf{35} (1998), 123--143. Also available at
  \texttt{http://e-math.ams.org/jourcgi/amsjournal?fn=120\&pg1=pii\&s1=S0273097998007459}
\end{enumerate}

Perhaps for this reason, May has been been explaining homotopy theory to
the algebraic geometers Beilinson and Drinfeld, in a seminar which
Drinfeld runs ``in the Russian style'' --- meaning that he asks lots of
questions and you talk until you drop dead from exhaustion. I went there
and tried to sell them on \(n\)-categories, and got quizzed for hours.
It was a bit scary, but actually lots of fun. Much better than those
seminars where everyone runs for the door after an hour regardless of
whether they understood a word --- and probably faster, the less they
understood!

But now I should stop dazzling you with buzzwords and actually explain
something. Lately James Dolan and I have been trying to learn more about
representations of simple Lie groups and their role in incidence
geometry. I first got interested in this when I was trying to understand
exceptional Lie groups and their connection to the octonions. Recently
we've made more progress. So, let me continue the story starting from
where I left off in \protect\hyperlink{week162}{``Week 162''}. If you
get confused, go back and read that!

The idea starts from noticing that states of a quantum system can be
described by unit vectors in the complex Hilbert space, but ``modulo
phase'': multiplying a unit vector by a unit complex number doesn't
change the physical state it describes. The space of all states is
called ``complex projective space''. If we start with the Hilbert space
\(\mathbb{C}^n\), this is a complex manifold with complex dimension
\(n-1\), so folks call it \(\mathbb{CP}^{n-1}\).

A different way to think about it is this: points of
\(\mathbb{CP}^{n-1}\) are the same as arbitrary nonzero vectors in
\(\mathbb{C}^n\), but where we count two vectors as the same if one is a
scalar multiple of the other. In other words, points of
\(\mathbb{CP}^{n-1}\) are \(1\)-dimensional subspaces of
\(\mathbb{C}^n\). This is nice because it encourages us to go on and
define lines in \(\mathbb{CP}^{n-1}\) to be \(2\)-dimensional subspaces
of \(\mathbb{C}^n\), and so on. This leads us into the world of
projective geometry, where all we have are points, lines, planes, etc.,
together with incidence relations like:

\begin{quote}
``the point \(P\) lies on the line \(Q\)'',

``the line \(Q\) lies on the plane \(R\)'',
\end{quote}

and so on, satisfying various axioms. There is no concept of angle or
distance in projective geometry.

Projective geometry goes way back to the Renaissance painters and their
interest in perspective, and axiomatic projective geometry was very
fashionable in the 19th century, but here we are seeing it in a more
modern light, because we're seeing its relation to quantum logic. In
quantum logic we view all these points, lines, planes, and so on as
\emph{propositions} about the state of our system: a point specifies the
state completely, a line specifies it a bit less, and so on. From this
viewpoint, the incidence relation ``lying on'' gets reinterpreted as
``implies''. Using standard tricks we can use implication to define the
logical operations ``and'' and ``or''\ldots{} but not ``not''!

Why not ``not''? Well, quantum logic certainly has a concept of
negation, but it's defined using the inner product on our Hilbert space,
not just its linear structure. As we've seen, any proposition
corresponds to a subspace of \(\mathbb{C}^n\); the negation of this
proposition corresponds to its \emph{orthogonal complement}. This takes
us outside the world of projective geometry, to a world where we also
have a concept of ``perpendicular''.

This means that the fragment of quantum logic that's defined just in
terms of implication is invariant under a larger symmetry group than
full-fledged quantum logic, which also includes ``not''. The
``implicational fragment'' only uses the linear structure of our Hilbert
space, so it's invariant under all linear transformations. Full-fledged
quantum logic also uses the inner product, so it's only invariant under
unitary transformations.

Actually, since multiplication by scalars acts trivially on complex
projective space, we don't lose anything by restricting attention to
transformations with determinant \(1\). Thus we can say that the
implicational fragment of quantum logic has
\(\mathrm{SL}(n,\mathbb{C})\) as a group of symmetries, while the
full-fledged theory has the smaller group \(\mathrm{SU}(n)\) as
symmmetries. In case you forgot: \(\mathrm{SL}(n,\mathbb{C})\) is the
group of all \(n\times n\) complex matrices with determinant \(1\),
while \(\mathrm{SU}(n)\) is the subgroup of \(n\times n\) unitary
matrices with determinant \(1\).

The simplest nontrivial example is \(n = 2\), so let's look at that.
Every student of quantum mechanics knows \(\mathbb{C}^2\) under the name
of the Hilbert space for a spin-\(1/2\) particle. Every student of
complex analysis knows \(\mathbb{CP}^1\) under the name of the Riemann
sphere. So, the space of states of a spin-\(1/2\) particle is the
Riemann sphere! Acting on this space we have two symmetry groups:
\(\mathrm{SL}(2,\mathbb{C})\), which is the double cover of the Lorentz
group in 4d spacetime, and \(\mathrm{SU}(2)\), which is the double cover
of the rotation group in 3d space. So, we're basically recovering
rotations as the symmetries of the quantum logic associated to a
spin-\(1/2\) particle - which is not so surprising --- but also
recovering Lorentz transformations as the symmetries of the
implicational fragment of this logic!

I've been struggling for years to understand the deep inner meaning of
this connection between quantum logic and special relativity, or perhaps
fit it into some larger framework that will give us some new insights
into physics. So far I've mainly been playing catch-up, learning a lot
of beautiful math that I should have known anyway. In
\protect\hyperlink{week162}{``Week 162''}, I sketched how this
connection fits into the theory of simple Jordan algebras. Now I want to
show you how it fits into the theory of simple Lie groups.

The starting-point is to notice that \(\mathrm{SL}(n,\mathbb{C})\) is a
complex simple Lie group, and ask how much of this story can be
generalized to \emph{arbitrary} complex simple Lie groups. The answer
is: a lot!

For starters, each complex simple Lie group \(G\) is the symmetries of a
kind of generalized projective geometry called an ``incidence
geometry''. You can learn a lot about this just by staring at the Dynkin
diagram of \(G\).

I explained Dynkin diagrams already in \protect\hyperlink{week62}{``Week
62''} - \protect\hyperlink{week65}{``Week 65''}, so instead of reviewing
them here, I'll plunge in with the simplest example. The Dynkin diagram
for \(\mathrm{SL}(n,\mathbb{C})\) has \(n-1\) dots in a row, connected
by edges. These dots and edges mean all sorts of different
things\ldots{} but in the game we're playing now, the dots correspond to
different types of ``figure'' in some incidence geometry, while the
edges correspond to ``incidence relations''!

For example, if \(n = 2\) we have \(\mathrm{SL}(2,\mathbb{C})\) acting
as symmetries of \(\mathbb{CP}^1\), and the Dynkin diagram is just \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\bullet$};
  \end{tikzpicture}
\] which is pretty boring. We have just one type of figure, namely
points, and no incidence relations.

For \(n = 3\) we get \(\mathrm{SL}(3,\mathbb{C})\) acting as symmetries
of the complex projective plane \(\mathbb{CP}^2\), and we get a more
interesting Dynkin diagram, with two types of figure and one incidence
relation: \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\bullet$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \draw[thick] (0,0) to (2,0);
  \end{tikzpicture}
\] The symmetry of the diagram hints at the duality between points and
lines in the theory of projective planes, which I discussed in
\protect\hyperlink{week145}{``Week 145''}. We see this symmetry also in
quantum logic, where negation sends the propositions corresponding to
``points'' to those corresponding to ``lines'', and vice versa.

You might object that the negation operation in quantum logic is not
invariant under \(\mathrm{SL}(n,\mathbb{C})\), but only under
\(\mathrm{SU}(n)\)! You'd be right, but these groups have an intimate
relationship: \(\mathrm{SU}(n)\) is the ``compact real form'' of
\(\mathrm{SL}(n,\mathbb{C})\), meaning that it's a simple Lie group in
its own right, but a compact one, and if you complexify it you get
\(\mathrm{SL}(n,\mathbb{C})\) back. Every complex simple Lie group has a
compact real form, and they go everywhere together, hand-in-glove. In
the game we're playing now, any complex simple Lie group acts as
symmetries of any incidence geometry, while its compact real form acts
as symmetries of a full-fledged quantum logic, including the concept of
negation. Unfortunately, the relation between the incidence geometry and
the quantum logic is still a bit mysterious to me\ldots{} except in the
case of \(\mathrm{SL}(n,\mathbb{C})\) and its compact real form
\(\mathrm{SU}(n)\), where I've already described how it works.

When \(n = 4\) the Dynkin diagram of \(\mathrm{SL}(n,\mathbb{C})\) looks
like this: \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\bullet$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \node[label=below:{planes}] at (4,0) {$\bullet$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] The pattern continues for higher \(n\). As you see, we always have a
duality symmetry switching high-dimensional and low-dimensional types of
figure.

How can we generalize this idea to arbitrary complex simple Lie groups?
The trick is to follow Felix Klein's ``Erlangen program'' relating
geometry and group theory. There are many kinds of geometry, each with
its own symmetry group. In a geometry with symmetry group \(G\),
different types of figure correspond to different \emph{subgroups} of
\(G\). The idea is that for each type of figure, there is a space \(X\)
of all figures of that type, upon which \(G\) acts. Given any two of
these figures, there's some element of \(G\) mapping one to the other:
that's what we mean by saying they're of the same type! You can show
this implies there's an isomorphism \[X = G/H\] for some subgroup \(H\)
of \(G\). \(H\) is the group of transformations that \emph{preserves} a
given figure --- that is, maps it to itself.

Conversely, any subgroup \(H\) can be thought of as determining a type
of figure! But in practice, some subgroups correspond to more familiar
types of figure than others. In particular, every complex simple Lie
group \(G\) has certain ``maximal parabolic subgroups'' coming from the
dots in its Dynkin diagram of \(G\), and these give the types of figure
that we really want to understand.

However, before we tackle these maximal parabolics, I need to talk about
some simpler kinds of subgroups and illustrate how they work in case of
\(\mathrm{SL}(n,\mathbb{C})\).

The group \(\mathrm{SL}(n,\mathbb{C})\) has subgroups consisting of:

\begin{itemize}
\tightlist
\item
  unitary matrices,
\item
  diagonal unitary matrices,
\end{itemize}

and

\begin{itemize}
\tightlist
\item
  upper triangular matrices,
\end{itemize}

all with determinant \(1\) of course. We can generalize all these
concepts to an arbitrary complex simple Lie group, getting the notions
of:

\begin{itemize}
\tightlist
\item
  maximal compact subgroup,
\item
  maximal torus,
\end{itemize}

and

\begin{itemize}
\tightlist
\item
  maximal solvable subgroup.
\end{itemize}

So, let's do it!

First, every complex simple Lie group \(G\) has a bunch of maximal
compact subgroups, all of which are isomorphic via conjugation inside G.
People often pick one, call it ``the'' maximal compact subgroup, and
denote it by \(K\). But don't be fooled: there are lots! For
\(\mathrm{SL}(n,\mathbb{C})\) they're all isomorphic to
\(\mathrm{SU}(n)\), and the obvious choice is \(\mathrm{SU}(n)\) itself.

People also call \(K\) the ``compact real form'' of \(G\). The reason is
that we can always recover \(G\) from \(K\) by a process called
``complexification'': the Lie algebra of \(K\) is a real vector space,
but if we make it complex, we get the Lie algebra of \(G\). As a result,
the dimension of \(G\) as a \emph{real} manifold is twice that of \(K\).
In fact \(G\) is always diffeomorphic to the product of \(K\) and the
Lie algebra of \(K\).

Second, \(K\) always has a bunch of maximal abelian subgroups. All these
are tori and all of them are isomorphic via conjugation inside \(K\). We
can also think of these guys as subgroups of \(G\), and then they work
out to be precisely the ``maximal tori'': subgroups of \(G\) that are
isomorphic to a torus and as big as possible. People often pick one,
call it ``the'' maximal torus, and denote it by \(H\) --- but again,
don't be fooled. For \(\mathrm{SL}(n,\mathbb{C})\) the obvious choice of
maximal torus consists of diagonal matrices \[
  \left(
    \begin{array}{cccc}
      *&0&0&0
    \\0&*&0&0
    \\0&0&*&0
    \\0&0&0&*
    \end{array}
  \right)
\] where the diagonal entries are unit complex numbers that multiply to
one. This is an \((n-1)\)-dimensional torus. Note that it's not a
maximal abelian subgroup of \(\mathrm{SL}(n,\mathbb{C})\) --- there are
other diagonal matrices in \(\mathrm{SL}(n,\mathbb{C})\), too. It's just
a maximal torus in \(\mathrm{SL}(n,\mathbb{C})\), and a maximal abelian
subgroup of \(\mathrm{SU}(n)\).

Third, \(G\) always has a bunch of maximal solvable subgroups, which
again are all isomorphic by conjugation inside \(G\). In case you
forgot: a group \(B\) is ``solvable'' if when you take the subgroup
\(B_1\) generated by commutators \[ghg^{-1}h^{-1}\] of elements of
\(B\), and then take the subgroup \(B_2\) generated by commutators of
elements of \(B_1\), and so on, you get down to the trivial group after
finitely many stages.

A maximal solvable subgroup of \(G\) is also called a ``Borel''
subgroup, and it's denoted \(B\). When
\(G = \mathrm{SL}(n,\mathbb{C})\), an obvious choice for \(B\) is the
group of upper triangular matrices with determinant \(1\): \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&0&*&*
    \\0&0&0&*
    \end{array}
  \right)
\] We could also use lower triangular matrices. As you might guess from
this example, every maximal torus of a complex simple Lie group sits
inside some Borel subgroup, and every Borel subgroup contains a maximal
torus.

It's good to check that \(B\) solvable in this example. Let's do it
using the Lie algebra method. The Lie algebra of \(B\) consists of all
matrices of the form \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&0&*&*
    \\0&0&0&*
    \end{array}
  \right)
\] where the diagonal entries sum to zero. Now, Lie brackets of matrices
like this are always of the form \[
  \left(
    \begin{array}{cccc}
      0&*&*&*
    \\0&0&*&*
    \\0&0&0&*
    \\0&0&0&0
    \end{array}
  \right)
\] Lie brackets of matrices like \emph{this} are always of the form \[
  \left(
    \begin{array}{cccc}
      0&0&*&*
    \\0&0&0&*
    \\0&0&0&0
    \\0&0&0&0
    \end{array}
  \right)
\] and Lie brackets of matrices like \emph{this} are always of the form
\[
  \left(
    \begin{array}{cccc}
      0&0&0&*
    \\0&0&0&0
    \\0&0&0&0
    \\0&0&0&0
    \end{array}
  \right)
\] Finally, Lie brackets of matrices like \emph{this} are always zero!
Since the Lie algebra of \(B\) shrank to nothing after finitely many
steps like this, and \(B\) is connected, it is solvable.

Now, back to incidence geometry. In this example, what type of figure
does the Borel subgroup correspond to? The answer is a ``maximal flag'':
a point lying on a line lying on a plane lying on\ldots.

To see this, remember that a point of \(\mathbb{CP}^{n-1}\) is a
\(1\)-dimensional subspace of \(\mathbb{C}^n\). An example is the
subspace of all vectors of this form: \[
  \left(
    \begin{array}{c}
      *\\0\\0\\0
    \end{array}
  \right)
\] It's easy to see that upper triangular matrices map this subspace to
itself. Or, in fancier lingo: the Borel subgroup preserves this point in
\(\mathbb{CP}^{n-1}\).

Similarly, a line in \(\mathbb{CP}^{n-1}\) is a \(2\)-dimensional
subspace of \(\mathbb{C}^n\). An example is the subspace of all guys of
this form: \[
  \left(
    \begin{array}{c}
      *\\*\\0\\0
    \end{array}
  \right)
\] Again, this is mapped to itself by the upper triangular matrices.

Similarly, a line in \(\mathbb{CP}^{n-1}\) is a \(3\)-dimensional
subspace of \(\mathbb{C}^n\). An example is the subspace of all guys of
this form: \[
  \left(
    \begin{array}{c}
      *\\*\\*\\0
    \end{array}
  \right)
\] And again, this is mapped to itself by the upper triangular matrices.
Continuing this, we get a maximal flag that is preserved by the Borel
subgroup. If you think about it, the Borel subgroup is \emph{exactly}
the subgroup of \(\mathrm{SL}(n,\mathbb{C})\) that preserves this
maximal flag. So, under Klein's correspondence between types of figure
and subgroups, the Borel subgroup corresponds to the type ``maximal
flag''!

Now, a maximal flag is a rather fancy type of figure, built from a bunch
of simpler ones satisfying a bunch of incidence relations. How do we get
our hands on these simpler building blocks?

To do this it's good to look at subgroups \emph{containing} our Borel
subgroup, since the bigger the subgroup, the less it preserves. It turns
out that for \(\mathrm{SL}(n,\mathbb{C})\) there are are \(2^{n-1}\)
subgroups containing any Borel subgroup. I'll list them for \(n = 4\),
starting with the Borel itself and working up to the whole group. For
each subgroup I'll say what type of figure it preserves. Here they are:
\[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&0&*&*
    \\0&0&0&*
    \end{array}
  \right)
  \qquad\text{a point on a line on a plane}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&0&*&*
    \\0&0&*&*
    \end{array}
  \right)
  \qquad\text{a point on a line}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&*&*&*
    \\0&0&0&*
    \end{array}
  \right)
  \qquad\text{a point on a plane}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\*&*&*&*
    \\0&0&*&*
    \\0&0&0&*
    \end{array}
  \right)
  \qquad\text{a line on a plane}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&*&*&*
    \\0&*&*&*
    \end{array}
  \right)
  \qquad\text{a point}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\*&*&*&*
    \\0&0&*&*
    \\0&0&*&*
    \end{array}
  \right)
  \qquad\text{a line}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\*&*&*&*
    \\*&*&*&*
    \\0&0&0&*
    \end{array}
  \right)
  \qquad\text{a plane}
\] \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\*&*&*&*
    \\*&*&*&*
    \\*&*&*&*
    \end{array}
  \right)
  \qquad\text{nothing}
\] As you can see, each subgroup preserves some sort of ``flag'': a
something on a something on a something, etc. The smaller the subgroup,
the bigger the flag. The Borel itself preserves a maximal flag. The
whole group preserves an empty flag --- nothing at all. But the really
interesting subgroups are the ones that are \emph{almost} the whole
group! These preserve the simplest types of figure: a point, a line, and
a plane.

We can turn these observations into definitions that apply to any
complex simple Lie group \(G\). We say a subgroup \(P\) of \(G\) is
``parabolic'' if it contains some Borel subgroup \(B\). We say \(G/P\)
is the corresponding space of ``flags''. The smallest parabolic subgroup
is \(B\) itself, and \(G/B\) is the space of ``maximal flags''. But
we're really interested in the ``maximal'' parabolic subgroups: the
biggest possible ones apart from \(G\) itself. If \(P\) is maximal
parabolic, \(G/P\) will be a space of minimal flags. These minimal flags
are the ``fundamental'' types of figure, from which fancier ones can be
built.

I won't explain it here, but it turns out that after fixing a Borel
subgroup of \(G\), you get parabolics from subsets of dots in the Dynkin
diagram of \(G\). The dots themselves correspond to maximal parabolics,
and these give fundamental types of figure in an incidence geometry.
Similarly, the edges give fundamental incidence relations!

Next time I'll illustrate all this stuff with the example of
\(\mathrm{SO}(n,\mathbb{C})\), the complex simple Lie group whose
compact real form is the rotation group \(\mathrm{SO}(n)\). But for now,
let me leave off by saying where I got some of this stuff. A good place
to learn about simple Lie groups and incidence geometries is in the work
of Freudenthal, especially this review article:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Hans Freudenthal, ``Lie groups in the foundations of geometry'',
  \emph{Adv. Math.} \textbf{1} (1964), 145--190.
\end{enumerate}

and this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Hans Freudenthal and H. de Vries, \emph{Linear Lie Groups}, Academic
  Press, New York, 1969.
\end{enumerate}

especially sections 68--75, which form a gentle introduction to Jacques
Tits' theory of incidence geometries and ``buildings''.

Freudenthal was a delightfully idiosyncratic character. He spent a lot
of time studying octonionic incidence geometries and a lot of time
designing LINCOS, a language for communication with extraterrestrial
intelligences. The latter occupation reflects itself in his use of
nonstandard terminology concerning simple Lie groups. In the above book
he writes:

\begin{quote}
A more imaginative nomenclature than one relying on overburdened terms
such as ``fundamental,'' ``principal,'' ``regular,'' ``normal,''
``characteristic,'' ``elementary,'' and so on is desirable. Inventors of
important mathematical notions should give their inventions suggestive
names. The disadvantage that good names might prevent the inventor's
name from being immortalized as an adjective would be more than
compensated by the advantage that this honor could not possibly be
bestowed on noninventors.
\end{quote}

Practicing what he preaches, he calls the Weyl group the ``kaleidoscope
group'', since a wonderful example is the group of reflections used in
an actual kaleidoscope. He also calls a Cartan subalgebra a ``trunk''
and its weights ``branches'', to go along with the existing terminology
of ``roots''. Alas, none of this terminology has ever caught on.

I love the preface of his book, which begins:

\begin{quote}
Purity of method has been pursued, sometimes as an ideal, sometimes as a
hobby, sometimes for no reason whatsoever. Impurity of method has been
allowed for pragmatic reasons or because of its charm. Group and Lie
algebra methods are by turns interwoven and neatly separated. Diction
vacillates between formality and looseness. Function notation has been
perfected, but still the authors have struggled with derivatives.
Categories have not been used, even where they were badly needed.
\end{quote}

More modern references say more about how incidence geometry is related
to representation theory via geometric quantization:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  William Fulton and Joe Harris, \emph{Representation Theory --- a First
  Course}, Springer Verlag, Berlin, 1991.
\end{enumerate}

and

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Robert J. Baston and Michael G. Eastwood, \emph{The Penrose Transform:
  its Interaction with Representation Theory}, Clarendon Press, Oxford,
  1989.
\end{enumerate}

In particular, the parabolic subgroups are precisely those subgroups
such that \(G/P\) is compact. In fact, all compact simply-connected
Kähler manifolds with a transitive action of \(G\) are of this form. So,
they're really just another way of talking about the ``coadjoint
orbits'' of the compact real form of \(G\). You can apply geometric
quantization to these manifolds to get all the unitary irreducible
representations of the compact real form of \(G\); the maximal
parabolics give the so-called ``fundamental representations'', which
generate the representation ring.

I couldn't resist writing that last paragraph, since I'd love to explain
this carefully someday, but I'm not sure I'll have time. It's incredibly
beautiful stuff!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week179}{%
\section{March 30, 2002}\label{week179}}

I've just been visiting my friend Minhyong Kim at the Korea Institute
for Advanced Studies (KIAS), and before I take off on my next jaunt I'd
like to mention a couple of cool papers he showed me.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Alain Connes and Dirk Kreimer, ``Renormalization in quantum field
  theory and the Riemann-Hilbert problem I: the Hopf algebra structure
  of graphs and main theorem'', \emph{Comm. Math. Phys.} \textbf{210}
  (2000), 249--273. Also available as
  \href{https://arxiv.org/abs/hep-th/9912092}{\texttt{hep-th/9912092}}.
\end{enumerate}

I've already mentioned Kreimer's work in
\protect\hyperlink{week122}{``Week 122''} and
\protect\hyperlink{week123}{``Week 123''}, and since then I've been to a
bunch of talks on it, but I've never fully absorbed it. Minhyong shamed
me into trying harder to understand what Kreimer is up to. It's really
important, because he's managed to take the nitty-gritty details of
renormalization and point people to the elegant math lurking inside.
Something like this is probably a prerequisite for cracking one of the
biggest problems in mathematical physics: finding a rigorous approach to
quantum field theory.

As you may know, renormalization is the process for sweeping infinities
under the rug in quantum field theory. There are lots of approaches,
which all give equivalent answers. My favorite is the approach pioneered
by Epstein and Glaser and explained here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  G. Scharf, \emph{Finite Quantum Electrodynamics}, Springer, Berlin,
  1995.
\end{enumerate}

since in this approach, the infinities never show up in the first place.
However, the work involved in this approach is comparable to that in
other approaches, and you wind up getting more or less the same thing: a
multiparameter family of recipes for computing complex numbers from
Feynman diagrams.

Hmm\ldots{} I guess I need to give a quick bare-bones explanation of
that last phrase! Feynman diagrams are graphs that describe processes
where particles interact, like this: \[
  \begin{tikzpicture}[scale=2]
    \begin{knot}[clip width=0]
      \strand[thick] (0,0)
        to (0.25,-0.75)
        to (0,-1.5);
      \strand[thick] (1,0)
        to (0.75,-0.75)
        to (1,-1.5);
      \strand[thick] (0.25,-0.75) to (0.75,-0.75);
    \end{knot}
    \node at (2.3,-0.1) {two particles come in,};
    \node at (2.3,-0.75) {they exchange a virtual particle,};
    \node at (2.3,-1.4) {and two particles go out};
  \end{tikzpicture}
\] and the number we compute from a Feynman diagram gives the amplitude
for the process to occur. The Feynman diagrams in a given theory are
built from certain basic building blocks, and we get one parameter for
each building block.

For example, in the quantum field theory called ``\(\varphi^3\)
theory'', the diagrams are trivalent graphs --- graphs with three edges
meeting at each vertex. As you can see from the above example, these
graphs are allowed to have ``external edges'' --- that is, loose ends
representing particles that come in or go out. Each external edge is
labelled by a vector in R\^{}4 describing the energy-momentum of the
corresponding particle.

The basic building blocks of Feynman diagrams in this theory are the
edge: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
  \end{tikzpicture}
\] and the vertex: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,-1.5) to (1,-3);
    \draw[thick] (2,0) to (1,-1.5);
  \end{tikzpicture}
\] We can draw these in any rotated way that we like. The parameter
corresponding to the edge is called the ``mass'' of the particle in this
theory, because in quantum theory, a particle's mass affects what it
does when it's just zipping along minding its own business. The
parameter corresponding to the vertex is called the ``coupling
constant'', because it affects how likely two particles are to couple
and give birth to a third.

Fancier theories will have more basic building blocks for their Feynman
diagrams: various kinds of edges corresponding to different kinds of
particles, and also various kinds of vertices, corresponding to
different kinds of interactions. This means these theories have more
parameters (masses and coupling constants). In every case, the basic
building blocks can be thought of as Feynman diagrams in their own
right\ldots{} that'll be important in a minute.

Okay. Here's what Connes and Kreimer do in the above paper. To say this
in a finite amount of time I'm afraid I'm gonna need to assume you know
some stuff about Hopf algebras\ldots.

First, they fix a renormalizable quantum field theory. They use the
\(\varphi^3\) theory in 6d spacetime, but it doesn't matter too much
which one; quantum electrodynamics or the Standard Model should work as
well.

They show that there's a Hopf algebra having ``one-particle
irreducible'' Feynman diagrams as a basis --- these are the Feynman
diagrams that don't fall apart into more connected components when you
remove one edge. In this Hopf algebra, the product of two Feynman
diagrams is just their disjoint union, but their coproduct is a sneakier
thing which encodes a lot of the crucial aspects of renormalization.
Oversimplifying a bit, the coproduct of a diagram \(x\) is
\[x \otimes 1 + 1 \otimes x + \sum_i x_i \otimes y_i\] where \(x_i\)
ranges over all subdiagrams of \(x\) whose external edges match those of
one of the elementary building blocks, and \(y_i\) is obtained from
\(x\) by collapsing the subdiagram \(x_i\) to the corresponding
elementary building block. Look at their paper for some pictures of how
this works, and also a more precise statement.

Next, by a general theorem on commutative Hopf algebras, we can think of
H as consisting of functions on some group \(G\), with pointwise
multiplication as the product in \(H\). Since elements of \(H\) are
linear combinations of Feynman diagrams, this means that any
\emph{point} of \(G\) gives a way to evaluate Feynman diagrams and get
numbers. The group \(G\) is an interesting sort of infinite-dimensional
Lie group which they study further in another paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Alain Connes and Dirk Kreimer, ``Renormalization in quantum field
  theory and the Riemann-Hilbert problem I: the beta-function,
  diffeomorphisms and the renormalization group'', \emph{Comm. Math.
  Phys.} \textbf{216} (2001), 215--241. Also available as
  \href{https://arxiv.org/abs/hep-th/0003188}{\texttt{hep-th/0003188}}.
\end{enumerate}

It may even deserve to be called the ``renormalization group'', which is
a piece of physics jargon that's been waiting for an interesting group
to come along\ldots{} but let's not worry about that now! All that
matters now is that each point in \(G\) gives a way to evaluate Feynman
diagrams.

Now, for any choice of values for all the parameters in our theory,
there's a simple recipe for evaluating Feynman diagrams. I won't explain
this recipe; it's one of those things you learn in any intro course on
quantum field theory. You could hope this recipe defines a point of
\(G\), but there's a catch: this recipe typically gives infinite
answers!

Luckily, using a trick called ``dimensional regularization'', one can
get finite answers if one analytically continues the dimension of
spacetime to any complex number \(z\) \emph{near} the actual dimension
\(d\). The infinities show up as a pole at \(z = d\). Connes and Kreimer
use this trick to get a map from a little circle around the point
\(z = d\) to the group \(G\). Let's call this map \[g\colon S^1 \to G\]
where \(S^1\) is the circle. Using some old ideas from complex analysis
(buzzword: the ``Riemann-Hilbert problem'') they write \(g\) as the
product of two maps \[g_+, g_-\colon S^1 \to G\] where \(g_+\) is
well-defined and analytic \emph{inside} the circle, and \(g_-\) is
well-defined and analytic \emph{outside}. The punchline is that
evaluating \(g_+\) at the point \(z = d\) we get a point in \(G\) which
gives the actual renormalized value of any Feynman diagram in our
theory!

For a bigger tour of Kreimer's ideas, try his book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Dirk Kreimer, \emph{Knots and Feynman Diagrams}, Cambridge University
  Press, Cambridge, 2000.
\end{enumerate}

Part of why Minhyong wanted to understand this stuff is that he also
invited Graeme Segal to the KIAS. Segal is one of the mathematical gurus
behind string theory, and he did some very important work on ``loop
groups'' --- maps from a circle into a group, made into a group by
pointwise multiplication:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Andrew Pressley and Graeme Segal, \emph{Loop Groups}, Oxford
  University Press, Oxford, 1986.
\end{enumerate}

The factorization of a map \(g\colon S^1 \to G\) into parts that are
analytic inside and outside the unit disk plays a big role in string
theory: it corresponds to taking certain 2d field theories called
Wess-Zumino-Witten models and splitting the solutions into left-moving
and right-moving modes. So, it's intriguing to find it also showing up
in renormalization theory.

Segal gave some talks on D-branes which I wish I had time to summarize.
One main point was that just as topological quantum field theories are
certain nice functors taking 2d cobordisms to linear operators,
topological quantum field theories ``with D-branes'' are certain nice
2-functors that know how to handle 2d cobordisms with corners. I can
only assume something similar is true of D-branes in conformal field
theory, where the cobordisms are equipped with a complex structure. He's
apparently writing a paper on this sort of thing with Gregory Moore,
which won't mention \(2\)-functors\ldots{} but us \(n\)-category
theorists know a \(2\)-functor when we see one!

Speaking of strings, my spies say everyone is raving about this new
paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  David Berenstein, Juan Maldacena and Horatiu Nastase, ``Strings in
  flat space and pp waves from \(N = 4\) Super Yang Mills'', available
  as
  \href{https://arxiv.org/abs/hep-th/0202021}{\texttt{hep-th/0202021}}.
\end{enumerate}

However, apart from this piece of gossip, I have very little to report!
Ask your local string theorist what it's all about.

Here's another cool paper Minhyong mentioned:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Yuri Manin and Matilde Marcolli, ``Holography principle and arithmetic
  of algebraic curves'', available as
  \href{https://arxiv.org/abs/hep-th/0201036}{\texttt{hep-th/0201036}}.
\end{enumerate}

It talks about Kirill Krasnov's extensive dictionary relating everything
about Riemann surfaces and 3d hyperbolic geometry to stuff about black
holes in 3d quantum gravity --- this is worth a Week in itself --- but
what really got my attention is that it develops a far-out analogy
between ``spacelike infinity'' in 3d quantum gravity and ``the prime at
infinity'' in algebra. Zounds!

Alas, I have to hit the sack now and catch some sleep before my morning
flight, or I would tell you more about this\ldots.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Not till we are lost \ldots{} do we begin to find ourselves and
realize where we are and the infinite extent of our relations.} ---
Henry David Thoreau



\hypertarget{week180}{%
\section{April 19, 2002}\label{week180}}

First, a news flash: they may have found a quark star\ldots{} or two!

In case you're wondering, a ``quark star'' is a hypothetical entity
smaller and denser than a neutron star, where the pressure is so high
that the neutrons get crushed into a mess of quarks. Nobody really knows
if this is possible without the darn thing collapsing all the way into a
black hole. However, if it happened, a bunch of the down quarks in the
neutron would turn into strange quarks, which are somewhat more massive,
but energetically favored nonetheless in situations like this where the
Pauli exclusion principle reigns supreme. Folks refer to this phenomenon
as ``strangeness enhancement''. It sounds like some sort of surgical
operation undergone by Michael Jackson, doesn't it? But anyway, for this
reason, quark stars are also known as ``strange stars''.

Back in \protect\hyperlink{week117}{``Week 117''} I described evidence
for strangeness enhancement in quark-gluon plasma experiments at
Brookhaven and elsewhere, but it would be really cool to see it in
nature. People have been looking for quark stars for some time, with no
success, but NASA has just announced the discovery of two entities that
\emph{might} be quark stars:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Cosmic X-rays reveal evidence for new form of matter,
  \texttt{http://www1.msfc.nasa.gov/NEWSROOM/news/releases/2002/02-082.html}
\end{enumerate}

The Chandra X-ray observatory (see \protect\hyperlink{week143}{``Week
143''} for info on this marvelous satellite) has seen two stars,
romantically entitled RXJ1856 and 3C58, that look sort of like neutron
stars\ldots{} but apparently too small or too cool to \emph{be} neutron
stars! There's always the possibility that something else is going on,
but folks are thinking they look like strange stars. Stay tuned.

Okay, now for some math. First some news on topos theory, and then I'll
return to the theme of \protect\hyperlink{week178}{``Week 178''}: Lie
groups and geometry\ldots{} leading up to a taste of twistors.

Peter Johnstone is a category theorist who can often be seen playing
backgammon in the common room of the Department of Pure Mathematics and
Mathematical Statistics at Cambridge University. He also selects the
wines at St.~Johns. But he must have been working dreadfully hard for
the last decade or so, because he's produced a book of mammoth
proportions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Peter Johnstone, \emph{Sketches of an Elephant: a Topos Theory
  Compendium}, Cambridge U. Press. Volume 1, comprising ``Part A:
  Toposes as Categories'', and ``Part B: \(2\)-categorical Aspects of
  Topos Theory'', 720 pages, to appear in June 2002. Volume 2,
  comprising ``Part C: Toposes as Spaces'', and ``Part D: Toposes as
  Theories'', 880 pages, to appear in June 2002. Volume 3, comprising
  ``Part E: Homotopy and Cohomology'', and ``Part F: Toposes as
  Mathematical Universes'', in preparation.
\end{enumerate}

I can't wait to dig into this. A topos is a kind of generalization of
the universe of set theory that we all know and love, but topos theory
is really a wonderful way to unify and generalize vast swathes of
mathematics --- you could say it's the way that logic and topology merge
when you take category theory seriously. I've really just begun to get a
glimmering of what it's all about, so I'm curious to see Johnstone's
overall view of the subject.

If you're wondering what a topos actually \emph{is}, and you're too
impatient to wait for Johnstone's books to come out, I suggest that you
start with my quick online summary:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  John Baez, ``Topos theory in a nutshell'',
  \texttt{http://math.ucr.edu/home/baez/topos.html}
\end{enumerate}

and then try the books I recommended in
\protect\hyperlink{week68}{``Week 68''}, along with this one:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Colin McLarty, \emph{Elementary Categories, Elementary Toposes},
  Oxford University Press, Oxford, 1992.
\end{enumerate}

which I only learned about later, when McLarty sent me a copy. I wish
I'd known about it much sooner: it's very nice! It starts with a great
tour of category theory, and then it covers a lot of topos theory,
ending with a bit on various special topics like the ``effective
topos'', which is a kind of mathematical universe where only effectively
describable things exist --- roughly speaking.

Now, in \protect\hyperlink{week178}{``Week 178''} I described some
things James Dolan and I were learning about Lie groups and geometry. In
the meantime we've learned so much that I sort of despair of conveying
it all\ldots{} beautiful, wonderful stuff! We're even beginning to
understand the theory of ``buildings'', which I had long considered an
impenetrable bastion of incomprehensibility.

But instead of rhapsodizing, let me dive in and explain as much as I
can. Last time I explained that every complex simple Lie group \(G\)
gives rise to a generalization of projective geometry. When we take
\(G=\mathrm{SL}(n,\mathbb{C})\) we get ordinary projective geometry, and
I focussed on this case, but I described how things work in general.
Today I want to dig a little deeper into the general theory then
consider a bunch of examples, leading up to Penrose's theory of
twistors.

First, remember how this game goes. Every complex simple Lie group \(G\)
has a bunch of maximal solvable subgroups, all basically the same as
each other --- so people pick one and call it ``the Borel subgroup'', or
\(B\) for short. When \(G = \mathrm{SL}(n,\mathbb{C})\) we can take
\(B\) to be the subgroup of upper triangular matrices. When doing
geometry with some symmetry group \(G\), any subgroup should be thought
of as the group of transformations that preserves some sort of
``figure'' --- some geometrical object. The importance of the Borel
subgroup is that it preserves a ``maximal flag''. For
\(G = \mathrm{SL}(n,\mathbb{C})\) acting on complex projective space,
this is just:

\begin{quote}
a point lying on a line lying on a plane lying on a \(3\)-space lying
on\ldots{}
\end{quote}

For other complex simple groups we'll get other concepts of ``maximal
flag'', which I'll describe later.

Having chosen a Borel subgroup \(B\), there is a finite set of subgroups
containing \(B\) and smaller than \(G\) --- people call these
``parabolic subgroups''. These preserve all the various smaller kinds of
flag, which in the \(\mathrm{SL}(n,\mathbb{C})\) case are things like

\begin{quote}
a point lying on a plane lying on a \(5\)-space
\end{quote}

or simply

\begin{quote}
a line
\end{quote}

For any parabolic subgroup \(P\), the quotient space \(G/P\) is called a
``flag manifold'', since it's the space of all flags of the given type.

The parabolics range in size from \(B\) to the ``maximal parabolic
subgroups''. The bigger the subgroup, the less it preserves, so the
maximal parabolics preserve the simplest flags, like ``a point'', ``a
line'', ``a plane'', and so on. In this case the flag manifold \(G/P\)
is usually called a ``Grassmannian''.

Now, the cool part is that you can read off the parabolic subgroups from
the Dynkin diagram of a simple Lie group: they correspond to subsets of
the dots! The maximal parabolics correspond to the dots themselves. For
\(\mathrm{SL}(n,\mathbb{C})\) it works like this\ldots{} I'll illustrate
with the case \(n = 4\): \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\bullet$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \node[label=below:{planes}] at (4,0) {$\bullet$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] So, to pick out a flag manifold, you just mark the dots you want. For
example, \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\times$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \node[label=below:{planes}] at (4,0) {$\times$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] gives the parabolic \(P\) such that \(\mathrm{SL}(4,\mathbb{C})/P\)
is the space of all ``points lying on a plane'' in \(\mathbb{CP}^3\). As
I explained earlier, this \(P\) is the subgroup of
\(\mathrm{SL}(4,\mathbb{C})\) consisting of all matrices of the form \[
  \left(
    \begin{array}{cccc}
      *&*&*&*
    \\0&*&*&*
    \\0&*&*&*
    \\0&0&0&*
    \end{array}
  \right)
\] If you look at the pictures in \protect\hyperlink{week178}{``Week
178''}, you should be able to figure out the recipe for getting this
subgroup from a subset of dots in the Dynkin diagram, at least in the
\(\mathrm{SL}(n,\mathbb{C})\) case.

Even better, this game lets you get all the finite-dimensional
irreducible representations of your complex simple group \(G\). I'll say
how it goes without explaining why it works. To get an irrep, just label
each Dynkin diagram dot with a natural number! The subset of dots
labelled by \emph{nonzero} numbers determines a parabolic subgroup
\(P\). The numbers themselves pick out a complex line bundle over
\(G/P\). The group \(G\) acts on \(G/P\), of course, and it also acts on
this line bundle. Now, \(G/P\) is always a complex manifold since \(G\)
and \(P\) are complex, so it makes sense to talk about
\emph{holomorphic} sections of this line bundle. The space of these
forms a finite-dimensional irrep of \(G\)!

To really understand this deeply, you should learn a bit about geometric
quantization. However, let's just assume it works and see what happens
in some examples.

First consider \(G = \mathrm{SL}(n,\mathbb{C})\). Here we've already
seen that the maximal parabolics are the subgroups preserving various
obvious figures in complex projective space: \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\bullet$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \node[label=below:{planes}] at (4,0) {$\bullet$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] The irrep corresponding to this numbering: \[
  \begin{tikzpicture}
    \node at (0,0) {$1$};
    \node at (2,0) {$0$};
    \node at (4,0) {$0$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] is the obvious representation of \(\mathrm{SL}(n,\mathbb{C})\) on
\(\mathbb{C}^n\). This irrep: \[
  \begin{tikzpicture}
    \node at (0,0) {$0$};
    \node at (2,0) {$1$};
    \node at (4,0) {$0$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] is the obvious rep of \(\mathrm{SL}(n,\mathbb{C})\) on the 2nd
exterior power of \(\mathbb{C}^n\) --- or in physics lingo, rank two
antisymmetric tensors. This irrep: \[
  \begin{tikzpicture}
    \node at (0,0) {$0$};
    \node at (2,0) {$0$};
    \node at (4,0) {$1$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] is the obvious rep of \(\mathrm{SL}(n,\mathbb{C})\) on the 3rd
exterior power of \(\mathbb{C}^n\). And so on, if there are more dots.
Note what we're really saying here: if you take the Grassmannian of all
\(j\)-dimensional subspaces in \(\mathbb{C}^n\), there's a god-given
complex line bundle on it whose space of holomorphic sections is the
\(j\)th exterior power of \(\mathbb{C}^n\).

In general, the irreps we get by labelling one dot with a \(1\) and the
rest with \(0\) are the most exciting: they're called the
``fundamental'' reps. In math jargon, they generate the representation
ring of \(G\). Even better, there's a simple recipe for taking a Dynkin
diagram with dots labelled by numbers and finding the corresponding
irrep inside a tensor product of symmetrized tensor powers of these
fundamental reps, where the numbers labelling the dots tell you which
powers to use. For \(\mathrm{SL}(n,\mathbb{C})\) this is just the theory
of Young diagrams, which I discussed in
\protect\hyperlink{week157}{``Week 157''}. So, we're just generalizing
the heck out of that.

Even if you don't understand what I just said, you can rest assured
knowing that we can completely master \emph{all} the irreps of \(G\)
once we figure out the fundamental ones. So, we'll focus on those.

We've more or less beat \(\mathrm{SL}(n,\mathbb{C})\) to death, so let's
see what happens with some other simple Lie groups\ldots{} for example,
the groups \(\mathrm{Spin}(n,\mathbb{C})\). If you don't know these
guys, first think about \(\mathrm{SO}(n,\mathbb{C})\). This is the group
of all linear transformations of \(\mathbb{C}^n\) preserving the
symmetric bilinear form \[x\cdot y = x_1 y_1 + \ldots + x_n y_n\]
Unfortunately \(\mathrm{SO}(n,\mathbb{C})\) is not simply connected, so
not all reps of its Lie algebra give reps of the group. So, to get group
representations from ways of labelling the Dynkin diagram by numbers, we
need to work with its double cover, the ``spin'' group
\(\mathrm{Spin}(n,\mathbb{C})\).

You may be more familiar with the compact real forms of these groups.
The compact real form of \(\mathrm{SO}(n,\mathbb{C})\) is the good old
rotation group in \(n\) dimensions, \(\mathrm{SO}(n)\). The compact real
form of \(\mathrm{Spin}(n,\mathbb{C})\) is the double cover of
\(\mathrm{SO}(n)\), called \(\mathrm{Spin}(n)\). The irreps of
\(\mathrm{Spin}(n,\mathbb{C})\) give unitary irreps of
\(\mathrm{Spin}(n)\), so you can think about them that way if you
prefer.

The Dynkin diagram of \(\mathrm{Spin}(n,\mathbb{C})\) looks really
different depending on whether \(n\) is even or odd. It takes a while
for the pattern to become clear --- it's obscured by lots of delightful
coincidences in low dimensions. I'll work through these low dimensions
and then say the general pattern. If you're the sort who can't stand
reading long lists of facts until you've seen the pattern they fit, jump
ahead to where I talk about \(\mathrm{Spin}(9,\mathbb{C})\) and
\(\mathrm{Spin}(10,\mathbb{C})\). I'm gonna climb my way up there
slowly, taking my time to smell the flowers.

The Dynkin diagram of \(\mathrm{Spin}(3,\mathbb{C})\) is just a single
dot: \[
  \bullet
\] just like the Dynkin diagram for \(\mathrm{SL}(2,\mathbb{C})\).
That's because they're isomorphic:
\[\mathrm{Spin}(3,\mathbb{C}) = \mathrm{SL}(2,\mathbb{C}).\] The
fundamental representation corresponding to the single dot in the Dynkin
diagram is called the ``spinor'' representation of
\(\mathrm{Spin}(3,\mathbb{C})\): it's just the obvious rep of
\(\mathrm{SL}(2,\mathbb{C})\) on \(\mathbb{C}^2\). This fact is crucial
for understanding spin-\(1/2\) particles in 3d space.

The Dynkin diagram of \(\mathrm{Spin}(4,\mathbb{C})\) is two dots, not
connected by an edge: \[
  \begin{tikzpicture}
    \node at (0,0) {$\bullet$};
    \node at (0,1.5) {$\bullet$};
  \end{tikzpicture}
\] just like the Dynkin diagram for
\(\mathrm{SL}(2,\mathbb{C})\times\mathrm{SL}(2,\mathbb{C})\). That's
because they're isomorphic:
\[\mathrm{Spin}(4,\mathbb{C}) = \mathrm{SL}(2,\mathbb{C})\times\mathrm{SL}(2,\mathbb{C}).\]
The fundamental reps coresponding to the two dots are called the
``left-handed'' and ``right-handed'' spinor representations of
\(\mathrm{Spin}(4,\mathbb{C})\): they're just the obvious reps of
\(\mathrm{SL}(2,\mathbb{C})\times\mathrm{SL}(2,\mathbb{C})\) on
\(\mathbb{C}^2\). This fact is crucial for understanding spin-\(1/2\)
particles in 4d spacetime.

The Dynkin diagram of \(\mathrm{Spin}(5,\mathbb{C})\) is two dots
connected by a double edge: \[
  \begin{tikzpicture}
    \draw[double,double equal sign distance] (0.5,0) to (1,0);
    \draw[double,double equal sign distance,-implies] (0,0) to (0.55,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
  \end{tikzpicture}
\] For an explanation of the double edge and the arrow see
\protect\hyperlink{week62}{``Week 62''} and
\protect\hyperlink{week64}{``Week 64''}, where I also explained that
this Dynkin diagram is the same as that of
\(\mathrm{Sp}(4,\mathbb{C})\), the group of transformations preserving a
symplectic structure on \(\mathbb{C}^4\). That's because these groups
are isomorphic:
\[\mathrm{Spin}(5,\mathbb{C}) = \mathrm{Sp}(4,\mathbb{C}).\] The
fundamental rep corresponding to the left dot in the Dynkin diagram
comes from the obvious rep of \(\mathrm{SO}(5,\mathbb{C})\) on
\(\mathbb{C}^5\) --- what physicists would call the ``vector'' rep. The
fundamental rep corresponding to the right dot comes from the obvious
rep of \(\mathrm{Sp}(4,\mathbb{C})\) on \(\mathbb{C}^4\) --- it's called
the ``spinor'' rep of \(\mathrm{Spin}(5,\mathbb{C})\). This would be
fundamental for studying spin-\(1/2\) particles in \(5\)-dimensional
spacetime if anyone were interested\ldots{} but not many people are.

The Dynkin diagram of \(\mathrm{Spin}(6,\mathbb{C})\) has three dots: \[
  \begin{tikzpicture}
    \node at (0,0) {$\bullet$};
    \node at (1,1) {$\bullet$};
    \node at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
  \end{tikzpicture}
\] This is the same as that of \(\mathrm{SL}(4,\mathbb{C})\), though
I've drawn it differently. That's because these groups are isomorphic:
\[\mathrm{Spin}(6,\mathbb{C}) = \mathrm{SL}(4,\mathbb{C}).\] The
fundamental rep corresponding to the left dot comes from the obvious rep
of \(\mathrm{SO}(6,\mathbb{C})\) on \(\mathbb{C}^6\) --- the ``vector''
rep again. The reps corresponding to the other dots are the left- and
right-handed spinor reps of \(\mathrm{Spin}(6,\mathbb{C})\), coming from
the obvious rep of \(\mathrm{SL}(4,\mathbb{C})\) on \(\mathbb{C}^4\) and
its dual. This is fundamental for understanding spin-\(1/2\) particles
in \(6\)-dimensional space --- for example, the 6 extra curled-up
dimensions in string theory. And as we'll see, it's also basic to
Penrose's theory of twistors!

At this point we're done with all the cute isomorphisms, so let us line
them up and admire them before bidding them farewell: \[
  \begin{aligned}
    \mathrm{Spin}(3,\mathbb{C}) &= \mathrm{SL}(2,\mathbb{C})
  \\\mathrm{Spin}(4,\mathbb{C}) &= \mathrm{SL}(2,\mathbb{C})\times\mathrm{SL}(2,\mathbb{C})
  \\\mathrm{Spin}(5,\mathbb{C}) &= \mathrm{Sp}(2,\mathbb{C})
  \\\mathrm{Spin}(6,\mathbb{C}) &= \mathrm{SL}(4,\mathbb{C}).
  \end{aligned}
\]

They give rise to isomorphisms of their maximal compact subgroups, so
let's say goodbye to those too: \[
  \begin{aligned}
    \mathrm{Spin}(3) &= \mathrm{SU}(2)
  \\\mathrm{Spin}(4) &= \mathrm{SU}(2)\times\mathrm{SU}(2)
  \\\mathrm{Spin}(5) &= \mathrm{Sp}(2)
  \\\mathrm{Spin}(6) &= \mathrm{SU}(4).
  \end{aligned}
\] Sometime we should return and learn to know them better\ldots{}
they've barely begun to display their many charms! But today we must
sail on to higher dimensions\ldots.

The Dynkin diagram of \(\mathrm{Spin}(7,\mathbb{C})\) has three dots: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \draw[double,double equal sign distance] (1.5,0) to (2,0);
    \draw[double,double equal sign distance,-implies] (1,0) to (1.55,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
  \end{tikzpicture}
\] The fundamental rep corresponding to the left dot comes from the
vector rep of \(\mathrm{SO}(7,\mathbb{C})\) on \(\mathbb{C}^7\). The rep
corresponding to the middle dot is the second exterior power of the
vector rep. The rep corresponding to the right dot is the spinor rep,
which is no longer so easy to describe without using Clifford algebras
--- see \protect\hyperlink{week93}{``Week 93''} or
\protect\hyperlink{week105}{``Week 105''} for more about those.

The Dynkin diagram of \(\mathrm{Spin}(8,\mathbb{C})\) has four dots: \[
  \begin{tikzpicture}
    \node at (-1,0) {$\bullet$};
    \node at (0,0) {$\bullet$};
    \node at (1,1) {$\bullet$};
    \node at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
    \draw[thick] (-1,0) to (0,0);
  \end{tikzpicture}
\] The fundamental rep corresponding to the left dot comes from the
vector rep of \(\mathrm{SO}(8,\mathbb{C})\) on \(\mathbb{C}^8\). The
middle dot corresponds to the second exterior power of the vector rep.
The top and bottom dots correspond to the left- and right-handed spinor
reps. Like the vector rep, these are also \(8\)-dimensional. This
coincidence arises from the symmetry of the diagram, which is called
``triality''.

I've said a lot about triality in \protect\hyperlink{week61}{``Week
61''}, \protect\hyperlink{week91}{``Week 91''} and elsewhere, but right
now it's just a distraction --- I'm trying to get you to see the pattern
of \(\mathrm{Spin}(n,\mathbb{C})\) Dynkin diagrams, and I'm hoping that
by now it's apparent: an alternation between odd and even dimensions,
and so on\ldots.

But just to be clear, let's look at \(\mathrm{SO}(n,\mathbb{C})\) for
\(n = 9\) and \(n = 10\), which illustrate the pattern even more
clearly. I'll also explain how how it's all related to incidence
geometry.

The Dynkin diagram of \(\mathrm{SO}(9,\mathbb{C})\) has \(4 = (9-1)/2\)
dots: \[
  \begin{tikzpicture}
    \draw[thick] (-1,0) to (1,0);
    \draw[double,double equal sign distance] (1.5,0) to (2,0);
    \draw[double,double equal sign distance,-implies] (1,0) to (1.55,0);
    \node at (-1,0) {$\bullet$};
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
  \end{tikzpicture}
\] The fundamental rep corresponding to the \(i\)th dot is the \(i\)th
exterior power of vector rep, \emph{except} for the last dot, which
corresponds to the spinor rep.

To see how the dots correspond to different types of geometrical figures
in some incidence geometry, first remember that we're starting with
\(\mathbb{C}^n\) equipped with a symmetric bilinear form:
\[x\cdot y = x_1 y_1 + \ldots + x_n y_n\] This is really different than
\(\mathbb{R}^n\) with its usual inner product, since it's perfectly
possible for a vector to have \(x\cdot x = 0\), and we can even get big
subspaces that are orthogonal to themselves. A subspace of
\(\mathbb{C}^n\) is called ``isotropic'' if all vectors in this subspace
are orthogonal to each other with respect to this form.

The idea of a subspace orthogonal to itself seems really weird at first!
If you've never thought about this, you should probably skip ahead to
the ``addendum'' at the end of this article, where I explain it in more
detail. It's closely related to the fact that lightlike vectors in
Minkowski spacetime are always orthogonal to themselves. In other words,
they have \(x\cdot x = 0\).

To construct an incidence geometry for \(\mathrm{SO}(n,\mathbb{C})\) and
make it as similar to projective geometry as possible, we work not with
\(\mathbb{C}^n\) but with the subspace of \(\mathbb{CP}^{n-1}\) coming
from vectors in \(\mathbb{C}^n\) with \(x\cdot x = 0\). Algebraic
geometers call this subspace a ``quadric''. In physics it arises
naturally from taking \((n-2)\)-dimensional Minkowski spacetime,
compactifying it in a certain way, and then complexifying it --- we'll
talk about this more later! Inside this quadric there are various types
of geometrical figures: \[
  \begin{tikzpicture}[scale=1.5]
    \draw[thick] (-1,0) to (1,0);
    \draw[double,double equal sign distance] (1.5,0) to (2,0);
    \draw[double,double equal sign distance,-implies] (1,0) to (1.55,0);
    \node[label=below:{points}] at (-1,0) {$\bullet$};
    \node[label={[label distance=-1mm]below:{null}}] at (0,0) {$\bullet$};
    \node at (0,-0.45) {lines};
    \node[label={[label distance=-1mm]below:{null}}] at (1,0) {$\bullet$};
    \node at (1,-0.47) {planes};
    \node[label={[label distance=-1mm]below:{null}}] at (2,0) {$\bullet$};
    \node at (2,-0.47) {$3$-spaces};
  \end{tikzpicture}
\] A ``point'' in the quadric is really a \(1\)-dimensional isotropic
subspace of \(\mathbb{C}^n\); a ``null line'' is a \(2\)-dimensional
isotropic subspace, and so on. We can talk about a point lying on a
line, or a line lying on a plane, and they mean the obvious things. This
gives the incidence geometry associated to
\(\mathrm{Spin}(n,\mathbb{C})\).

Putting together everything I've said so far: for \(n\) odd, the \(i\)th
dot in the Dynkin diagram of \(\mathrm{Spin}(n,\mathbb{C})\) corresponds
to a maximal parabolic \(P\) such that \(\mathrm{Spin}(n,\mathbb{C})/P\)
is the manifold consisting of all isotropic \(i\)-dimensional subspaces
in \(\mathbb{C}^n\) --- or in other words, all null \((i-1)\)-spaces in
the corresponding quadric. And this manifold, called an ``orthogonal
Grassmannian'', has a complex line bundle on it whose space of
holomorphic sections is the \(i\)th fundamental rep of
\(\mathrm{Spin}(n,\mathbb{C})\).

For \(n\) even, let's look at \(\mathrm{SO}(10,\mathbb{C})\).

The Dynkin diagram of \(\mathrm{SO}(10,\mathbb{C})\) has \(5 = 10/2\)
dots: \[
  \begin{tikzpicture}
    \node at (-2,0) {$\bullet$};
    \node at (-1,0) {$\bullet$};
    \node at (0,0) {$\bullet$};
    \node at (1,1) {$\bullet$};
    \node at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
    \draw[thick] (-2,0) to (0,0);
  \end{tikzpicture}
\] The fundamental rep corresponding to the \(i\)th dot is the \(i\)th
exterior power of the vector rep, \emph{except} for the last two dots,
which correspond to the left- and right-handed spinor reps.

In the language of incidence geometry, the dots again correspond to
different types of figures in a quadric: \[
  \begin{tikzpicture}[scale=1.5]
    \node[label=below:{points}] at (-2,0) {$\bullet$};
    \node[label={[label distance=-1mm]below:{null}}] at (-1,0) {$\bullet$};
    \node at (-1,-0.45) {lines};
    \node[label=right:{null planes}] at (0,0) {$\bullet$};
    \node[label=right:{left-handed $4$-spaces}] at (1,1) {$\bullet$};
    \node[label=right:{right-handed $4$-spaces}] at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
    \draw[thick] (-2,0) to (0,0);
  \end{tikzpicture}
\] The big difference from the odd-dimensional case is that there are
two kinds of spaces of the highest dimension listed, and we leave out
the next-highest dimension. In our example we get:

\begin{itemize}
\tightlist
\item
  \emph{points} in the quadric, which are \(1\)-dimensional isotropic
  subspaces of \(\mathbb{C}^{10}\)
\item
  \emph{null lines} in the quadric, which are \(2\)-dimensional
  isotropic subspaces of \(\mathbb{C}^{10}\)
\item
  \emph{null planes} in the quadric, which are \(3\)-dimensional
  isotropic subspaces of \(\mathbb{C}^{10}\)
\item
  \emph{left-handed \(4\)-spaces} in the quadric, which are left-handed
  \(5\)-dimensional subspaces of \(\mathbb{C}^{10}\)
\item
  \emph{right-handed \(4\)-spaces} in the quadric, which are
  right-handed \(5\)-dimensional subspaces of \(\mathbb{C}^{10}\)
\end{itemize}

But what are these left- and right-handed subspaces? The answer involves
the Hodge star operator, so if you don't know what that is, skip this
paragraph, because it will only make matters worse! Any oriented
\(p\)-dimensional subspace of \(\mathbb{C}^{10}\) determines a
\(p\)-form \(w\), namely its volume form. If you hit this with the Hodge
star operator, you get a \((10-p)\)-form \(*w\) which corresponds to the
orthogonal complement of your subspace. In particular, the Hodge star
operator maps \(5\)-forms to 5-forms, and satisfies \[** = -1\] This
means that its eigenvalues are \(i\) and \(-i\). Thus there are
``self-dual'' \(5\)-forms with \[*w = iw\] and ``anti-self-dual'' ones
with \[*w = -iw,\] which give two kinds of \(5\)-dimensional subspaces
of \(\mathbb{C}^{10}\) that are their own orthogonal complement: the
so-called ``right-handed'' and ``left-handed'' ones. There's nothing
special about the number 10 here; any even number \(n\) will do, though
we should leave out the factor of ``\(i\)'' in the above formulas when
\(n\) is a multiple of 4, since then the square of the Hodge star
operator on \(n/2\)-forms is \(1\) instead of \(-1\).

Okay, that pretty much concludes my story for
\(\mathrm{Spin}(n,\mathbb{C})\). I could do some other examples, but
we're probably both getting worn out; if you want, you can read about
them in section 23.3 of this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  William Fulton and Joe Harris, \emph{Representation Theory --- a First
  Course}, Springer Verlag, Berlin, 1991.
\end{enumerate}

So instead, let me conclude with a few remarks about twistors. taken
from here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Robert J. Baston and Michael G. Eastwood, \emph{The Penrose Transform:
  its Interaction with Representation Theory}, Clarendon Press, Oxford,
  1989.
\end{enumerate}

The field equations for massless particles like photons are conformally
invariant. The group \(\mathrm{SO}(2,4)\) acts as conformal
transformations of 4d Minkowski spacetime. To be precise, we should
admit that some of these are just partially defined, like conformal
inversion: \[x \mapsto \frac{x}{x\cdot x}\] However, they become
everywhere defined if we switch to a slightly bigger space, the
``conformal compactification'' of Minkowski spacetime.

The great realization of Roger Penrose was that it's nice to go even
further and \emph{complexify} this conformal compactification, getting a
\(4\)-dimensional complex manifold \(M\) with a \emph{complex} metric.
Minkowski spacetime sits inside this wonderful space \(M\) just like the
real line sits inside the Riemann sphere. A lot of physics becomes
easier on \(M\), just like a lot of math is easier to do on the Riemann
sphere than on the real line.

Now, since \(\mathrm{SO}(2,4)\) is a real form of
\(\mathrm{SO}(6,\mathbb{C})\), the whole group
\(\mathrm{SO}(6,\mathbb{C})\) acts as symmetries of \(M\). Of course the
double cover \(\mathrm{Spin}(6,\mathbb{C})\) also acts on \(M\), so
let's use that. Here's the cool part:
\[M = \mathrm{Spin}(6,\mathbb{C})/P\] where \(P\) is the maximal
parabolic corresponding to this dot on the Dynkin diagram for
\(\mathrm{Spin}(6,\mathbb{C})\): \[
  \begin{tikzpicture}
    \node at (0,0) {$\times$};
    \node at (1,1) {$\bullet$};
    \node at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
  \end{tikzpicture}
\] We've seen this diagram before. In the language of incidence
geometry, the dots correspond to different figures in a quadric: \[
  \begin{tikzpicture}
    \node[label=left:{points}] at (0,0) {$\bullet$};
    \node[label=right:{left-handed planes}] at (1,1) {$\bullet$};
    \node[label=right:{right-handed planes}] at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
  \end{tikzpicture}
\] so points of \(M\) are just points of this quadric!

If you unravel some of the definitions, this says that
\[M = \{\mbox{$1$-dimensional isotropic subspaces of $\mathbb{C}^6$}\},\]
so in physics lingo, \(M\) is the space of lightlike lines through the
origin in \(\mathbb{C}^6\)\ldots{} but remember, these are
\emph{complex} lines.

So far, this stuff actually works in any dimension: the space of
1-dimensional isotropic subspaces of \(\mathbb{C}^n\) is the same as
what you get by complexifying the conformal compactification of
\((n-2)\)-dimensional Minkowski spacetime, and so on.

But now we can use one of those charming coincidences:
\[\mathrm{Spin}(6,\mathbb{C}) = \mathrm{SL}(4,\mathbb{C})\] This means
we can also write \[M = \mathrm{SL}(4,\mathbb{C})/P\] where now we think
of \(P\) as a parabolic in \(\mathrm{SL}(4,\mathbb{C})\). Let's see what
\(M\) looks like in these terms. \(\mathrm{SL}(4,\mathbb{C})\) acts on
\(\mathbb{CP}^3\), and we've seen that the dots in the Dynkin diagram
for \(\mathrm{SL}(4,\mathbb{C})\) correspond to these different types of
geometrical figures in \(\mathbb{CP}^3\): \[
  \begin{tikzpicture}
    \node[label=left:{lines}] at (0,0) {$\bullet$};
    \node[label=right:{points}] at (1,1) {$\bullet$};
    \node[label=right:{planes}] at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
  \end{tikzpicture}
\] So, we get yet another description of our marvelous spacetime:
\[M = \{\mbox{lines in $\mathbb{CP}^3$}\}\] or if you prefer:
\[M = \{\mbox{$2$-dimensional subspaces of $\mathbb{C}^4$}\}\] Whew!
What's the point? Well, these descriptions of the complexification of
conformally compactified Minkowski spacetime let Penrose use incidence
geometry methods to solve conformally invariant field equations, like
Maxwell's equations or the Yang-Mills equations.

But what's a twistor? That's easy: it's just a spinor for
\(\mathrm{Spin}(6)\), either left-handed or right-handed. In other
words, twistors are the fundamental reps corresponding to these dots on
the Dynkin diagram: \[
  \begin{tikzpicture}
    \node at (0,0) {$\bullet$};
    \node[label=right:{left-handed twistors}] at (1,1) {$\bullet$};
    \node[label=right:{right-handed twistors}] at (1,-1) {$\bullet$};
    \draw[thick] (1,-1) to (0,0) to (1,1);
  \end{tikzpicture}
\] In the language of incidence geometry, these dots correspond to the
two sorts of null planes in \(M\). Penrose likes to think of these null
planes as more fundamental than points\ldots.

There's a lot more to say, but I'll stop here! If you want more, try
this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  S. A. Huggett and K.P. Tod, \emph{An Introduction to Twistor Theory},
  Cambridge U. Press, Cambridge, 1994.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Addendum:} Someone who prefers to remain anonymous asked me to
give some examples of ``isotropic'' subspaces of \(\mathbb{C}^n\). I
really should have done this earlier, because isotropic subspaces seem
very mysterious before you've seen them, but very simple afterwards.
They have a beautiful connection with special relativity, especially the
geometry of \emph{light}.

So, let me give some examples. But since complex numbers are weird,
let's start with \(\mathbb{R}^n\) equipped with a metric of some
signature or other, and look at the isotropic subspaces in there. An
isotropic subspace is just a vector subspace where all vectors are
orthogonal to each other. This is the same as a subspace in which all
vector have \(x\cdot x=0\) --- or in physics lingo, one where all
vectors are \emph{lightlike}.

For starters consider good old Minkowski space, \(\mathbb{R}^{3,1}\).
This has 3 space directions and 1 time direction, and it has a bunch of
\(1\)-dimensional isotropic subspaces. Why? Simple: these are just light
rays through the origin.

Are there any \(2\)-dimensional isotropic subspaces in Minkowski
spacetime? No! To find one of these, we'd need two light rays through
the origin that were orthogonal to each other. And this is impossible,
basically because all lightlike vectors have a nonzero time component.
To find two orthogonal light rays, we'd need to have two different time
directions!

So, in \(\mathbb{R}^{3,1}\) the biggest isotropic subspaces are
\(1\)-dimensional. But if we had a spacetime like \(\mathbb{R}^{2,2}\),
with two space directions and two time directions, we could find
\(2\)-dimensional isotropic subspaces. For example, if the metric on
\(\mathbb{R}^{2,2}\) looks like this:
\[(x,y,s,t)\cdot(x',y',s',t') = xx' + yy' - ss' - tt'\] then here are
two lightlike vectors that are orthogonal to each other:
\[(1,0,1,0) \quad\text{and}\quad (0,1,0,1).\]

Since they are orthogonal, every linear combination of them is lightlike
as well. So, these vectors span a 2d isotropic subspace.

Hopefully you get the picture now: to get an \(n\)-dimensional isotropic
subspace in \(\mathbb{R}^{p,q}\) we need at least \(n\) time dimensions
and at least \(n\) space dimensions. So, there will be isotropic
subspaces of dimensions going from zero on up to the \emph{minimum} of
\(p\) and \(q\).

Now we're ready to bring the complex numbers into the story! We can take
a real vector space with a metric on it and ``complexify'' it by letting
our vectors have complex coefficients instead of real ones, and using
the same formula for the metric. But the funny thing about
``complexifying'' is that it actually \emph{simplifies} things in
certain ways. Since \(i^2 = -1\), you can turn a vector from timelike to
lightlike or vice versa just by multiplying it by \(i\)! This means the
distinction between space and time isn't such a big deal anymore. In
particular, it doesn't matter how many space or time directions we had
to begin with; after complexifying them, all the spaces
\(\mathbb{R}^{p,q}\) look just like \(\mathbb{C}^n\) (\(n = p+q\)) with
the metric \[x\cdot y = x_1 y_1 + \ldots + x_n y_n\] In other words, all
these spaces \(\mathbb{R}^{p,q}\) are sitting inside \(\mathbb{C}^n\) as
different ``real parts''.

It's also easy to see that if we start with an isotropic subspace of
\(\mathbb{R}^{p,q}\), and take \emph{complex} linear combinations of the
vectors in that subspace, we get an isotropic subspace of
\(\mathbb{C}^n\). This means all the stuff we just learned about the
``real world'' has ramifications for the ``complex world''.

For example, we instantly know that \(\mathbb{C}^n\) has isotropic
subspaces of dimension up to the minimum of \(p\) and \(q\), where \(p\)
and \(q\) are \emph{any} numbers with \(p+q = n\). To get this minimum
as big as possible, we should take \(p = q = n/2\). Then we'll get
isotropic subspaces of dimensions going all the way up to \(n/2\). But
we can only do this when \(n\) is even! When \(n\) is odd, the best we
can do is \((n-1)/2\).

This shows that isotropic subspaces of \(\mathbb{C}^n\) work differently
depending on whether \(n\) is odd or even. I described this in more
detail above, where I separately treated \(\mathrm{SO}(n,\mathbb{C})\)
for \(n\) odd and \(n\) even.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Addendum:} Here are two posts on \texttt{sci.physics.research}
which address this mysterious fact: there's no dot in the Dynkin diagram
for \(\mathrm{SO}(2n,\mathbb{C})\) corresponding to the
\((n/2-1)\)-dimensional isotropic subspaces of \(\mathbb{C}^{2n}\), even
though there is one for every \emph{other} dimension from \(1\) to
\(n/2\).

\begin{quote}
From: James Dolan Subject: Re: This Week's Finds in Mathematical Physics
(Week 180) Date: Thu, 13 Jun 2002

marc bellon wrote:

\begin{quote}
John Baez writes:
\end{quote}

\begin{quote}
\begin{quote}
Borcis wrote:
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
John Baez wrote:
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
Boris Borcic wrote:
\end{quote}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
None of the diagrams for \(\mathbb{C}^n\), n even, shows an entry for
n/2-1 dimensional isotropic subspaces --- how should we read this fact ?
\end{quote}
\end{quote}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
\begin{quote}
I don't know what it means. Isotropic subspaces of this dimension
certainly exist, but for some reason the theory I am describing here
does not regard them as important. It's not an arbitrary decision on
anyone's part; it's built into the logic of the subject --- but I don't
understand it.
\end{quote}
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
\begin{quote}
No doubt a temporary phenomenon :)
\end{quote}
\end{quote}
\end{quote}

\begin{quote}
\begin{quote}
Let's hope so.
\end{quote}
\end{quote}

\begin{quote}
Let me propose an explanation. It is sufficient to consider the four
dimensional case. In the two-dimensional case, there are two isotropic
lines, one of which is self-dual and the other anti-self-dual, so that
the configuration is completely fixed, consistent with the abelian
character of \(\mathrm{SO}(2)\). Now when I choose an isotropic line is
\(\mathbb{C}^4\), its orthogonal is a three dimensional subspace which
contains it, so that the extension of the isotropic line to an isotropic
plane is equivalent to choosing an isotropic line in a two-dimensional
space. But in view of the two-dimensional case, no choice has to be
made, so that an isotropic line uniquely define two isotropic plane, one
self-dual, the other anti-self-dual. Reciprocally, a self-dual isotropic
plane and an anti-self-dual one evidently cannot coincide, but they
cannot either be complementary: in this case they are dual to each other
using the metric and are of the same self-duality.
\end{quote}

\begin{quote}
To give an isotropic line in \(\mathbb{C}^4\) is therefore equivalent to
give a pair of isotropic planes, one self-dual and the other
anti-self-dual. AFAIK, it is the property used in the twistor program of
Penrose: you parameterize the light rays (null lines) by the isotropic
planes it lies on. More generally, when considering \(\mathrm{SO}(2n)\),
you do not need to consider the \((n-1)\)-dimensional isotropic plane,
since they are uniquely defined by the combination of a self-dual
\(n\)-space and an anti-self dual one, if they have a
\((n-2)\)-dimensional space in common.
\end{quote}

this seems like a good explanation. extrapolating from this case, maybe
whenever we have a dynkin diagram corresponding to a particular sort of
incidence geometry, and a chosen dot in the diagram corresponding to a
particular sort of ``point'' in the geometry, then for any
``anti-chain'' in the dynkin diagram, the type of partial flag
corresponding to the anti-chain is uniquely determined by (and thus
representable as) the intersection of the subspaces in the partial flag.

thus in the case described by marc bellon, the dynkin diagram is a
``\(d\)'' series diagram such as \(d_5\): \[
  \begin{tikzpicture} 
    \node at (-2,0) {$\bullet$};
    \node at (-1,0) {$\bullet$};
    \node at (0,0) {$\bullet$};
    \node at (1,1) {$\bullet$};
    \node at (1,-1) {$\bullet$};
    \draw (1,-1) to (0,0) to (1,1);
    \draw (-2,0) to (0,0);
  \end{tikzpicture}
\] and the chosen dot (actually an asterisk in the above picture) is the
leftmost one. labeling the dots by letters and placing the chosen dot at
top we have: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (0,-2) to (1,-3);
    \draw[thick] (-1,-3) to (0,-2);
    \node[fill=white] at (0,0) {$a$};
    \node[fill=white] at (0,-1) {$b$};
    \node[fill=white] at (0,-2) {$c$};
    \node[fill=white] at (1,-3) {$d$};
    \node[fill=white] at (-1,-3) {$e$};
  \end{tikzpicture}
\] then \(a\) so-called ``anti-chain'' with respect to the partial order
``\(x\) is in more direct proximity to \(a\) than \(y\) is'' is a
dot-set \(s\) such that no member of \(s\) is subordinate to any other
member; thus for example \(\{\}\), \(\{b\}\), and \(\{d,e\}\) are
anti-chains but since \(e\) is subordinate to \(c\), \(\{c,e\}\) isn't
an anti-chain.

\(\{d,e\}\) is in fact the only anti-chain in the above partial order
with more than one dot. arranging the anti-chains in order from those
with a larger collection of subordinates to those with a smaller
collection, we have: \[
  \begin{tikzpicture}
    \draw[thick] (0,1) to (0,-2) to (1,-3) to (0,-4);
    \draw[thick] (0,-4) to (-1,-3) to (0,-2);
    \node[fill=white] at (0,1) {$\{a\}$};
    \node[fill=white] at (0,0) {$\{b\}$};
    \node[fill=white] at (0,-1) {$\{c\}$};
    \node[fill=white] at (0,-2) {$\{d,e\}$};
    \node[fill=white] at (1,-3) {$\{d\}$};
    \node[fill=white] at (-1,-3) {$\{e\}$};
    \node[fill=white] at (0,-4) {$\{\}$};
  \end{tikzpicture}
\] now for each anti-chain we can try to calculate the dimension of the
intersection of all of the subspaces in a partial flag of the type
corresponding to the anti-chain (that is, containing one subspace of
each type corresponding to a dot in the anti-chain). according to marc
bellon we get these dimensions: \[
  \begin{tikzpicture}
    \draw[thick] (0,1) to (0,-2) to (1,-3) to (0,-4);
    \draw[thick] (0,-4) to (-1,-3) to (0,-2);
    \node[fill=white] at (0,1) {$0$};
    \node[fill=white] at (0,0) {$1$};
    \node[fill=white] at (0,-1) {$2$};
    \node[fill=white] at (0,-2) {$3$};
    \node[fill=white] at (1,-3) {$4$};
    \node[fill=white] at (-1,-3) {$4$};
    \node[fill=white] at (0,-4) {$8$};
  \end{tikzpicture}
\] and this more or less explains the mystery which boris borcic and
john baez were discussing, as to why it seemed at first that
\(3\)-dimensional subspaces play no interesting role in the incidence
geometry of the \(d_5\) dynkin diagram (and correspondingly for other
``\(d\)'' series diagrams): it turns out that \(3\)-dimensional
subspaces \emph{do} play an interesting role here, but they're related
to a multi-dot anti-chain in the dynkin diagram instead of to a single
dot. the importance of anti-chains here comes as a bit of a surprise if
your intuition about incidence geometry is based on classical projective
geometry, where the dynkin diagram is in the ``\(a\)'' series and the
chosen dot is an end-dot, because in that case there are no multi-dot
anti-chains.

now we can take an arbitrary dynkin diagram and an arbitrary chosen dot
in it and try to calculate for the corresponding incidence geometry the
dimensions of the types of subspaces corresponding to the anti-chains in
the partial order, making some optimistic assumptions. consider for
example the dynkin diagram \(e_7\): \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (5,0);
    \draw[thick] (2,0) to (2,1);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
    \node at (3,0) {$\bullet$};
    \node at (4,0) {$\bullet$};
    \node at (5,0) {$\bullet$};
    \node at (2,1) {$\bullet$};
  \end{tikzpicture}
\] with the rightmost dot as the chosen dot. then we have: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (0,-3) to (-1,-4);
    \draw[thick] (0,-3) to (1,-4) to (1,-5);
    \node[fill=white] at (0,0) {$a$};
    \node[fill=white] at (0,-1) {$b$};
    \node[fill=white] at (0,-2) {$c$};
    \node[fill=white] at (0,-3) {$d$};
    \node[fill=white] at (-1,-4) {$e$};
    \node[fill=white] at (1,-4) {$f$};
    \node[fill=white] at (1,-5) {$g$};
  \end{tikzpicture}
\] and the anti-chains for the partial order are: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (0,-4) to (-1,-5) to (0,-6) to (1,-7);
    \draw[thick] (0,-4) to (1,-5) to (0,-6);
    \draw[thick] (1,-5) to (2,-6) to (1,-7);
    \node[fill=white] at (0,0) {$\{a\}$};
    \node[fill=white] at (0,-1) {$\{b\}$};
    \node[fill=white] at (0,-2) {$\{c\}$};
    \node[fill=white] at (0,-3) {$\{d\}$};
    \node[fill=white] at (0,-4) {$\{e,f\}$};
    \node[fill=white] at (-1,-5) {$\{f\}$};
    \node[fill=white] at (1,-5) {$\{e,g\}$};
    \node[fill=white] at (0,-6) {$\{g\}$};
    \node[fill=white] at (2,-6) {$\{e\}$};
    \node[fill=white] at (1,-7) {$\{\}$};
  \end{tikzpicture}
\] using an optimistic method of calculation related to methods
mentioned by john baez in some previous posts in this thread but not
really explained there either, we obtain for the dimensions of the
corresponding types of subspace: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (0,-4) to (-1,-5) to (0,-6) to (1,-7);
    \draw[thick] (0,-4) to (1,-5) to (0,-6);
    \draw[thick] (1,-5) to (2,-6) to (1,-7);
    \node[fill=white] at (0,0) {$0$};
    \node[fill=white] at (0,-1) {$1$};
    \node[fill=white] at (0,-2) {$2$};
    \node[fill=white] at (0,-3) {$3$};
    \node[fill=white] at (0,-4) {$4$};
    \node[fill=white] at (-1,-5) {$5$};
    \node[fill=white] at (1,-5) {$5$};
    \node[fill=white] at (0,-6) {$10$};
    \node[fill=white] at (2,-6) {$6$};
    \node[fill=white] at (1,-7) {$27$};
  \end{tikzpicture}
\] so that's what this calculation predicts: that \(e_7\) geometry
involves a compact \(27\)-dimensional manifold of ``points'', with types
of special subspaces of dimensions 1, 2, 3, 4, 6, and 10, plus two
different types of special subspaces of dimension 5. the special
\(4\)-dimensional subspaces and one of the types of special
\(5\)-dimensional subspaces are evidently of ``anti-chain'' type. i'd be
interested to know whether \(e_7\) geometry has ever been described
along these lines, or more generally whether special subspaces of the
``anti-chain'' type have been studied or at least noticed, beyond the
cases described by marc bellon.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\begin{quote}
From: James Dolan Subject: Re: This Week's Finds in Mathematical Physics
(Week 180) Date: Sat, 15 Jun 2002

i wrote: \textgreater{} now we can take an arbitrary dynkin diagram and
an arbitrary chosen \textgreater{} dot in it and try to calculate for
the corresponding incidence \textgreater{} geometry the dimensions of
the types of subspaces corresponding to the \textgreater{} anti-chains
in the partial order, making some optimistic assumptions. \textgreater{}
consider for example the dynkin diagram \(e_7\): \textgreater{} \[
>   \begin{tikzpicture}
>     \draw[thick] (0,0) to (5,0);
>     \draw[thick] (2,0) to (2,1);
>     \node at (0,0) {$\bullet$};
>     \node at (1,0) {$\bullet$};
>     \node at (2,0) {$\bullet$};
>     \node at (3,0) {$\bullet$};
>     \node at (4,0) {$\bullet$};
>     \node at (5,0) {$\bullet$};
>     \node at (2,1) {$\bullet$};
>   \end{tikzpicture}
> \] \textgreater{} with the rightmost dot as the chosen dot. then we
have: \textgreater{} \[
>   \begin{tikzpicture}
>     \draw[thick] (0,0) to (0,-3) to (-1,-4);
>     \draw[thick] (0,-3) to (1,-4) to (1,-5);
>     \node[fill=white] at (0,0) {$a$};
>     \node[fill=white] at (0,-1) {$b$};
>     \node[fill=white] at (0,-2) {$c$};
>     \node[fill=white] at (0,-3) {$d$};
>     \node[fill=white] at (-1,-4) {$e$};
>     \node[fill=white] at (1,-4) {$f$};
>     \node[fill=white] at (1,-5) {$g$};
>   \end{tikzpicture}
> \] \textgreater{} and the anti-chains for the partial order are:
\textgreater{} \[
>   \begin{tikzpicture}
>     \draw[thick] (0,0) to (0,-4) to (-1,-5) to (0,-6) to (1,-7);
>     \draw[thick] (0,-4) to (1,-5) to (0,-6);
>     \draw[thick] (1,-5) to (2,-6) to (1,-7);
>     \node[fill=white] at (0,0) {$\{a\}$};
>     \node[fill=white] at (0,-1) {$\{b\}$};
>     \node[fill=white] at (0,-2) {$\{c\}$};
>     \node[fill=white] at (0,-3) {$\{d\}$};
>     \node[fill=white] at (0,-4) {$\{e,f\}$};
>     \node[fill=white] at (-1,-5) {$\{f\}$};
>     \node[fill=white] at (1,-5) {$\{e,g\}$};
>     \node[fill=white] at (0,-6) {$\{g\}$};
>     \node[fill=white] at (2,-6) {$\{e\}$};
>     \node[fill=white] at (1,-7) {$\{\}$};
>   \end{tikzpicture}
> \] \textgreater{} using an optimistic method of calculation related to
methods \textgreater{} mentioned by john baez in some previous posts in
this thread but not \textgreater{} really explained there either, we
obtain for the dimensions of the \textgreater{} corresponding types of
subspace: \textgreater{} \[
>   \begin{tikzpicture}
>     \draw[thick] (0,0) to (0,-4) to (-1,-5) to (0,-6) to (1,-7);
>     \draw[thick] (0,-4) to (1,-5) to (0,-6);
>     \draw[thick] (1,-5) to (2,-6) to (1,-7);
>     \node[fill=white] at (0,0) {$0$};
>     \node[fill=white] at (0,-1) {$1$};
>     \node[fill=white] at (0,-2) {$2$};
>     \node[fill=white] at (0,-3) {$3$};
>     \node[fill=white] at (0,-4) {$4$};
>     \node[fill=white] at (-1,-5) {$5$};
>     \node[fill=white] at (1,-5) {$5$};
>     \node[fill=white] at (0,-6) {$10$};
>     \node[fill=white] at (2,-6) {$6$};
>     \node[fill=white] at (1,-7) {$27$};
>   \end{tikzpicture}
> \] \textgreater{} so that's what this calculation predicts: that
\(e_7\) geometry \textgreater{} involves a compact \(27\)-dimensional
manifold of ``points'', with types of \textgreater{} special subspaces
of dimensions 1, 2, 3, 4, 6, and 10, plus two \textgreater{} different
types of special subspaces of dimension 5. the special \textgreater{}
\(4\)-dimensional subspaces and one of the types of special
\(5\)-dimensional \textgreater{} subspaces are evidently of
``anti-chain'' type.

having thought about it some more, i now think that we can give much
more specific information about the nature of the geometry here, and in
a much simpler way.

given a dotted dynkin diagram, this time for example say: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (6,0);
    \draw[thick] (2,0) to (2,1);
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (3,0) {$*$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (5,0) {$g$};
    \node[fill=white] at (6,0) {$h$};
    \node[fill=white] at (2,1) {$a$};
  \end{tikzpicture}
\] we can consider the partially ordered set of all connected
sub-diagrams including the chosen dot, in this case: \[\bullet\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (1,0) {$\bullet$};
    \node[fill=white] at (0,0) {$d$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$f$};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,1) to (0,0) to (1,0);
    \node at (1,0) {$\bullet$};
    \node[fill=white] at (0,0) {$d$};
    \node[fill=white] at (0,1) {$a$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] to (0,0) to (2,0);
    \node at (2,0) {$\bullet$};
    \node[fill=white] at (0,0) {$c$};
    \node[fill=white] at (1,0) {$d$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] to (0,0) to (2,0);
    \node at (1,0) {$\bullet$};
    \node[fill=white] at (0,0) {$d$};
    \node[fill=white] at (2,0) {$f$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] to (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$f$};
    \node[fill=white] at (2,0) {$g$};
  \end{tikzpicture}
\] \[
  \begin{gathered}
    \begin{tikzpicture}
      \draw[thick] (0,0) to (2,0);
      \draw[thick] (1,0) to (1,1);
      \node at (2,0) {$\bullet$};
      \node[fill=white] at (0,0) {$c$};
      \node[fill=white] at (1,0) {$d$};
      \node[fill=white] at (1,1) {$a$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (3,0);
      \node at (3,0) {$\bullet$};
      \node[fill=white] at (0,0) {$b$};
      \node[fill=white] at (1,0) {$c$};
      \node[fill=white] at (2,0) {$d$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (2,0);
      \draw[thick] (0,0) to (0,1);
      \node at (1,0) {$\bullet$};
      \node[fill=white] at (0,0) {$d$};
      \node[fill=white] at (2,0) {$f$};
      \node[fill=white] at (0,1) {$a$};
    \end{tikzpicture}
  \\
    \begin{tikzpicture}
      \draw[thick] (0,0) to (3,0);
      \node at (2,0) {$\bullet$};
      \node[fill=white] at (0,0) {$c$};
      \node[fill=white] at (1,0) {$d$};
      \node[fill=white] at (3,0) {$f$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (3,0);
      \node at (1,0) {$\bullet$};
      \node[fill=white] at (0,0) {$d$};
      \node[fill=white] at (2,0) {$f$};
      \node[fill=white] at (3,0) {$g$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (3,0);
      \node at (0,0) {$\bullet$};
      \node[fill=white] at (1,0) {$f$};
      \node[fill=white] at (2,0) {$g$};
      \node[fill=white] at (3,0) {$h$};
    \end{tikzpicture}
  \end{gathered}
\] \[
  \begin{gathered}
    \begin{tikzpicture}
      \draw[thick] (0,0) to (3,0);
      \draw[thick] (2,0) to (2,1);
      \node at (3,0) {$\bullet$};
      \node[fill=white] at (0,0) {$b$};
      \node[fill=white] at (1,0) {$c$};
      \node[fill=white] at (2,0) {$d$};
      \node[fill=white] at (2,1) {$a$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (3,0);
      \draw[thick] (1,0) to (1,1);
      \node at (2,0) {$\bullet$};
      \node[fill=white] at (0,0) {$c$};
      \node[fill=white] at (1,0) {$d$};
      \node[fill=white] at (3,0) {$f$};
      \node[fill=white] at (1,1) {$a$};
    \end{tikzpicture}
  \\
    \begin{tikzpicture}
      \draw[thick] (0,0) to (4,0);
      \node at (3,0) {$\bullet$};
      \node[fill=white] at (0,0) {$b$};
      \node[fill=white] at (1,0) {$c$};
      \node[fill=white] at (2,0) {$d$};
      \node[fill=white] at (4,0) {$f$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (4,0);
      \node at (2,0) {$\bullet$};
      \node[fill=white] at (0,0) {$c$};
      \node[fill=white] at (1,0) {$d$};
      \node[fill=white] at (3,0) {$f$};
      \node[fill=white] at (4,0) {$g$};
    \end{tikzpicture}
    \qquad
    \begin{tikzpicture}
      \draw[thick] (0,0) to (4,0);
      \node at (1,0) {$\bullet$};
      \node[fill=white] at (0,0) {$d$};
      \node[fill=white] at (2,0) {$f$};
      \node[fill=white] at (3,0) {$g$};
      \node[fill=white] at (4,0) {$h$};
    \end{tikzpicture}
  \end{gathered}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (4,0);
    \draw[thick] (2,0) to (2,1);
    \node at (3,0) {$\bullet$};
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (2,1) {$a$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (4,0);
    \draw[thick] (1,0) to (1,1);
    \node at (2,0) {$\bullet$};
    \node[fill=white] at (0,0) {$c$};
    \node[fill=white] at (1,0) {$d$};
    \node[fill=white] at (3,0) {$f$};
    \node[fill=white] at (4,0) {$g$};
    \node[fill=white] at (1,1) {$a$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (5,0);
    \node at (3,0) {$\bullet$};
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (5,1) {$g$};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (5,0);
    \draw[thick] (2,0) to (2,1);
    \node at (3,0) {$\bullet$};
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (5,0) {$g$};
    \node[fill=white] at (2,1) {$a$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (5,0);
    \draw[thick] (1,0) to (1,1);
    \node at (2,0) {$\bullet$};
    \node[fill=white] at (0,0) {$c$};
    \node[fill=white] at (1,0) {$d$};
    \node[fill=white] at (3,0) {$f$};
    \node[fill=white] at (4,0) {$g$};
    \node[fill=white] at (5,0) {$h$};
    \node[fill=white] at (1,1) {$a$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (6,0);
    \node at (3,0) {$\bullet$};
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (5,0) {$g$};
    \node[fill=white] at (6,0) {$h$};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (6,0);
    \draw[thick] (2,0) to (2,1);
    \node at (3,0) {$\bullet$};
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (5,0) {$g$};
    \node[fill=white] at (6,0) {$h$};
    \node[fill=white] at (2,1) {$a$};
  \end{tikzpicture}
\] then each sub-diagram in the partial order can be interpreted as a
type of special subspace of the space of points in the \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (6,0);
    \draw[thick] (2,0) to (2,1);
    \node[fill=white] at (0,0) {$b$};
    \node[fill=white] at (1,0) {$c$};
    \node[fill=white] at (2,0) {$d$};
    \node[fill=white] at (3,0) {$*$};
    \node[fill=white] at (4,0) {$f$};
    \node[fill=white] at (5,0) {$g$};
    \node[fill=white] at (6,0) {$h$};
    \node[fill=white] at (2,1) {$a$};
  \end{tikzpicture}
\] geometry, with the partial order (not completely explicit in the
above picture) indicating the containment relationships between the
subspaces in a complete so-called ``flag'' configuration, including
subspaces generated by intersection from the ``principal'' subspaces in
the flag. furthermore, intersection of sub-diagrams corresponds
perfectly to intersection of subspaces in the flag.

thus in this case the space of points of the geometry contains special
subspaces that look like projective lines (since \[\bullet\] is the
dotted dynkin diagram for projective line geometry), two kinds of
special subspaces that look like projective planes (since \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (1,0) {$\bullet$};
    \node[fill=white] at (0,0) {$d$};
  \end{tikzpicture}
\] and \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$f$};
  \end{tikzpicture}
\] are slightly different ways of drawing the dotted dynkin diagram for
projective plane geometry), three kinds of subspaces that look like
projective \(3\)-spaces (since \[
  \begin{tikzpicture}
    \draw[thick] (0,1) to (0,0) to (1,0);
    \node at (1,0) {$\bullet$};
    \node[fill=white] at (0,1) {$a$};
    \node[fill=white] at (0,0) {$d$};
  \end{tikzpicture}
\] and \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
    \node at (2,0) {$\bullet$};
    \node[fill=white] at (0,0) {$c$};
    \node[fill=white] at (1,0) {$d$};
  \end{tikzpicture}
\] and \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$f$};
    \node[fill=white] at (2,0) {$g$};
  \end{tikzpicture}
\] are isomorphic to the dotted dynkin diagram for projective
\(3\)-space geometry), and so forth. since the \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (1,0) {$\bullet$};
    \node[fill=white] at (0,0) {$d$};
  \end{tikzpicture}
\] sub-diagram and the \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$f$};
  \end{tikzpicture}
\] sub-diagrams intersect in \[\bullet\] the intersection of special
projective planes of the two different types will be a special
projective line if the two special projective planes lie in a single
flag. and so forth.

(one minor defect in this treatment is that the semi-lattice of
connected sub-diagrams containing the chosen dot needs to be
supplemented by one extra element at the top to account for the
singleton subspaces of the geometry; i'm not going to worry about that
for now.)
\end{quote}

\begin{quote}
now let's return to the example discussed by marc bellon. we have a
\(d\)-series dynkin diagram dotted at the boring end, thus for example
\(d_5\): \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,1);
    \draw[thick] (2,0) to (3,-1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,1) {$d$};
    \node[fill=white] at (3,-1) {$e$};
  \end{tikzpicture}
\] the semi-lattice of connected sub-diagrams containing the chosen dot
is: \[\bullet\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,1) {$d$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,-1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,-1) {$e$};
  \end{tikzpicture}
\] \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,1);
    \draw[thick] (2,0) to (3,-1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,1) {$d$};
    \node[fill=white] at (3,-1) {$e$};
  \end{tikzpicture}
\] we see that a flag in this geometry includes a projective line
corresponding to \[\bullet\] a larger projective plane corresponding to
\[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
  \end{tikzpicture}
\] a larger projective \(3\)-space corresponding to \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
  \end{tikzpicture}
\] two larger projective \(4\)-spaces corresponding to \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,1) {$d$};
  \end{tikzpicture}
  \qquad
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,-1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,-1) {$e$};
  \end{tikzpicture}
\] whose intersection is the projective \(3\)-space, and finally the
space of all points in the geometry, corresponding to \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0) to (3,1);
    \draw[thick] (2,0) to (3,-1);
    \node at (0,0) {$\bullet$};
    \node[fill=white] at (1,0) {$b$};
    \node[fill=white] at (2,0) {$c$};
    \node[fill=white] at (3,1) {$d$};
    \node[fill=white] at (3,-1) {$e$};
  \end{tikzpicture}
\] since the projective \(3\)-space appears as the intersection of the
two projective \(4\)-spaces, it's in some sense redundant and thus not
one of the ``principal'' subspaces in the flag. but it's there
nevertheless, thus more or less resolving boris borcic's mystery of the
missing isotropic subspace.
\end{quote}

\begin{quote}
this all seems simple enough (in principle) now that it must be
well-known, but i don't know where it might be discussed in reasonably
plain language.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{If you want to get a view of the world you live in, climb a little
rocky mountain with a neat small peak. But the big snowpeaks pierce the
world of clouds and cranes, rest in the zone of five colored banners and
writhing crackling dragons in veils of ragged mist and frost crystals,
into a pure transparency of blue.} --- Gary Snyder



\hypertarget{week181}{%
\section{May 1, 2002}\label{week181}}

At the beginning of April I went up to Mathematical Sciences Research
Institute in Berkeley to a conference on \(n\)-categories and nonabelian
Hodge theory, which I should tell you about sometime\ldots{} but the
very first thing I did is take a detour and give a talk at the
University of California at Santa Cruz.

U. C. Santa Cruz has a beautiful campus, with enormous rolling grassy
fields and redwood groves. And indeed it must be pretty idyllic there,
because the main thing the students used to complain about was that the
courses \emph{aren't graded} --- which makes it harder for them to get
jobs when they leave this paradise. I think grades are being phased in
now. Too bad!

Anyway, I wound up talking a lot to Richard Montgomery, who teaches in
the math department and works on the gravitational 3-body problem.
Except when one mass is much smaller than the other two --- see my
discussion of Lagrange points in \protect\hyperlink{week150}{``Week
150''} --- this problem is still packed with mysteries! Montgomery and
other have turned their attention to the case where all 3 masses are
equal and proved there exist solutions with amazing properties: for
example, one where the total angular momentum is zero and all 3 masses
chase each other around a figure-8-shaped curve!

For details, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Alain Chenciner and Richard Montgomery, ``A remarkable periodic
  solution of the three-body problem in the case of equal masses'',
  \emph{Ann. of Math.} \textbf{152} (2000), 881--901. Also available as
  \href{https://arxiv.org/abs/math.DS/0011268}{\texttt{math.DS/0011268}}.
\end{enumerate}

For a more popular account see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Richard Montgomery, ``A new solution to the three-body problem'',
  \emph{AMS Notices} \textbf{48} (May 2001), 471--481. Also available as
  \texttt{http://www.ams.org/notices/200105/fea-montgomery.pdf}
\end{enumerate}

and for Java applets illustrating this and other solutions based on
computer simulations by Carles Simo, try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Bill Casselman, ``A new solution to the three body problem --- and
  more'', at \texttt{http://www.ams.org/new-in-math/cover/orbits1.html}
\end{enumerate}

There are lots of other unsolved puzzles concerning point particles
interacting via Newtonian gravity. They're not very practical, but
they're lots of fun!

For example, can we find a periodic orbit where N particles move around
in the plane and trace out an arbitrary desired \emph{braid?} For
strongly attractive potentials like \(-1/r^a\) where \(a\) is greater
than or equal to \(2\), the answer is ``yes'' --- this is not hard to
prove by variational methods. However, the question remains largely open
for gravity, where \(a = 1\). See:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\item
  Cristopher Moore, ``Braids in classical gravity'', \emph{Phys.
  Rev.~Lett.} \textbf{70} (1993), 3675--3679. Also available at
  \texttt{http://www.santafe.edu/media/workingpapers/92-07-034.pdf}

  Cristopher Moore, ``The 3-body (and \(n\)-body) problem'',
  \texttt{http://www.santafe.edu/\textasciitilde{}moore/gallery.html}
\end{enumerate}

In fact, Cris Moore first discovered the figure-8 solution of the
gravitational 3-body problem in his 1993 paper, using computer
calculations. His student Michael Nauenberg made this movie of it, which
you can find with many others on Moore's website:

\[\includegraphics{../images/cris_moore_figure8.png}\]

Also see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Richard Montgomery, ``The \(N\)-body problem, the braid group, and
  action-minimizing periodic solutions'', \emph{Nonlinearity}
  \textbf{11} (1998), 363--371. Also available at
  \texttt{http://count.ucsc.edu/\textasciitilde{}rmont/papers/NbdyBraids.pdf}
\end{enumerate}

There is also the issue of whether a particle can shoot off to infinity
in a finite amount of time. Of course this isn't possible in the real
world, but Newtonian physics has no ``speed limit'', and we're
idealizing our particles as points. So, if two or more of them get
arbitrarily close to each other, the potential energy they liberate
could in principle give another particle enough kinetic energy to zip
off to infinity! Then our solution becomes undefined after a finite
amount of time.

Zhihong Xia showed this can actually happen in the \(N\)-body problem
for \(N = 5\) or bigger:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Zhihong Xia, ``The existence of non-collision singularities in
  Newtonian systems'', \emph{Ann. Math.} \textbf{135} (1992), 411--468.
\end{enumerate}

or for a more popular account:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Donald G. Saari and Zhihong Xia, ``Off to infinity in finite time'',
  \emph{AMS Notices} (May 1995), 538--546. Also available at
  \texttt{http://www.ams.org/notices/199505/saari-2.pdf}
\end{enumerate}

As far as I know, the question is still open for \(N = 4\). Another
question concerns how \emph{likely} it is for our solution to become
undefined in a finite amount of time. If it's infinitely improbable, we
say we have ``asymptotic completeness'' for the \(N\)-body problem. I
seem to recall that the \(N\)-body problem has been shown asymptotically
complete for \(N = 3\), but not higher \(N\).

Now --- back to my tale of Lie groups and geometry!

So far I've talked about how to any complex simple Lie group \(G\) we
can associate an ``incidence geometry'': a generalization of projective
geometry having \(G\) as its symmetry group. Each different type of
``figure'' in this geometry corresponds to a dot in the Dynkin diagram
for \(G\). For example, when \(G = \mathrm{SL}(4,\mathbb{C})\) we have
\[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\bullet$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \node[label=below:{planes}] at (4,0) {$\bullet$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] For each dot, the space of all figures of the corresponding type is
called a ``Grassmannian'', and it's a manifold of the form G/P, where P
is a ``maximal parabolic'' subgroup of G.

More generally, any subset of dots in the Dynkin diagram corresponds to
a type of ``flag''. A flag is a collection of figures satisfying certain
incidence relations. For example, this subset: \[
  \begin{tikzpicture}
    \node[label=below:{points}] at (0,0) {$\times$};
    \node[label=below:{lines}] at (2,0) {$\bullet$};
    \node[label=below:{planes}] at (4,0) {$\times$};
    \draw[thick] (0,0) to (4,0);
  \end{tikzpicture}
\] corresponds to the type of flag consisting of a point lying on a
plane. The space of all flags of a particular type is called a ``flag
manifold'', and it's a manifold of the form \(G/P\), where \(P\) is a
``parabolic'' subgroup of \(G\).

I also said a bit about how we can quantize this entire story! This is
actually what got me interested in this whole business. In loop quantum
gravity we run around claiming that space is made of quantum triangles,
quantum tetrahedra and the like --- see
\protect\hyperlink{week113}{``Week 113''} and
\protect\hyperlink{week134}{``Week 134''} if you don't believe me. The
whole theory emerges naturally from the way Euclidean and Lorentzian
geometry are related to representations of the rotation and Lorentz
groups, but it got me wondering how the story would change if we changed
the group to something fancier --- as we might in a theory that tried to
unify gravity with other forces, for example. So I started studying
incidence geometry and group representations, and wound up learning lots
of math so beautiful that it has, so far, completely sidetracked me from
my original goal! I'll get back to it eventually\ldots.

Anyway, let me say more about this quantum aspect now. This is the royal
road to understanding representations of simple Lie groups. For
starters, fix a complex simple Lie group \(G\) and any parabolic
subgroup \(P\). Since \(G\) and \(P\) are complex Lie groups, the flag
manifold \(G/P\) is a complex manifold. More precisely, it has a complex
structure that is invariant under the action of \(G\).

On the other hand, we can write the flag manifold as \(K/L\), where
\(K\) is the maximal compact subgroup of \(G\), and \(L\) is the
intersection of \(K\) and \(P - L\) is called a ``Levi subgroup''. Since
\(K\) is compact, we can take any Riemannian metric on the flag manifold
and average it with respect to the action of \(K\) to get a Riemannian
metric that is invariant under the action of \(K\).

So, the flag manifold has a complex structure and metric that are both
invariant under \(K\)!

If this doesn't thrill you, consider the simplest example: \[
  \begin{aligned}
    G &= \mathrm{SL}(2,\mathbb{C})
  \\K &= \mathrm{SU}(2)
  \\P &= \{\mbox{upper triangular matrices in $\mathrm{SL}(2,\mathbb{C})$}\}
  \\L &= \{\mbox{diagonal matrices in $\mathrm{SL}(2,\mathbb{C})$}\}
  \end{aligned}
\] Here \(G/P = K/L\) is a \(2\)-sphere, the complex structure is the
usual way of thinking of this as the Riemann sphere, and the metric can
be any multiple of the usual round metric on the sphere. The complex
structure is invariant under all of \(G = \mathrm{SL}(2,\mathbb{C})\).
That's why \(\mathrm{SL}(2,\mathbb{C})\) is the double cover of the
group of conformal transformations of the Riemann sphere! The metric is
only invariant under \(K = \mathrm{SU}(2)\). That's why
\(\mathrm{SU}(2)\) is the double cover of the group of rotations of the
sphere!

All this stuff is wonderfully important in physics --- especially since
\(\mathrm{SL}(2,\mathbb{C})\) is also the double cover of the Lorentz
group, and the Riemann sphere is also the ``heavenly sphere'' upon which
we see the distant stars. I have already lavished attention on this
network of ideas in \protect\hyperlink{week162}{``Week 162''}\ldots{}
but what we're engaged in now is generalizing it to \emph{arbitrary}
complex simple Lie groups!

Now, a basic principle of geometry is that any two of the following
structures on a manifold determine the third \emph{if} they satisfy a
certain compatibility condition:

\begin{itemize}
\tightlist
\item
  complex structure \(J\)
\item
  Riemannian metric \(g\)
\item
  symplectic structure \(w\)
\end{itemize}

and in this case we get a ``Kaehler manifold'': a manifold with a
complex structure \(J\) and a complex inner product on the tangent
vectors whose real part is \(g\) and whose imaginary part is \(w\).

Furthermore, one of the big facts of quantization is that while the
phase space of a classical system is a symplectic manifold, we can only
quantize it and get a Hilbert space if we equip it with some extra
structure\ldots{} for example, by making it into a Kaehler manifold!
Once the phase space is a Kaehler manifold, we can look for a complex
line bundle over it with a connection whose curvature is the symplectic
structure. If this bundle exists, it's essentially unique, and we can
take the space of its holomorphic sections to be the Hilbert space of
states of the \emph{quantum} version of our system. For details, try my
webpage on geometric quantization, or these books, listed in rough order
of increasing difficulty and depth:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\item
  John Baez, ``Geometric quantization'',
  \texttt{http://math.ucr.edu/home/baez/quantization.html}
\item
  J. Snyatycki, \emph{Geometric Quantization and Quantum Mechanics},
  Springer-Verlag, New York, 1980.
\item
  Nicholas Woodhouse, \emph{Geometric Quantization}, Oxford U. Press,
  Oxford, 1992.
\item
  Norman E. Hurt, \emph{Geometric Quantization in Action: Applications
  of Harmonic Analysis in Quantum Statistical Mechanics and Quantum
  Field Theory}, Kluwer, Boston, 1983.
\end{enumerate}

In the beautiful situation I'm discussing now, the math gods are kind:
the complex structure and metric on the flag manifold fit together to
make it into a Kaehler manifold, so we can quantize it and get a Hilbert
space. And since everything in sight is invariant under the group K, our
Hilbert space becomes a unitary representation of K. This rep turns out
to be irreducible\ldots{} and we get all the unitary irreps of compact
simple Lie groups this way!

By easy abstract nonsense, the unitary irreps of \(K\) are also all the
finite-dimensional irreps of \(G\). So, we've just conquered a great
deal of territory in the land of group representations. You may have
seen other ways to get all the irreps of simple Lie groups: for example,
``heighest-weight representations'' or ``geometric quantization of
coadjoint orbits''. In fact, all these tricks are secretly just
different ways of talking about the same thing. It took me years to
learn this secret, but it's yours for free!

However, there are some small subtleties we shouldn't sweep under the
rug. We've seen that our flag manifold has a god-given complex
structure, but it usually has \emph{lots} of \(K\)-invariant metrics,
since we could take \emph{any} metric and average it with respect to the
action of \(K\). So, there are lots of \(K\)-invariant Kaehler
structures on our flag manifold.

How many are there? Well, I said that we get a flag manifold from any
subset of the dots in the Dynkin diagram for \(G\). It turns out that
\(K\)-invariant Kaehler structure on this flag manifold correspond to
ways of labelling the dots in this subset with positive real numbers.
And we can geometrically quantize the flag manifold to get an irrep of
\(G\) precisely when these numbers are \emph{integers!}

The simplest situation is when our flag manifold is a Grassmannian. This
corresponds to a single dot in the Dynkin diagram. If we label this dot
with the number \(1\), we get a so-called ``fundamental representation''
of our group. I sketched in \protect\hyperlink{week180}{``Week 180''}
how to get all the other irreps from these.

Now let me illustrate all this stuff by going through all the classical
series of simple Lie groups and seeing what we get.

\begin{itemize}
\item
  \(\mathrm{A}_n\): Here are the Grassmannians for some of the
  \(\mathrm{A}_n\) series, that is, the groups
  \(\mathrm{SL}(n+1,\mathbb{C})\). I've drawn the Dynkin diagrams with
  each dot labelled by the corresponding type of geometrical figure and
  the dimension of the Grassmannian of all figures of this type. We can
  think of these figures as vector subspaces of \(\mathbb{C}^{n+1}\). We
  can also think of them as spaces of one less dimension in
  \(\mathbb{CP}^n\). Either way, we are talking about \emph{projective}
  geometry:

\begin{verbatim}
  A1                              1d subspaces
  \mathrm{SL}(2,\mathbb{C})                              o
                                       1


  A2                       1d subspaces  2d subspaces
  \mathrm{SL}(3,\mathbb{C})                       o---------------o
                                2               2


  A3                1d subspaces  2d subspaces  3d subspaces
  \mathrm{SL}(4,\mathbb{C})                o------------o---------------o
                         3             4               3


  A4          1d subspaces  2d subspaces  3d subspaces  4d subspaces
  \mathrm{SL}(5,\mathbb{C})          o------------o---------------o------------o
                   4            6               6            4
\end{verbatim}

  Recognize the numbers labelling the Dynkin diagram dots? It's a weird
  modified version of Pascal's triangle --- but can you figure out the
  pattern?

  No? I claim you learned this table of numbers when you were in grade
  school: just tilt your head 45 degrees and you'll recognize it!

  Next, here's what we get from quantizing these Grassmannians. I've
  labelled each dot by the name of the corresponding fundamental
  representation and its dimension. All these reps are exterior powers
  of the obvious rep of \(\mathrm{SL}(n+1,\mathbb{C})\) on
  \(\mathbb{C}^{n+1}\). We call elements of the \(p\)th exterior power
  ``\(p\)-vectors'', or ``multivectors'' in general:

\begin{verbatim}
  A1                                vectors 
  \mathrm{SL}(2,\mathbb{C})                              o
                                       2


  A2                        vectors        bivectors
  \mathrm{SL}(3,\mathbb{C})                      o---------------o
                               3               3


  A3                   vectors     bivectors      3-vectors
  \mathrm{SL}(4,\mathbb{C})                o-------------o--------------o
                         4             6              4


  A4          vectors      bivectors      3-vectors    4-vectors
  \mathrm{SL}(5,\mathbb{C})        o-------------o--------------o------------o
                 5            10             10            5
\end{verbatim}

  Here the numbers labelling the dots form Pascal's triangle! So we see
  that Pascal's triangle is a quantized version of the multiplication
  table. (That was the answer to the previous puzzle, by the way --- our
  triangle was just the multiplication table viewed from a funny angle.)
\item
  \(\mathrm{B}_n\): Next let's look at the \(\mathrm{B}_n\) series.
  \(\mathrm{B}_n\) is another name for the complexified rotation group
  \(\mathrm{SO}(2n+1,\mathbb{C})\), or if you prefer, its double cover
  \(\mathrm{Spin}(2n+1,\mathbb{C})\). A Grassmannian for this group is a
  space consisting of all \(p\)-dimensional ``isotropic'' subspaces of
  \(\mathbb{C}^{2n+1}\) --- that is, subspaces on which a nondegenerate
  symmetric bilinear form vanishes.

  As I explained in \protect\hyperlink{week180}{``Week 180''}, these
  Grassmannians show up when we study relativity in odd-dimensional
  Minkowski spacetime, especially when we complexify and compactify.
  Another way to put it is that this is all about \emph{conformal}
  geometry in odd dimensions! We've already seen that conformal geometry
  in even dimensions is very different, and we'll get to that later.

  Here are the Grassmannians and their dimensions:

\begin{verbatim}
                                   isotropic 
  B1                              1d subspaces
  \mathrm{Spin}(3,\mathbb{C})                             o
                                        1


                            isotropic     isotropic          
  B2                       1d subspaces  2d subspaces
  \mathrm{Spin}(5,\mathbb{C})                     o======\Rightarrow=======o
                                3               3


                     isotropic     isotropic     isotropic
  B3                1d subspaces  2d subspaces  3d subspaces
  \mathrm{Spin}(7,\mathbb{C})              o--------------o======\Rightarrow=======o
                         5              7               6


               isotropic     isotropic      isotropic     isotropic
  B4          1d subspaces  2d subspaces   3d subspaces  4d subspaces
  \mathrm{Spin}(9,\mathbb{C})        o-------------o---------------o======\Rightarrow======o
                   7            11              12             10 
\end{verbatim}

  I'm sure these are well-known, but James Dolan and I had a lot of fun
  one evening working these out, using a lot of numerology that we
  eventually justified by a method I'll explain later.

  Here's a bigger chart of these dimensions:

\begin{verbatim}
  B1                           1

  B2                         3    3

  B3                      5    7    6

  B4                    7   11   12   10

  B5                 9   15   18   18   15

  B6              11   19   24   26   25   21

  B7            13  23   30   34   35   33   28

  B8          15  27   36   42   45   45   42   36  
\end{verbatim}

  I leave it as an easy puzzle to figure out the pattern, and a harder
  puzzle to prove it's true. Don't be overly distracted by the symmetry
  lurking in rows 2, 5, and 8 --- every third row has this symmetry, but
  it's a bit of a red herring!

  If we quantize these Grassmannians we get these fundamental reps of
  \(\mathrm{Spin}(2n+1,\mathbb{C})\):

\begin{verbatim}
  B1                                 spinors
  \mathrm{Spin}(3,\mathbb{C})                             o
                                        2



  B2                          vectors        spinors   
  \mathrm{Spin}(5,\mathbb{C})                     o======\Rightarrow=======o
                                5               4



  B3                   vectors       bivectors       spinors
  \mathrm{Spin}(7,\mathbb{C})              o--------------o======\Rightarrow=======o
                         7             21               8



  B4             vectors     bivectors        3-vectors      spinors
  \mathrm{Spin}(9,\mathbb{C})        o-------------o---------------o======\Rightarrow======o
                   9            36              84             16
\end{verbatim}

  As before, the dimension of the space of \(p\)-vectors in
  \(q\)-dimensional space comes straight from Pascal's triangle: it's
  \(q\) choose \(p\). But now we also have spinor reps; the dimensions
  of these are powers of 2.
\item
  \(\mathrm{C}_n\): Next let's look at the Grassmannians for the
  \(\mathrm{C}_n\) series, that is, the symplectic groups
  \(\mathrm{Sp}(2n,\mathbb{C})\). This is the only series of classical
  groups I haven't touched yet! Just as the \(\mathrm{A}_n\) series are
  symmetry groups of projective geometry and the \(\mathrm{B}_n\) and
  \(\mathrm{D}_n\) series are symmetry groups of conformal geometry, the
  \(\mathrm{C}_n\) series are symmetry groups of ``projective
  symplectic'' geometry. Unfortunately I don't know much about this
  subject --- at least not consciously. It should be important in
  physics, but I'm not sure where!

  Anyway, \(\mathrm{Sp}(2n,\mathbb{C})\) is the group of linear
  transformations of \(\mathbb{C}^{2n}\) that preserve a symplectic
  form: that is, a nondegenerate \emph{antisymmetric} bilinear form. A
  Grassmannian for this group again consists of all \(p\)-dimensional
  isotropic subspaces of \(\mathbb{C}^{2n}\), where now a subspace is
  ``isotropic'' if the symplectic form vanishes on it.

  Here's a little table of these Grassmannians:

\begin{verbatim}
                                   isotropic 
  C1                              1d subspaces
  \mathrm{Sp}(2,\mathbb{C})                               o
                                        1


                            isotropic     isotropic          
  C2                       1d subspaces  2d subspaces
  \mathrm{Sp}(4,\mathbb{C})                       o=======<=======o
                                3               3


                     isotropic     isotropic     isotropic
  C3                1d subspaces  2d subspaces  3d subspaces
  \mathrm{Sp}(6,\mathbb{C})                o--------------o=======<=======o
                         5              7               6


               isotropic     isotropic      isotropic     isotropic
  C4          1d subspaces  2d subspaces   3d subspaces  4d subspaces
  \mathrm{Sp}(8,\mathbb{C})          o-------------o---------------o=======<======o
                   7            11              12             10 
\end{verbatim}

  You'll notice the dimensions are the same as in the \(\mathrm{B}_n\)
  case! That's because their Dynkin diagrams are almost the same: for
  reasons I may someday explain, dimensions of flag manifolds don't care
  which way the little arrows on the Dynkin diagrams point, since they
  depend only on the \emph{reflection group} associated to this diagram
  (see \protect\hyperlink{week62}{``Week 62''}).

  However, the dimensions of the fundamental representations are
  different from the \(\mathrm{B}_n\) case --- and I don't even know
  what they are! The basic idea is this: the space of \(p\)-vectors is
  no longer an irrep for \(\mathrm{Sp}(2n,\mathbb{C})\), but contracting
  with the symplectic form maps \(p\)-vectors to \((p-2)\)-vectors, and
  the kernel of this map is the \$p4th fundamental rep of
  \(\mathrm{Sp}(2n)\). Let's call these guys ``irreducible
  \(p\)-vectors''.

  Oh heck, I can \emph{guess} the dimensions of these guys from
  this\ldots{} I guess they're just the dimension of the \(p\)-vectors
  minus the dimension of the \((p-2)\)-vectors. Here's a table of these
  guesses:

\begin{verbatim}
  C1                                 vectors
  \mathrm{Sp}(2,\mathbb{C})                               o
                                        2


                                            irreducible 
  C2                          vectors        bivectors
  \mathrm{Sp}(4,\mathbb{C})                       o=======<=======o
                                4               5


                                    irreducible     irreducible
  C3                    vectors      bivectors       3-vectors
  \mathrm{Sp}(6,\mathbb{C})                o--------------o=======<=======o
                         6              14              14


                             irreducible     irreducible    irreducible
  C4              vectors     bivectors       3-vectors      4-vectors
  \mathrm{Sp}(8,\mathbb{C})          o-------------o---------------o=======<======o
                   8            27              48             42
\end{verbatim}

  Maybe someone can tell if they're right.
\item
  \(\mathrm{D}_n\): Finally, \(\mathrm{D}_n\) is another name for the
  complexified rotation group \(\mathrm{SO}(2n,\mathbb{C})\) or its
  double cover \(\mathrm{Spin}(2n,\mathbb{C})\). The \(p\)th
  Grassmannian for this group consists of all \(p\)-dimensional
  isotropic subspaces of the space \(\mathbb{C}^{2n}\) equipped with a
  nondegenerate symmetric bilinear form --- \emph{except} for the
  top-dimensional Grassmannians, as I explained last week. These consist
  of self-dual or anti-self-dual subspaces. Self-duality is the special
  feature of conformal geometry in \emph{even} dimensions!

  Here are the Grassmannians and their dimensions:

\begin{verbatim}
                                   1
                                   o self-dual 2d subspaces

  D2                                      
  \mathrm{Spin}(4,\mathbb{C})                 


                                   o anti-self-dual 2d subspaces
                                   1





                                      3
                                      o self-dual 3d subspaces
                                     /
                                    /
  D3                               /
  \mathrm{Spin}(6,\mathbb{C})                     4 o isotropic 1d subspaces
                                   \
                                    \
                                     \
                                      o anti-self-dual 3d subspaces
                                      3




                                           6
                                          o self-dual 4d subspaces
                                         /
                         isotropic      /
  D4                   1d subspaces    /
  \mathrm{Spin}(8,\mathbb{C})                   o-------o isotropic 2d subspaces 
                              6       9\
                                        \
                                         \
                                          o anti-self-dual 4d subspaces
                                           6




                                                 10
                                                 o self-dual 5d subspaces
                                                /            
                                               / 
  D5             1d subspaces  2d subspaces   /
  \mathrm{Spin}(10,\mathbb{C})           o-----------o---------o isotropic 3d subspaces
                       8          13        15\
                                               \
                                                \
                                                 o anti-self-dual 5d subspaces
                                                 10
\end{verbatim}

  You'll notice that the numbers on the ``fishtails'' are triangular
  numbers: 1, 3, 6, 10\ldots{} I'll say more later about how to
  calculate the rest of these numbers.

  As explained last week, the fundamental reps of the \(\mathrm{D}_n\)
  consist of p-vectors, except for those at the fishtails, which are
  left- and right-handed spinor reps:

\begin{verbatim}
                                   2
                                   o left-handed spinors

  D2                                      
  \mathrm{Spin}(4,\mathbb{C})                 


                                   o right-handed spinors
                                   2





                                      4
                                      o left-handed spinors
                                     /
                                    /
  D3                               /
  \mathrm{Spin}(6,\mathbb{C})                     6 o vectors
                                   \
                                    \
                                     \
                                      o right-handed spinors
                                      4




                                          8
                                          o left-handed spinors
                                         /
                                        /
  D4                       vectors     /
  \mathrm{Spin}(8,\mathbb{C})                   o-------o bivectors
                              8      28\
                                        \
                                         \
                                          o right-handed spinors
                                           8




                                                 16
                                                 o left-handed spinors
                                                /            
                                               / 
  D5                vectors      bivectors    /
  \mathrm{Spin}(10,\mathbb{C})           o-----------o---------o 3-vectors
                       10         45       120\
                                               \
                                                \
                                                 o right-handed spinors
                                                 16
\end{verbatim}

  Again the dimension of the space of \(p\)-vectors in \(q\)-dimensional
  space comes from Pascal's triangle, while the dimensions of the spinor
  reps are powers of 2.
\end{itemize}

Let me conclude by listing the dimensions of Grassmannians for the
exceptional groups, as computed by James Dolan. I strongly doubt he's
the first to have computed these --- at this stage we're mainly learning
and reinventing known stuff --- but he did it using a nice trick I'd
like to mention. I was shocked at how unfamiliar these numbers were to
me, because all these Grassmannians should be definable using the
octonions:

\begin{verbatim}
                  -------
G2              5 --->--- 5
                  -------



\mathrm{F}_4            43------48==\Rightarrow===48------43



                                21
                                |
                                |
                                |
E6              16------25------29------25------16



                                42
                                |
                                |
                                |
E7              33------47------53------50------42------27




                                92
                                |
                                |
                                |
E8              78------98-----106-----104------99------83------57
\end{verbatim}

You can calculate dimensions of these and all the other Grassmannians
for simple Lie groups by the following easy trick. Given the Dynkin
diagram for \(G\) and a chosen dot in it, remove this dot to get one or
more Dynkin diagrams for groups \(G_i\). Work out the dimension of the
space of maximal flags for \(G\), and subtract all the dimensions of the
spaces of maximal flags for the \(G_i\). Voila! You get the dimensions
of the Grassmannian corresponding to the \(i\)th dot.

The dimensions of maximal flag manifold for \(G\) is easy to compute, in
turn, because it's just \(\dim(G) - \dim(B)\), where \(B\) is the Borel.
And dimension of the Borel is just \((\dim(G) + \dim(T))/2\), where
\(T\) is the maximal torus, so that \(\dim(T)\) is the number of dots in
the Dynkin diagram.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Mathematics is the part of physics where experiments are cheap.}
--- V. I. Arnold,
\href{http://pauli.uni-muenster.de/~munsteg/arnold.html}{On teaching
mathematics}



\hypertarget{week182}{%
\section{June 19, 2002}\label{week182}}

It's been a long time, but in the last Week's Finds I was telling you
about my adventures this spring in northern California, and I hadn't
quite gotten around to telling you about that cool conference on
``Nonabelian Hodge Theory'' at the MSRI in Berkeley. I'll continue my
story about that now\ldots{}

\ldots but first, a little detour through the Nile valley!

Egyptians liked to write fractions as the sum of reciprocals of
integers. For example, instead of writing \[\frac56\] those folks would
write something like \[\frac12 + \frac13\] Nobody is sure why, but one
possibility is that they started with a neat notation for \(1/n\), and
then wanted to extend this to handle other fractions, and couldn't think
of anything better.

Of course they \emph{could} have written \(m/n\) as
\[\underbrace{\frac1n+\ldots+\frac1n}_{\mbox{$m$ terms}}\] but they
preferred to use as few terms as possible. This leads to some tricky
questions. For example: clearly every fraction of the form \(4/n\) can
be written using 4 terms --- but can you always make do with just 3?
Nobody knows! This is called the Erdos-Strauss conjecture. Alan Swett
claims to have shown you only need 3 terms if \(n\) is less than or
equal to \(10^{14}\). For example:
\[\frac{4}{8689} = \frac{1}{2175} + \frac{1}{1718250} + \frac{1}{14929874250}.\]
For much more on this, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  David Eppstein, ``Egyptian fractions'',
  \texttt{http://www.ics.uci.edu/\textasciitilde{}eppstein/numth/egypt/}
\item
  Alan Swett, ``The Erdos-Strauss conjecture'',
  \texttt{http://math.uindy.edu/swett/esc.htm}
\end{enumerate}

Egyptian fraction problems have a spooky way of showing up in various
unrelated mathematical contexts\ldots{} which have a spooky way of
turning out not to be unrelated after all!

For example, suppose we are trying to classify all the Platonic solids.
We're looking for ways to tile the surface of a sphere with regular
\(n\)-gons, with \(m\) meeting at each vertex. Suppose there is a total
of \(V\) vertices, \(E\) edges, and \(F\) faces. Since the Euler
characteristic of the sphere is \(2\), we have \[V - E + F = 2.\] Since
each face has \(n\) edges but 2 faces meet along each edge, we have
\[nF = 2E.\] Since each vertex has \(m\) edges meeting it but each edge
meets 2 vertices, we also have \[mV = 2E.\] Putting these equations
together we get \[2E\left(\frac1n + \frac1m - \frac12\right) = 2\] or
\[\frac1n + \frac1m = \frac12 + \frac1E.\] An Egyptian fractions
problem! It's obvious that this can only have solutions if
\(1/n + 1/m > 1/2\). And interestingly, all the solutions of this
inequality do indeed correspond to Platonic solids\ldots{} at least if
\(n,m > 2\). Here they are:

\begin{longtable}[]{@{}ll@{}}
\toprule
\((n,m)\) & Platonic solid\tabularnewline
\midrule
\endhead
\((3,3)\) & tetrahedron\tabularnewline
\((3,4)\) & octahedron\tabularnewline
\((4,3)\) & cube\tabularnewline
\((3,5)\) & icosahedron\tabularnewline
\((5,3)\) & dodecahedron\tabularnewline
\bottomrule
\end{longtable}

The cases \(n = 1,2\) don't give Platonic solids in the usual sense:
after all, most people don't like polygons to have just 1 or 2 edges.
Neither do the cases \(m = 1,2\), since most people don't like polyhedra
to have just 1 or 2 faces meeting at a vertex!

One can argue about whether these are irrational prejudices. But it's
actually good to study \emph{all} unordered pairs of natural numbers
with \[\frac1n + \frac1m > \frac12\] since they correspond to \emph{all}
the isomorphism classes of finite subgroups of the rotation group! The
Platonic solids have their symmetry groups, which don't change when we
switch \(n\) and \(m\). The solution \((n,1)\) corresponds to the cyclic
group \(\mathbb{Z}_n\): the symmetries of a regular \(n\)-gon, where
you're not allowed to flip it over. The solution \((n,2)\) corresponds
to the dihedral group \(D_n\): the symmetries of a regular n-gon where
you \emph{are} allowed to flip it over.

In some weird sense, maybe we should think of \(\mathbb{Z}_n\) and
\(D_n\) as the symmetry groups of Platonic solids with only 1 or 2
faces. I'll leave you to ponder the Platonic solids with only 1 or 2
vertices. If you get stuck, look up the word ``hosohedron''!

The story gets better if we also consider solutions of
\[\frac1n + \frac1m = \frac12\] which formally correspond to Platonic
solids where the number \(E\) of edges is infinite. In fact, these
correspond to tilings of the plane by regular polygons:

\begin{longtable}[]{@{}ll@{}}
\toprule
\((n,m)\) & tilings of the plane by\ldots{}\tabularnewline
\midrule
\endhead
\((3,6)\) & regular triangles\tabularnewline
\((6,3)\) & regular hexagons\tabularnewline
\((4,4)\) & (regular) squares\tabularnewline
\bottomrule
\end{longtable}

Similarly, solutions of \[\frac1n + \frac1m < \frac12\] give tilings of
the hyperbolic plane. For example, Escher used \((n,m) = (6,4)\) in some
of his prints, like this:
\[\includegraphics[scale=0.68]{../images/escher.png}\]

Let me try to arrange all this information in a table, using lines to
separate the spherical, planar and hyperbolic regions:

\begin{longtable}[]{@{}llllllll@{}}
\toprule
\begin{minipage}[b]{0.10\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=1\)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=2\)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=3\)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=4\)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=5\)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=6\)\strut
\end{minipage} & \begin{minipage}[b]{0.10\columnwidth}\raggedright
\(n=7\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=1\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_1\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_2\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_3\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_4\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_5\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_6\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_7\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=2\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_2\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_2\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_3\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_4\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_5\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_6\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_7\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=3\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_3\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_3\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
tetrahedron\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
cube\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
dodecahedron\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=4\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_4\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_4\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
octahedron\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=5\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_5\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_5\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
icosahedron\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=6\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_6\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_6\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.10\columnwidth}\raggedright
\(m=7\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(\mathbb{Z}_7\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
\(D_7\)\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage} & \begin{minipage}[t]{0.10\columnwidth}\raggedright
!!!\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\begin{verbatim}
     n=1   n=2      n=3         n=4     n=5           n=6         n=7


m=1  Z_1   Z_2      Z_3         Z_4     Z_5           Z_6         Z_7


m=2  Z_2   D_2      D_3         D_4     D_5           D_6         D_7

                                                    ------------=======
m=3  Z_3   D_3   tetrahedron   cube   dodecahedron | hexagonal |   
                                                   |  tiling   |
                              ---------=============------------
m=4  Z_4   D_4   octahedron  | square |
                             | tiling |
                             | --------
m=5  Z_5   D_5   isosahedron ||
                             ||
                 ------------ |          hyperbolic tilings
m=6  Z_6   D_6  | triangular  |                
                |   tiling    |
                | -------------    
m=7  Z_7   D_7  ||
                ||
\end{verbatim}

Now, the same Egyptian fraction problem comes up when studying other
problems, too. For example, suppose you are trying to find a basis of
\(\mathbb{R}^n\) consisting of unit vectors that are all at 90-degree or
120-degree angles from each other. We can describe a problem like this
by drawing a bunch of dots, one for each vector, and connecting two dots
with an edge when they're supposed to be at a 120-degree angle from each
other. If two dots are not connected, they should be at right angles to
one another.

So, for example, this diagram tells us to find a basis for
\(\mathbb{R}^3\) consisting of unit vectors all at 120 degree angles
from each other: \[
  \begin{tikzpicture}[scale=0.75]
    \draw (0,0) to (2,0) to (1,1.73) to cycle;
    \node at (0,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
    \node at (1,1.73) {$\bullet$};
  \end{tikzpicture}
\] It's easy to see this is impossible, since three vectors all at 120
degrees from each must lie in a plane --- so they can't be linearly
independent. On the other hand, this diagram gives a solvable problem:
\[
  \begin{tikzpicture}[scale=1.5]
    \draw[thick] (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
  \end{tikzpicture}
\] You just pick two unit vectors at right angles to each other and
wiggle the third one around until it's at a 120-degree angle to both.
It's not hard.

So, the question is: which diagrams give solvable problems?

This is actually a very fun puzzle: it's very famous, but most books
manage to make it seem really boring and ``technical'', so you should
really spend some time thinking about it for yourself. I'll give away
the answer, but I won't say how you prove it's true.

First, it's easy to see that if a diagram consists of a bunch of
separate pieces, and you can solve the problem for each piece, you can
solve the problem for the whole diagram. So, it's sufficient to consider
the case of connected diagrams.

Second, a connected diagram can only give a solvable problem if it's
Y-shaped, like this: \[
  \begin{tikzpicture}[scale=0.5]
    \draw[thick] (0,0) to (9,0);
    \draw[thick] (3,0) to (3,2);
    \foreach \x in {0,1,2,3,4,5,6,7,8,9}
      \node at (\x,0) {$\bullet$};
    \node at (3,1) {$\bullet$};
    \node at (3,2) {$\bullet$};
  \end{tikzpicture}
\] Third, a diagram like this gives a solvable problem only if
\[\frac1k + \frac1n + \frac1m > 1\] where \((k,n,m)\) are the numbers
labelling the tips of the Y when we number it like this: \[
  \begin{tikzpicture}[scale=0.5]
    \draw[thick] (0,0) to (9,0);
    \draw[thick] (3,0) to (3,2);
    \node[fill=white] at (0,0) {$4$};
    \node[fill=white] at (1,0) {$3$};
    \node[fill=white] at (2,0) {$2$};
    \node[fill=white] at (3,0) {$1$};
    \node[fill=white] at (4,0) {$2$};
    \node[fill=white] at (5,0) {$3$};
    \node[fill=white] at (6,0) {$4$};
    \node[fill=white] at (7,0) {$5$};
    \node[fill=white] at (8,0) {$6$};
    \node[fill=white] at (9,0) {$7$};
    \node[fill=white] at (3,1) {$2$};
    \node[fill=white] at (3,2) {$3$};
  \end{tikzpicture}
\] So for example, this particular problem is not solvable because
\(\frac14 + \frac13 + \frac17 < 1\).

Now, it's easy to see what we can only get
\(\frac1k + \frac1n + \frac1m > 1\) if one of the numbers is \(1\) or
\(2\). If one of the numbers is \(1\), our ``Y-shaped'' diagram is
actually just a straight line of dots! We can also describe this
straight line by taking one of the numbers to be \(2\), like this: \[
  \begin{tikzpicture}[scale=0.7]
    \draw[thick] (0,0) to (6,0);
    \node[fill=white] at (0,0) {$2$};
    \node[fill=white] at (1,0) {$1$};
    \node[fill=white] at (2,0) {$2$};
    \node[fill=white] at (3,0) {$3$};
    \node[fill=white] at (4,0) {$4$};
    \node[fill=white] at (5,0) {$5$};
    \node[fill=white] at (6,0) {$6$};
  \end{tikzpicture}
\] except for the boring case where we have just a single dot. So, let's
assume one of the numbers is \(2\). By symmetry we can assume this
number is \(k\). We are thus looking for pairs \((n,m)\) with
\[\frac12 + \frac1n + \frac1m > 1\] or in other words
\[\frac1n + \frac1m > \frac12.\] This is the same problem as before! So
the problem we're dealing with now is very much like classifying
Platonic solids!

Even better, these diagrams I've been drawing are called ``Dynkin
diagrams'', and we can use them to get certain incredibly important
finite-dimensional Lie algebras called ``simply-laced simple Lie
algebras''. For a taste of how this works, reread
\protect\hyperlink{week65}{``Week 65''} and some previous Weeks.

Similarly, we get certain \emph{infinite-dimensional} Lie algebras
called ``simply-laced affine Lie algebras'' when
\[\frac1n + \frac1m = \frac12,\] and ``simply-laced hyperbolic Kac-Moody
algebras'' when \[\frac1n + \frac1m < \frac12.\] So, our whole big table
above translates into a table of Lie algebras! Let me draw it with the
standard names of these Lie algebras below their diagrams.
Unfortunately, I'll have to make it very small to fit everything in. So,
for example, I'll draw the so-called \(\mathrm{E}_8\) Dynkin diagram: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (6,0);
    \draw[thick] (2,0) to (2,1);
    \foreach \x in {0,1,2,3,4,5,6}
      \node at (\x,0) {$\bullet$};
    \node at (2,1) {$\bullet$};
  \end{tikzpicture}
\] as this puny miserable thing: \[
  \begin{tikzpicture}[scale=0.15]
    \foreach \x in {0,1,2,3,4,5,6}
      \node at (\x,0) {$\bullet$};
    \node at (2,1) {$\bullet$};
  \end{tikzpicture}
\] This is what we get:

\begin{verbatim}
    n=1      n=2        n=3         n=4          n=5           n=6

     o        o          o           o            o             o   
m=1  o       oo        ooo        oooo        ooooo       ooooooo
    
     A2       A3         A4          A5           A6            A7



     o        o          o           o            o             o   
m=2  oo      ooo       oooo       ooooo       oooooo      oooooooo

     A3       D4         D5          D6           D7            D8

                                                        ----------------==
                                                       |               |
     o        o          o           o            o    |        o      |
m=3  ooo     oooo      ooooo      oooooo      ooooooo  |  ooooooooo    |
                                                       |               |
     A4       D5         E6          E7           E8   |        E8^1   |
                                                       |               |
                                ------------===========-----------------
                               |           |
     o        o          o     |     o     |      o             o   
m=4  oooo    ooooo     oooooo  |  ooooooo  |  oooooooo     oooooooooo
                               |           |
     A5       D6         E7    |    E7^1   |       
                               |           |
                               | ----------
                               ||
     o        o          o     ||    o            o             o   
m=5  ooooo   oooooo    ooooooo || oooooooo    ooooooooo    ooooooooooo
                               ||
     A6       D7         E8    ||   
                               ||       hyperbolic Kac-Moody algebras
                      --------- |         
                     |          |
     o        o      |   o      |    o            o             o   
m=6  oooooo  ooooooo | oooooooo | ooooooooo   oooooooooo   oooooooooooo  
     A7       D8     |          |
                     |   E8^1   |
                     |          |
                     | ----------
                     ||
                     ||
\end{verbatim}

This mysterious way that the same Egyptian fraction problem shows up in
classifying Platonic solids and simply-laced simple Lie algebras is
actually the tip an iceberg sometimes called the ``McKay
correspondence'' --- though important aspects of it go back to the
theory of Kleinian singularities. I talked about the McKay
correspondence in \protect\hyperlink{week65}{``Week 65''}, so that's a
good place to dig deeper, but you should really look at some of the
references in there, and also these two --- both of which explain the
mysterious word ``hosohedron'':

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\item
  H. S. M. Coxeter, \emph{Generators and relations for discrete groups},
  Springer, Berlin, 1984.
\item
  Joris van Hoboken, \emph{Platonic solids, binary polyhedral groups,
  Kleinian singularities and Lie algebras of type \(A\),\(D\),\(E\)},
  Master's Thesis, University of Amsterdam, 2002, available at
  \texttt{http://home.student.uva.nl/joris.vanhoboken/scriptiejoris.ps}
  or
  \texttt{http://math.ucr.edu/home/baez/joris\_van\_hoboken\_platonic.pdf}
\end{enumerate}

Okay. Now --- back to that conference at the Mathematical Sciences
Research Institute! You can look at transparencies and watch videos of
the talks here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  MSRI streaming video archive, Spring 2002,
  \texttt{http://www.msri.org/publications/video/index04.html}
\end{enumerate}

If you like watching math talks, there's a lot to see here --- not just
this one conference, but all the MSRI conferences! For example, right
after the nonabelian Hodge theory conference there was one on conformal
field theory and supersymmetry, featuring talks by bigshots like Richard
Borcherds, Dan Freed, Igor Frenkel, Victor Kac, and Jean-Bernard Zuber
--- just to name a few. You can see talks by all these folks.

But anyway, let me start by telling you what nonabelian Hodge theory
is\ldots.

Hmm. I guess I should \emph{start} by telling you what \emph{abelian}
Hodge theory is!

In its simplest form, Hodge theory talks about how differential forms on
a smooth manifold get extra interesting structure when the manifold has
extra interesting structure. To warm up, let me remind you about what we
can do when our manifold has \emph{no} extra interesting structure.
Whenever we have a smooth manifold \(M\) there's an ``exterior
derivative'' operator \(d\) going from \(p\)-forms on \(M\) to
\((p+1)\)-forms on M. This is just a generalization of grad, curl, div
and all that. In particular it satisfies \[d^2 = 0,\] so the space of
``closed'' \(p\)-forms: \[\{w \mid dw = 0\}\] contains the space of
``exact'' \(p\)-forms: \[\{w \mid \mbox{$w = du$ for some $u$}\}.\] This
makes it fun to look at the vector space of closed \(p\)-forms modulo
exact \(p\)-forms. This is called the ``\(p\)th de Rham cohomology group
of \(M\)'', or \[H^p(M)\] for short. It only depends on the topology of
\(M\); its size keeps track of the number of \(p\)-dimensional holes in
\(M\). When \(M\) is compact, it agrees with the cohomology computed in
a bunch of other ways that topologists like.

Fine. But now, suppose \(M\) has a Riemannian metric on it! Then we can
write down a version of the Laplacian for differential forms. A function
is a \(0\)-form, so we're just generalizing the Laplacian you already
know and love. Differential forms whose Laplacian is zero are called
``harmonic''. Every harmonic \(p\)-form is closed, but if \(M\) is
compact life is even better: the vector space of harmonic \(p\)-forms is
isomorphic to the \(p\)th de Rham cohomology of \(M\).

This is great: it means the de Rham cohomology, which only depends on
the \emph{topology} of \(M\), can also be thought of as the space of
solutions of a \emph{differential equation} on \(M\)! This gets
topologists and analysts talking to each other, and has all sorts of
marvelous spinoffs and generalizations.

Some people call this stuff ``Hodge theory''. But Hodge theory goes
further when \(M\) has more structure --- most notably, when it's a
Kaehler manifold!

A Kaehler manifold is to the complex plane as a Riemannian manifold is
to the real line. More precisely, it's is a manifold whose tangent
spaces have been made into \emph{complex} vector spaces and equipped
with a \emph{complex} inner product. Of course the real part of the
inner product makes it into a Riemannian manifold. That lets us parallel
transport vectors, so we demand a compatibility condition: parallel
transporting a vector and then multiplying it by \(i\) is the same as
multiplying it by \(i\) and then parallel transporting it! This makes
complex analysis work well on Kaehler manifolds.

Now, if you've taken complex analysis, you may remember how people use
it to find solutions of Laplace's equation\ldots{} like when they're
studying electrostatics, or the flow of fluids with no viscosity or
vorticity --- an idealization that von Neumann mockingly called ``dry
water''. On the complex plane we can talk about ``holomorphic''
functions, which satisfy the Cauchy-Riemann equation: \[
  \frac{df}{d\overline{z}} = 0
  \qquad
  \left(
    \text{note:}\,\,
    \frac{df}{d\overline{z}} = \frac{df}{dx} + i\frac{df}{dy}
  \right)
\] and also the complex conjugates of these, called ``antiholomorphic''
functions, which satisfy \[
  \frac{df}{dz} = 0
  \qquad
  \left(
    \text{note:}\,\,
    \frac{df}{dz} = \frac{df}{dx} - i\frac{df}{dy}
  \right)
\] Both holomorphic and antiholomorphic functions are automatically
harmonic, so we can find solutions of Laplace's equation this way. But
even better, every harmonic function is a linear combination of a
holomorphic and an antiholomorphic one!

All this stuff works much more generally for \(p\)-forms on Kaehler
manifolds. To get going, let's think a bit more about the complex plane.
If we have any \(1\)-form on the complex plane we can write it as a
linear combination of \(dx\) and \(dy\), where \(x\) and \(y\) are the
usual coordinates on the plane. But things get nicer if we work with
\emph{complex-valued} differential forms. Then we can form linear
combinations like \[dz = dx + idy\] and \[d\overline{z} = dx - idy\] and
express any \(1\)-form as a linear combination of \emph{these} in a
unique way. We call these the \((1,0)\) and \((0,1)\) parts of our
\(1\)-form.

This means that if we have a function \(f\), we can take its exterior
derivative and chop it into its \((1,0)\) part and \((0,1)\) part:
\[df = \partial f+\overline{\partial}f.\] These guys are called
``Dolbeault operators''.

Anyway, it turns out that \[\overline{\partial}f = 0\] is just a slick
way of writing Cauchy-Riemann equation, which says that \(f\) is
holomorphic. You should check this for yourself! Similarly,
\[\partial f = 0\] says that \(f\) is antiholomorphic.

Now let me say how all this stuff generalizes to arbitrary Kaehler
manifolds. We can decompose any \(p\)-form on a Kaehler manifold into
its \((i,j)\) parts where \(i+j = p\). For example, a \((1,2)\)-form in
\(4\) dimensions might look something like this in complex coordinates:
\[f dz_1\wedge d\overline{z}_3\wedge d\overline{z}_2 + g dz_2\wedge d\overline{z}_3\wedge d\overline{z}_4.\]
We have \[d = \partial + \overline{\partial}\] where \(\partial\) maps
\((i,j)\)-forms to \((i+1,j)\)-forms, while \(\overline{\partial}\) maps
\((i,j)\)-forms to \((i,j+1)\)-forms. This allows us to take the de Rham
cohomology groups of our manifold \(M\) and write them as a direct sum
of smaller vector spaces, which I'll call \[H^{i,j}(M)\] for short.

So far I don't think I've used anything about the metric on \(M\), so
all this would work whenever \(M\) is a so-called ``complex manifold''.
But if we really have a Kaehler manifold, and it's compact, we can say
more: a \(p\)-form is harmonic if and only if all its \((i,j)\) parts
are. This means \(H^{i,j}(M)\) is isomorphic to the space of harmonic
\((i,j)\)-forms. Alternatively, you can describe \(H^{i,j}(M)\) just in
terms of \(\partial\): you just take the \((i,j)\)-forms in here:
\[\{w \mid \overline{\partial}w = 0\}\] modulo those in here:
\[\{w \mid \mbox{$w=\overline{\partial}u$ for some $u$}\}\] This is
called the ``\((i,j)\)th Dolbeault cohomology group of \(M\)''.

That's Hodge theory in a nutshell. There's even \emph{more} you can do
when \(M\) is a Kaehler manifold, but I'm getting a little tired, so
I'll just let you read about that here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  R. O. Wells, \emph{Differential analysis on complex manifolds},
  Springer, Berlin, 1980.
\end{enumerate}

This is a really \emph{great} book for learning about all sorts of good
geometry stuff, starting with differential forms and working on up
through Hodge theory, pseudodifferential operators, sheaves and so on.

But anyway, I've given you a little taste of Hodge theory. The main
thing to remember is that when your manifold is complex, the cohomology
becomes ``bigraded'': instead of just \[H^p(M)\] you get \[H^{i,j}(M).\]
So now, what's nonabelian Hodge theory?

The basic idea is simple: instead of askng what extra structure the
\emph{homology groups} get when \(M\) is a complex manifold, we ask what
extra structure the \emph{homotopy type} of \(M\) gets when \(M\) is a
complex manifold. The homotopy type includes invariants like the
homotopy groups, but also more. How are these constrained by the fact
that \(M\) is complex?

Unfortunately, to describe the answer --- even a little teeny part of
the answer --- I need to turn up the math level a notch.

For starters we can consider the fundamental group \(\pi_1(M)\). But
this is hard to relate to differential geometry, so we will immediately
water it down by picking an algebraic group \(G\) and looking at
homomorphisms of \(\pi_1(M)\) into \(G\). These are basically the same
thing as flat \(G\)-bundles over \(M\), so it's easier to see how \(M\)
being a complex manifold affects things. We can even be sneaky and study
this for all \(G\) at once by forming a group \(\Pi_1(M)\) called the
``proalgebraic completion'' of \(\pi_1(M)\). This is a proalgebraic
group --- an inverse limit of algebraic groups --- which contains
\(\pi_1(M)\) and has the property that any homomorphism from
\(\pi_1(M)\) into an algebraic group \(G\) extends uniquely to a
proalgebraic group homomorphism from \(\Pi_1(M)\) to \(G\).

It's nice to ask what extra structure \(\Pi_1(M)\) gets when \(M\) is a
complex manifold, because this question has a nice answer.

To get ready for how nice the answer is, first go back to plain old
abelian Hodge theory. Note that making the cohomology of \(M\) bigraded
gives an obvious way for the algebraic group \(\mathbb{C}^\times\), the
nonzero complex numbers, to act on the cohomology. The reason is that
for each integer there's a representation of \(\mathbb{C}^\times\) where
the number \(z\) acts as multiplication by \(z^n\), so gradings are just
another way of talking about \(\mathbb{C}^\times\) actions. Since the
cohomology of \(M\) is automatically graded, putting \emph{another}
grading on it amounts to letting \(\mathbb{C}^\times\) act on it.

So in plain old Hodge theory, the answer to ``What extra structure does
the cohomology of \(M\) get when \(M\) is complex?'' is:

\begin{quote}
``It gets an action of \(\mathbb{C}^\times\)!''
\end{quote}

And it turns out that in nonabelian Hodge theory, the answer to ``What
extra structure does \(\Pi_1(M)\) get when \(M\) is complex?'' is:

\begin{quote}
``It gets an action of \(\mathbb{C}^\times\)!''
\end{quote}

This is incredibly cool, but the story goes a lot further. The
fundamental group is just the beginning; you can do something similar
for the higher homotopy groups --- but it's a lot more subtle. In fact,
you can do something similar directly to the homotopy type of \(M\)!
When \(M\) is a compact complex manifold, there's a homotopy type called
the ``schematization of \(M\)'' whose fundamental group is \(\Pi_1(M)\)
--- and there's an action of \(\mathbb{C}^\times\) on this homotopy
type!

By the way, when \(M\) is a compact Kaehler manifold the action of
\(\mathbb{C}^\times\) on its cohomology extends to a natural action of
\(\mathrm{SL}(2,\mathbb{C})\), as explained in Wells' book. I wonder if
\(\mathrm{SL}(2,\mathbb{C})\) acts on the schematization of \(M\)?

I learned about most of this fancy stuff from an incredibly lucid talk
by Bertrand Toen. Unfortunately there seems to be no video of his talk,
since he gave it down the hill at U. C. Berkeley instead of at the MSRI
--- and the handwritten notes at the MSRI website are rather illegible.
So you want to learn more about this, you should probably start with
this quick summary of abelian Hodge theory:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\tightlist
\item
  Tony Pantev, ``Review of abelian Hodge theory'',
  \texttt{http://www.msri.org/publications/ln/msri/2002/introstacks/pantev/1/index.html}
\end{enumerate}

and then take the deep plunge into this paper:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{7}
\tightlist
\item
  Ludmil Katzarkov, Tony Pantev and Bertrand Toen, ``Schematic homotopy
  types and non-abelian Hodge theory I: The Hodge decomposition'',
  available at
  \href{https://arxiv.org/abs/math.AG/0107129}{\texttt{math.AG/0107129}}.
\end{enumerate}

There are a lot of model categories and \(n\)-categories lurking in the
background of this subject, as well as ideas that originated in physics,
like ``Higgs bundles''. For the brave reader I recommend these papers:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  Bertrand Toen, ``Toward a Galoisian interpretation of homotopy
  theory'', available as
  \href{https://arxiv.org/abs/math.AT/0007157}{\texttt{math.AT/0007157}}.
\end{enumerate}

This answers the question: ``the fundamental group is to covering spaces
as the whole homotopy type is to\ldots{} what?'' The fact that it's in
French probably makes it easier to understand.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Bertrand Toen and Gabriele Vezzosi, ``Algebraic geometry over model
  categories (a general approach to derived algebraic geometry)'',
  available as
  \href{https://arxiv.org/abs/math.AG/0110109}{\texttt{math.AG/0110109}}.
\end{enumerate}

This is only for badass mathematicians who find algebraic geometry and
homotopy theory insufficiently mindblowing when taken separately. Ever
wondered what an affine scheme would be like if you replaced the ground
field by an \(E_\infty\) ring spectrum? Then this is for you.

(I thank David Eppstein for pointing out the work of Alan Swett.)

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{Geometry may sometimes appear to take the lead over analysis, but
in fact precedes it only as a servant goes before his master to clear
the path and light him on his way.} --- James Sylvester



\hypertarget{week183}{%
\section{July 30, 2002}\label{week183}}

I'm now in England, visiting the category theorists in Cambridge. Before
coming here I went to a wonderful conference in honor of Graeme Segal's
60th birthday. Most of the talks there described the marvelous different
ways in which ideas from string theory are spreading throughout
mathematics. I should really tell you about this stuff\ldots{} it's very
cool\ldots{} but right now I'm in the mood for talking about something
simpler: some ways in which ideas from \emph{quantum theory} are
spreading throughout mathematics.

Quantum theory is digging its way ever deeper into the mathematical
psyche: for every branch of math, people seem to be developing a
corresponding quantized version, from ``quantum groups'' to ``quantum
cohomology''. Now there is even a textbook on ``quantum calculus'',
suitable for undergraduates:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Victor Kac and Pokman Cheung, \emph{Quantum Calculus}, Springer,
  Berlin, 2002.
\end{enumerate}

Indeed, we'll soon see that quantum calculus is based on an even simpler
subject that deserves to be called ``quantum arithmetic''!

This book talks about two modified versions of calculus: the
``\(h\)-calculus'' and the ``\(q\)-calculus''. The letter \(h\) stands
for Planck's constant, while the letter \(q\) stands for quantum. They
are adjustable parameters related by the formula \[q = \exp(ih).\] In
particular, these modified versions of calculus reduce to Sir Isaac
Newton's good old ``classical calculus'' in the limit where \[h \to 0\]
or alternatively, \[q \to 1.\]

One eerie thing about these modified versions of calculus is that people
discovered them before quantum mechanics --- and they even used the
letters ``\(h\)'' and ``\(q\)'' in their formulas! In particular, the
use of the letter ``\(q\)'' seems to go back all the way to Gauss, who
wrote about a \(q\)-analogue of the binomial formula and other things.

So what's the idea? Like many great ideas, it's pathetically simple. To
get the \(h\)-calculus, you just leave out the limit in the definition
of the derivative, using this instead: \[\frac{f(x+h)-f(x)}{h}\] In the
limit as \(h \to 0\), this reduces to the usual derivative.

There is a lot to say about this, but deeper and more mysterious
mathematics arises from the \(q\)-calculus, where we use the
``\(q\)-derivative'': \[\frac{f(qx)-f(x)}{qx-x}\] This reduces to the
usual derivative as \(q \to 1\). Note that the \(h\)-derivative says how
\(f(x)\) changes when you \emph{add} something to \(x\), while the
\(q\)-calculus says how it changes when you \emph{multiply} \(x\) by
something.

Some choices of \(q\) are more interesting than others. If \(q\) is a
complex number with \(|q| = 1\), we can take the \(q\)-derivative of a
function that's defined only on the unit circle in the complex plane!
Multiplying by a unit complex number rotates the unit circle a bit, just
as adding a real number translates the real line. If you think about
this for a while you'll see the relationship between the \(h\)-calculus
and the \(q\)-calculus, and how it's especially nice when we set
\(q = \exp(ih)\).

Alternatively, if \(q\) is an integer, we can take the \(q\)-derivative
of a function that's defined only on the integers! This is especially
cool when \(q\) is a prime or a power of a prime; then there are nice
connections to algebra.

Pretty much anything you can do with calculus, you can do with the
\(q\)-calculus. There are \(q\)-integrals, \(q\)-trigonometric
functions, \(q\)-exponentials, and so on. If you try books like this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  George E. Andrews, Richard Askey, Ranjan Roy, \emph{Special
  Functions}, Cambridge U. Press, Cambridge, 1999.
\end{enumerate}

you'll see there are even \(q\)-analogues of all the special functions
you know and love --- Bessel functions, hypergeometric functions and so
on. And like I said, the really weird thing is that people invented them
\emph{before} their relation to quantum mechanics was understood.

I can't possibly explain all this stuff here, but a good way to get
started is to look at the \(q\)-analogue of Taylor's formula. In
ordinary calculus this formula says how to reconstruct any sufficiently
nice function from its derivatives at zero:
\[f(x) = f(0) + f'(0) x + f''(0)\frac{x^2}{2!} + \ldots\] In
\(q\)-calculus we can write down the \emph{exact} same formula using
\(q\)-derivatives and \(q\)-factorials! The nth \(q\)-derivative of a
function is defined in the obvious way, by taking the \(q\)-derivative
over and over. Let's do this to the function \(x^n\). If we take its
\(q\)-derivative \emph{once} we get:
\[\frac{(qx)^n-x^n}{qx-x} = \frac{q^n-1}{q-1}x^{n-1}\] We can make this
look almost like the usual derivative of \(x^n\) if we define the
``\(q\)-integer'' \([n]\) by
\[[n] = \frac{q^n-1}{q-1} = 1+q+q^2+\ldots+q^{n-1}\] Then the
\(q\)-derivative of \(x^n\) is just \[[n] x^{n-1}\] This implies that
the \(n\)th \(q\)-derivative of \(x^n\) is the ``\(q\)-factorial''
\[[n]! = [1] [2] \ldots [n] \] This in turn means that the usual Taylor
formula still works if we replace derivatives by \(q\)-derivatives and
factorials by \(q\)-factorials.

Now, starting with \(q\)-factorials we can define \(q\)-binomial
coefficients: \[\frac{[n]!}{[m]![n-m]!}\] and then cook up a
\(q\)-Pascal's triangle, prove a \(q\)-binomial theorem, and so on. It's
not just a matter of recapitulating ordinary calculus, either:
eventually we run into lots of cool identities that have no classical
analogues, like the ``Jacobi triple product formula'':
\[\sum_{n\in\mathbb{Z}} q^{\frac{n(n+1)}{2}}x^n = \prod_{i\in\mathbb{N}^{\geqslant0}} (1+xq^i)(1+x^{-1}q^{i-1})(1-q^i)\]
Now, personally I'm not a big fan of identities just for the sake of
identities. However, I like taking identities and trying to find their
``secret inner meaning'' --- mainly by seeing how they come from
isomorphisms between interesting mathematical structures. The mysterious
identities of \(q\)-mathematics provide an ample playground for this
game, especially since they're all related in intricate ways.

If you ever get stuck on a desert island you can have lots of fun
reinventing quantum calculus, and if you \emph{don't}, you can read Kac
and Cheung's book. So either way, there's no point in me describing its
contents further; instead, I want to say more about how
\(q\)-mathematics is related to physics.

For starters, let's see how the canonical commutation relations change
when we use a \(q\)-derivative to define the momentum operator, instead
of an ordinary derivative. Remember what Schroedinger said: a particle
on a line is described by a ``wavefunction'', which is a complex
function on the line, say \(\psi\). The position operator \(Q\)
multiplies a wavefunction by \(x\): \[(Q \psi)(x) = x \psi(x)\] while
the momentum operator \(P\) basically takes their derivative:
\[(P \psi)(x) = -i \psi'(x)\] The canonical commutation relations say
that \[PQ - QP = -i.\] Now, how does this change if we define the
momentum operator using the \(q\)-derivative instead? I could do this
calculation for you, but you'll be a much better person if you do it
yourself --- it's incredibly easy, so \emph{please} do it. The answer is
\[PQ-qQP = -i.\] In other words, we must replace the commutator
\(PQ - QP\) by a ``\(q\)-commutator''. This is the tip of a big iceberg:
the whole theory of Lie algebras has a ``\(q\)-deformed'' version where
\(q\)-commutators of various sorts take the place of commutators --- and
just as Lie algebras go along with Lie groups, these \(q\)-deformed Lie
algebras go along with ``quantum groups''.

Now let's check to see if you're paying attention. The alert reader
should have already noticed an incredible glaring contradiction in what
I've said! I put it there on purpose, to make an important point.

No? It's simple. I said that making \(q\) different from \(1\) is like
making Planck's constant different from \(0\) --- going from classical
to quantum. People working on quantum groups often say this. But look
what we just did! We took the canonical commutation relations, which are
\emph{already} quantum-mechanical, and modified \emph{them} by making
\(q\) different from 1. This is blatantly obvious if we put Planck's
constant where it belongs in the above formulas, instead of hiding it by
setting it equal to \(1\). The momentum operator is really
\[(P \psi)(x) = -i \hbar \psi'(x)\] so the canonical commutation
relations are \[PQ - QP = -i \hbar\] and when we use a \(q\)-derivative
in the momentum operator they become \[PQ - qQP = -i \hbar.\] So there
really are \emph{two} adjustable parameters floating around: Planck's
constant and this mysterious new ``\(q\)''!

In fact, I've been complaining about this for years: it's only in
certain special contexts that you can think of the ``\(q\)'' or
``\(h\)'' in quantum calculus as related to Planck's constant; here's
one in which they're obviously distinct. So what's the physical meaning
of \(q\)-deformation?

One person to take a stab at this is Shahn Majid:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Shahn Majid, \emph{Foundations of Quantum Group Theory}, Cambridge U.
  Press, Cambridge, 2000.
\end{enumerate}

In this book he says \(q\) is related to Newton's gravitational
constant. This would be cool, because then you could take your theory of
quantum gravity, full of formulas like \[PQ - qQP = -i \hbar,\] and make
the quantum effects small by letting \(\hbar \to 0\), or make the
gravitational effects go away by setting \(q \to 1\). The problem is,
I've never seen a theory of quantum gravity like this! Neither loop
quantum gravity nor string theory work this way.

In fact, both loop quantum gravity people and string theorists agree on
how to quantize gravity without matter in 3 spacetime dimensions. This
is about the \emph{only} thing they agree on. Quantum gravity in 3
dimensions is full of \(q\)-mathematics, and in this theory \(q\) is the
exponential of something involving the \emph{cosmological constant}.
When \(q = 1\) you get the quantum theory of flat 3d spacetime, since
then Einstein's equations say that spacetime is flat --- this is a
peculiarity of 3 dimensions. But when \(q\) is different from \(1\), you
get the quantum theory of a spacetime having constant curvature: a
nonzero cosmological constant means the vacuum has energy density, which
curves spacetime!

For some interesting new insights into this, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  John Barrett, ``Geometrical measurements in three-dimensional quantum
  gravity'', available as
  \href{https://arxiv.org/abs/gr-qc/0203018}{\texttt{gr-qc/0203018}}.
\end{enumerate}

When we make the cosmological constant nonzero in 3d quantum gravity we
must replace the group \(\mathrm{SU}(2)\) by the quantum group
\(\mathrm{SU}_q(2)\). Based on this, one can argue that quantum groups
are misnamed --- they should really be called ``cosmological groups''.
Another way to put it is this: ordinary groups are already perfectly
sufficient for most of quantum theory; quantum groups show up only in
certain special contexts.

This goes to show that the deep inner meaning of the ``\(q\)'' in
quantum groups is still up for debate. Mathematically it has a lot to do
with replacing groups by non-cocommutative Hopf algebras, whose
representations form a braided rather than symmetric monoidal category.
Here Majid and I agree completely: Planck's constant is about deviations
from commutativity while this ``\(q\)'' stuff is about deviations from
co-commutativity, or the failure of braidings to be symmetric. Still, I
think one should try to understand this more deeply. The amazing things
that happen when \(q\) is a power of a prime number have got to be an
important clue! I'll talk about this more next week.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Addendum:} Toby Bartels brought up an important point in a reply
on the newsgroup \texttt{sci.physics.research}:

\begin{quote}
John Baez wrote in small part:
\end{quote}

\begin{quote}
\begin{quote}
In fact, I've been complaining about this for years: it's only in
certain special contexts that you can think of the ``\(q\)'' or
``\(h\)'' in quantum calculus as related to Planck's constant; here's
one in which they're obviously distinct. So what's the physical meaning
of \(q\)-deformation?
\end{quote}
\end{quote}

\begin{quote}
If \(q = \exp h\), then \(h\) couldn't possibly be Planck's constant,
because Planck's constant is not dimensionless. (Or when you make it
dimensionless, you generally fix its value, and then it makes no sense
to speak of varying \(q\).) To get a dimensionless constant for \(h\),
use (\(\hbar G \Lambda/c^3\)), where \(\hbar\) = Planck's constant,
\(G\) = Newton's constant, \(\Lambda\) = cosmological constant, and
\(c\) = speed of light.
\end{quote}

\begin{quote}
If you're coming from the POV where you only had 3 of these before, with
the 4th equal to \(0\) (or infinite in the case of \(c\)), then you're
going to view changing from \(q = 1\) to some other \(q\) as varying the
value of the 4th constant. Thus John (a quantum gravity theorist that
often sets \(\hbar\), \(G\), and \(c\) to fixed values) thinks that it's
\(\Lambda\), while Majid (who studied quantum field theory, which fixes
\(\hbar\) and \(c\) and thinks of \(\Lambda\) as a fixed QFT
effect){[}*{]} thinks that it's \(G\). But it is the dimensionless ratio
that matters to everybody.
\end{quote}

\begin{quote}
{[}*{]}I'm being presumptuous here.
\end{quote}

\begin{quote}
-- Toby Bartels
\end{quote}

I replied:

\begin{quote}
Toby Bartels wrote:

\begin{quote}
John Baez wrote in small part:
\end{quote}

\begin{quote}
\begin{quote}
In fact, I've been complaining about this for years: it's only in
certain special contexts that you can think of the ``\(q\)'' or
``\(h\)'' in quantum calculus as related to Planck's constant; here's
one in which they're obviously distinct. So what's the physical meaning
of \(q\)-deformation?
\end{quote}
\end{quote}

\begin{quote}
If \(q = \exp h\), then \(h\) couldn't possibly be Planck's constant,
because Planck's constant is not dimensionless. (Or when you make it
dimensionless, you generally fix its value, and then it makes no sense
to speak of varying \(q\).)
\end{quote}

It might make sense to treat Planck's constant as dimensionless and
still talk of varying its value.

However, you're certainly right about this: in applications of
\(q\)-mathematics to quantum gravity, we make Planck's constant
dimensionless by combining it with Newton's gravitational constant, the
speed of light, and the cosmological constant in this way:

\begin{quote}
To get a dimensionless constant for \(h\), use
(\(\hbar G \Lambda/c^3\)), where \(\hbar\) = Planck's constant, \(G\) =
Newton's constant, \(\Lambda\) = cosmological constant, and \(c\) =
speed of light.
\end{quote}

\ldots{} or something like that. I think the formula depends on the
dimension of spacetime, and so far it's in \((2+1)\)d spacetime that all
the really solid applications of \(q\)-mathematics to quantum gravity
arise. But the basic idea is robust, and it doesn't depend on the
dimension of spacetime:

We get a dimensionless constant by measuring the density of the vacuum
in Planck masses per Planck volume!

In other words: using \(\hbar\) \(G\) and \(c\) we can construct units
of length, time, mass and so on --- and then we can talk about the
energy density of the vacuum, measured in those units, and get something
dimensionless.

This explains why \(q\)-mathematics only shows up when we do quantum
gravity with a nonzero cosmological constant (or perhaps matter).

\begin{quote}
If you're coming from the POV where you only had 3 of these before, with
the 4th equal to 0 (or infinite in the case of \(c\)), then you're going
to view changing from \(q = 1\) to some other \(q\) as varying the value
of the 4th constant. Thus John (a quantum gravity theorist that often
sets \(\hbar\), \(G\), and \(c\) to fixed values) thinks that it's
\(\Lambda\) {[}\ldots{]}
\end{quote}

Right. Actually, the real reason I like to claim it's \(\Lambda\) is
that this is the most surprising of the four alternatives.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{When we try to pick out anything by itself, we find it hitched to
everything else in the Universe.} --- John Muir



\hypertarget{week184}{%
\section{August 4, 2002}\label{week184}}

To really know a subject you've got to learn a bit of its history. If
that subject is topology, you've got to read this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  I. M. James, editor, \emph{History of Topology}, Elsevier, New York,
  1999.
\end{enumerate}

From a blow-by-blow account of the heroic papers of Poincare to a
detailed account by Peter May of the prehistory of stable homotopy
theory\ldots{} it's all very fascinating. You'll probably want to study
some more of the subject by the time you're done!

In order to satisfy that craving, I want to tell you how to compute some
homology groups. But we'll do it a strange way: using
``\(q\)-mathematics''. I began talking about \(q\)-mathematics last
week, but now I want to dig deeper.

At first, it looks like there are two really \emph{different} places
where this \(q\)-stuff shows up. One is when you do mathematics with
\(q\)-deformed quantum groups replacing the Lie groups you know and love
--- this is important in string theory, knot theory, and loop quantum
gravity. In this case it's best if \(q\) is a unit complex number,
especially an nth root of unity:
\[q = \exp\left(\frac{2\pi i}{n}\right)\] You'll notice that in string
theory, knot theory and loop quantum gravity, \emph{loops} play a big
role. This is no coincidence; in a way, quantum groups are just a
technical device for studying ``loop groups'', which are groups
consisting of functions from a circle to some specified Lie group.

See, in quantum physics problems with a loop group as the symmetry
group, these symmetries tend to hold only \emph{up to a phase}. The
precise way these phases work depends on the parameter \(q\).
Mathematically, this means that instead the loop group itself, the
symmetries are really described by a slightly larger group that keeps
track of these phases, called a ``central extension'' of the loop group.
This has led people to spend huge amounts of energy studying
representations of central extensions of loop groups --- which turn out
to be much more economically understood, in a rather subtle way, as
representations of quantum groups. In all this work the parameter \(q\)
plays a major role.

For more on this try these books:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  Andrew Pressley and Graeme Segal, \emph{Loop Groups}, Oxford U. Press,
  Oxford, 1986.
\item
  Vyjayanathi Chari and Andrew Pressley, \emph{A Guide to Quantum
  Groups}, Cambridge U. Press, Cambridge, 1994.
\item
  Jürgen Fuchs, \emph{Affine Lie Algebras and Quantum Groups}, Cambridge
  U. Press, Cambridge, 1992.
\end{enumerate}

Taken together, they provide a pretty good view of what I'm talking
about. In case you're wondering, an ``affine Lie algebra'' is the Lie
algebra of a central extension of a loop group.

Mathematical physicists know all about this sort of \(q\)-stuff. But
\(q\)-stuff also shows up when we do mathematics with finite fields.
Here I don't mean ``field'' in the physics sense --- I mean an algebraic
gadget where you can add, subtract, multiply and divide! Physicists are
happiest when their field is the real or complex numbers. But
mathematicians also like fields with finitely many elements. If \(q\) is
a power of a prime number, there is a unique field with \(q\) elements,
called \(\mathbb{F}_q\). Even better, these are \emph{all} the finite
fields. If \(q\) is itself prime, \(\mathbb{F}_q\) is just the integers
\(\mod q\). We can get the other finite fields using a trick very much
like how we get the complex numbers from the reals by throwing in the
square root of minus one.

Don't be scared: this is already \emph{more} than what you'll need to
know about finite fields to understand what I'm going to say!

And here's what I'm going to say: lots of formulas for counting
structures on finite sets have \(q\)-versions that tell you how to count
structures on projective spaces over \(\mathbb{F}_q\). Remember, a
``projective space'' is just the space of all line through the origin in
a vector space. The basic idea is this mystical analogy:

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
\(q=1\) & finite sets\tabularnewline
\(q=p^n\) for \(p\) prime & projective spaces over
\(\mathbb{F}_q\)\tabularnewline
\bottomrule
\end{longtable}

This analogy is so powerful that it really pays to think of finite sets
as projective spaces over \(\mathbb{F}_1\), the ``field with one
element'' --- even though there is no such field!

Let's start with some examples. How many points does an \(n\)-element
set have? Answer: the integer \[n.\] Next: how many lines through the
origin does an \(n\)-dimensional vector space over \(\mathbb{F}_q\)
have? Of course, these lines are points in the corresponding projective
space. Answer: the \(q\)-integer
\[[n] = \frac{q^n-1}{q-1} = 1+q+q^2+\ldots+q^{n-1}.\] Remember from last
week that the basic idea behind ``\(q\)-arithmetic'' was to replace
integers by these \(q\)-integers. To see why this answer is right, first
note that we determine a line through the origin by picking any nonzero
vector. There are \(q^n - 1\) of these. However, two vectors determine
the same line if one is a nonzero multiple of the other, and there are
\(q - 1\) nonzero elements of \(\mathbb{F}_q\). So, the actual number of
lines through the origin is \[\frac{q^n-1}{q-1} = [n].\]

Here's another example. How many ways are there to order a set with
\(n\) elements? Answer: \[n!=1\cdot2\cdot\ldots\cdot n.\] Next: how many
maximal flags are there in an \(n\)-dimensional vector space over
\(\mathbb{F}_q\)? Answer: the \(q\)-factorial
\[[n]! = [1][2]\ldots[n].\] Remember, a maximal flag is a line through
the origin contained in a plane through the origin contained in \ldots{}
and so on, up to the top dimension. As we've seen, there are \([n]\)
ways to choose a line \(L\) like this in our vector space \(V\). The
next step is to choose a plane containing \(L\). This is the same as
choosing a line in the quotient space \(V/L\), which has one dimension
less, so there are \([n-1]\) ways to do this. And so on, giving us
\([n]!\) maximal flags.

Here's yet another example. How many \(m\)-element subsets does an
\(n\)-element set have? Answer: the binomial coefficient
\[\frac{n!}{m!(n-m)!}\] Next: how many \(m\)-dimensional subspaces are
there of an \(n\)-dimensional space over \(\mathbb{F}_q\)? Answer: the
\(q\)-binomial coefficient \[\frac{[n]!}{[m]![n-m]!}\] I'll leave this
one as an exercise.

It goes on and on like this: all sorts of structures that can be defined
for finite sets have analogues for the projective geometry of finite
fields, and when we count these, the former tend to give us ``ordinary
mathematics'', while the latter give us ``\(q\)-mathematics'', which
reduces to ordinary mathematics at \(q = 1\).

Clearly this pattern is trying to tell us something; the question is
what. As always, it pays to focus on the simplest case, since that's
where everything starts. I said that the number of lines through the
origin in an \(n\)-dimensional vector space over the field with \(q\)
elements is \[[n] = \frac{q^n-1}{q-1} = 1+q+q^2+\ldots+q^{n-1}.\] But
now let's think about why the \emph{second} equation here is true!

Of course this is just the formula for summing a geometric series, but
we can also categorify this formula. In other words: we can think of
\([n]\) not as the mere \emph{number} of lines through the origin in an
\(n\)-dimensional vector space over \(\mathbb{F}_q\), but as the actual
\emph{set} of such lines. To prove the second equation, we should thus
find a nice way to write this set as \(1\) special line, together with
\(q\) more lines, and then \(q^2\) more, and so on.

To do this, pick a maximal flag: a 1d subspace contained in a 2d
subspace contained in a 3d subspace\ldots{} and so on. There is one line
through the origin contained in our 1d subspace --- namely the subspace
itself. There are \(q\) lines through the origin contained in the 2d
subspace but not in the 1d subspace. There are \(q^2\) lines in the 3d
subspace but not the 2d subspace. And so on. \emph{Voila!}

Combinatorists call this a ``bijective proof'': a proof that two numbers
are equal which actually establishes a bijection between the finite sets
they count. It's an example of ``categorification'' because we've taken
an equation and found the isomorphism that explains it --- taking us
from math in the \emph{set} of natural numbers to math in the
\emph{category} of finite sets.

The cool part is, this proof works for \emph{all} fields, not just
finite ones. For example, over the real numbers we can use it to take
the projective space \(\mathbb{RP}^{n-1}\) and chop it into pieces like
this:
\[\mathbb{RP}^{n-1} = \mathbb{R}^0 + \mathbb{R}^1 + \ldots + \mathbb{R}^{n-1}\]
Topologically speaking, we've just decomposed \(\mathbb{RP}^{n-1}\) as a
union of open balls, or ``cells''. This makes it easy to calculate its
Euler characteristic. Even-dimensional cells contribute \(1\) to the
Euler characteristic, while odd-dimensional cells contribute \(-1\), so
we get
\[|\mathbb{RP}^{n-1}| = (-1)^0 + (-1)^1 + \ldots + (-1)^{n-1} = \frac{(-1)^n-1}{(-1)-1}\]
or in other words, \(0\) if \(n\) is even and \(1\) if \(n\) is odd.
Here I'm using \(|X|\) to stand for the Euler characteristic of \(X\).

You'll notice that the Euler characteristic is working here exactly like
the cardinality did in the finite field case. That's no coincidence! The
Euler characteristic and its evil twin the ``homotopy cardinality'' are
both generalizations of cardinality, as I explained in
\protect\hyperlink{week147}{``Week 147''}. If we use Schanuel's improved
version of the Euler characteristic, which lets us chop up a space \(X\)
and calculate \(|X|\) by summing the Euler characteristics of the
pieces, we have \(|\mathbb{R}| = -1\), so
\[|\mathbb{RP}^{n-1}| = |\mathbb{R}^0+\mathbb{R}^1+\ldots+\mathbb{R}^{n-1}| = |\mathbb{R}|^0+|\mathbb{R}|^1+\ldots+|\mathbb{R}|^{n-1} = [n]\]
where \([n]\) is the \(q\)-integer where \(q = |\mathbb{R}| = -1\). So
if you want to shock your friends, you can tell them that the real
numbers are the field with \(-1\) elements!

What about the complex numbers? Well, as spaces we have
\[\mathbb{C} = \mathbb{R}^2\] so we get
\[|\mathbb{C}| = |\mathbb{R}|^2 = 1.\] This implies that the Euler
characteristic of \(\mathbb{CP}^{n-1}\) is \([n]\), where now
\(q = |\mathbb{C}| = 1\). In other words, it's just \(n\).

Now that we've gotten this wonderful new insight we can test it on
fancier examples, like flag manifolds. I already showed you that the
number of maximal flags in an \(n\)-dimensional vector space over
\(\mathbb{F}_q\) is the \(q\)-factorial \[[n]!\] And if you look back,
you'll see I gave a bijective proof. This means that if we work over the
real or complex numbers, the same proof gives a cell decomposition of
the \emph{manifold} of maximal flags in \(\mathbb{R}^n\) or
\(\mathbb{C}^n\) --- the ``flag manifold'', for short. So we can just
calculate some \(q\)-factorials: \[
  \begin{aligned}
    [1]! &= 1
  \\\,[2]! &= 1 + q
  \\\,[3]! &= 1 + 2q + 2q^2 + q^3 
  \\\,[4]! &= 1 + 3q + 5q^2 + 6q^3 + 5q^4 + 3q^5 + q^6
  \end{aligned}
\] and read off all sorts of fun stuff. For example, the flag manifold
of \(\mathbb{R}^4\) has a cell decomposition like
\[\mathbb{R}^0 + 3\mathbb{R} + 5\mathbb{R}^2 + 6\mathbb{R}^3 + 5\mathbb{R}^4 + 3\mathbb{R}^5 + \mathbb{R}^6\]
meaning that there's 1 zero-cell, 3 one-cells, 5 two-cells and so on.
Similarly, the flag manifold of \(\mathbb{C}^4\) has a cell
decomposition like
\[\mathbb{C}^0 + 3\mathbb{C} + 5\mathbb{C}^2 + 6\mathbb{C}^3 + 5\mathbb{C}^4 + 3\mathbb{C}^5 + \mathbb{C}^6\]
meaning that there's 1 zero-cell, 3 two-cells, 5 four-cells and so on.
(Their dimensions are twice as big now, since \(\mathbb{C}\) has
dimension 2.)

In particular, the Euler characteristic of the flag manifold in \(n\)
dimensions is just \([n]!\), where we set \(q = -1\) in the real case
and \(q = 1\) in the complex case. But in the complex case we can say
more!

Whenever you build a space from cells, you can compute its homology from
a chain complex with one generator for each cell and a differential
saying how the cells of dimension \(n\) are glued to the cells of
dimension \(n-1\). But since the complex flag manifold is built from
only even-dimensional cells, the differential is zero in this case. This
means you can read off its \(n\)th homology group by just counting the
number of \(n\)-cells! The homology group is just \(\mathbb{Z}^k\),
where \(k\) is this number.

So for example, if some nasty guy demands that you calculate the 10th
homology of the complex flag manifold in 4 dimensions, you just tell him
``I know it's a free abelian group\ldots{}'' and calculate \[
  \begin{aligned}
    [4]! &= 1 (1 + q) (1 + q + q^2) (1 + q + q^2 + q^3) 
  \\&= 1 + 3q + 5q^2 + 6q^3 + 5q^4 + 3q^5 + q^6
  \end{aligned}
\] You know the \(q^5\) term gives you the \(10\)-cells in this flag
manifold, since the complex numbers have dimension 2. You see the
coefficient of this term is \(3\), so you say ``\ldots{} and it's
\(\mathbb{Z}^3\).'' He will then think you know algebraic topology, and
go away.

The same sort of trick works for Grassmannians, too. The Grassmannian
\(\mathrm{Gr}(n,k)\) is the set of all \(k\)-dimensional subspaces of an
\(n\)-dimensional vector space. This makes sense over any field. I
already said that over the finite field \(\mathbb{F}_q\), the
cardinality of this Grassmannian is the \(q\)-binomial coefficient
\[|\mathrm{Gr}(n,k)| = \frac{[n]!}{[k]![n-k]!}\] The same formula gives
the Euler characteristic of this Grassmannian over the real numbers if
we set \(q = -1\), and over the complex numbers if we set \(q = 1\). Of
course \(q = 1\) just gives the ordinary binomial coefficients.

So, for example, the Euler characteristic of the manifold of
\(2\)-dimensional subspaces of \(\mathbb{C}^4\) is the same as the
number of ways of choosing \(2\) elements from a \(4\)-element set! A
nice example of the unity of mathematics.

Also, since complex Grassmannians are built from only even-dimensional
cells, we can read off their homology groups just like we did for
complex flag manifolds. Let's work out the homology of
\(\mathrm{Gr}(4,2)\), for example. We start by working out the
\(q\)-binomial coefficient:
\[\frac{[4]!}{[2]![2]!} = \frac{1(1+q)(1+q+q^2)(1+q+q^2+q^3)}{1(1+q)1(1+q)} = 1+q+2q^2+q^3+q^4.\]
It's mildly surprising that this ratio works out to be a polynomial, but
of course we know it must! Reading off the coefficients, we get:

\begin{itemize}
\tightlist
\item
  the \(0\)th homology group is \(\mathbb{Z}\)
\item
  the \(2\)nd homology group is \(\mathbb{Z}\)
\item
  the \(4\)th homology group is \(\mathbb{Z}^2\)
\item
  the \(6\)th homology group is \(\mathbb{Z}\)
\item
  the \(8\)th homology group is \(\mathbb{Z}\)
\end{itemize}

and while we're at it, we've learned this Grassmannian is 8-dimensional
as a \emph{real} manifold --- or \(4\)-dimensional as a complex
manifold. Note how the \(n\)th homology group is the same as the
\((8-n)\)th; this comes from Poincare duality.

On a lighter note: the best way to simplify this sort of expression
\[\frac{1(1+q)(1+q+q^2)(1+q+q^2+q^3)}{1(1+q)1(1+q)}\] is to use base
\(q\). Then it's just
\[\frac{1\times11\times111\times1111}{1\times11\times1\times11} = \frac{111\times1111}{11} = \frac{123321}{11} = 11211\]
where I did the last step using long division. And of course the last
quantity is \[1+q+2q^2+q^3+q^4.\] By the way, the cells we've been
counting are called ``Schubert cells''.

I'll quit here for now, but actually this is just the tip of the
iceberg. I've been talking how \(q\)-factorials are related to
projective geometry, but as readers of
\protect\hyperlink{week178}{``Week 178''},
\protect\hyperlink{week180}{``Week 180''} and
\protect\hyperlink{week181}{``Week 181''} will know, there exists a
generalization of projective geometry for any simple Lie group. In fact,
for \emph{any} simple Lie group \(G\) and \emph{any} parabolic subgroup
\(P\) there is a decomposition of \(G/P\) into Schubert cells, and these
cells are counted by the coefficients of a certain polynomial in \(q\).
Using these you can massively generalize everything I just told you!
I'll explain this stuff in future Weeks.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Addendum:} Here's my reply to a request for clarification from
my friend Squark:

\begin{quote}
Squark wrote:

\begin{quote}
John Baez wrote:
\end{quote}

\begin{quote}
\begin{quote}
If we use Schanuel's improved version of the Euler characteristic, which
lets us chop up a space \(X\) and calculate \(|X|\) by summing the Euler
characteristics of the pieces, we have \(|\mathbb{R}| = -1\),
\(\mathbb{C} = \mathbb{R}^2\), so we get
\[|\mathbb{C}| = |\mathbb{R}|^2 = 1.\] How does this Schanuel thingie
work? \(\mathbb{R}\) and \(\mathbb{C}\) are both contractible, so it has
to be principally different from the usual Euler characteristic!
\end{quote}
\end{quote}

Right. Schanuel's Euler characteristic is not homotopy invariant like
the usual Euler characteristic, and it's only defined for nice spaces,
like polyhedral sets. However, it has a great property to make up for
these sins: whenever we can chop up a polyhedral set \(A\) into nice
parts \(B\) and \(C\), we have \[|A| = |B| + |C|\] We also have
\[|X\times Y| = |X| \times |Y|,\] and homeomorphic nice spaces have the
same Schanuel Euler characteristic. One can check that for compact
manifolds, the Schanuel Euler characteristic matches the usual one, so
my strange calculations really do give the standard ``right answers''.

Schanuel's Euler characteristic of a point is \(1\): \[|*| = 1\] so the
Schanuel Euler characteristic of the open interval must be \(-1\): we
have \[(0,1) = (0,1/2) + \{1/2\} + (1/2,1)\] so if \[|(0,1)| = x\] we
have \[x = x + 1 + x\] so \(x = -1\).

This means that the Schanuel Euler characteristic of a half-open
interval is zero: \[(0,1] = (0,1) + \{1\}\] so
\[|(0,1]| = |(0,1)| + |\{1\}| = -1+1 = 0.\] The Schanuel Euler
characteristic of a circle is \(0\) as well, since we can chop it into
two (or three, or more) half-open intervals.

The Schanuel Euler characteristic of an open square is \(1\):
\[|(0,1)\times(0,1)| = |(0,1)|\times|(0,1)| = -1\times-1 = 1\] and the
S-E characteristic of a closed square is \(1\times1 = 1\).

Now, just as a consistency check, write the closed square as the union
of an open square and its boundary. The boundary is homeomorphic to a
circle, so we should get \(1 + 0 = 1\). It works!

A good reference on this stuff is:

James Propp, ``Exponentiation and Euler measure'', available at
\texttt{http://www.arXiv.org/abs/math.CO/0204009}.

Here you'll see that what I'm calling Schanuel's Euler characteristic
goes back to work before Schanuel. Also, if you push it far enough, it
gives a fascinating approach to dealing with ``sets with negative
numbers of elements'' --- for example, it gives a kind of combinatorial
interpretation of identities like \[\binom{-2}{3} = -4\] Schanuel was
trying to categorify the integers: that's why he came up with this
stuff.

Also see \protect\hyperlink{week147}{``Week 147''} for more!
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\emph{We should declare instead candidly that we dwell on mathematics
and affirm its statements for the sake of its intellectual beauty, which
betokens the reality of its conceptions and the truth of its assertions.
For if this passion were extinct, we would cease to understand
mathematics; its conceptions would dissolve and its proofs carry no
conviction.} --- Michael Polyani



\hypertarget{week185}{%
\section{August 30, 2002}\label{week185}}

I'd like to continue the story of ``\(q\)-mathematics'' which I was
telling you in \protect\hyperlink{week183}{``Week 183''} and
\protect\hyperlink{week184}{``Week 184''}. Sorry for the enormous pause
--- I was travelling around a bunch.

Let's see\ldots{} where were we? We were talking about
``\(q\)-deformation'' - a method of systematically modifying vast tracts
of math and physics by introducing a new parameter ``\(q\)'', in such a
way that everything reduces to stuff you already knew when \(q = 1\).

First we talked about the \(q\)-derivative: \[\frac{f(qx)-f(x)}{qx-x}\]
and how we can reinvent mathematics by replacing the ordinary derivative
with this gadget: modifying the commutation relations in quantum
mechanics, replacing groups by quantum groups, and so on. I didn't say
too much about this, but there's a lot to say. Here's a good place to
get started:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Yu. I. Manin, \emph{Quantum Groups and Noncommutative Geometry}, Les
  Publ. du Centre de Recherches Math., Universite de Montreal, Montreal,
  1988.
\end{enumerate}

Next we took an idiosyncratic detour into ``\(q\)-arithmetic''. We
started with the \(q\)-integers: \[[n] = 1+q+\ldots+q^{n-1}\] which show
up first from the fact that the \(q\)-derivative of \(x^n\) is
\[\frac{(qx)^n-x^n}{qx-x} = [n]x^{n-1}.\] From these we built
\(q\)-factorials and \(q\)-binomial coefficients, and saw that these
functions arise naturally from ``\(q\)-deforming'' combinatorics. In
ordinary combinatorics, you count structures on sets. In \(q\)-deformed
combinatorics, you instead count structures on projective spaces over
the field with \(q\) elements, \(\mathbb{F}_q\). All the formulas look
the same, except that wherever you had integers, you need to carefully
replace them by \(q\)-integers!

We also saw that by taking these formulas and setting \(q = -1\) and
\(q = 1\), we can calculate the Euler characteristics of some projective
varieties defined over the real and complex numbers.

So: certain bits of combinatorics, projective geometry over finite
fields, and real or complex projective geometry are all somehow part of
a unified theory. We can prove theorems simultaneously for all these
subjects and then specialize to the case we want just by setting q to
the right value. It's sort of like tuning to whatever radio station you
want by turning the dial. It's even good to tune \(q\) to be complex,
when we're studying quantum groups\ldots{} but I don't feel like
listening to those stations right now! Right now I want to ponder the
basics a bit more. Like: what does all this have to do with quantum
mechanics?

In \protect\hyperlink{week183}{``Week 183''} I described how to
\(q\)-deform the ``Schroedinger representation'' of a quantum particle
on a line, in which its state is described by a wavefunction. The basic
idea was to leave the position operator alone, but replace the
derivative in the momentum operator by a \(q\)-derivative.

However, there's another way to describe a quantum particle on the line,
called the ``Fock representation''. Here we have an abstract basis of
states \(\vert 0\rangle, \vert 1\rangle, \vert 2\rangle, \ldots\) where
secretly we think of \(\vert n\rangle\) as the \(n\)th eigenstate of the
harmonic oscillator Hamiltonian. There are annihilation and creation
operators \(a\) and \(a^*\) which push us up and down this ladder of
states. We can describe these very efficiently if we think of states as
being polynomials, with \[\vert n\rangle = \frac{x^n}{n!}\] In these
terms, the creation operator \(a^*\) is just multiplication by \(x\),
while the annihilation operator \(a\) is differentiation. These satisfy
\[
  \begin{aligned}
    a\vert n\rangle &= \vert n-1\rangle
  \\a^*\vert n\rangle &= (n+1) \vert n+1\rangle
  \end{aligned}
\] so we get the commutation relations \[a a^* - a^* a = 1.\] In case
you're wondering, my conventions differ slightly from the usual ones,
because my states \(\vert n\rangle\) aren't normalized --- but there's a
good reason for this, which will become clear in due course.

We can define other operators starting from the annihilation and
creation operators. First, there's the harmonic oscillator Hamiltonian:
\[H = a^* a\] As you can easily check for yourself, it has our nice
basis of states as eigenvectors: \[H\vert n\rangle = n \vert n\rangle\]
It's also called the ``number operator'', because its eigenvalue in the
\(n\)th state is just \(n\).

Next, we can define position and momentum operators \(Q\) and \(P\) by:
\[Q=\frac{a+a^*}{\sqrt{2}} \qquad P=\frac{a-a^*}{i\sqrt2}\] It's easy to
check that they satisfy the same commutation relations \[PQ - QP = -i\]
as in the Schrodinger representation. To get a full-blown isomorphism
between the Fock and Schrodinger representations, we just need to map
the state \(\vert 0\rangle\) to a wisely chosen Gaussian function on the
line, and the rest falls into place\ldots.

But anyway, having already \(q\)-deformed the Schroedinger
representation, let's \(q\)-deform the Fock representation. It's pretty
simple: we leave the creation operator alone, but use the
\(q\)-derivative as our annihilation operator! This gives the
\(q\)-deformed commutation relations: \[a a^* - q a^* a = 1\] If we now
define a basis of states by \[\vert n\rangle = \frac{x^n}{[n]!}\] we get
\[
  \begin{aligned}
    a\vert n\rangle &= \vert n-1\rangle
  \\a^*\vert n\rangle &= [n+1] \vert n+1\rangle
  \end{aligned}
\] We can also define a \(q\)-deformed Hamiltonian by \[H = a^* a\] and
we get \[H\vert n\rangle = [n] \vert n\rangle\] so we could call this
operator the ``\(q\)-number operator''.

We could march on like this, but now I want to take a quantum leap. If
we ``categorify'' the ordinary Fock representation, we get the
combinatorics of structures on finite sets. And if we categorify the
\(q\)-deformed Fock representation, we get the combinatorics of
structures on projective spaces over the field with \(q\) elements!

Let me explain\ldots.

Ordinary combinatorics counts structures on finite sets. It's fun to do
this using ``generating functions''. To do this, suppose we have some
type of structure that we can put on a finite set --- like an ordering,
or a partition, or a way of coloring the set, or making it into a graph
of some sort, or whatever: anything we might want to count! Let's call
this type of structure \(F\), and let \(F_k\) stand for the set of all
ways we can put this structure on a \(k\)-element set, and let \(|F_k|\)
be the \emph{number} of all ways we can put this structure on a
\(k\)-element set. Then we can define a function \(|F|\) by
\[|F|(x) = \sum\frac{F_k}{k!}x^k.\] This is called the ``generating
function'' of \(F\). Of course, the sum might not converge; it's really
just a formal power series.

For example, suppose \(F\) is ``2-colorings'' --- to put a structure
like this on a finite set, we color each element either red or blue.
There are \(2^k\) ways to do this to a \(k\)-element set, so
\[|F_k| = 2^k\] and thus \[|F|(x) = \sum\frac{2^k}{k!}x^k = \exp(2x).\]
More generally, if \(F\) is ``\(n\)-colorings'', its generating function
is \[|F|(x) = \exp(nx).\]

Here's another example that's even simpler. Suppose \(G\) is ``being an
\(n\)-element set''. This is such a boring structure that you might
never have thought about it. There's exactly one way to put this
structure on an \(k\)-element set if \(k\) = \(n\), and none if \(k\) is
different from \(n\), so \[|G|(x) = \frac{x^n}{n!}\] You should
recognize this function: a while back, I called it the \(n\)th
eigenstate of the harmonic oscillator Hamiltonian! This is cool, because
in physics we often think of this state as one in which there are n
identical bosons present --- for example, \(n\) photons. That's why the
harmonic oscillator is also called the ``number operator''. Now we're
seeing that this ``\(n\)-particle state'' is also the generating
function of ``being an \(n\)-element set''. So the quantum mechanics of
identical bosons may not be so weird after all.

The generating function \[|F|(x) = \exp(nx)\] also corresponds to a
famous state in Fock space, called a ``coherent state''. For example, a
laser beam is a coherent state of photons. If you're curious about the
details, see:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  John Baez and Michael Weiss, ``Photons, schmotons'', available at
  \texttt{http://math.ucr.edu/home/baez/photon}
\end{enumerate}

But don't worry about it too much: my main point is just that it's fun
to take types of structure, work out their generating functions, and
think of these as states in Fock space.

To take this a step further, let's see how the creation and annihilation
operators fit into the picture.

First, since these are linear operators, we should think about how
\emph{addition} fits into the picture! In quantum mechanics, adding
states is called ``superposition''. But what about in combinatorics?
What corresponds to adding generating functions?

It's very nice. Given two types of structure, say \(F\) and \(G\), we
can define a type of structure \(F+G\) by saying an \(F+G\)-structure on
the set \(S\) consists of either an \(F\)-structure on \(S\) or a
\(G\)-structure on \(S\). This gives us \[|F+G| = |F| + |G|\] which
justifies the notation \(F+G\). It means we can think of \(F+G\) as a
``superposition'' of structure types. Of course you might complain that
in quantum mechanics we can do more than add states: we can also
multiply them by complex numbers! We can't do this with structure types;
we can only multiply those by \emph{natural} numbers, via repeated
addition.

So the combinatorics of structures on finite sets is like a bare-bones
version of quantum mechanics, without the complex numbers or even
subtraction. You might think we're doing quantum mechanics over the
natural numbers, and that's close --- but we're actually doing quantum
mechanics over the category of finite sets!

To make the idea of ``categorified quantum mechanics'' really precise,
I'll need to jack up the math level a fair amount. This may be a bit
scary, so I'll do it later in this article, after everyone has already
stopped reading.

But now, what about the creation operator? Since this involves
multiplication, I'd better tell you how to \emph{multiply} structure
types.

We can define a type of structure \(FG\) by saying an \(FG\)-structure
on \(S\) consists of a way of chopping \(S\) into two disjoint subsets
and putting an \(F\)-structure on the first subset and a \(G\)-structure
on the second. If we make this definition, we get \[|FG| = |F| |G|\]
I'll let you check this!

Now let's invent a creation operation \(A^*\) on structure types that
reduces to the usual creation operator \(a^*\) when we take their
generating functions. In other words, we want an operation \(A^*\) with
\[|A^*F| = a^*|F|\] The operator \(a^*\) is multiplication by \(x\), and
we've seen that \(x\) is the generating function of the structure type
``being a \(1\)-element set''. So if we call that structure type \(X\),
the operation \[A^*F = XF\] does what we want.

But what is \(A^*F\) really \emph{like?}

Well, to put a structure of this type on a set \(S\), we chop it into
two parts, put an \(X\)-structure on one part, and put an
\(F\)-structure on the other. So putting an \(A^*F\)-structure on a set
really just means picking a point from that set, removing it, and
putting an \(F\)-structure on what's left!

This business about ``removing a point'' may sound more like
annihilation than creation. But you can check that if you have an
\(F\)-structure on a set with n elements, you get an \(A^*F\)-structure
on a set with n+1 elements. It's just like how you translate the
function \(f(x)\) to the \emph{left} one notch by forming the new
function \(f(x+1)\). You might have thought that would translate the
function to the \emph{right} --- but pushing points to the right pushes
functions to the left.

So the creation operator really does push the particle number up by one.
In particular, if we stretch our notation and let \(\vert n\rangle\)
stand for the structure type ``being an \(n\)-element set'', we get
\[A^*\vert n\rangle = (n+1) \vert n+1\rangle\] just like we should.

The annihilation operator for structure types is similar. Let's call it
\(A\). To put an \(AF\)-structure on the set \(S\), we pick an extra
point, say \(*\), and put an \(F\)-structure on the disjoint union
\(S \sqcup \{*\}\). I'll let you check that with this definition,
\[|AF| = a|F|\] and \[A\vert n\rangle = \vert n-1\rangle\] as desired.

The creation and annihilation operators are linear: \[
  \begin{aligned}
    A(F+G) &= AF + AG
  \\A^*(F+G) &= A^*F + A^*G
  \end{aligned}
\] where the equals sign is secretly an isomorphism\ldots{} you see,
we're categorifying! We also have an isomorphism \[A A^* = A^* A + 1\]
which is just a categorified version of \[a a^* = a^* a + 1,\] cleverly
rewritten to avoid subtraction. You should prove this yourself! If you
get stuck, the answer is here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  John Baez and James Dolan, ``From finite sets to Feynman diagrams'',
  in \emph{Mathematics Unlimited --- 2001 and Beyond}, vol.~1,
  eds.~Bjorn Engquist and Wilfried Schmid, Springer, Berlin, 2001,
  pp.~29-50. Also available as
  \href{https://arxiv.org/abs/math.QA/0004133}{math.QA/0004133}.
\end{enumerate}

\ldots{} along with lots of other stuff, like the inner product on our
categorified Fock representation --- and indeed, a categorification of
the whole theory of Feynman diagrams. However, to describe these we need
to go a bit beyond the concept of ``structure type'' and talk about
``stuff types'', which would be too much of a digression here.

At this point I should mention that the idea of categorifying the Fock
representation was worked out by Jim Dolan and myself in a lengthy
series of coffee-shop conversations. On the other hand, people have used
generating functions in combinatorics for a long time. There are a lot
of really fun things you can do with them! For a nice easy introduction,
try this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Ronald L. Graham, Donald E. Knuth, and Oren Patashnik, \emph{Concrete
  Mathematics: a Foundation for Computer Science}, 2nd edition,
  Addison-Wesley, Reading, Massachusetts, 1994.
\end{enumerate}

To dig deeper, try these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\item
  Herbert Wilf, \emph{Generatingfunctionology}, Academic Press, Boston,
  1994. Also available for free at
  \texttt{http://www.cis.upenn.edu/\textasciitilde{}wilf/}
\item
  Richard P. Stanley, \emph{Enumerative Combinatorics}, two volumes,
  Cambridge U. Press, Cambridge, 1999.
\end{enumerate}

However, it was only in the 1980s that Andre Joyal gave a precise
definition of a ``structure type'' --- he called them ``especes de
structures'', so English speakers often call them ``species'':

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{6}
\item
  Andre Joyal, \emph{Une theorie combinatoire des series formelles},
  \emph{Adv. Math.} \textbf{42} (1981), 1--82.
\item
  Andre Joyal, ``Foncteurs analytiques et especes de structures'', in
  \emph{Combinatoire Enumerative}, Springer Lecture Notes in Mathematics
  \textbf{1234}, Springer, Berlin (1986), 126--159.
\end{enumerate}

I also urge you to read this excellent book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{8}
\tightlist
\item
  F. Bergeron, G. Labelle, and P. Leroux, \emph{Combinatorial species
  and tree-like structures}, Cambridge, Cambridge U. Press, 1998.
\end{enumerate}

But now let me get to the punchline. We can talk about structures not
just on finite sets, but on projective spaces over the field with \(q\)
elements, where \(q\) is any prime power. In
\protect\hyperlink{week184}{``Week 184''} I started trying to convince
you that there is a very fruitful analogy between these. If \(V\) is a
\(n\)-dimensional vector space over this field, and \(\mathbb{P}(V)\) is
the projective space consisting of all lines through the origin in
\(V\), we should think of \(\mathbb{P}(V)\) as a \(q\)-deformed version
of an \(n\)-element set. For example, the number of points in
\(\mathbb{P}(V)\) is the \(q\)-integer
\[[n] = 1 + q + \ldots + q^{n-1}\] So, let \(F\) be any type of
structure we can put on a projective space like this. Let \(F_k\) stand
for the \emph{set} of all ways we can put this structure on
\(\mathbb{P}(V)\) when \(V\) is our favorite \(k\)-dimensional vector
space. Let \(|F_k|\) be the \emph{number} of all ways we can do this.
Then we can define the generating function \(|F|\) by
\[|F|(x) = \sum\frac{|F_k|}{[k]!}x^k\] Now there's a \(q\)-factorial in
the denominator!

We can add structure types just as before, and get \[|F+G| = |F| + |G|\]
However, we have to multiply them differently. To put an
\(FG\)-structure on \(\mathbb{P}(V)\), we pick a subspace \(U\) of \(V\)
and put an \(F\)-structure on \(\mathbb{P}(U)\) and a \(G\)-structure on
\(\mathbb{P}(V/U)\). With this sneaky definition we get
\[|FG| = |F| |G|\] This only works because there's \(q\)-factorial in
our definition of generating function!

Now for the new creation and annihilation operators. To put an
\(A^*F\)-structure on \(\mathbb{P}(V)\), we pick a \(1\)-dimensional
subspace \(L\) in \(V\) and put an \(F\)-structure on
\(\mathbb{P}(V/L)\). To put an \(AF\)-structure on \(\mathbb{P}(V)\) we
take a \(1\)-dimensional vector space \(L\) and put an \(F\)-structure
on \(\mathbb{P}(V+L)\). Note that these definitions are almost like the
old ones! But now we get the \(q\)-deformed commutation relation:
\[A A^* = q A^* A + 1\] The equation here is really an isomorphism.

If we let \(\vert n\rangle\) be the structure of ``being the
projectivization of an \(n\)-dimensional vector space'', we have \[
  \begin{aligned}
    A\vert n\rangle &= \vert n-1\rangle
  \\A^*\vert n\rangle &= [n+1] \vert n+1\rangle
  \end{aligned}
\] We can also define a Hamiltonian by \[H = A^* A\] and we get
\[H\vert n\rangle = [n] \vert n\rangle\] where now the eigenvalues are
\(q\)-integers.

In short, we've categorified the \(q\)-deformed Fock representation!

To wrap up, I'd like to make the underlying category theory in this
story a bit more precise. I'm afraid I'll have to turn up the math level
a notch now.

First, here's how Joyal's theory works. A ``structure type'' is really a
functor \[F\colon \mathsf{FinSet}_0 \to \mathsf{Set}\] where
\(\mathsf{FinSet}_0\) is the groupoid of finite sets and bijections, and
\(\mathsf{Set}\) is the category of sets and functions.

So: if you feed \(F\) a finite set \(X\) it spits out \(F(X)\), the set
of all structures on \(X\) of the given type. For example, if \(F\) is
the structure type of ``orderings'', \(F(X)\) would be the set of all
orderings of \(X\).

But also: if you feed your structure type a bijection
\(f\colon X \to Y\), it spits out a function
\(F(f)\colon F(X) \to F(Y)\). This describes how we can transfer any
structure on \(X\) to a structure on \(Y\) using the bijection \(f\).
For example, we can use our bijection to turn any ordering of \(X\) into
an ordering of \(Y\).

There is actually a category of structure types, where the objects are
functors \[F\colon \mathsf{FinSet}_0 \to \mathsf{Set}\] and the
morphisms are natural transformations between these. I'll call this
category \(\mathsf{Set}[[x]]\), because it's really a categorification
of the set of formal power series with natural number coefficients,
\(\mathbb{N}[[x]]\). But I want to explain exactly what this means!

In Platonic heaven, there's an enormous chart showing how you can
categorify all sorts of concepts. It starts out something like this:

\begin{longtable}[]{@{}ll@{}}
\toprule
\textbf{Mathematics based on sets} & \textbf{Mathematics based on
categories}\tabularnewline
\midrule
\endhead
sets & categories\tabularnewline
functions between sets & functors between categories\tabularnewline
equations between functions & natural isomorphisms between
functors\tabularnewline
elements of sets & objects of categories\tabularnewline
equations between elements & isomorphisms between objects\tabularnewline
\bottomrule
\end{longtable}

\ldots{} and it goes on forever. In particular, if you look further down
this chart, you'll see that \(\mathbb{N}\) appears in the left-hand
column as the free commutative rig on no generators, \(\mathsf{Set}\)
appears in the right-hand column as the free symmetric \(2\)-rig on no
generators.

Huh?

A ``rig'' is a ``ring but without negatives'' --- hence the missing
letter n.~More precisely, it's a set with two monoid structures, \(+\)
and \(\times\), where \(+\) is commutative and \(\times\) distributes
over \(+\). We call a rig ``commutative'' if the multiplication is also
commutative. The most important rig of all is the natural numbers, since
this is the free rig on no generators. It's also the free commutative
rig on no generators.

There are actually different ways to categorify the concept of rig and
get a notion of ``\(2\)-rig'', but one nice way is to define it as a
category with colimits equipped with a monoidal structure that
distributes over the colimits. Having colimits is like having addition;
the monoidal structure is like multiplication. We call a \(2\)-rig
``symmetric'' if the monoidal structure is symmetric; this is like being
commutative. The most important \(2\)-rig of all is the category
\(\mathsf{Set}\), since this is the free \(2\)-rig on no generators.
It's also the free symmetric \(2\)-rig on no generators.

The free commutative rig on \emph{one} generator is \(\mathbb{N}[x]\),
the rig of polynomials in \(x\) with natural number coefficients. We
need to do a kind of ``completion'' process, throwing in certain
infinite sums, to get \(\mathbb{N}[[x]]\), the rig of formal power
series in x with natural number coefficients. The theory of \(2\)-rigs
allows infinite sums automatically, so the free symmetric \(2\)-rig on
one generator is called \(\mathsf{Set}[[x]]\) --- and this is the
category of structure types! Addition and multiplication in this
\(2\)-rig turn out to work exactly as I've already described.

There's a lot more to say about this, but the interesting thing to me
now is that when we \(q\)-deform \(\mathsf{Set}[[x]]\), we get the
category of structures on projective spaces over the field with \(q\)
elements. And the \emph{really} interesting part is that while this is a
monoidal category, it's no longer symmetric. However, it's almost
\emph{braided}. Actually, Joyal and Street showed this in a related
situation, namely where one considers not a \emph{set} of structures on
a projective space, but a \emph{complex vector space} of structures:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{9}
\tightlist
\item
  Andre Joyal and Ross Street, ``The category of representations of the
  general linear groups over a finite field'', \emph{Jour. Alg.}
  \textbf{176} (1995), 908--945.
\end{enumerate}

They even show that the braiding satisfies the Hecke relations, familiar
from the theory of the quantum group \(\mathrm{SL}_q(n)\)! This shows
there's a really deep relationship between the \(q\)-deformation in the
theory of quantum groups and the strange \(q\)-deformation I'm talking
about here, where \(q\) is a power of a prime number. There are indeed
other clues pointing to a relation of this sort, but this seems like the
most fundamental one I've seen so far\ldots{} and I'm trying to get to
the bottom of things!

I hope the general picture is clear:

\begin{longtable}[]{@{}ll@{}}
\toprule
\begin{minipage}[b]{0.38\columnwidth}\raggedright
\(q=1\)\strut
\end{minipage} & \begin{minipage}[b]{0.56\columnwidth}\raggedright
\(q=p^n\) for \(p\) prime\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.38\columnwidth}\raggedright
finite sets\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
projective spaces over \(\mathbb{F}_q\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.38\columnwidth}\raggedright
permutation groups \(S_n\)\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
projective special linear groups \(\mathrm{PSL}(n,\mathbb{F}_q)\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.38\columnwidth}\raggedright
structure types\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\(q\)-deformed structure types\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.38\columnwidth}\raggedright
Fock representation\strut
\end{minipage} & \begin{minipage}[t]{0.56\columnwidth}\raggedright
\(q\)-deformed Fock representation\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

We're thinking of the groupoid formed by the projective spaces and their
symmetry groups \(\mathrm{PSL}(n,\mathbb{F}_q)\) as a \(q\)-deformed
version of the groupoid formed by the finite sets and their symmetry
groups \(S_n\). The functors from these groupoids to \(\mathsf{Set}\)
are ``structure types'', and taking generating functions of these we get
the Fock representation.

In a sense, all this relies on the analogy between the permutation
groups \(S_n\) and the groups \(\mathrm{PSL}(n)\). The groups
\(\mathrm{PSL}(n)\) have Dynkin diagrams like this: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (5,0);
    \foreach \x in {0,1,2,3,4,5}
      \node at (\x,0) {$\bullet$};
  \end{tikzpicture}
\] and we call this series of Dynkin diagrams the ``\(A\)'' series. So,
you should wonder if there is a grand generalization of everything I've
said so far to \emph{other} Dynkin diagrams. And the answer appears to
be: yes!

I'll talk a bit about this next week.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\hypertarget{week186}{%
\section{September 10, 2002}\label{week186}}

Okay, now let's pull together all the strands of our story about Dynkin
diagrams and \(q\)-mathematics. The story can be summarized in a rather
elaborate diagram, of which this is the first part:

\begin{verbatim}
                          DYNKIN DIAGRAM
                          /             \
                         /               \
           pick a field /                 \ 
                       /                   \
                      /                     \
                     /        Weyl group     \
           SIMPLE ALGEBRAIC ----------> COXETER GROUP 
                 GROUP                        | 
                    |                         | 
              FLAG VARIETY             COXETER COMPLEX 
                     \                       /
                      \                     /
                       \                   /
                        \                 /
                         \               /
                          \             /
                           \           /
                           $q$-POLYNOMIAL
\end{verbatim}

We start with a Dynkin diagram and see what we can do with it; we'll
find that two separate routes lead to the same polynomial, which for
lack of a better name I'll call the ``\(q\)-polynomial''. In recent
weeks I've hinted that starting with the Dynkin diagrams in the
\(\mathrm{A}_n\) series, like this: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (4,0);
    \foreach \x in {0,1,2,3,4}
      \node at (\x,0) {$\bullet$};
  \end{tikzpicture}
\] we get the polynomials called ``\(q\)-factorials''. Now I'll sketch
the story for arbitrary Dynkin diagrams!

Way back in \protect\hyperlink{week62}{``Week 62''} I showed how a
Dynkin diagram gives a finite reflection group: that is, a finite group
of symmetries of \(n\)-dimensional Euclidean space, generated by
reflections, one for each of the \(n\) dots in the diagram, satisfying
relations described by the edges in the diagram. In fact, I noted that
this trick works for a slightly more general class of diagrams called
``Coxeter diagrams''. The resulting groups are called ``Coxeter
groups''.

But let's not go for maximal generality: any Dynkin diagram gives us a
Coxeter group, and that's enough for now. Some of these Coxeter groups
are symmetry groups of Platonic solids and their analogues in other
dimensions: the regular polytopes. For example, starting with this
Dynkin diagram: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\mathrm{A}_2$};
  \end{tikzpicture}
\] we get the symmetry group of the equilateral triangle, while starting
with this one: \[
  \begin{tikzpicture}
    \draw[double,double equal sign distance] (0.5,0) to (1,0);
    \draw[double,double equal sign distance,-implies] (0,0) to (0.55,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\mathrm{B}_2$};
  \end{tikzpicture}
\] we get the symmetry group of the square, and starting with this one:
\[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
    \node at (3,0) {$\mathrm{A}_3$};
  \end{tikzpicture}
\] we get the symmetry group of the regular tetrahedron. Other Coxeter
groups are symmetry groups of polytopes that aren't regular. This, for
example: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (6,0);
    \draw[thick] (4,0) to (4,1);
    \foreach \x in {0,1,2,3,4,5,6}
      \node at (\x,0) {$\bullet$};
    \node at (4,1) {$\bullet$};
    \node at (7,0.5) {$E_8$};
  \end{tikzpicture}
\] is the symmetry group of a non-regular polytope in 8 dimensions with
240 vertices!

However, some Coxeter groups are not naturally regarded as the symmetry
groups of polytopes. So, to deal with all Coxeter groups in a systematic
way, it's better to think of them as symmetries of certain simplicial
complexes called ``Coxeter complexes''. Roughly speaking, a simplicial
complex is a gadget made of points, line segments, triangles,
tetrahedra, \(4\)-simplices, and so on --- all stuck together in a nice
way.

If you have a Coxeter diagram with \(n\) dots, the highest dimension of
the simplices in its Coxeter complex will be \(n-1\), and it will have
one of these top-dimensional simplices for each element of the Coxeter
group. For example, I've already said this Dynkin diagram: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (1,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\mathrm{A}_2$};
  \end{tikzpicture}
\] gives the Coxeter group consisting of symmetries of the equilateral
triangle --- by which I mean all reflections and rotations. This group
has 6 elements, so the Coxeter complex is built from 6 line segments
together with lower-dimensional simplices (points) --- and in fact, it's
just a hexagon.

A hexagon is also what you get by dividing each edge of the equilateral
triangle into two parts. That's no coincidence: whenever our Coxeter
group is naturally the symmetries of a polytope, we can get the Coxeter
complex by ``barycentrically subdividing'' the surface of this polytope
- which basically means sticking an extra vertex in the middle of every
face of the polytope and using these to chop its surface into simplices.

For example, this diagram \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (2,0);
    \node at (0,0) {$\bullet$};
    \node at (1,0) {$\bullet$};
    \node at (2,0) {$\bullet$};
    \node at (3,0) {$\mathrm{A}_2$};
  \end{tikzpicture}
\] gives the symmetry group of the tetrahedron, so we can get its
Coxeter complex by barycentrically subdividing the surface of the
tetrahedron, obtaining a shape with 24 triangles. Surprise: this is just
the size of the symmetry group of the tetrahedron!

But that's how it always works: the number of top-dimensional simplices
in the Coxeter complex is the number of elements in the Coxeter group.
Even better, if you pick any top-dimensional simplex in the Coxeter
complex, there always exists a \emph{unique} element of the Coxeter
group that maps it to any other top-dimensional simplex. So the Coxeter
complex is the best possible thing made out of simplices on which the
Coxeter group acts as symmetries.

Now, all of this has been done starting with a Dynkin diagram and
nothing else. But we can do other stuff if we pick a field, like the
real numbers \(\mathbb{R}\) or the complex numbers \(\mathbb{C}\) --- or
if you're feeling daring, the field \(\mathbb{F}_q\) with \(q\)
elements, where \(q\) is some power of a prime number.

First and most importantly, a field lets us define a ``simple algebraic
group''. If we use \(\mathbb{R}\) or \(\mathbb{C}\) as our field these
are just the usual real or complex simple Lie groups associated with
Dynkin diagrams, which I explained in \protect\hyperlink{week63}{``Week
63''} and \protect\hyperlink{week64}{``Week 64''}. These are
tremendously important in physics, and that's what got me going on this
business in the first place! But we can also mimic this procedure using
other fields, and if we use the finite field \(\mathbb{F}_q\), we get
fascinating connections to \(q\)-mathematics\ldots{} which I've begun
explaining in recent Weeks.

No matter what field we use, the group we get will be the symmetries of
a kind of ``incidence geometry'': a setup with stuff like points, lines,
and planes, but perhaps also other geometrical figures that they never
told you about in school. There will be one type of geometrical figure
for each dot in our Dynkin diagram!

In the case where our field is the complex numbers, I explained these
incidence geometries rather carefully in
\protect\hyperlink{week178}{``Week 178''},
\protect\hyperlink{week179}{``Week 179''} and
\protect\hyperlink{week180}{``Week 180''}. But they're pretty similar
for other fields, so to a zeroth approximation you can sort of fake it
and pretend they work just the same. Eventually that attitude will get
you in trouble, but hopefully you'll notice when it happens.

For example, the Dynkin diagram \(\mathrm{A}_n\) has \(n\) dots in a row
like this: \[
  \begin{tikzpicture}
    \draw[thick] (0,0) to (4,0);
    \foreach \x in {0,1,2,3,4}
      \node at (\x,0) {$\bullet$};
  \end{tikzpicture}
\] and this gives the symmetry groups of \emph{projective} geometry: the
geometry of points, lines, planes, and so on up to dimension \(n\).

More precisely, if we pick any field \(\mathbb{F}\), we can use this
diagram to concoct the group \(\mathrm{SL}(n+1,\mathbb{F})\) consisting
of \((n+1)\times(n+1)\) matrices with entries in \(\mathbb{F}\) and
determinant equal to \(1\). This group acts on the projective
\(n\)-space \(\mathbb{FP}^n\) --- the space of all \(1\)-dimensional
subspaces of the vector space \(\mathbb{F}^{n+1}\). Just as in the
complex case, we can talk about points, lines, planes and the like in
\(\mathbb{FP}^n\), and also incidence relations like ``this point lies
on that line''. These relations satisfy the axioms of projective
geometry, as explained in \protect\hyperlink{week162}{``Week 162''}. The
group \(\mathrm{SL}(n+1,\mathbb{F})\) acts on all these geometrical
figures in a way that preserves the incidence relations\ldots{} so we
say it's a symmetry group for this particular projective geometry!

(If you prefer the group \(\mathrm{PSL}(n+1,\mathbb{F})\), that's fine
too; maybe even better. They have the same Lie algebra so it's not all
that big a deal.)

The same general sort of thing works for all other Dynkin diagrams, too.
The \(\mathrm{B}_n\) and \(\mathrm{D}_n\) series give the symmetry
groups of conformal geometries, while the \(\mathrm{C}_n\) series give
the symmetry groups of symplectic geometries, and the exceptional Dynkin
diagrams give symmetry groups of ``exceptional geometries'' associated
to the octonions and their analogues for other fields.

In general, whenever we pick a Dynkin diagram and a field we get a
geometry. We define a ``maximal flag'' in this geometry to consist of
one geometrical figure of each type, all incident. The set of maximal
flags turns out to be the key to understanding all the different kinds
of incidence geometry in a unified way. When our field is the real or
complex numbers this set is a manifold, often called the ``flag
manifold'' --- it's a special case of the flag manifolds described in
\protect\hyperlink{week180}{``Week 180''}. But over other fields, the
set of maximal flags is not a manifold but an ``algebraic variety''. If
you don't know what that means, don't worry: I'm only mentioning this
because then we get to call it the ``flag variety'' and sound
intelligent. The real point here is that there's a wonderful analogy:

\begin{longtable}[]{@{}ll@{}}
\toprule
simple algebraic groups & Coxeter groups\tabularnewline
\midrule
\endhead
flag varieties & Coxeter complexes\tabularnewline
\bottomrule
\end{longtable}

Just as a Coxeter group acts as symmetries of its Coxeter complex, a
simple algebraic group acts as symmetries of its flag variety. But the
analogy goes far deeper than that! In a certain strange way, you really
can think of the Coxeter group as a simple algebraic group over the
field \(\mathbb{F}_q\) where \(q = 1\), and you can think of the Coxeter
complex as the corresponding flag variety.

Of course, there \emph{is no} field \(\mathbb{F}_q\) with \(q = 1\).
Nonetheless, all sorts of formulas that work for other values of \(q\)
for simple algebraic groups over \(\mathbb{F}_q\) and their flag
varieties, apply when \(q = 1\) to Coxeter groups and their Coxeter
complexes! I gave the primordial example in
\protect\hyperlink{week184}{``Week 184''}, which comes from the Dynkin
diagram \(\mathrm{A}_n\). The number of points in the flag variety of
the group \(\mathrm{SL}(n+1,\mathbb{F}_q)\) is the \(q\)-factorial
\[[n+1]! = [1] [2] \ldots [n+1]\] where
\[[i] = 1 + q + q^2 + \ldots + q^{i-1}\] When we set \(q = 1\) in this
formula, we get the ordinary factorial \((n+1)!\), and this is the
number of total orderings of an \(n\)-element set. It's also the number
of top-dimensional simplices in the Coxeter complex for \(\mathrm{A}_n\)
--- and that's the way to think about it that works for other Dynkin
diagrams.

In general, the trick is to set up a kind of incidence geometry starting
from the Coxeter complex, in which the top-dimensional simplices serve
as maximal flags, and the \(0\)-simplices serve as geometrical figures
of the various types\ldots{} where two figures are ``incident'' if the
\(0\)-simplices are both vertices of some top-dimensional simplex!

To get a tiny taste of how this stuff works, consider the Dynkin diagram
\(\mathrm{A}_2\). We've seen that the Coxeter complex is a
barycentrically subdivided triangle:

\begin{verbatim}
                               x
                              / \
                             /   \
                            /     \
                           /       \
                          o         o
                         /           \
                        /             \
                       /               \
                      /                 \
                     x---------o---------x
\end{verbatim}

or viewed a bit differently, a hexagon:

\begin{verbatim}
                            x-----o
                           /       \
                          /         \
                         o           x
                          \         /
                           \       /
                            x-----o
\end{verbatim}

Here the vertices marked \(\times\) are the vertices of the original
triangle, while the vertices marked \(\bullet\) correspond to its edges.
We make up a puny little geometry where the \(\times\)'s are called
``points'' and the \(\bullet\)'s are called ``lines''. And we say a
point and a line are ``incident'' if the \(\times\) and \(\bullet\) are
the two ends of a line segment.

Note that any two distinct points are incident to a unique line, and any
two distinct lines are incident to a unique point! This is
characteristic of projective plane geometry. And that's just right,
because \(\mathrm{A}_2\) is the Dynkin diagram corresponding to
projective plane geometry. If we do projective plane geometry over a
field \(\mathbb{F}\), the group \(\mathrm{SL}(3,\mathbb{F})\) acts as
symmetries. But for this puny little geometry, the \emph{Coxeter group}
acts as symmetries. This is the symmetry group of the triangle, which is
the group of permutations of its three vertices.

More generally, suppose we start with the diagram \(\mathrm{A}_n\). Then
we'd see that its Coxeter group consists of permutations of \(n+1\)
things: the vertices of an \(n\)-simplex. The Coxeter complex would be
gotten by barycentrically subdividing the surface of this \(n\)-simplex.
And the Coxeter group would act on a puny little geometry built from the
Coxeter complex, very much as \(\mathrm{SL}(n+1,\mathbb{F})\) acts on
the projective space \(\mathbb{FP}^n\).

As I explained in \protect\hyperlink{week184}{``Week 184''} and
\protect\hyperlink{week185}{``Week 185''}, this relation between
permutation groups and the groups \(\mathrm{SL}(n+1,\mathbb{F})\) is
just the tip of a very big iceberg. What I'm saying now is that a
similar story works for all the other Dynkin diagrams, too!

To explain how this works, I'd need to tell you about the ``Bruhat
decomposition'' of a flag variety. And to explain it \emph{really} well,
I'd need to tell you about Jacques Tits' theory of ``buildings''. Jim
Dolan and I have been studying this over the last year, and it's really
cool\ldots{} but alas, it's too big a subject to explain here! So think
of this Week as a mere \emph{advertisement} for the theory of buildings,
if you like. I'll give you some references at the end.

Okay. So far I've talked about two kinds of things we can get from
Dynkin diagrams: ``flag varieties'', if we pick a field, and ``Coxeter
complexes'', where we don't need to pick a field. Now let's bring in the
\(q\)-mathematics! It turns out that that we can decategorify either the
flag variety or the Coxeter complex and get something I call the
``\(q\)-polynomial''.

We can define this polynomial in four equivalent ways:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  the coefficient of \(q^i\) in this polynomial is the number of Coxeter
  group elements of length \(i\). Here we ``length'' of any element in
  the Coxeter group is its length as a word when we write it as product
  of the generating reflections.
\item
  the coefficient of \(q^i\) in this polynomial is the number of
  top-dimensional simplices of distance \(i\) from a chosen
  top-dimensional simplex in the Coxeter complex. Here we measure
  ``distance'' between top-dimensional simplices in the hopefully
  obvious way, based on how many walls you need to cross to get from one
  to the other.
\item
  the coefficient of \(q^i\) in this polynomial is the number of
  \(i\)-cells in the Bruhat decomposition of the flag variety. Here the
  ``Bruhat decomposition'' is a standard way of writing the flag variety
  as a disjoint union of ``\(i\)-cells'', that is, copies of
  \(\mathbb{F}^i\) where \(\mathbb{F}\) is our field and \(i\) is a
  natural number. These \(i\)-cells are called either ``Bruhat'' or
  ``Schubert'' cells, depending on who you talk to.
\item
  the coefficient of \(q^i\) is the rank of the \((2i)\)th homology
  group of the flag variety defined over the complex numbers. More
  precisely: this homology group is isomorphic to \(\mathbb{Z}^k\) for
  some natural number \(k\), called the ``rank'' of the homology group.
\end{enumerate}

It's easy to see that a) and b) are equivalent; ditto for c) and d). The
equivalence between b) and c) is deeper; it comes from the wonderful
analogy between Coxeter complexes and flag varieties.

Let's calculate the \(q\)-polynomial of \(\mathrm{A}_2\) using method
b):

\begin{verbatim}
                              0
                           x-----o
                        1 /       \ 1
                         /         \
                        o           x
                         \         /
                        2 \       / 2
                           x-----o
                              3
\end{verbatim}

I've written down the distance of each top-dimensional simplex from a
given one. There's one of distance \(0\), two of distance \(1\), two of
distance \(2\), and 1 of distance \(3\). This gives
\[q^3 + 2q^2 + 2^q + 1 =  [3]!\] just as it should.

We can distill all sorts of nice information from the \(q\)-polynomial.
For example, starting from facts a) -- d) we immediately get:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{4}
\item
  the degree of this polynomial is the maximum length of an element of
  the Coxeter group. There is in fact a unique element with maximum
  length, called the ``long word''.
\item
  the degree of this polynomial is the dimension of the flag variety
  over any field.
\end{enumerate}

and also:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{6}
\item
  the value of this polynomial at \(q\) a prime power is the cardinality
  of the flag variety over the field \(\mathbb{F}_q\).
\item
  the value of this polynomial at \(q = 1\) is the number of elements in
  the Coxeter group.
\item
  the value of this polynomial at \(q = 1\) is the Euler characteristic
  of the flag variety over the complex numbers.
\item
  the value of this polynomial at \(q = -1\) is the Euler characteristic
  of the flag variety defined over the real numbers.
\end{enumerate}

We can summarize this network of relations in the following diagram:

\begin{verbatim}
                          DYNKIN DIAGRAM
                          /             \
                         /               \
           pick a field /                 \ 
                       /                   \
                      /                     \
                     /       Weyl group      \
           SIMPLE ALGEBRAIC ----------> COXETER GROUP 
                 GROUP                        | 
                    |                         | 
              FLAG VARIETY             COXETER COMPLEX 
                     \                       /
                      \                     /
                       \                   /
                        \                 /
                         \               /
                          \             /
                           \           /
                            q-POLYNOMIAL
 value at a prime power q /   |  |  |  \degree
                         /    |  |  |   \
    number of points in /     |  |  |  dimension of flag variety =
  flag variety over F_q       |  |  |  length of longest word in Coxeter group
                              |  |  |
                              |  |  |
                value at q = 1|  |  |ith coefficient
                              |  |  |
         number of Coxeter group | number of Coxeter group 
                        elements | elements of length i =
               = number of cells | number of i-cells  
                 in flag variety | in flag variety = 
       = Euler characteristic of | rank of (2i)th homology group of
             flag variety over C | flag variety over C
                                 |
                                 |
                                 |value at q = -1
                                 |
              Euler characteristic of flag variety over R 
\end{verbatim}

Besides things I've already explained, I stuck in an extra arrow showing
that you can get the Coxeter group from a simple algebraic group by
forming something called its ``Weyl group''. I explained this connection
way back in \protect\hyperlink{week62}{``Week 62''}. If we work over the
real numbers and use the compact real form of our simple Lie group, the
Weyl group acts on the Lie algebra of the maximal torus of this group
--- the so-called ``Cartan algebra''. In this context it's good to think
of the Coxeter complex as sitting inside the Cartan algebra!

Next week I'll go through a bunch of examples. Right now, let me just
give you some references for further reading.

To understand most of what I'm saying you mainly just need to understand
the ``Bruhat decomposition'' of the flag variety. For a quick sketch of
how this works over the complex numbers, try this book:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  William Fulton and Joe Harris, \emph{Representation Theory --- a First
  Course}, Springer Verlag, Berlin, 1991.
\end{enumerate}

For a treatment of it over arbitrary fields, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Francois Digne and Jean Michel, \emph{Representations of Finite Groups
  of Lie Type}, London Mathematical Society Student Texts \textbf{21},
  Cambridge U. Press, Cambridge, 1991.
\end{enumerate}

But to understand the relation to incidence geometry, it will help a lot
if you eventually study ``buildings''. This subject has a certain
reputation for obscurity. One good place to start is this book written
by someone who was himself trying to understand the subject:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Kenneth S. Brown, \emph{Buildings}, Springer, Berlin, 1989.
\end{enumerate}

Another is this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Paul Garrett, \emph{Buildings and Classical Groups}, Chapman \& Hall,
  London, 1997.
\end{enumerate}

For a lot more information about how finite simple groups show up as
symmetries of buildings, try:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{4}
\tightlist
\item
  Antonio Pasini, \emph{Diagram Geometries}, Oxford U. Press, Oxford,
  1994.
\end{enumerate}

and for the original source, go to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{5}
\tightlist
\item
  Jacques Tits, \emph{Buildings of Spherical Type and Finite BN-pairs},
  Springer Lecture Notes in Mathematics \textbf{386}, Berlin, New York,
  1974.
\end{enumerate}

Even better, come and sit in on Jim Dolan's seminar on the subject, here
at UCR!

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}



\end{document}
