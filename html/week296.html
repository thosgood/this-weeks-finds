<TITLE> week296 </TITLE>



<P>
For many weeks I've been threatening to bring some serious math into
my discussion of electrical circuits.  Today I'll finally start: I'll
try to use a little symplectic geometry to treat electrical circuits made of
linear resistors as morphisms in a compact dagger-category.  

<P>
But first, here's a great book you should all grab:

<P>
1) Jerry Shurman, Geometry of the Quintic, Wiley, New York, 1997. 
Also available at <a href = "http://people.reed.edu/~jerry/Quintic/quintic.html">http://people.reed.edu/~jerry/Quintic/quintic.html</a>

<P>
I've recommended this book before.  Now Shurman has made it
freely available on his website!  In 1888, Felix Klein used the
icosahedron to solve the general quintic equation:

<P> a x<sup>5</sup> + b x<sup>4</sup> + c x<sup>3</sup> + d
x<sup>2</sup> + e x + f = 0

<P> 
Shurman's book explains Klein's ideas in a very nice way, using a
bit of modern math to make them easier to understand.  It's a
wonderful story.  For a bit about how it connects to other ideas, see
&quot;<a href = "week230.html">week230</A>&quot;.

<P>
Now, on to electrical circuits.  Before I get into the math, I want to
remind you why it's worth bothering with.  Electrical circuits are
interesting and important in themselves, but that's not all!  They're
also great examples of physical systems built from interacting
components.  As we've seen starting in &quot;<a href =
"week288.html">week288</A>&quot;, there are many <i>types</i> of systems
like this.  But luckily, there's a big mathematically precise analogy
relating a bunch of them:


<PRE>
                displacement    flow          momentum      effort
                     q           q'              p            p'

Mechanics       position       velocity       momentum      force
(translation)

Mechanics       angle          angular        angular       torque
(rotation)                     velocity       momentum

Electronics     charge         current        flux          voltage
                                              linkage

Hydraulics      volume         flow           pressure      pressure
                                              momentum

Thermodynamics  entropy        entropy        temperature   temperature
                               flow           momentum

Chemistry       moles          molar          chemical      chemical
                               flow           momentum      potential
</PRE>

So, we can go quite far by picking one kind - say, electrical circuits -
and focusing on that.  The rest are isomorphic.  

<P>
Even if we focus on systems of one kind, there are lot of choices
left:

<ul>
<li>
We can study fully general nonlinear systems, or restrict our
attention to linear ones.  

<P>
</li>
<li>We can study quantum-mechanical systems, or classical ones.

<P>
</li>
<li>We can study dissipative systems (where energy is not conserved), or
conservative ones (where it is).

<P>
</li>
<li>We we can study dynamical systems (where things change with time)
or static ones (where they don't).

<P>
</li>
<li>We can study open systems (which interact with their environment)
or closed ones (which don't).
</li>
</ul>

<P>
In fact all five choices are independent, so we have 32 subjects to
study!  But in recent weeks I've focused on electrical circuits made
of linear resistors where the voltages and currents don't depend on
time.  This amounts to studying

<P>
<div align = "center">
        LINEAR CLASSICAL DISSIPATIVE STATIC OPEN SYSTEMS.
</div>

<P>
&quot;Linear&quot;, &quot;classical&quot; and &quot;static&quot; are
all ways to make our system boring - or at least, easy to understand.
But &quot;open&quot; brings category theory into the game, since we
can combine two open systems by feeding the outputs of one into the
inputs of the other - and this can be seen as composing morphisms.
Also, we saw last week that linear classical dissipative static open
systems can be understood using the principle of least power!

<P>
Now I would like to describe a category that has linear classical
dissipative static open systems as morphisms.  To make things more 
concrete, let's think of these systems as electrical circuits made
of linear resistors.

<P>
But there is a sixth choice to be made!  We can treat these circuits
either as &quot;distributed&quot; or &quot;lumped&quot;.

<P>
What do I mean by this?  Well, if we treat a circuit as
&quot;distributed&quot;, we know about every detail of it: for
example, we can say it's made of 27 resistors, with particular
resistances, hooked up in a certain way.  But if we treat it as
&quot;lumped&quot;, we treat it as a black box with some wires hanging
out.  We're not allowed to peek inside the box.  All we know is what
it does, viewed externally.

<P>
For example, we could have a fancy circuit like this:

<PRE>
    x
    |
    o
   / \
  /   \
 o-----o
  \   /
   \ /
    o
    |
    x
</PRE>

Each edge has some resistance, as explained in &quot;<a href =
"week294.html">week294</A>&quot;, and the x's mark the input and
output.  Here's another, simpler, circuit of the same sort:

<PRE>
    x
    |
    |
    |
    x
</PRE>

When we treat these circuits as &quot;distributed&quot;, they're different.
Why?  Because they look different.  But when we treat them as
&quot;lumped&quot;, they might be the same!  Why?  Because no matter what
resistances we choose for the edges of the fancy circuit, the current
through it is proportional to the voltage across it... just like the
simple one.  So if this constant of proportionality is the same, they
count as the same &quot;lumped&quot; circuit.

<P>
(In case you're about to object: we're only treating these circuits
<i>statically</i>.  If you feed a rapidly changing voltage across the two
circuits, they will behave differently, since it takes time for
changes to propagate.  But that's irrelevant here.)

<P>
More precisely, let us say that two circuits built from linear
resistors count as the same &quot;lumped&quot; circuit if:

<P>
   they have the same number of inputs, say m,

<P>
   they have the same number of outputs, say n

<P>
   the currents on their input and output wires are given by the 
   same function of the electrostatic potentials on those wires,
   say

<P>
   f: R<sup>m+n</sup>  &rarr; R<sup>m+n</sup>

<P>
Since we're looking at linear circuits, the function f will be linear.
However, not every linear function f is allowed!  To understand which
ones are, it's good to use the principle of least power.  Here we 
describe a lumped circuit using a function

<P>
Q: R<sup>m+n</sup> &rarr; R 

<P>
This gives the power as a function of the potentials at the inputs and
outputs.  We can recover f by taking the gradient of Q.  Since Q is
quadratic, its gradient is a linear function of position.

<P>
Which functions Q are allowed?  Well, this function must be what
mathematicians call a &quot;quadratic form&quot;: in other words, a
homogeneous quadratic polynomial.  It must be nonnegative.  And, it
must not change if we add the same number to each potential.

<P>
I suspect that every function Q meeting these three conditions comes
from an actual electrical circuit built from resistors.  If you know,
please tell me!  

<P>
I don't love the third condition, because it depends heavily on the
standard basis of the vector space R<sup>m+n</sup>.  I hope we can
drop this condition if we allow circuits that include an extra kind of
circuit element: besides resistors, also &quot;grounds&quot;.  A
&quot;ground&quot; is a place where a wire is connected to the earth,
which - by convention - has potential zero.

<P>
For example, suppose we have this circuit, with one input connected 
to a ground, and no outputs:

<PRE>
    x
    |
    |
    =
</PRE>

The funny little &quot;=&quot; thing is the ground.  For this circuit the power
is described by a quadratic form Q in one real variable v.  If the
wire has resistance R &gt; 0, we have

<P>
Q(v) = v<sup>2</sup> / R

<P>
What if we want Q = 0?  Well, then we should use a circuit like this,
instead:

<PRE>
    x
    |
    |
    o
</PRE>
In other words: one input, no outputs, and a wire that just dangles in
mid-air instead of being connected to a ground.

<P>
Using resistors and grounds, I hope we can build circuits corresponding 
to arbitrary nonnegative quadratic forms.  So, let's try to describe a
category where:

<P>
<UL>
<LI>
  An object is a finite-dimensional real vector space.  
</LI>
<P>
<LI>
  A morphism Q: V &rarr; W is a nonnegative quadratic form Q on V+W.
</LI>
</UL>

<P>
How do we compose these morphisms?  Using the principle of minimum
power!  Given morphisms P: U &rarr; V and Q: V &rarr; W, we define their
composite QP: U &rarr; W by

<P>
QP(u,w) = min<sub>v &isin; V</sub> P(u,v) + Q(v,w)

<P>
It's easy to check that this is associative: it's analogous to matrix
multiplication, but with addition replacing the usual multiplication
of numbers, and min replacing the usual sum.  Indeed, this idea has
been widely used to reformulate the principle of least action in
classical mechanics as a mutant version of the &quot;matrix mechanics&quot;
approach to quantum mechanics:

<P>
2) G. L. Litvinov, The Maslov dequantization, idempotent and tropical
mathematics: a brief introduction, available as <a href = "http://arXiv.org/abs/arXiv:math/0507014">arXiv:math/0507014</A>.

<P>
3) John Baez, Spans in quantum theory, <a href = "http://math.ucr.edu/home/baez/span/">http://math.ucr.edu/home/baez/span/</a>

<P>
But the physics is different now: we are minimizing power rather than
action.

<P>
There's just one slight glitch.  Our would-be category doesn't have
identity morphisms!  This is easy to check mathematically.  Physically, 
the reason is clear.  The identity morphism 1: R &rarr; R should correspond
to a perfectly conductive wire, like this:

<PRE>
  x  
  |  
  |  
  |  
  x  
</PRE>

This is also called a &quot;short circuit&quot; - see &quot;<a href =
"week294.html">week294</A>&quot;.  But what's the corresponding
quadratic form?  Well, it doesn't exist.  But the idea is that the
power used by this circuit would be <i>infinite</i> if the potentials at
the two ends were different.  So, heuristically, the quadratic form
should be

<P>
Q(v,w) = +&infin;(v-w)<sup>2</sup>

<P>
This doesn't really make sense, except as some sort of mysterious 
limit of the quadratic form for a resistor with resistance R:

<P>
Q(v,w) = (v-w)<sup>2</sup> / R

<P>
as R approaches 0 from above.  In other words, the perfectly
conductive wire is the limiting case of a resistor.

<P>
So, what can we do?  There are lots of options.  One is to note that
perfectly conductive wires don't really exist, and be content with
what we've got.  Namely: a &quot;semicategory&quot;, which is like a
category, but without identity morphisms.

<P>
Most people don't like semicategories.  So, if you're like most
people, you'll be relieved to hear that any semicategory can be made
into a category by formally throwing in identity morphisms.  We don't
lose any information this way.  Even better, a category arises from a
semicategory in this way iff it has this special property: whenever the
composite of two morphisms is an identity morphism, both must be
identity morphisms.  So, semicategories aren't really more general
than categories.  We can think of them as categories with this extra
property!

<P>
If we extend our semicategory to a category this way, the result has
some nice properties.  First, it's a &quot;monoidal category&quot;, meaning 
roughly a category with tensor products:

<P>
4) nLab, Monoidal category, <a href = "http://ncatlab.org/nlab/show/monoidal+category">http://ncatlab.org/nlab/show/monoidal+category</a>

<P>
The tensor product corresponds to setting two circuits side by side:

<PRE>
        |               |  |  |
    --------         ------------   
   |        |       |            |
   |        |       |            |
    --------         ------------
      |  |            |  |  |  |
</PRE>

Mathematically, the tensor product of objects V and W is their direct
sum V+W, while the tensor product of morphisms Q:V &rarr; W and Q':V'
&rarr; W' is the quadratic form Q+Q' given by:

<P>
(Q+Q')(v,v',w,w') = Q(v,w) + Q'(v',w')

<P>
Our category also has &quot;duals for morphisms&quot;.  Intuitively, this means
that we can take any circuit Q: V &rarr; W built from resistors:

<PRE>
        |             
    --------        
   |    Q   |       
    --------        
      |  |          
</PRE>
and reflect it across a horizontal line, switching inputs and outputs
like this:

<PRE>
      |  |          
    --------        
   |   Q<sup>&dagger;</sup>   |       
    --------        
        |             
</PRE>

to obtain a new circuit Q<sup>&dagger;</sup>: W &rarr; V.
Mathematically this operation is defined as follows:

<P>
Q<sup>&dagger;</sup>(v,w) = Q(w,v)

<P>
A category with duals for morphisms is usually called a
&quot;dagger-category&quot;.  It's easy to check that our category is
one of those:

<P>
5) nLab, Dagger-category, <a href = "http://ncatlab.org/nlab/show/dagger-category">http://ncatlab.org/nlab/show/dagger-category</a>

<P>
However, our category has some defects.  First of all, there's no
morphism corresponding to two perfectly conductive wires that cross
like this:

<PRE>
  \   /
   \ /
    /
   / \
  /   \
</PRE>
If we had that, we'd get a &quot;symmetric monoidal category&quot;:

<P>
6) nLab, Symmetric monoidal category, 
<a href = "http://ncatlab.org/nlab/show/symmetric+monoidal+category">http://ncatlab.org/nlab/show/symmetric+monoidal+category</a>

<P>
Our category so far also lacks a morphism corresponding to a perfectly
conductive bent wire like this:

<PRE>
  |   |
  |   |
   \_/
</PRE>

or like this:

<PRE>
    _
   / \
  |   |
  |   |
</PRE>

If we had these morphisms, obeying the obvious &quot;zig-zag identities&quot;:

<PRE>
  |     _       |       _     |
  |    / \      |      / \    |
  |   /   |  =  |  =  |   \   |
   \_/    |     |     |    \_/
          |     |     |
</PRE>
then our monoidal category would have &quot;duals for objects&quot;, in the
sense explained back in &quot;<a href = "week89.html">week89</A>&quot;.  

<P>
It seems reasonable to allow all these circuits made of perfectly
conductive wires, even though they correspond to idealized limits of
circuits we can actually build.  They don't cause any mathematical
contradictions.  And they should give a very nice category: a
symmetric monoidal category with duals for objects and morphisms.
Categories of this sort are called &quot;dagger-compact&quot;:

<P>
7) nLab, Dagger-compact category, 
<a href = "http://ncatlab.org/nlab/show/dagger+compact+category">http://ncatlab.org/nlab/show/dagger+compact+category</a>

<P>
Dagger-compact categories are very important in physics.  A classic
example is the category of finite-dimensional Hilbert spaces, with
linear operators as morphisms, and the usual tensor product of vector
spaces.  Another example is the category of (n-1)-dimensional compact
oriented manifolds, with n-dimensonal cobordisms as morphisms.  The
interplay between these examples is important in topological quantum
field theory.  People like Samson Abramsky, Bob Coecke, Chris Heunen,
Dusko Pavlovich, Peter Selinger and Jamie Vicary have done a lot to
formulate all of quantum mechanics in terms of dagger-compact
categories.  Here are the fundamental references:

<P>
8) Samson Abramsky and Bob Coecke, A categorical semantics of quantum
protocols, in Proceedings of the 19th IEEE conference on Logic in
Computer Science (LICS04), IEEE Computer Science Press (2004).
Also available at <a href = "http://arXiv.org/abs/quant-ph/0402130">arXiv:quant-ph/0402130</A>.

<P>
9) Peter Selinger, Dagger compact closed categories and completely
positive maps, in Proceedings of the 3rd International Workshop on
Quantum Programming Languages (QPL 2005), ENTCS 170 (2007), 139-163.
Also available at <a href = "http://www.mscs.dal.ca/~selinger/papers.html#dagger">http://www.mscs.dal.ca/~selinger/papers.html#dagger</a>

<P>
You can use compact dagger-categories to clarify what it means,
physically, for a complex Hilbert space to be equipped with an
orthonormal basis:

<P>
10) Bob Coecke, Dusko Pavlovic, and Jamie Vicary, A new description of
orthogonal bases, available as
<a href = "http://arxiv.org/abs/0810.0812">arXiv:0810.0812</a>.

<P>
You can use them to explain the traditional approach to quantum logic
in terms of orthomodular lattices:

<P>
11) Chris Heunen, Categorical Quantum Models and Logics, Amsterdam
University Press, 2009.  Also available at  
<a href = "http://www.comlab.ox.ac.uk/people/chris.heunen/about.html">http://www.comlab.ox.ac.uk/people/chris.heunen/about.html</a>

<P>
You can even use them to motivate the appearance of complex
numbers in quantum mechanics:

<P>
12) Jamie Vicary, Completeness and the complex numbers, available as
<a href = "http://arxiv.org/abs/0807.2927">arXiv:0807.2927</a>.

<P>
So, if there is a compact dagger-category of electrical circuits, we
should find it and study it.  I've decided that category theory should
not be saved for fancy stuff like the foundations of quantum theory.  
It can serve as a general language for studying systems made of parts,
and we should take full advantage of it!

<P>
Let's try.  Let's take the category described so far and supplement it
with a &quot;cup&quot;:

<PRE>
  |   |
  |   |
   \_/
</PRE>
a &quot;cap&quot;:
<PRE>
    _
   / \
  |   |
  |   |
</PRE>
and a &quot;symmetry&quot;:

<PRE>
  \   /
   \ /
    /
   / \
  /   \
</PRE>
We could formally throw in these morphisms, just like we threw in
identities.  But there is a less artificial solution which solves all
these problems in one blow.  We can take a lesson from symplectic
geometry, and notice that nonnegative quadratic forms are a special
case of something called &quot;Lagrangian correspondences&quot;.
These include identity morphisms as well as the cap, cup, and
symmetry.

<P>
Let me explain!  Suppose Q is a quadratic form on a vector space V.
Then its differential dQ is a one-form, so it gives an element of V*
for each point of V.  But since Q is quadratic, its differential
depends linearly on the point of Q, so we get a linear map

<P>
dQ: V &rarr; V*

<P>
This is a highbrow formulation of something I already told you in
lowbrow way.  But now let's go a bit further.  The graph of dQ is a
linear subspace of the cartesian product V &times; V*.  But V &times;
V* is better than a mere vector space.  We can think of it as the
cotangent bundle T*V.  So, it's a &quot;symplectic&quot; vector space:

<P>
13) Wikipedia, Symplectic vector space,
<a href = "http://en.wikipedia.org/wiki/Symplectic_vector_space">http://en.wikipedia.org/wiki/Symplectic_vector_space</a>

<P>
Namely, it has a &quot;symplectic structure&quot; - that is, a nondegenerate
antisymmetric bilinear form &omega; given by:

<P>
&omega;((v,f),(v',f')) = f(v') - f'(v)

<P>
And it's a general fact that the graph of any quadratic form on V is a
&quot;Lagrangian&quot; subspace of T*V = V &times; V*, meaning a
maximal subspace on which &omega; vanishes.

<P>
But, there are Lagrangian subspaces of T*V that are not the graphs of
quadratic forms.  There are also &quot;limits&quot; of graphs of quadratic
forms - precisely the sort of thing we want now!  After all, every
circuit made of perfectly conductive wires can be thought of as a 
limit of circuits made of resistors.

<P>
So, we can try a category where:

<P>
<UL>
<LI>
  An object is a finite-dimensional real vector space.  
</LI>
<P>
<LI>
  A morphism S: V &rarr; W is a Lagrangian subspace of T*(V+W).
</LI>
</UL>
<P>

Remember that an element of V describes the potentials on the input
wires of our circuit, while W does the same job for the output wires.
An element of V+W describes the potentials on input and output wires.
Currents live in the dual vector space, so an element of T*(V+W)
describes the potentials and currents on input and output wires.  The
Lagrangian subspace describes the potentials and currents that are
allowed by our circuit.

<P>
We can also change perspective and say:

<P>
<UL>
<LI>
  An object is a finite-dimensional real vector space.  
</LI>
<P>
<LI>
  A morphism S: V &rarr; W is a Lagrangian subspace of T*V &times; T*W.
</LI>
</UL>

<P>
Here an element of T*V describes the potentials and currents on the
input wires, while T*W does the same job for the output wires.  As
before, the Lagrangian subspace of T*V &times; T*W describes the potentials
and currents that are allowed by our circuit.  But now we can think of
it as <i>relation</i> between T*V and T*W.  This makes it clear how to
compose morphisms: we compose them according to the usual method for 
composing relations.

<P>
This perspective will be familiar to symplectic geometers who know
about &quot;Lagrangian correspondences&quot;, also known as
&quot;canonical relations&quot;.  We're studying a special case of
those, namely the linear case.  If you want to learn more, try:

<P>
14) Alan Weinstein, Symplectic categories, available as
<a href = "http://arxiv.org/abs/0911.4133">arXiv:0911.4133</a>.

<P>
Weinstein writes:

<P>
<BLOCKQUOTE>
   Following in part some (unpublished) ideas of the author, Guillemin
   and Sternberg observed that the linear canonical relations (i.e.,
   lagrangian subspaces of products of symplectic vector spaces) could
   be considered as the morphisms of a category, and they constructed
   a partial quantization of this category (in which lagrangian subspaces
   are enhanced by half-densities).  The automorphism groups in this
   category are the linear symplectic groups, and the restriction of the
   Guillemin-Sternberg quantization to each such group is a
   metaplectic representation.  On the other hand, the quantization of
   certain compositions of canonical relations leads to ill-defined
   operations at the quantum level, such as the evaluation of a delta
   &quot;function&quot; at its singular point, or the multiplication of delta
   functions.
</BLOCKQUOTE>
<P>

Here's the reference to Guillemin and Sternberg:

<P>
15) Victor Guillemin and Shlomo Sternberg, Some problems in integral
geometry and some related problems in microlocal analysis, Amer. 
J. Math. 101 (1979), 915-955.

<P>
I learned symplectic geometry from Guillemin in grad school, so I'm
happy to see it being applied to resistors!  And the discussion of
quantization suggests a way to understand resistors quantum-mechanically.  
In fact there's a bit of literature on this subject already:

<P>
16) Michel H. Devoret, Quantum fluctuations in electrical circuits, 
in Quantum Fluctuations, eds. S. Reynaud, E. Giacobino and J. 
Zinn-Justin, Elsevier, 1997.  Also available at
<a href = "http://qulab.eng.yale.edu/documents/reprints/Houches_fluctuations.pdf">http://qulab.eng.yale.edu/documents/reprints/Houches_fluctuations.pdf</a>

<P>
But for now, the classical theory is interesting enough.  I guess I
need to start by checking my claim:

<P>
<blockquote>
  <b>Claim:</b> there is a compact dagger-category where:

<UL>
<LI>
  An object is a finite-dimensional real vector space.  
</LI>
<P>
<LI>
  A morphism S: V &rarr; W is a Lagrangian subspace of T*V &times; T*W.
</LI>
<P>
<LI>
  We compose morphisms using composition of relations.
</LI>
<P>
<LI>
  The tensor product is given by direct sum.
</LI>
<P>
<LI>
  The symmetry is the obvious thing.
</LI>
<P>
<LI>
  The dagger of a subspace of T*V &times; T*W is the corresponding 
  subspace of T*W &times; T*V.  
</LI>
</UL>
</blockquote>

<P>
This category is mathematically elegant, but &quot;too big&quot;,
because its morphisms include a lot more than Lagrangian subspaces
coming from nonnegative quadratic forms, and limits of these.  There's
a well-known topology on the set of Lagrangian subspaces of a
symplectic vector space, so the concept of limit is well-defined here.
If we restrict attention to Lagrangian subspaces coming from
nonnegative quadratic forms, and limits of these, do we get a
subcategory?  It might seem obvious - but shockingly, composition is
<i>not continuous</i> with respect to this well-known topology!  Weinstein
gives a counterexample.  So, there's something nontrivial to check.

<P>
If we do get a subcategory, will it still be a compact dagger-category?
Yes, I think so, because it contains the cup

<PRE>
  |   |
  |   |
   \_/
</PRE>
and cap:
<PRE>
    _
   / \
  |   |
  |   |
</PRE>
and symmetry:

<PRE>
  \   /
   \ /
    /
   / \
  /   \
</PRE>
So, this would be a very nice thing.

<P>
I thank James Dolan, Peter Selinger,
Alan Weinstein and Simon Willerton for 
helping me figure out these ideas.


<p>
<HR><P>

<b>Addendum</b>: I thank Mikael Vejdemo-Johansson for catching a typo.

<P>
For more discussion visit the
<a href = "http://golem.ph.utexas.edu/category/2010/04/this_weeks_finds_in_mathematic_57.html"><i>n</i>-Category Caf&eacute;</a>.

<p>
<HR><P>

<i>Reality has been around since long before you showed up.  Don't go
calling it nasty names like &quot;bizarre&quot; or
&quot;incredible&quot;.  The universe was propagating complex
amplitudes through configuration space for ten billion years before
life ever emerged on Earth.  Quantum physics is not &quot;weird&quot;.
You are weird.</i> - <a href = "http://lesswrong.com/lw/hs/think_like_reality/">Eliezer Yudkowsky</a>

<p>
<HR><P>



