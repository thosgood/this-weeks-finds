<TITLE> week297 </TITLE>

<!-- BEGIN HEADER -->
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week296.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week298.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE>
<H4> May 9, 2010 </H4>
<H2> This Week's Finds in Mathematical Physics (Week 297) </H2>
<H4> John Baez </H4>
<!-- END HEADER -->


<P>
This week I'll talk about electrical circuits and Dirichlet forms.
But first: knot sculptures, special relativity in finance, lazulinos,
some peculiar infinite sums, and a marvelous fact about the number
12.  

<P>
Here are some cool sculptures of knots by Karel Vreeburg:

<p>
<div align = "center">
<a href = "http://www.karelvreeburg.nl/site/kunstwerk/13285086_Hidden-Split-Torus-2.html">
<img border = "2" src = "vreeburg/vreeburg_sculpture.2.jpg">
</a>
<br/>
<br/>
<br/>

<a href = "http://www.karelvreeburg.nl/site/kunstwerk/13285088_Verscholen-540-Twisted-Torus.html">
<img border = "2" src = "vreeburg/vreeburg_sculpture.1.jpg">
</a>
<br/>
<br/>
<br/>

<a href = "http://www.karelvreeburg.nl/site/kunstwerk/13610288_Verborgen-Oneindige-Trefoil-Knoop.html">
<img border = "2" src = "vreeburg/vreeburg_sculpture.3.jpg">
</a>
<br/>
<br/>
<br/>
</div>

1) Karel Vreeburg, 
<a href = "http://www.karelvreeburg.nl/site/kunstwerken/357933_Beelden.html">http://www.karelvreeburg.nl/site/kunstwerken/357933_Beelden.html</a>

<P>
The polished forms emerge from rough stone much as mathematical
abstractions emerge from physical reality.  And I'm reminded of what
Michelangelo said.   &quot;Every block of stone has a statue inside it,
and the task of the sculptor is to discover it.&quot;

<P>
Next - remember that big glitch in the stock market last Thursday,
when the Dow Jones dropped 9.2% in less than an hour, and then bounced
back?  For a while, about a trillion dollars had evaporated!

<P>
The worst part is, nobody knows why.  But apparently one part of the
problem was that some electronic communication systems were lagging
behind, seeing a delayed view of what was really going on.  But guess
how long this lag was.  Just 0.1 seconds!

<P>
That's only three quarters the time it takes light to circle 
the Earth.  But these days it's considered an unacceptably long
time for computer trading.  So, we've reached the point where special
relativity is important in economics.  The Newtonian concept of
&quot;the same time at different places&quot; is no longer adequate:

<P>
<blockquote>
   A 1-millisecond advantage in trading applications can be worth $100
   million a year to a major brokerage firm, by one estimate. The
   fastest systems, running from traders' desks to exchange data
   centers, can execute transactions in a few milliseconds - so fast,
   in fact, that the physical distance between two computers
   processing a transaction can slow down how fast it happens. This
   problem is called data latency - delays measured in split
   seconds. To overcome it, many high-frequency algorithmic traders
   are moving their systems as close to the Wall Street exchanges as
   possible.
</blockquote>

<P>
This quote is from:

<P>
2) Richard Martin, Wall Street's quest to process data at the 
speed of light, Information Week, April 23, 2007.  Also available
at <a href = "http://www.informationweek.com/news/infrastructure/showArticle.jhtml?articleID=199200297">http://www.informationweek.com/news/infrastructure/showArticle.jhtml?articleID=199200297</a>

<P>
See also:

<P>
3) Kid Dynamite's World, Market Speed Bumps,
<a href = "http://fridayinvegas.blogspot.com/2010/05/market-speed-bumps.html">http://fridayinvegas.blogspot.com/2010/05/market-speed-bumps.html</a>

<P>
where someone comments:

<blockquote>
   What I suspect happened (following on moments after KD's
   explanation ends) is that some meaningful trigger point on stop
   loss orders was exceeded. This could have been a small wave of
   selling from Bloomberg running the video of the crowd getting
   agitated in Greece (which was at about 2:40PM EST), but whatever
   the case - a wave of selling started. That in turn brought the
   price down, which triggered some stop loss orders, which in turn
   fueled more stop loss orders, along with any humans and machines
   that just sold on the steep drop.

<P>
   However, given the heavy volume at the time, the <a href =
   "http://www.wikinvest.com/wiki/High-Frequency_Trading_%28HFT%29">HFT
   systems</a> that would normally jump in (albeit at much lower bids)
   didn't even get to see accurate representations of the order books,
   because I was seeing at least a 100ms delay in quotes from <a href
   = "http://en.wikipedia.org/wiki/NYSE_Arca">ARCA</a> (the only <a
   href =
   "http://en.wikipedia.org/wiki/Electronic_communication_network">ECN</a>
   I measured accurately).

<P>
   So, at least with ARCA and probably the other exchanges as well,
   everyone was running with at least a 100ms delayed snapshot of the
   world. Given that I stopped calculating this delay when my own
   software shutdown at 2:41PM (4 minutes before the peak of chaos),
   this is probably understating matters somewhat.

<P>
   If you can't see that the order book is missing bids because you
   are operating 100ms behind the actual trades taking place, then
   there is a meaningful window when the bids in the order book can
   all be taken out before anyone even knows that they should be
   placing bids!

<P>
   Further, once you recognize that you are operating with stale
   information (and 100ms is quite stale if you are seeing the markets
   plunge the way they were), there is no way you are going to enter
   orders, since you don't have any clue where to place them, and if
   you do - you place them with much wider spreads than normal, which
   in conjunction with market sell orders brings the trading price
   down along with the bid/ask midpoint.

</blockquote>

I guess it's just a matter of time before <i>general</i> relativity
becomes important in finance.  I thank Mike Stay and Henry Baker for
bringing this issue to my attention.

<P>
I also enjoyed this blog post by Mike:

<P>
4) Mike Stay, Lazulinos, 
<a href = "http://reperiendi.wordpress.com/2010/04/27/lazulinos/">http://reperiendi.wordpress.com/2010/04/27/lazulinos/</a>

<P>
It's about a newly discovered quasiparticle with astounding
properties.  If you want to really understand what's going on, read
the paper by Alexander Craigie - there's a link at the end of Mike's
post.

<P>
Next, an observation from Robert Baillie.  Take this series:

<P>
&pi;/&radic;8 = 1 + 1/3 - 1/5 - 1/7 + 1/9 + 1/11 - ...

<P>
Square each term, add them up... and you get the square of
the previous sum:

<P>
&pi;<sup>2</sup>/8 = 1 + 1/3<sup>2</sup> + 1/5<sup>2</sup> +
1/7<sup>2</sup> + 1/9<sup>2</sup> + 1/11<sup>2</sup> + ...

<P>
Don't tell undergraduates about this - they are already confused
enough!

<P>
And finally, a comment from Nora Ganter.  If you look at the
cohomology of the symmetric groups, you find an element of order 12 in
H<sup>3</sup>(S<sub>n</sub>,Q/Z) for n greater or equal to 4.  But the
third cohomology of a group classifies ways of extending it to a
2-group.  So whenever you realize a finite group as a group of
permutations of 4 or more things, you automatically get a way of
extending it to a 2-group!

<P>
I would like to understand this better.  In particular, the 
number 12 here should be related to the fact that

<P>
&pi;<sub>k+3</sub>(S<sup>k</sup>) = Z/24 

<P>
for k &ge; 5.  After all, stable homotopy groups of spheres are
related to the cohomology of symmetric groups, since the group
completion of the classifying space of the groupoid of finite sets is
&Omega;<sup>&infin;</sup>S<sup>&infin;</sup> - see &quot;<a href =
"week199.html">week199</a>&quot; if you don't know what I'm talking
about here.  But I'm confused about the numbers 12 versus 24 here, and
also the role of Q/Z coefficients.

<P>
Does someone know a place where you can look up cohomology groups
of the symmetric groups?

<P>
Next: electrical circuits!

<P>
Last week I discussed electrical circuits made of (linear) resistors
and &quot;grounds&quot; - places where wires touch an object whose
electrostatic potential is zero.  I want to fill in some missing
pieces today.

<P>
Suppose we have such a circuit with n wires dangling out of it.  I've
been calling these &quot;inputs&quot; and &quot;outputs&quot; - but
today I don't care which ones are inputs and which ones are outputs,
so let's call them all &quot;terminals&quot;.

<P>
We saw last time that our circuit gives a function

<P>
Q: R<sup>n</sup> &rarr; R

<P>
This tells you how much power the circuit uses as a function of the 
electrostatic potential at each terminal.

<P>
It's pretty easy to see that Q is a &quot;quadratic form&quot;,
meaning that

<P>
Q(&phi;) = &sum;<sub>i,j</sub> Q<sub>ij</sub> &phi;<sub>i</sub>
&phi;<sub>j</sub>

<P>
for some matrix Q<sub>ij</sub>, which we can assume is symmetric.  And
it's easy to see that Q is &quot;nonnegative&quot;, meaning

<P>
Q(&phi;) &ge; 0

<P>
I wildly guessed that every nonnegative quadratic form comes from a
circuit made of resistors and grounds.  Since then I've learned a few
things, thanks to Ben Tilly and Tom Ellis.

<P>
For starters, which nonnegative quadratic forms do we get from circuits 
built only from resistors?  We certainly don't get all of them.  For 
example, if n = 2, every circuit built from just resistors has

<P>
Q(&phi;) = c (&phi;<sub>1</sub> - &phi;<sub>2</sub>)<sup>2</sup> 

<P>
for some nonnegative number c.  So, we'll never get this quadratic
form:

<P>
Q(&phi;) = (&phi;<sub>1</sub> + &phi;<sub>2</sub>)<sup>2</sup>

<P>
even though it's nonnegative.   In general, for any n, we can get
a lot of quadratic forms just by connecting each terminal to each 
other with a resistor.  Such circuits give precisely these quadratic 
forms: 

<P>
Q(&phi;) = &sum;<sub>i,j</sub> c<sub>ij</sub> (&phi;<sub>i</sub> - &phi;<sub>j</sub>)<sup>2</sup>

<P>
where the numbers c<sub>ij</sub> are nonnegative.  We can assume
without loss of generality that c<sub>ii</sub> = 0.  The numbers
c<sub>ij</sub> are <i>reciprocals</i> of resistances, so we're
allowing resistors with infinite resistance, but not with zero
resistance.

<P>
It turns out that quadratic forms of the above type are famous:
they're called &quot;Dirichlet forms&quot;.  People have characterized
them in lots of ways.  Here's one: they're the nonnegative quadratic
forms that vanish when &phi; is constant:

<P>
&phi;<sub>i</sub> = &phi;<sub>j</sub> for all i,j implies Q(&phi;) = 0

<P>
and also satisfy the &quot;Markov property&quot;:

<P>
Q(&phi;) &ge; Q(&psi;)

<P>
when &psi;<sub>i</sub> is the minimum of &phi;<sub>i</sub> and 1.  This
characterization is Proposition 1.7 here:

<P>
5) Christophe Sabot, Existence and uniqueness of diffusions on finitely
ramified self-similar fractals, Section 1: Dirichlet forms on finite 
sets and electrical networks, Annales Scientifiques de l'École Normale 
Supérieure, Sér. 4, 30 (1997), 605-673.  Available at 
<a href = "http://www.numdam.org/numdam-bin/item?id=ASENS_1997_4_30_5_605_0">http://www.numdam.org/numdam-bin/item?id=ASENS_1997_4_30_5_605_0</a>

<P>
Sabot doesn't prove this result, which he considers &quot;well
known&quot;.  Instead, he points us to this book, which is not
only fun to read, but also free:

<P>
6) P. G. Doyle and J. L. Snell, Random Walks and Electrical Circuits,
Mathematical Association of America, 1984.
Also available at <a href = "http://www.math.dartmouth.edu/~doyle/">http://www.math.dartmouth.edu/~doyle/</a>

<P>
You may wonder what random walks and diffusions on fractals have to do
with electrical circuits!  The idea is that we can take a limit of
electrical circuits that get more and more complicated and get a
<i>fractal</i>.  The electrical conductivity of this fractal can be
reinterpreted as heat conductivity, using the analogies described back
in &quot;<a href = "week289.html">week289</A>&quot;.  And then we can
study the heat equation on this fractal.  This equation says how heat
diffuses with the passage of time.

<P>
But there's nothing special about <i>heat</i>.  We can use the heat
equation to describe the diffusion of just about anything.  We could
even use it to describe the diffusion of tiny drunken men who stumble
around aimlessly on our fractal!  And that's where &quot;random
walks&quot; come in.

<P>
It turns out that in situations like this, the heat equation is
completely determined by a quadratic form called a &quot;Dirichlet
form&quot;.  But it's not a quadratic form on R<sup>n</sup> anymore:
it's a quadratic form on a space of real-valued functions on our
fractal.

<P>
In fact Dirichlet forms were first studied, not for finite sets or
fractals, but for nice regions in Euclidean space - the sort of
regions you'd normally consider when studying the heat equation.  In
this case the Dirichlet form arises from the Laplacian:

<P>
Q(&phi;) = - &int; &phi;&nabla;<sup>2</sup>&phi;

<P>
where &phi; is a function on our region.  The moral is that we should
think of any Dirichlet form as a generalized Laplacian!

<P>
There's a huge literature on Dirichlet forms.  Most of it focuses on 
analytical subleties that don't matter for our pathetically simple 
examples.  For a little taste, try this review of two books on 
Dirichlet forms:

<P>
7) Review by Daniel Stroock, Bull. Amer. Math. Soc. 33 (1996) 87-92. 
Also available at
<a href = "http://www.ams.org/journals/bull/1996-33-01/S0273-0979-96-00617-9/">http://www.ams.org/journals/bull/1996-33-01/S0273-0979-96-00617-9/</a>

<P>
Among other things, he mentions a simpler characterization of Dirichlet
forms.  We're only considering quadratic forms

<P>
Q: R<sup>n</sup> &rarr; R

<P>
and it turns out such a form is Dirichlet iff

<P>
Q(&phi;) &ge; Q(&psi;)

<P>
whenever 

<P>
|&phi;<sub>i</sub> - &phi;<sub>j</sub>| &ge; |&psi;<sub>i</sub> - &psi;<sub>j</sub>|

<P>
for all i,j.  It's a fun exercise to see that this is equivalent to
our previous characterization.  And there's a simple physical idea
behind this one: a circuit made of resistors will use more power when
the potentials at different terminals differ by bigger amounts!

<P>
Okay... I'm digressing a bit.  Let's get back on track.

<P>
We've seen that the quadratic form of a circuit made from resistors is
Dirichlet whenever the circuit is of a special form: namely, when it
has one resistor connecting each pair of terminals.  

<P>
But what about other circuits made from resistors, like this?

<PRE>
        x           x
        |           |
        o-----------o
       / \          |
      /   \         |
     /     o--------o
    |     / \       | 
    |    /   \      |
    o---o-----o-----o
    |   |           |
    x   x           x
</PRE>

Here the x's are the terminals, but there are also other vertices,
which I'll call &quot;internal vertices&quot;.  Also, not every vertex
is connected to every other vertex.  Do we get a larger class of
quadratic forms if we allow more general circuits like this?

<P>
No!  All we get are Dirichlet forms!

<P>
For starters, it doesn't matter that not every vertex is connected
to every other vertex.  We can connect them with wires that have
infinite resistance, and nothing changes.  (Remember, we're allowing
infinite resistance.)

<P>
So, the only interesting thing is the presence of &quot;internal
vertices&quot;.  Why are the quadratic forms of circuits with internal
vertices still Dirichlet forms?

<P>
This follows from Sabot's Proposition 1.8.  Let me explain the idea.
Suppose, for example, that we have a nonnegative quadratic form in 3
variables

<P>
Q: R<sup>3</sup> &rarr; R

<P>
Then we can get a quadratic form in 2 variables by taking the 
minimum of Q as the third variable ranges freely:

<P>
P(&phi;<sub>1</sub>, &phi;<sub>2</sub>) = min<sub>&phi;<sub>3</sub></sub>  Q(&phi;<sub>1</sub>, &phi;<sub>2</sub>, &phi;<sub>3</sub>)

<P>
Physically this corresponds to taking a circuit with 3 terminals, 
like this:

<PRE>
    x         x
     \       /
      \     /
       \   /
        \ /
         x
</PRE>
and treating it as a circuit with 2 terminals by regarding 
the third terminal as an internal vertex:

<PRE>
    x         x
     \       /
      \     /
       \   /
        \ /
         o
</PRE>
This means we let the potential at this vertex vary freely; by the
principle of minimum power, it will do whatever it takes to minimize
the power.  So, we get a new circuit whose quadratic form is

<P>
P(&phi;<sub>1</sub>, &phi;<sub>2</sub>) =
min<sub>&phi;<sub>3</sub></sub> Q(&phi;<sub>1</sub>,
&phi;<sub>2</sub>, &phi;<sub>3</sub>)

<P>
More generally, we can take a nonnegative quadratic form in n
variables, and take any subset of these variables, and get a new
quadratic form by this minimization trick.  And Sabot claims that if
the original form was Dirichlet, so is the new one.  He doesn't prove
this, but I think it's easy - try it!

<P>
Sabot calls this trick for getting new Dirichlet forms from old ones
the &quot;trace map&quot;.  He also describes another trick, the
&quot;gluing map&quot;.  This lets us take the Dirichlet form of a
circuit and get a new Dirichlet form by gluing together some
terminals.  For example, we could start with this circuit:

<PRE>
    x         x
     \       /
      \     /
       \   /
        \ /
         x
</PRE>
and glue the top two terminals together, getting this circuit:

<PRE>
         x
        / \
       /   \
       \   /
        \ /
         x
</PRE>
Both the trace map and the gluing map have interesting category-
theoretic interpretations.  For example, the gluing map lets us
<i>compose</i> electrical circuits - or more precisely, their
Dirichlet forms - by gluing the outputs of one onto the inputs of
another.

<P>
Finally, suppose we allow grounds as well as resistors.  Sabot
considers circuits of this sort in the following beautiful paper:

<P>
8) Christophe Sabot, Electrical networks, symplectic reductions, and
application to the renormalization map of self-similar lattices,
Proc. Sympos. Pure Math. 72 (2004), 155-205.  Also available as <a
href =
"http://arxiv.org/abs/math-ph/0304015">arXiv:math-ph/0304015</a>.

<P>
He only considers circuits of a special form.  They have no internal
vertices, just terminals.  As before, each pair of terminals is
connected with a resistor.  But now, each terminal is also connected
to the ground via a resistor!  Such circuits give exactly these
quadratic forms:

<P>
Q(&phi;) = &sum;<sub>i,j</sub> c<sub>ij</sub> (&phi;<sub>i</sub> - &phi;<sub>j</sub>)<sup>2</sup>  +  &sum;<sub>i</sub> c<sub>i</sub> &phi;<sub>i</sub><sup>2</sup>

<P>
where c<sub>ij</sub> and c<sub>i</sub> are nonnegative numbers.  

<P>
Let's call these &quot;generalized Dirichlet forms&quot;.  I believe
these generalized Dirichlet forms are characterized by the Markov
property:

<P>
Q(&phi;) &ge; Q(&psi;)

<P>
when &psi;<sub>i</sub> is the minimum of &phi;<sub>i</sub> and 1.  

<P>
These generalized Dirichlet forms don't include <i>all</i> the
nonnegative quadratic forms.  Why?  Because, as Ben Tilly pointed out,
they don't include quadratic forms where the cross-terms
&phi;<sub>i</sub> &phi;<sub>j</sub> have positive coefficients.  So,
for example, we don't get this:

<P>
Q(&phi;<sub>1</sub>, &phi;<sub>2</sub>) = (&phi;<sub>1</sub> + &phi;<sub>2</sub>)<sup>2</sup>

<P>
Sabot claims that generalized Dirichlet forms are closed under the
trace map and gluing.  Given this, the same argument I already
sketched shows that <i>every</i> electrical circuit built from
resistors and grounds has a quadratic form that's a generalized
Dirichlet form!

<P>
So, it's all been worked out...

<P>
Even better, Sabot explains how quadratic forms on a vector space V
give Lagrangian subspaces of T*V.  This is the trick I used last week
to introduce wires of zero resistance.

<P>
A wire with zero resistance would use an infinite amount of power if
you put a different electrostatic potential at each end.  KABANG! -
the ultimate &quot;short circuit&quot;!  So, wires with zero
resistance are not physical realistic, but they're useful
idealizations: they serve as identity morphisms in the
category-theoretic description of electrical circuits.  Circuits
containing these wires can still be described using Lagrangian
subspaces.  These subspaces <i>don't</i> come from quadratic forms.
But they are limits of subspaces that do.

<P>
Now we can make this more precise.  There's a manifold consisting of
all Lagrangian subspaces of T*V - the &quot;Lagrangian
Grassmannian&quot;.  Sitting in here is the set of generalized
Dirichlet forms on V.  We can take the closure of that set and get a
space C(V).  Points in C(V) correspond to circuits built from
resistors, grounds, and wires of zero resistance.  Sabot says this
space is discussed here:

<P>
9) Y. Colin de Verdiere, Reseaux electriques planaires I,
Comment. Math. Helv. 69 (1994), 351-374.  Also available at
<a href = "http://www-fourier.ujf-grenoble.fr/~ycolver/All-Articles/94a.pdf">http://www-fourier.ujf-grenoble.fr/~ycolver/All-Articles/94a.pdf</a>.

<P>
So, Sabot, Verdiere and the rest of the Dirichlet form crowd have done
almost everything I want... <i>except</i> phrase their results in the
language of category theory!  And that, of course, is my real goal: to
develop category theory as a language for physics and engineering.

<P>
Last week I gave a preliminary try at describing a category whose
morphisms are electrical circuits built from resistors and grounds.  
I said:

<P>
<blockquote>
  <b>Claim:</b> there is a dagger-compact category where:

<UL>
<LI>
  An object is a finite-dimensional real vector space.  
</LI>
<P>
<LI>
  A morphism S: V &rarr; W is a Lagrangian subspace of T*V &times; T*W.
</LI>
<P>
<LI>
  We compose morphisms using composition of relations.
</LI>
<P>
<LI>
  The tensor product is given by direct sum.
</LI>
<P>
<LI>
  The symmetry is the obvious thing.
</LI>
<P>
<LI>
  The dagger of a subspace of T*V &times; T*W is the corresponding 
  subspace of T*W &times; T*V.  
</LI>
</UL>
</blockquote>

<P>
The problem was that this category has too many morphisms.  If we only
want physically realistic circuits - or <i>almost</i> realistic ones,
since we're allowing wires of zero resistance - we should work not
with all Lagrangian subspaces of T*R<sup>m</sup> &times; T*R<sup>n</sup>, 
but only those lying in the subset C(R<sup>m</sup> &times; R<sup>n</sup>).  
So, let's try:

<P>
<blockquote>
  <b>Claim:</b> there is a dagger-compact category where:

<UL>
<LI>
  An object is a natural number.
</LI>
<P>
<LI>
  A morphism S: m &rarr; n is a point in  C(R<sup>m</sup> &times; R<sup>n</sup>).
</LI>
<P>
<LI>
  We compose morphisms using composition of relations.
</LI>
<P>
<LI>
  The tensor product is given by direct sum.
</LI>
<P>
<LI>
  The symmetry is the obvious thing.
</LI>
<P>
<LI>
  The dagger of a point in C(R<sup>m</sup> &times; R<sup>n</sup>) is
  the corresponding point in C(R<sup>n</sup> &times; R<sup>m</sup>). 
</LI> 
</UL>
  </blockquote>

<P>
There are a few things to check here.  I haven't checked them all.

<P>
By the way: in case you actually want to study this stuff, I should
point out that Sabot's second paper uses &quot;Dirichlet form&quot; to
mean what I'm calling a generalized Dirichlet form, and uses
&quot;conservative Dirichlet form&quot; to mean what I'm calling a
Dirichlet form.  So, be careful.

<P>
Also, here's another worthwhile reference:

<P>
10) Jun Kigami, Analysis on Fractals, Cambridge U. Press.  First
60 pages available at 
<a href = "http://www-an.acs.i.kyoto-u.ac.jp/~kigami/AOF.pdf">http://www-an.acs.i.kyoto-u.ac.jp/~kigami/AOF.pdf</a>

<P>
It's full of information on Dirichlet forms and electrical circuits.
And it gives yet another characterization of Dirichlet forms!  I don't
love it - but I might as well tell you about it.

<P>
A Dirichlet form on R<sup>n</sup> is a nonnegative quadratic form that 
vanishes when &phi; is constant:

<P>
&phi;<sub>i</sub> = &phi;<sub>j</sub> for all i,j implies Q(&phi;) = 0

<P>
and satisfies

<P>
Q(&phi;) &ge; Q(&psi;)

<P>
whenever

<P>
&psi;<sub>i</sub> = &phi;<sub>i</sub> if 0 &lt; &phi;<sub>i</sub> &lt; 1
<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        1     if &phi;<sub>i</sub> &gt; 1
<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        0     if &phi;<sub>i</sub> &lt; 0

<P>
This is yet another way to say that power decreases when the
potentials at the terminals are closer together.

<P>
Kigami also explains the relation between Dirichlet forms and Markov
processes.  His Theorem B.3.4. says that for a measure space X, there
is a one-to-one correspondence between Dirichlet forms on
L<sup>2</sup>(X) and strongly continuous semigroups on
L<sup>2</sup>(X) that map functions in L<sup>1</sup>(X) to functions
of the same sort, and map nonnegative functions whose integral is 1 to
functions of the same sort.  Such semigroups are called
&quot;Markov&quot;.  The classic example is provided by the heat
equation!  But in our electrical circuit example, we're considering
the pathetically simple case where X is a finite set.

<P>
One simple thing that deserves to be emphasized is that a Dirichlet
form is not a kind of quadratic form on an abstract vector space.
It's a kind of quadratic form on a space of functions!  In particular,
in my discussion above, R<sup>n</sup> really means the algebra of
functions on an n-element set - and in the second dagger-compact
category mentioned above, the objects should really be finite sets.  I
was just working with a skeletal subcategory, to make things less
intimidating.

<P>
Okay, I'll stop here for now.  Later I plan to bring inductors and
capacitors into the game... and loop groups!

<p>
<HR><P>

<b>Addendum:</b> My friend Bruce Smith wrote:

<blockquote>
   I can't tell for sure, from what you wrote about grounds in week297
   (and the last few Weeks), whether you are aware of this way to
   think about them: there is a 1-1 correspondence between circuits
   that can include grounds, and circuits that can't. To implement it,
   starting with a circuit that can include grounds, just add an extra
   terminal, call it &quot;G&quot; for &quot;ground&quot;, and replace
   every internal ground with a 0-resistance connection to that
   terminal G. Also, in your thinking about potentials at terminals,
   replace &quot;the potential at T<sub>i</sub>&quot; with &quot;the potential
   difference between T<sub>i</sub> and G&quot; (or equivalently but
   differently, require that the potential at G is always 0).

<P>
   (I'm pretty sure you must be aware of this, but somehow it didn't
   show up as a simplifier in your explanation as much as, or as
   explicitly as, I thought it ought to.)

<P>
   If 0 resistance bothers you, note that it can be reduced away (by
   eliminating internal terminals in your resulting circuit) unless
   you had a ground directly connected to a terminal; if you were
   allowing that, then in your new circuit you'd better be allowing
   direct connections between two terminals, but I presume that
   whatever difficulties this causes in either case are essentially
   the same.

</blockquote>

For more discussion, visit the <a href = "http://golem.ph.utexas.edu/category/2010/05/this_weeks_finds_in_mathematic_58.html"><em>n</em>-Category Caf&eacute;</a>.


<p>
<HR><P>
<i>Discussions about theoretical engineering research often feels like
visiting a graveyard in the company of Nietzsche. From the beginning
of my career until now, I have always been hearing that 'the field is
dead', 'circuit theory is dead', 'information theory is dead', 'coding
theory is dead', 'control theory is dead', 'system theory is dead',
'linear system theory is dead', 'H<sub>&infin;</sub> is dead'. Good
science, however, is always alive.  The community may not appreciate
the vibrancy of good ideas, but it is there. The absence of this
impatience is one of the things that makes working in a mathematics
department simply more pleasant.</i> - Jan C. Willems

<p>
<HR><P>
<!-- BEGIN FOOTER -->
&#169; 2010  John Baez<br>
baez@math.removethis.ucr.andthis.edu <br>
<P>
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week296.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week298.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE><!-- END FOOTER -->



