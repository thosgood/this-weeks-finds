<TITLE> week157 </TITLE>

<!-- BEGIN HEADER -->
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week156.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week158.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE>
<H4> September 24, 2000 </H4>
<H2> This Week's Finds in Mathematical Physics (Week 157) </H2>
<H4> John Baez </H4>
<!-- END HEADER -->


<P>
I never write issues of This Week's Finds about topics that people
request.  I only write about what I happen to be studying at a given
moment - nothing else seems to work.  But when my friend Minhyong Kim
asked me to do an issue on Young diagrams, I decided to break this 
rule just once.  Young diagrams are too cool to ignore.

<P>
Physics relies a lot on <em>symmetry</em> to simplify problems, and there are 
two kinds of diagrams that show up a lot in this context: Dynkin diagrams 
and Young diagrams.  

<P>
Dynkin diagrams first show up when you study shapes with lots of
reflection symmetries, like crystals and Platonic solids.  They wind up
being good for all sorts of other stuff, like classifying simple Lie
groups and their representations.  I talked about them in &quot;<A HREF
= "week62.html">week62</A>&quot; - &quot;<A HREF =
"week65.html">week65</A>&quot;.

<P>
But what about Young diagrams?  These are also important for studying
group representations, but for a more limited class of groups: the
&quot;classical&quot; groups.

<P>
As with composers of music, there's no precise list of groups that count
as &quot;classical&quot;.  But in general, a classical group should consist of
linear transformations that preserve some nice geometrical structure on
a vector space.  A good example is SU(N), the group of all linear
transformations of an N-dimensional complex vector space that preserve
an inner product and volume form.  In less elevated language, SU(N) is
the group of all N x N unitary matrices with determinant 1.

<P>
The symmetric group S<sub>n</sub> may also be considered an honorary classical
group, even though it's defined in terms of a <em>set</em> rather than a
<em>vector space</em>.  
S<sub>n</sub> is the group of all permutations of an n-element
set.  

<P>
Rather amazingly, Young diagrams can be used to classify all 3 of
these things, which at first seem quite different in flavor:

<UL>
<LI> conjugacy classes in S<sub>n</sub>
<LI> irreducible representations of S<sub>n</sub>
<LI> irreducible representations of SU(N)
</UL>

<P>
Let me sketch how this goes, and then say a bit about the <em>other</em>
things you can do with Young diagrams.

<P>
Say we have any permutation g in S<sub>n</sub>, like this:

<PRE>
1 &rarr; 2
2 &rarr; 4 
3 &rarr; 3
4 &rarr; 1
5 &rarr; 6
6 &rarr; 5
7 &rarr; 7
</PRE>
Note that 1 gets mapped to 2, which gets mapped to 4, which gets mapped
back to 1 again.   Similarly, 5 gets mapped to 6, which gets mapped back
to 5.  The number 3 gets mapped to itself right away, as does 7.  No matter 
where we start, we always cycle back eventually.  So our permutation
consists of a bunch of &quot;cycles&quot;:

<P>
(1,2,4) (5,6) (3) (7)

<P>
and writing down this &quot;cycle decomposition&quot; completely describes the
permutation.   To simplify life, we always write down these cycles in
order of decreasing length.  We also write the lowest number in each
cycle first.  

<P>
Now suppose we conjugate our permutation g by some other permutation,
say h.  This gives the permutation hgh^{-1}.  How does the cycle
decomposition of this compare with that of g?  It looks almost the same!
For example, it might look like this:

<P>
(2,7,6) (1,3) (4) (5)

<P>
There are the same number of cycles, each the same length as before. 
The only thing that changes are the numbers in each cycle.  These get
switched around by means of the permutation h.  

<P>
In short, when we conjugate a permutation, all that remains unchanged is
the picture we get by writing down its cycle decomposition and blotting
out the specific numbers in each cycle, like this:

<PRE>
(X,X,X) (X,X) (X) (X)
</PRE>
Folks usually write each cycle as a row, like this:

<PRE>
X X X
X X
X
X
</PRE>
This is called a &quot;Young diagram&quot;!  But instead of X's, people
usually draw boxes.  So a Young diagram is just a bunch of rows of
boxes, arranged in order of decreasing length.

<P>
Okay: so far I've shown how conjugacy classes of permutations in S<sub>n</sub>
correspond to Young diagrams with a total of n boxes.  Now I want to do
the same for irreducible representations of S<sub>n</sub>.  

<P>
This is cool for the following reason: for any finite group, the number
of irreducible representations is the same as the number of conjugacy
classes of group elements.  But in general there's no natural way to 
match up irreducible representations with conjugacy classes.  The group
S<sub>n</sub> just happens to be specially nice in this way.

<P>
Here I must turn up the math level slightly... for example, I'll assume
you know what &quot;irreducible representations&quot; means!  I'll even
show off by calling them &quot;irreps&quot; for short.  But to be nice,
I'll start by reviewing some general facts about representations of
finite groups.

<P>
Suppose G is a finite group.  Then G has only finitely many irreps, all
finite-dimensional.  Every finite-dimensional representation of G is a
direct sum of copies of these irreps.  

<P>
To get our hands on these irreps, let C[G] be the space of formal linear
combinations of elements of G.  This is called the &quot;group
algebra&quot; of G, since it becomes an algebra using the product in G.
Any representation of the group G becomes a representation of C[G] in an
obvious way, and vice versa.

<P>
With some work, one can show that C[G] is isomorphic to an algebra
of block diagonal matrices.  For example, C[S<sub>3</sub>] is isomorphic to the
algebra of matrices like this:

<PRE>
   * * 0 0 
   * * 0 0
   0 0 * 0 
   0 0 0 *
</PRE>
where the * entries can be any complex number whatsoever.  Since
matrices act on vectors by matrix multiplication, we can use this to get
a bunch of representations of C[G], and thus of G - one representation
for each block.  And this trick gives us all the irreps of G!  For
example, S<sub>3</sub> has one 2-dimensional irrep, coming from the 2 x
2 block in the above matrix, and two 1-dimensional irreps, coming from
the two 1 x 1 blocks.

<P>
This wonderful fact does not solve all our problems.  If someone hands
us a finite group G, we still need to work to find which algebra of block
diagonal matrices C[G] is isomorphic to.  How do we do this?  

<P>
The trick is to find elements of C[G] corresponding to matrices that
are the identity matrix in one block and zero in the rest, like these:

<PRE>
            1 0 0 0            0 0 0 0             0 0 0 0 
            0 1 0 0            0 0 0 0             0 0 0 0 
            0 0 0 0            0 0 1 0             0 0 0 0 
            0 0 0 0            0 0 0 0             0 0 0 1

              p<sub>1</sub>                 p<sub>2</sub>                  p<sub>3</sub>
</PRE>
If we can find these guys, the rest is easy: C[G] is a direct sum of
&quot;blocks&quot;

<P>
                    {p<sub>i</sub> a p<sub>i</sub> : a in C[G]}

<P>
each of which is isomorphic to some algebra of n x n matrices.

<P>
How do we find these guys p<sub>i</sub> in C[G]?  It's actually pretty
straightforward to characterize them:

<UL>
<LI> They are idempotent: p<sub>i</sub><sup>2</sup> = p<sub>i</sub>.
<LI> They are central: p<sub>i</sub> x = x p<sub>i</sub> for all x in C[G].
<LI> They are minimal: if p<sub>i</sub> is the sum of two central idempotents, one 
   of them must be zero.
</UL>
<P>
So we've reduced the problem of finding the irreps of a finite group G
to the problem of finding &quot;minimal central idempotents&quot; in the group 
algebra C[G].

<P>
To go further, we need to know more about our group G.  So now I'll take
G to be the permutation group S<sub>n</sub> and tell you how to get the minimal
central idempotents.  We'll get one for each Young diagram with n boxes!

<P>
Say we have a Young diagram with n boxes, like this:

<PRE>
X X X
X X
X
X
</PRE>
Then we can pack it with numbers from 1 to n like this:

<PRE>
1 2 3
4 5
6
7
</PRE>
There are a bunch of permutations in S<sub>n</sub> called &quot;column
permutations&quot;, that only permute the numbers within each column of
our Young diagram.  And there are a bunch called &quot;row
permutations&quot;, that only permute the numbers within each row.

<P>
We can form an idempotent p in C[S<sub>n</sub>] that antisymmetrizes over all 
column permutations.  We get p by taking the sum of all <em>even</em> column
permutations minus the sum of all <em>odd</em> column permutations, and then
dividing by the total number of column permutations.

<P>
Similarly, we can form an idempotent q in C[S<sub>n</sub>] that
symmetrizes over all row permutations.  We get q by taking the sum of
all row permutations divided by the number of row permutations.

<P> 
Now here's the cool part: pq is a minimal central idempotent in
C[S<sub>n</sub>], and we get all minimal central idempotents this way!
This isn't very obvious, but I went over the proof before writing this,
so I know it's true.

<P>
Consider n = 3, for example.  There are 3 Young diagrams in this case:
<PRE>
      X X X            X X               X
                       X                 X
                                         X
</PRE>
so S<sub>3</sub> has 3 minimal central idempotents and thus 3 irreps,
confirming something I already said.

<P>
There is a lot more to say about this, but now I want to switch gears
and tell you how representations of SU(N) are classified by Young
diagrams.   Since SU(N) consists of N x N matrices, it has an obvious
representation on the vector space C^N, which people call the
&quot;fundamental&quot; representation.   This is an irrep.  If we're trying to
cook up irreps of SU(N), this is an obvious place to start.

<P>
How can we get a bunch of representations of SU(N) starting from the
fundamental representation?  One way is to take the fundamental
representation and tensor it with itself a bunch of times, say n times:

<PRE>
           C^N tensor C^N tensor ... tensor C^N tensor C^N
           |------------------n copies-------------------|

</PRE>
There's no reason in the world this new representation should be
irreducible.  But we can try to chop it up into irreducible bits.  And
the easiest way to do this is to look for bits that transform in nice
ways when we permute the n copies of C^N.  In physics lingo, we have a
space of tensors with n indices, and we can look for subspaces
consisting of tensors that transform in specified ways when we permute
the indices.  For example, there will be a subspace consisting of
&quot;totally symmetric&quot; tensors that don't change at all when we
permute the indices.  And a subspace of &quot;totally
antisymmetric&quot; tensors that change sign whenever we interchange two
indices.  And so on....

<P>
But to make the &quot;and so on&quot; precise, we need Young diagrams.  After all,
these describe all the representations of the permutation group.  

<P>
Here's how it works.  The space 

<PRE>
      V =  C^N tensor C^N tensor ... tensor C^N tensor C^N
           |------------------n copies-------------------|

</PRE>
is not only a representation of SU(N); it's also a representation of
S<sub>n</sub>.  And the actions of these two groups commute!  This means that
we can chop up V into subspaces using the minimal central idempotents
in S<sub>n</sub>, and each of these subspaces will be a representation of SU(N).

<P>
This much is obvious.  The really cool part is that all these subspaces
are <em>irreducible</em> representations of SU(N).  Even better, we get 
<em>all</em> the irreps of SU(N) by this process, as we let n vary.

<P>
In other words, any Young diagram gives us an irrep of SU(N) consisting
of tensors that transform in a certain way under permutation of indices,
and we get all irreps this way.  

<P>
If you think about it, some of these irreps will be a bit silly.  If we
have a Young diagram with more than N rows, we'll be antisymmetrizing
over more than N indices, which gives a zero-dimensional representation
of SU(N).  We can ignore these.  

<P>
Also, if we have a Young diagram that has just one column and exactly N
rows, we'll get the space of completely antisymmetric tensors with N
indices.  This is a 1-dimensional space.  Applying a matrix in SU(N) to
a tensor of this sort just multiplies it by the determinant of that
matrix, which is 1 by the definition of SU(N).  So this Young diagram
gives the trivial representation of SU(N).  That's not too silly - the
trivial representation is important, in its own trivial sort of way.
But notice: the trivial representation is already described by the Young
diagram with <em>no</em> boxes!  So it's redundant to also consider the Young
diagram with one column and N rows.

<P>
By the same logic, we can remove any column with exactly N rows from a 
Young diagram without changing the rep of SU(N) that we get.

<P>
So here's the bottom line: irreps of SU(N) correspond in a 1-1 way with
Young diagrams having fewer than N rows.  

<P>
Okay, I've shown you how Young diagrams classify conjugacy classes of
S<sub>n</sub>, irreps of S<sub>n</sub>, and irreps of SU(N).  But this is really just the
tip of the iceberg!

<P>
First of all, we can use Young diagrams packed with numbers, called
&quot;Young tableaux&quot;, to do all sorts of calculations involving
irreps of S<sub>n</sub> and SU(N).  Say we tensor two irreps and want to
decompose it as a direct sum of irreps: how do we do it?  Well, we play
a little game with Young tableaux and out pops the answer.  One relevant
buzzword is &quot;Littlewood-Richardson rules&quot;.  Or say we have an
irrep of S<sub>n</sub> and want to know how it decomposes into irreps
when we restrict it to a subgroup like S<sub>n-1</sub>.  Or the same for
SU(N) and SU(N-1).  How do we do this?  More messing with Young
tableaux.  Here one relevant buzzword is &quot;branching rules&quot;.

<P>
I'll warn you right now: there is an <em>enormous</em> literature on this
stuff.  The combinatorics of Young diagrams is one of those things that
everyone has worked on, from hardnosed chemists to starry-eyed category
theorists.  It takes a lifetime to master this material, and I certainly
have <em>not</em>.  But learning even a little is fun, so don't 
be <em>too</em> scared.

<P>
Second of all, Young diagrams are also good for studying the
representations of other classical groups, notably GL(N), SL(N), O(N),
SO(N), U(N) and Sp(N).  All these groups have an obvious &quot;fundamental
representation&quot;, and we can cook up lots of reps by taking the nth
tensor power of the fundamental representation and hitting it with
minimal central idempotents in C[S<sub>n</sub>].  The story I just told you for
SU(N) can be repeated with slight or not-so-slight variations for all
these other groups.

<P>
Third, we can &quot;q-deform&quot; the whole story, replacing any one of
these classical groups by the associated &quot;quantum group&quot;, and
replacing C[S<sub>n</sub>] by the corresponding &quot;Hecke
algebra&quot;.  This is really important in topological quantum field
theory and the theory of type II subfactors.

<P>
Fourth, there are nice relationships between Young diagrams and 
algebraic geometry, like the &quot;Schubert calculus&quot; for the cohomology 
ring of a Grassmanian.

<P>
And there's a lot more, but I have to stop somewhere.

<P>
So, how does one start learning this stuff?

<P>
If you have a certain amount of patience for old-fashioned terminology,
I might recommend going back to the classic text on classical groups:

<P>
1) Hermann Weyl, The Classical Groups, Their Invariants and Representations,
Princeton U. Press, Princeton, 1997.

<P>
Weyl coined the term &quot;classical groups&quot; for the purposes of this book,
which was first published in 1939.  His prose is beautiful, but I warn
you, this book is not the way to learn Young diagrams in a hurry.

<P>
For a user-friendly approach that's aimed at physicists, but still
includes proofs of all the key results, you can't beat this:

<P>
2) Irene Verona Schensted, A Course on the Applications of Group Theory
to Quantum Mechanics, NEO Press, Box 32, Peaks Island, Maine.

<P>
A girlfriend of mine gave me a copy when I was a college student, but
only much later did I realize how great a book it is.  Unfortunately
it's out of print!  Someone should reprint this gem.

<P>
Here's another book that covers Young diagrams together with applications
to physics:

<P>
3) Shlomo Sternberg, Group Theory and Physics, Cambridge U. Press,
Cambridge, 1994.

<P>
Both these books, but especially the latter, describe applications of
Young diagrams to particle physics, like Gell-Mann's famous &quot;eight-fold
way&quot;, which was based on positing an SU(3) symmetry between the up, down
and strange quarks.

<P>
Then there are more advanced texts, for when your addiction to Young
diagrams becomes more serious.  For the combinatorial side of things,
these are good:

<P>
4) Gordon Douglas James and Adalbert Kerber, The Representation Theory 
of the Symmetric Group, Addison-Wesley, Reading, Massachusetts, 1981.

<P>
5) Bruce Eli Sagan, The Symmetric Group: Representations, Combinatorial 
Algorithms, and Symmetric Functions, Wadsworth and Brooks, Pacific Grove,
California, 1191.

<P>
For a more conceptual approach to representation theory that puts Young
diagrams in a bigger context, try this:

<P>
6) Roe Goodman and Nolan R. Wallach, Representations and Invariants of the 
Classical Groups, Cambridge University Press, Cambridge, 1998.

<P>
It's sort of an updated version of Weyl's book.  Finally, here's
a mathematically sophisticated book that really gives you a Young
diagram workout:

<P>
7) William Fulton, Young Tableaux: With Applications to Representation
Theory and Geometry, Cambridge U. Press, Cambridge, 1997.

<P>
Now, my friend Allen Knutson is a real Young diagram fiend.  Together
with Terry Tao, he helped prove something called &quot;Horn's conjecture&quot;,
which had been bugging people for decades, and has implications for a
huge number of questions.  I have a feeling Allen is going to send me a
nasty email saying that I didn't actually say anything <em>interesting</em>
about Young diagrams.  In an attempt to pacify him, I'll direct you to
Fulton's excellent review article on this subject:

<P>
8) William Fulton, Eigenvalues, invariant factors, highest weights, and
Schubert calculus, Bull. Amer. Math. Soc. 37 (2000), 209-249, also
available as <A HREF =
"http://arXiv.org/abs/math.AG/9908012">math.AG/9908012</A>.

<P>
as well as Allen and Terry's papers on the subject:

<P>
9) Allen Knutson and Terence Tao, The honeycomb model of GL(n) tensor
products I: the saturation conjecture, preprint available as 
<A HREF = "http://arXiv.org/abs/math.RT/9807160">math.RT/9807160</A>

<P>
10) Allen Knutson, The symplectic and algebraic geometry of Horn's problem,
preprint available as
<A HREF = "http://arXiv.org/abs/math.LA/9911088">math.LA/9911088</A>.

<P>
11) Allen Knutson and Terence Tao, Honeycombs and sums of Hermitian
matrices, preprint available as <A HREF =
"http://arXiv.org/abs/math.RT/0009048">math.RT/0009048</A>

<P>
But I should also mention the question that Horn's conjecture settles!

<P>
There are many ways to phrase it; here's the easiest one.  If you
know the eigenvalues of two n x n Hermitian matrices A and B, what are
the possible eigenvalues of their sum?  There are a bunch of linear 
inequalities that must hold; find a necessary and sufficient set.

<P>
This may not seem related to Young diagrams, but it is....

<P>




<p> <hr>
<em>Devin had been studying this region for ten years, poking his
way through a place not much larger than the town in which he
lived, and had still not deciphered half its routes.  This hugeness
inside of smallness creates a matrix of intersections, precious
and incalculable channels one after the next.  It is a fractal landscape
like the surface of a leaf, veins within veins, or the arborescent
feathers of ice forming barbs within barbs across the surface of a pond.</em> -
Craig Childs, Soul of Nowhere
<P>
<HR><P>
<!-- BEGIN FOOTER -->
&#169; 2000  John Baez<br>
baez@math.removethis.ucr.andthis.edu <br>
<P>
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week156.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week158.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE><!-- END FOOTER -->
