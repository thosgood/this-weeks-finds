<TITLE> week288 </TITLE>

<!-- BEGIN HEADER -->
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week287.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week289.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE>
<H4> January 1, 2010 </H4>
<H2> This Week's Finds in Mathematical Physics (Week 288) </H2>
<H4> John Baez </H4>
<!-- END HEADER -->


<P>
Happy New Decade!  I hope you're doing well.  This week I'll say more
about rational homotopy theory, and why the difference between
equality and isomorphism is important for understanding the weather 
in space.  But first: electrical circuits!

<P>
But even before that... guess what this is a picture of:

<P>
<div align = "center">
<img border = "2" src = "http://math.ucr.edu/home/baez/linear_dunes.jpg">
</div>

<P>
Now, what about electrical circuits?

<P>
I've been thinking This Week's Finds has become a bit too far removed
from its roots in physics.  This problem started when I quit working
on quantum gravity and started focusing on n-categories.  Overall it's
been a big boost to my sanity.  But I don't want This Week's Finds to
be comprehensible only to an elite coterie of effete mathematicians -
the sort who eat simplicial presheaves for breakfast and burp up
monoidal bicategories.

<P>
So, in an effort to prevent This Week's Finds from drifting off into
the stratosphere of abstraction, I've decided to talk a bit about
electrical circuits.  Admittedly, these are less glamorous than
theories of quantum gravity.  But: they actually work!  And there is 
a lot of nice math involved.

<P>
I rarely dare predict what <em>future</em> Week's Finds will discuss, because
I know from bitter experience that I change my mind.  But lately I've
started writing a new way: long stories with lots of episodes, which I
can dole out a bit at a time.  So I know that for at least a few Weeks
I'll talk about electrical circuits - and various related things.

<p>
<div align = "center">
<a href = "http://www.free-circuits.com/circuits/audio/135/10w-audio-amplifier-with-bass-boost">
<img border = "none" src = "electronics_circuit_diagram_10W_amplifier_with_bass_boost.gif">
</a>
<font size = "-1">
<br/> 10 watt amplifier with bass boost </font>
</div>

<P>
I've been trying to understand electrical circuits using category
theory for a long time.  Indeed, Peter Selinger and I are very slowly
writing a paper on this subject.  The basic inspiration is that
electrical circuit diagrams look sort of like Feynman diagrams, flow
charts, and various other diagrams that have &quot;inputs&quot; and
&quot;outputs&quot;.  I love diagrams like this!  All the kinds I've
met so far can be nicely formalized using category theory.  For an
explanation, try this:

<P>
1) John Baez and Mike Stay, Physics, topology, logic and computation:
a Rosetta Stone, to appear in New Structures in Physics, ed. Bob
Coecke.  Available at <a href = "http://arxiv.org/abs/arXiv:0903.0340">arXiv:0903.0340</a>.

<P>
And after I spent a while thinking about electrical circuits using
category theory, I realized that this perspective might shed light on
analogies between circuits and other systems.

<P>
For example: mechanical systems made from masses and springs!  

<P>
Indeed, whenever I teach linear differential equations, I like to
explain the basic equation describing a &quot;damped harmonic
oscillator&quot;: for example, a rock hanging on a spring.

<P>
<div align = "center">
<img src = "damped_spring.gif">
</div>
<P>

Then I explain how the same equation describes the simplest circuit
made of a resistor, an inductor, and a capacitor - the so-called
&quot;RLC circuit&quot;.  It's a nice easy example of how the same
math applies to superficially different but secretly isomorphic
problems!

<P>
Let me explain.  I hope this is a chance to help mathematicians review
their physics and ask questions about it over on the <i>n</i>-Category 
Caf&eacute;.

<P>
Let the height of a rock hanging on a spring be q(t) at time t, where
q(t) is negative when the end of the spring is down below its
equilibrium position.  Then making all sort of simplifying assumptions
and approximations, we have:

<P>
m q&quot;(t) = - c q'(t) - k q(t) + F(t)

<P>
where:

<ul>
<li>
   m is the <a href = "http://en.wikipedia.org/wiki/Mass">mass</a> of the rock.
<P>
</li>
<li>
   c is the <a href = "http://en.wikipedia.org/wiki/Damping">damping 
   coefficient</a>, which describes the force due to
   friction: we're assuming this force is proportional to the rock's
   velocity, but points the other way.
<P>
</li>
<li>
   k is the <a href = "http://en.wikipedia.org/wiki/Hooke%27s_law">spring 
   constant</a>, which describes the force due to the
   spring: we're assuming this force is proportional to how much the
   spring is stretched from its equilibrium position, but points the
   other way.
<P>
</li>
<li>
   F(t) is the externally applied <a href =
   "http://en.wikipedia.org/wiki/Force">force</a>, e.g. if you push on
   the rock.  
</li> 
</ul>

<P>
This equation is just <a href =
"http://en.wikipedia.org/wiki/Newton%27s_laws_of_motion#Newton.27s_second_law">Newton's
second law</a>, force equals mass times acceleration.  The left side
of the equation is mass times acceleration; the right side is the
total force.

<P>
Now for the analogy.  Everything here is analogous to something in an
RLC circuit!  An <a href =
"http://en.wikipedia.org/wiki/RLC_circuit#Series_RLC_with_Th.C3.A9venin_power_source">RLC
circuit</a> has current flowing around a loop of wire with 4 gizmos on
it: a resistor, an inductor, a capacitor, and a voltage source - for
example, a battery.

<P>
<div align = "center">
<img src = "RLC_series_circuit.png">
</div>
<P>



<P>
I won't say much about these gizmos.  I just want to outline the
analogy.  The amount of current is analogous to the velocity of the
rock, so let's call it q'(t).  The resistor acts to slow the current
down, just as friction acts to slow down the rock.  The inductor is
analogous to the mass of the rock.  The capacitor is analogous to the
spring - but according to the usual conventions, a capacitor with a
big &quot;capacitance&quot; acts like a weak spring.  Finally, the
voltage source is analogous to the external force.

<P>
So, here's the equation that governs the RLC circuit:

<P>
L q&quot;(t) = - R q'(t) - (1/C) q(t) + V(t)
<P>
where

<P>
<ul>
<li>
L is the <a href =
"http://en.wikipedia.org/wiki/Inductance">inductance</a> of the
<a href = "http://en.wikipedia.org/wiki/Inductor">inductor</a>.  

<P>
<div align = "center">
<img src = "electronics_inductor_symbol.png">
<br/>
<font size = "-1">
inductor
</font>
</div>
<P>

</li>
<li>
R is the <a href =
"http://en.wikipedia.org/wiki/Electrical_resistance">resistance</a> of the
<a href = "http://en.wikipedia.org/wiki/Resistor">resistor</a>.
<P>
<div align = "center">
<img src = "electronics_resistor_symbol.png">
<br/>
<font size = "-1">
resistor
</font>
</div>
<P>

</li>
<li>
C is the <a href =
"http://en.wikipedia.org/wiki/Capacitance">capacitance</a> of the
<a href = "http://en.wikipedia.org/wiki/Capacitor">capacitor</a>.
<P>
<div align = "center">
<img src = "electronics_capacitor_symbol.png">
<br/>
<font size = "-1">
capacitor
</font>
</div>
<P>

</li>
<li>
V is the <a href =
"http://en.wikipedia.org/wiki/Voltage">voltage</a> of the <a href = "http://en.wikipedia.org/wiki/Voltage_source">voltage source</a>.
<P>
<div align = "center">
<img src = "electronics_voltage_source_symbol.jpg">
<br/>
<font size = "-1">
voltage source
</font>
</div>
</li> </ul>

<P>
As you can see, the equation governing the RLC circuit is the same as
the one that governs a rock on a spring!  True, 1/C plays the role of
k, since a capacitor with a big capacitance acts like a spring with a
small spring constant.  But this is just a difference in conventions.
The systems are isomorphic!

<P>
We could have fun solving the above equation and pondering what the 
solutions mean, but that would be the class I teach.  Instead,
I want to explain how this famous analogy between mechanics and 
electronics is just one of many analogies.

<P>
When I started thinking seriously about electrical circuits and
category theory, I mentioned them my student Mike Stay, and he
reminded me of the &quot;hydraulic analogy&quot; where you think of an
electrical current flowing like water through pipes.  There's a 
decent introduction to this here:

<P>
2) Wikipedia, Hydraulic analogy, 
<a href = "http://en.wikipedia.org/wiki/Hydraulic_analogy">http://en.wikipedia.org/wiki/Hydraulic_analogy</a>
 
<P>
Apparently this analogy goes back to the early days when people were
struggling to understand electricity, before electrons had been
observed.  The famous electrical engineer Oliver Heaviside pooh-poohed
this analogy, calling it the &quot;drain-pipe theory&quot;.  I think
he was making fun of William Henry Preece.  Preece was another
electrical engineer, who liked the hydraulic analogy and disliked
Heaviside's fancy math.  In his inaugural speech as president of the
Institution of Electrical Engineers in 1893, Preece proclaimed:

<P>
<blockquote>
  True theory does not require the abstruse language of mathematics to 
  make it clear and to render it acceptable.   All that is solid and 
  substantial in science and usefully applied in practice, have been 
  made clear by relegating mathematic symbols to their proper store 
  place - the study.
</blockquote>

<P>
According to the judgement of history, Heaviside made more progress in
understanding electromagnetism than Preece.  But there's still a nice
analogy between electronics and hydraulics.

<P>
In this analogy, a pipe is like a wire.  Water is like electrical
charge.  The flow of water plays the role of &quot;current&quot;.
Water pressure plays the role of &quot;voltage&quot;.

<P>
A resistor is like a narrowed pipe:

<P>
<div align = "center">
<img src = "electronics_analogy_reduced_pipe_resistor.png">
</div>
<P>

An inductor is like a heavy turbine placed inside a pipe: this makes
the water tend to keep flowing at the same rate it's already flowing!
In other words, it provides a kind of &quot;inertia&quot;, analogous
to the mass of our rock.  Finally, a capacitor is like a tank with
pipes coming in from both ends, and a rubber sheet dividing it in two
lengthwise:

<P>
<div align = "center">
<img src = "electronics_analogy_flexible_tank_capacitor.png">
</div>
<P>

When studying electrical circuits as a kid, I was shocked when I first
learned that capacitors <i>don't let the electrons through</i>.
Similarly, this gizmo doesn't let the water through.

<P>
Okay... by now you're probably wanting to have the analogies laid out
more precisely.  So that's what I'll do.  But I'll throw in one more!
I've been talking about the mechanics of a rock on a spring, where the
motion of the rock up and down is called <em>translation</em>.  But we can
also study <em>rotation</em> in mechanics.  And then we get these analogies:

<PRE><b>
                displacement    flow          momentum      effort
                     q           q'              p            p'

Mechanics       position       velocity       momentum      force
(translation)

Mechanics       angle          angular        angular       torque
(rotation)                     velocity       momentum

Electronics     charge         current        flux          voltage
                                              linkage

Hydraulics      volume         flow           pressure      pressure
                                              momentum
</b></PRE>

The top row lists 4 concepts from the theory of general systems, and
my favorite symbols for them, where the prime stands for time
derivative - if I could, I'd use a dot.  The other rows list what
these concepts are called in the subjects listed.  So,
&quot;displacement&quot; is the general concept which people call
&quot;position&quot; in the mechanics of translation.  Similarly,
&quot;flow&quot; and &quot;effort&quot; correspond to
&quot;velocity&quot; and &quot;force&quot;, while &quot;momentum&quot;
is just &quot;momentum&quot;.

<P>
I found this chart here:

<P>
3) Dean C. Karnopp, Donald L. Margolis and Ronald C. Rosenberg,
System Dynamics: a Unified Approach, Wiley, New York, 1990.

<P>
I discovered this wonderful book after an intensive search for stuff
that makes the analogies between mechanics, electronics and hydraulics
explicit.  It turns out there's a whole theory devoted to precisely
this!  It's sometimes called &quot;systems theory&quot; or
&quot;network theory&quot;.  Engineers use this theory to design and
analyze systems made out of mechanical, electronic, and/or hydraulic
components: springs, gears, levers, pulleys, pumps, pipes, motors,
resistors, capacitors, inductors, transformers, amplifiers, and more!

<P>
Engineers often describe such systems using a notation called
&quot;bond graphs&quot;.  Bond graphs are reminscent of Feynman
diagrams... so they're simply <em>begging</em> to be understood as a
branch of applied category theory.  In fact, there's an interesting
blend of category theory, symplectic geometry and complex analysis at
work here.  So in the Weeks to come, I'd like to tell you more about
bond graphs and analogies between different kinds of systems.

<P>
(I'll warn you right now that Karnopp, like most experts on systems
theory, use the symbols &quot;f&quot; and &quot;e&quot; for flow and effort, instead of q'
and p'.  It's more or less impossible to find a unified notation for
general systems that doesn't conflict with some existing notation
used in the study of some <em>particular</em> kind of system.  But since I
want to get into symplectic geometry, I want to use some notation that
reminds me of that - and for physicists, symplectic geometry is the
study of &quot;conjugate variables&quot; like position q and momentum p.)

<P>
Okay... enough of this for now.  

<P>
Last week I introduced the differential graded commutative algebra
approach to rational homotopy theory.  Next week I'll get into the
differential graded Lie algebra approach, filling in another corner 
of the triangle here:

<PRE>
                      RATIONAL SPACES
                         /      \  
                        /        \  
                       /          \  
                      /            \
                     /              \
      DIFFERENTIAL GRADED ------- DIFFERENTIAL GRADED
      COMMUTATIVE ALGEBRAS           LIE ALGEBRAS
</PRE>
But I realized there's some important stuff I can tell you 
before we get to that!  

<P>
Last time I told you how Sullivan defined &quot;rational differential
forms&quot; for any topological space X:

<P>
  First he converted this space into a simplicial set Sing(X).  

<P>
  Then he defined an algebra A of functions that are polynomials 
  with rational coefficients on each simplex of Sing(X).  

<P>
  Then he defined his algebra &Omega;(A) of rational differential forms,
  using a general recipe that takes a commutative algebra A and spits
  out a differential graded commutative algebra.

<P>
But towards the end, I admitted that homotopy theorists feel perfectly
fine about studying simplicial sets rather than topological spaces.
The reason is that both the category of simplicial sets
and the category of topological spaces are &quot;<a href = 
"http://ncatlab.org/nlab/show/model+category">model categories</a>&quot; - 
contexts where you can do homotopy theory.  
Moreover, these model categories are &quot;<a href = 
"http://ncatlab.org/nlab/show/Quillen+equivalence">Quillen 
equivalent</a>&quot; - the same in every way that
matters for homotopy theory!  Don't worry too much if you don't know
about model categories and Quillen equivalence.  The point is that we
have a functor that converts spaces into simplicial sets:

<P>
Sing: [topological spaces] &rarr; [simplicial sets]

<P>
and its right adjoint going back the other way, called &quot;geometric
realization&quot;:

<P>
| &nbsp; | : [simplicial sets] &rarr; [topological spaces]


<P>
which we also saw last time.  And, these let us freely switch
viewpoints between topological spaces and simplicial sets.

<P>
So, while in &quot;<a href = "week286.html">week286</A>&quot; I
defined rational spaces to be specially nice <em>topological
spaces</em>, I could equally well have defined them to be specially
nice <em>simplicial sets</em>.  Taking this viewpoint, we can forget
about topological spaces, and think of Sullivan's innovation as a
recipe for defining rational differential forms on a <em>simplicial
set</em>.

<P>
This is a good idea.  Among other things, it helps us see more simply
what was so new about rational differential forms when Sullivan first
discovered them.

<P>
What's new is that they give a functor that takes any simplicial set S
and gives a differential graded algebra that's <em>commutative</em> and whose
cohomology is the rational cohomology of S.  

<P>
(By which I mean: the rational cohomology of the space |S|.)

<P>
You see, it's not so hard to achieve this if we drop our insistence
that our differential graded algebra be <em>commutative</em>.  This has been
known for a long time.  You start with your simplicial set S and
define a &quot;rational n-cochain&quot; on it to be a function that eats
n-simplices and spits out rational numbers.  This gives a cochain
complex
         
<PRE>
       d          d          d
C<sup>0</sup>(S) ---&gt; C<sup>1</sup>(S) ---&gt; C<sup>2</sup>(S) ---&gt; ...
</PRE>

where C<sup>n</sup>(S) is the vector space of rational n-cochains.
This cochain complex is usually called C*(S), where the star stands
for the variable n.  And there's a standard way to make C*(S) into a
differential graded algebra, using a product called the &quot;cup
product&quot;.  But, it's not a differential graded
<em>commutative</em> algebra.

<P>
Instead, it's only graded commutative &quot;up to chain
homotopy&quot;.  So, we don't have

<P>
v &cup; w = (-1)<sup>pq</sup> w &cup; v

<P>
when v is in C<sup>p</sup>(S) and w is in C<sup>q</sup>(S).  But, we do have 

<P>
v &cup; w = (-1)<sup>pq</sup> w &cup; v + da(v,w)

<P>
where a(v,w) is something that depends on v and w.  This is good
enough to imply that when we take the cohomology of our cochain
complex, we get a graded commutative algebra.  This algebra is called
H*(S), and the product in here is also called the cup product.  You
can read a lot about it in basic books on algebraic topology.  Here's
one that's free online:

<P>
4) Allen Hatcher, Algebraic Topology, Section 3.2: Cup Product, 
available at <a href = "http://www.math.cornell.edu/~hatcher/AT/ATch3.pdf">http://www.math.cornell.edu/~hatcher/AT/ATch3.pdf</a>

<P>
The memorably numbered Theorem 3.14 says the cup product is graded
commutative.

<P>
So you might say: &quot;So, who cares if the cup product of cochains is
graded commutative merely up to chain homotopy?  When we go to
cohomology, that distinction washes away!&quot;

<P>
Well, it turns out there can be lots interesting information in this
chain homotopy a(v,w).  At least, this is true when we do cohomology
using the integers or the integers modulo some prime as our
coefficients - instead of rational numbers, as we've been doing.

<P>
In fact this chain homotopy is the tip of an enormous iceberg!  For
starters, it satisfies an interesting equation, but only up chain
homotopy...  and that chain homotopy satisfies an equation of its own,
but only up to homotopy, and so on.  So, we get a differential graded
algebra that's graded commutative up to an infinite series of chain
homotopies.  Folks call this sort of gadget an
&quot;E<sub>&infin;</sub>-algebra&quot;.

<P>
And when we work over the integers mod some prime, we can squeeze
interesting information out of all these chain homotopies.  They're
called &quot;Steenrod operations&quot;.  You can use them to distinguish spaces
that would be indistinguishable if you merely used their cohomology as
a graded commutative algebra!

<P>
At least, that's what they say.  I don't <em>personally</em> run
around using Steenrod operations to distinguish weird spaces 
that shady characters pull out of their coat pockets on dark
streetcorners.  Some topologists actually do.  But what fascinates me
is the subtle distinction between equations that hold &quot;on the
nose&quot; and equations that hold only up to homotopy, or up to
isomorphism.  Sometimes you can &quot;strictify&quot; a gadget where
the equations hold only up to homotopy, and get them to hold on the
nose.  But sometimes you can't.

<P>
Once I was giving a talk about n-categories and Roger Penrose was
in the audience.  I said the most basic fact about n-categories was:

<P>
<div align = "center">
          &cong; &ne; =
</div>

<P>
He raised his hand and asked:

<P>
<div align = "center">
          &cong; &cong; = ?
</div>

<P>
Very good question!  And the answer is: sometimes yes, sometimes no.
This is where things get interesting!

<P>
So, it's a famous puzzle whether you can find some functorial way to 
turn a simplicial set S into a differential graded commutative algebra
A*(S) whose cohomology is the usual cohomology H*(S).  This is called the 
&quot;commutative cochain problem&quot;.

<P>
I haven't said it precisely enough yet, since there's a cheap and easy
way to solve the version I just stated: just A*(S) to be the cohomology
H*(S) itself, with d = 0.  What a dirty trick!

<P>
To rule out such tricks people demand various extra good properties.  
For example, the usual cochains C*(S) are &quot;extendible&quot;: any cochain
on a little simplicial set extends to a cochain on a bigger one.  
In other words, if 

<P>
S &rarr; T

<P>
is an inclusion of simplicial sets, then the corresponding map 

<P>
C*(T) &rarr; C*(S)

<P>
is onto.  This is definitely not true if we replace C* by H*.  

<P>
This paper gives a bit of history of the commutative cochains problem:

<P>
5) Bohumil Cenkl, Cohomology operations from higher products in the de
Rham complex, Pacific J. Math. 140 (1989), 21-33.  Available at
<a href = "http://projecteuclid.org/euclid.pjm/1102647247">http://projecteuclid.org/euclid.pjm/1102647247</a>

<P>
It gives a somewhat different statement of the problem, which alas I
don't understand, and it proves that this version has no solution if
we work over the integers.  But over the rationals it <em>does</em>, if we
take A*(S) to be the rational differential forms on our simplicial set
S.

<P>
Just so you don't think this is pie-in-the-sky stuff, I should
emphasize that this problem actually matters in electrical
engineering, where we might triangulate spacetime and study discrete
analogues of famous differential equations on the resulting simplicial
complex!  My friends Robert Kotiuga and Eric Forgy have thought about
this a lot.  

<P>
Here's a nice excerpt from the website of a
conference at Boston University.  I bet Robert Kotiuga wrote this.  It
mentions &quot;Whitney forms&quot;, which are simplex-wise linear
differential forms on a simplicial set.  These are closely related to
Sullivan's simplex-wise <i>polynomial</i> differential forms.

<P>
<blockquote>
    The analysis of electric circuits, using <a href = "http://en.wikipedia.org/wiki/Kirchhoff%27s_circuit_laws">Kirchhoff's Laws</a>, brought
   topology into electrical engineering over 150 years ago.  Hermann
   Weyl's reformulation of Kirchhoff's laws in terms of homology over
   80 years ago is an abstraction which is proving to be essential in
   the finite element analysis of three-dimensional electromagnetic
   fields.  It enables computers to be programmed to identify an
   electrical circuit in an electromagnetic field problem - a task once
   considered the domain of the engineer's intuition. In &quot;control
   theory&quot; parlance, circuit theory equations are low frequency model
   reductions of distributed parameter electromagnetic systems, and
   homology theory yields the key mathematical tools for obtaining robust
   numerical algorithms.  One aspect of the workshop will deal with
   large scale homology calculations and the realization of cycles
   representing generators of integral homology groups as embedded
   manifolds.  The underlying homology calculations involve large sparse
   integer matrices with remarkable structure even when the underlying
   finite element meshes are &quot;unstructured&quot;.  One aim of the workshop
   is to bring together those performing large scale homology
   calculations in the context of dynamical systems and point cloud
   data analysis, with those requiring more geometrical applications
   of homology groups in electromagnetics.

<P>
   Over two decades ago, boundary value problems arising in the
   analysis of quasistatic electromagnetic fields were reinterpreted
   in terms of Hodge theory on manifolds with boundary.  This observation
   is quite natural when Maxwell's equations are viewed in the context of
   differential forms and the problem of defining potentials is
   phrased in terms of de Rham cohomology.  This observation, along
   with the variational formulation of Hodge theory on manifolds with
   boundary, created a revolution in the finite element analysis of
   electromagnetic fields.  When phrased this way, the most difficult
   theoretical problems were actually solved in the 1950's by Andre Weil
   and Hassler Whitney who were concerned with problems in algebraic
   topology. They had an explicit interpolation formula for turning
   simplicial cochains into piecewise linear differential forms.  This
   formula gives a chain homotopy between the algebraic complexes
   involved, and an isomorphism of cohomology rings.  Although it took
   30 years for Whitney forms to impact engineering practice, once the
   genie was out of the bottle, there was no way to put it back in.
   In the early 1990s, Whitney form techniques solved the problem of
   &quot;spurious modes&quot; appearing in electromagnetic cavity resonator
   calculations and soon after became widely accepted as an essential
   tool which is only recently being appreciated in the context of
   nanophotonics.

<P>
   It is important to re-examine this Whitney form revolution in the
   context of recent attempts to develop &quot;discrete exterior
   calculus,&quot; &quot;mimetic discretizations,&quot;
   &quot;compatible discretizations&quot; etc. For example, in
   algebraic topology it is well known that simplicial cochains do not
   admit a graded-commutative, associative product analogous to the
   wedge product on differential forms. This classical result, known
   as &quot;the commutative cochain problem,&quot; is surprising and
   unintuitive in light of the fact that simplicial cochains admit a
   graded-commutative, associative product on the level of cohomology,
   analogous to the one induced by the wedge product in the de Rham
   complex. The bottom line is that these types of classical results
   are often ignored by newcomers trying to develop a discrete
   approach to calculus.  Obviously, there is still some important
   technology transfer to be performed between algebraic topology and
   numerical analysis!  Much of the mathematical work was done by
   Patodi, Dodziuk and Muller in the 1970's, has been exploited by
   electrical engineers, but has been largely ignored by applied
   mathematicians.  Although the multiplicative structure on
   differential forms does not seem to be very important in the
   context of linear boundary value problems, it seems to play an
   important role in magnetohydrodynamics.  Magnetohydrodynamics, in
   turn is an essential tool in space physics, in particular, in the
   growing field of space weather.
</blockquote>

<P>
So you see, everything is related.  The difference between equality
and isomorphism matters when you're trying to simulate the weather in
space!  That's the kind of thing that makes math so fun.  Here's the
conference webpage:

<P>
5) Advanced Computational Electromagnetics 2006 (ACE 'O6), Boston
University, <a href = "http://www.bu.edu/eng/ace2006/">http://www.bu.edu/eng/ace2006/</a>

<P>
You can learn more here:

<P>
6) P. W. Gross and P. Robert Kotiuga, Electromagnetic Theory and
Computation: A Topological Approach, Cambridge University Press,
2004. 

<P>
Someday my discussion of electrical circuits may expand to include
some algebraic topology.  But all I want to explain now is the usual
cup product on the cochains C*(S) for a simplicial set S.  We'll 
need this in the Weeks to come!

<P>
Actually, it'll be easier if I work with chains instead of cochains.
For us a chain complex will be a list of vector spaces and linear maps

<PRE>
     d       d      d
C<sub>0</sub> &lt;--- C<sub>1</sub> &lt;--- C<sub>2</sub> &lt;--- ...
</PRE>

with d<sup>2</sup> = 0.  We call the whole thing
C<sub><sub>*</sub></sub>, where now the star is a subscript.  I'll
show you the usual way to get a chain complex
C<sub><sub>*</sub></sub>(S) from a simplicial set, and then show you a
way to <em>comultiply</em> chains.  Then you can get the cochains by
taking duals:

<P>
C<sup>n</sup>(S) = C<sub>n</sub>(S)*

<P>
This will give a way to multiply chains.

<P>
Here's how it goes.  The idea is that we define the comultiplication
directly at the level of simplicial sets and then feed it through a
couple of functors.  There's a functor 

<P>
F: [simplicial sets] &rarr; [simplicial vector spaces]

<P>
and a functor

<P>
N: [simplicial vector spaces] &rarr; [chain complexes]

<P>
Composing these will give the chains C<sub><sub>*</sub></sub>(S) for a simplicial set S.

<P>
The first functor 

<P>
F: [simplicial sets] &rarr; [simplicial vector spaces]

<P>
creates the free simplicial vector space on a simplicial set.  
This functor is symmetric monoidal: it carries products of simplicial
spaces to tensor products of simplicial vector spaces.  The second
functor

<P>
N: [simplicial vector spaces] &rarr; [chain complexes]

<P>
is called the &quot;normalized chain complex&quot; or &quot;normalized Moore
complex&quot; functor.  This functor is an equivalence of categories! 
It's <em>almost</em> symmetric monoidal, but not quite, and this is 
where all the subtlety lies.

<P>
The category of simplicial sets has finite products.  So, every
simplicial set has a diagonal map:

<P>
&Delta;: S &rarr; S &times; S

<P>
It also a unique map to the simplicial set called 1, which 
consists of single 0-simplex:

<P>
&epsilon;: S &rarr; 1

<P>
These two maps satisfy the usual axioms of a commutative monoid,
written out as commutative diagrams, except with the arrows pointing
backwards.  So, S is a &quot;cocommutative comonoid&quot; in the category of
simplicial sets.  

<P>
Indeed, whenever you have any category with finite products, every
object in it becomes a cocommutative comonoid - and in a unique way!

<P>
So far, this is a completely bland fact of life.
If we feed our simplicial set S through the functor

<P>
F: [simplicial sets] &rarr; [simplicial vector spaces]

<P>
what happens?  Well, because this functor is monoidal it sends
comonoids to comonoids.  And because it's <em>symmetric</em> monoidal, it
sends <em>cocommutative</em> comonoids to <em>cocommutative</em> comonoids.  And a
cocommutative comonoid in simplicial vector spaces is the same as a
&quot;simplicial cocommutative coalgebra&quot;.  

<P>
(I love this kind of stuff, but not everyone does: that's why I
save it for the very end of each Week's Finds.)

<P>
So, we've turned our simplicial set S into a simplicial cocommutative
coalgebra F(S).  Now feed this gizmo into the next functor:

<P>
N: [simplicial vector spaces] &rarr; [chain complexes]

<P>
By definition, we get the chains on S:

<P>
N(F(S)) = C<sub><sub>*</sub></sub>(S)

<P>
And thanks to the wonders of functoriality, these chains are blessed
with a comultiplication

<P>
C<sub><sub>*</sub></sub>(&Delta;): C<sub><sub>*</sub></sub>(S) &rarr; C<sub><sub>*</sub></sub>(S) &otimes; C<sub><sub>*</sub></sub>(S)

<P>
and counit

<P>
C<sub><sub>*</sub></sub>(S) &rarr; Q

<P>
where Q is our ground field, the rationals.  

<P>
And <em>if</em> the functor N were also symmetric monoidal,
C<sub><sub>*</sub></sub>(S) would also be a cocommutative comonoid,
but now in the world of chain complexes.  In other words, it would be
a &quot;differential graded cocommutative coalgebra&quot;.  Then,
taking duals, the cochains C*(S) would be a DGCA!

<P>
But I warned you: things aren't quite so simple.  

<P>
I said the functor N is <em>almost</em> a symmetric monoidal functor.  But
not quite.  

<P>
For starters, it's a &quot;lax monoidal functor&quot;, which implies among other
things that there's a natural transformation

<P>
EZ: N(X) &otimes; N(Y) &rarr; N(X &otimes; Y)

<P>
This is called the Eilenberg-Zilber map.  The word &quot;lax&quot; means that
this map isn't necessarily an isomorphism.  A lax monoidal functor is
good enough to send monoids to monoids.  That's important - but it's
no use to us now, since we've got a comonoid on our hands!

<P>
On the other hand, N is also an &quot;oplax monoidal functor&quot;, which implies
among other things that there's a natural transformation going the other
way

<P>
AW: N(X &otimes; Y) &rarr; N(X) &otimes; N(Y)

<P>
This is called the Alexander-Whitney map.  The word &quot;oplax&quot; means that
this map isn't necessarily an isomorphism - but now it's going the
opposite way.  An oplax monoidal functor is good enough to send 
comonoids to comonoids.   Yay!

<P>
So, our cochains C<sub><sub>*</sub></sub>(S) do indeed form a comonoid in the world
of chain complexes - that is, &quot;differential graded coalgebra&quot;.

<P>
However, it's not cococommutative!  

<P>
To dig deeper into this, I'd need to draw lots of pictures or write
lots of formulas, and I don't feel in the mood for that.  So, I'll
just say what I hope you're thinking: the passage from simplicial
vector spaces to chain complexes is quite tricky.  

<P>
For example, it's sort of frustrating that we have these EZ and AW
maps going both ways, but they're not inverses!  In fact they come
very close.  Eilenberg-Zilber followed by Alexander-Whitney is the
identity on N(X) &otimes; N(Y).  Alas, Alexander-Whitney followed by
Eilenberg-Zilber is not the identity on N(X &otimes; Y).  But, it's chain
homotopic to the identity!

<P>
You can read more about the &quot;normalized Moore complex&quot; functor here:

<P>
7) nLab, Moore complex, available at 
<a href = "http://ncatlab.org/nlab/show/Moore+complex">http://ncatlab.org/nlab/show/Moore+complex</a>

<P>
The fact that it's an equivalence of categories is called the 
&quot;Dold-Kan correspondence&quot;.  You can read more about this here:

<P>
8) nLab, Dold-Kan correspondence, available at
<a href = "http://ncatlab.org/nlab/show/Dold-Kan+correspondence">http://ncatlab.org/nlab/show/Dold-Kan+correspondence</a>

<P>
And I should point out that while I've been working with vector spaces
over the rational numbers, everything I've said about the functors F 
and N generalize to R-modules for an arbitrary commutative ring R.  
So, we have

<P>
F: [simplicial sets] &rarr; [simplicial R-modules]

<P>
N: [simplicial R-modules] &rarr; [chain complexes of R-modules]

<P>
with all the good (or frustrating) properties that I just described.
The nLab pages focus somewhat on the case where R = Z, where we get

<P>
F: [simplicial sets] &rarr; [simplicial abelian groups]

<P>
N: [simplicial abelian groups] &rarr; [chain complexes of abelian groups]

<P>
This is indeed the most fundamental case.

<P>
Finally, what about that picture at the beginning?  If you're smirking 
just because you can guess what <em>planet</em> it was taken on, wipe that 
smile off your face!  If I showed you a picture of a city and asked 
you where it is, would you say &quot;Earth&quot;?

<P>
These pictures show linear dunes on the north polar region of Mars:
latitude 78 degrees north, longitude 209 degrees east.  

<P>
(Hmm, on Earth
there was a big battle between the British and French to say what
longitude counts as &quot;0 degrees&quot;.  How did it work on Mars?)

<P>
Anyway, according to Maria Banks:

<P>
<blockquote>
   This observation shows linear dunes in the north polar region of
   Mars.  Linear or longitudinal sand dunes are elongated, sharp
   crested ridges that are typically separated by a sand-free surrounding
   surface.

<P>
   These features form from bi-directional winds and extend parallel
   to the net wind direction. In this case, the net wind direction
   appears to be from the west-southwest.  Linear sand dunes are found
   in many different locations on Earth and commonly occur in long
   parallel chains with regular spacing.

<P>
   Superimposed on the surface of the linear dunes are smaller
   secondary dunes or ripples. This is commonly observed on
   terrestrial dunes of this size as well.  Polygons formed by
   networks of cracks cover the substrate between the linear dunes and
   may indicate that ice-rich permafrost (permanently frozen ground)
   is present or has been present geologically recently in this
   location.
</blockquote>

<P>
9) HiRISE (High Resolution Imaging Science Experiments), Linear dunes
in the north polar region, <a href = "http://hirise.lpl.arizona.edu/PSP_009739_2580">http://hirise.lpl.arizona.edu/PSP_009739_2580</a>

<p>
<HR><P>
<b>Addenda</b>: I thank Richard Lozes and Jonathan vos Post for
catching typos.  Jesse McKeown pointed out a NASA website that 
addresses my puzzle about how people settled on a definition of
longitude on Mars:

<P>
10) NASA, The Martian Prime Meridian - longitude zero,
<a href = "http://www.nasaimages.org/luna/servlet/detail/nasaNAS~4~4~16934~120671:The-Martian-Prime-Meridian----Longi">http://www.nasaimages.org/luna/servlet/detail/nasaNAS~4~4~16934~120671:The-Martian-Prime-Meridian----Longi</a>

<P>

<blockquote>

On Earth, the longitude of the Royal Observatory in Greenwich, England
is defined as the "prime meridian," or the zero point of
longitude. Locations on Earth are measured in degrees east or west
from this position. The prime meridian was defined by international
agreement in 1884 as the position of the large "transit circle," a
telescope in the Observatory's Meridian Building. The transit circle
was built by Sir George Biddell Airy, the 7th Astronomer Royal, in
1850.  (While visual observations with transits were the basis of
navigation until the space age, it is interesting to note that the
current definition of the prime meridian is in reference to orbiting
satellites and Very Long Baseline Interferometry (VLBI) measurements
of distant radio sources such as quasars. This "International
Reference Meridian" is now about 100 meters east of the Airy Transit
at Greenwich.) For Mars, the prime meridian was first defined by the
German astronomers W. Beer and J. H. M&auml;dler in 1830-32. They used
a small circular feature, which they designated "a," as a reference
point to determine the rotation period of the planet. The Italian
astronomer G. V. Schiaparelli, in his 1877 map of Mars, used this
feature as the zero point of longitude. It was subsequently named
Sinus Meridiani ("Middle Bay") by Camille Flammarion. When Mariner 9
mapped the planet at about 1 kilometer (0.62 mile) resolution in 1972,
an extensive "control net" of locations was computed by Merton Davies
of the RAND Corporation. Davies designated a 0.5-kilometer-wide crater
(0.3 miles wide), subsequently named "Airy-0" (within the large crater
Airy in Sinus Meridiani) as the longitude zero point. (Airy, of
course, was named to commemorate the builder of the Greenwich
transit.) This crater was imaged once by Mariner 9 (the 3rd picture
taken on its 533rd orbit, 533B03) and once by the Viking 1 orbiter in
1978 (the 46th image on that spacecraft's 746th orbit, 746A46), and
these two images were the basis of the Martian longitude system for
the rest of the 20th Century. The Mars Global Surveyor (MGS) Mars
Orbiter Camera (MOC) has attempted to take a picture of Airy-0 on
every close overflight since the beginning of the MGS mapping
mission. It is a measure of the difficulty of hitting such a small
target that nine attempts were required, since the spacecraft did not
pass directly over Airy-0 until almost the end of the MGS primary
mission, on orbit 8280 (January 13, 2001). In the left figure above,
the outlines of the Mariner 9, Viking, and Mars Global Surveyor images
are shown on a MOC wide angle context image, M23-00924. In the right
figure, sections of each of the three images showing the crater Airy-0
are presented. A is a piece of the Mariner 9 image, B is from the
Viking image, and C is from the MGS image. Airy-0 is the larger crater
toward the top-center in each frame. The MOC observations of Airy-0
not only provide a detailed geological close-up of this historic
reference feature, they will be used to improve our knowledge of the
locations of all features on Mars, which will in turn enable more
precise landings on the Red Planet by future spacecraft and explorers.

</blockquote>

<P>
For more discussion, visit the friendly and welcoming 
<a href = "http://golem.ph.utexas.edu/category/2010/01/this_weeks_finds_in_mathematic_49.html"><em>n</em>-Category Caf&eacute;</a>.

<p>
<HR><P>
<em>If you haven't found something strange during the day, it hasn't been
much of a day.</em> - John Wheeler


<p>
<HR><P>
<!-- BEGIN FOOTER -->
&#169; 2010  John Baez<br>
baez@math.removethis.ucr.andthis.edu <br>
<P>
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week287.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week289.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE><!-- END FOOTER -->
