<TITLE> week83 </TITLE>





<P>
I'll return to the tale of n-categories this week, and continue to explain
the mysteries of duals and inverses.  But first let me describe two new
papers by Connes. 

<P>
1) Alain Connes, Gravity coupled with matter and the foundation of
non-commutative geometry, preprint available as <A HREF = "http://xxx.lanl.gov/abs/hep-th/9603053">hep-th/9603053</A>.

<P>
Ali H. Chamseddine and Alain Connes, The spectral action principle, 
preprint available as <A HREF = "http://xxx.lanl.gov/abs/hep-th/9606001">hep-th/9606001</A>.

<P>
The second paper here fills in details that are missing from the first.
Hopefully lots of you know that Connes is the wizard of operator theory
who turned to inventing a new branch of geometry, &quot;noncommutative
geometry&quot;.  The idea of algebraic geometry is that we can study
a space by studying the functions on that space - which typically form
some kind of commutative algebra.  If we let the algebra become
noncommutative, it is no longer functions on some space, but we can pretend
it is nonetheless, and do geometry by analogy with the commutative case.
This is very much based on the philosophy of quantum mechanics, where
the observables form a noncommutative algebra, yet are analogous to the
commutative algebras of observables of classical mechanics, these
commutative algebras consisting simply of functions on the classical space
states.   

<P>
In quantum mechanics, the failure of two observables to commute implies
that they cannot always be simultaneously measured with arbitrary
accuracy; there is a very precise mathematical statement of Heisenberg's
uncertainty principle that makes this quantitative.  We can thus think
of noncommutative geometry as &quot;quantum geometry&quot;, geometry where the
uncertainty principle of quantum mechanics has infected the very notion
of space itself!  In noncommutative geometry it impossible to
simultaneously measure all the coordinates of a point with arbitrary
accuracy, because they do not commute!

<P>
For the definitive introduction to noncommutative geometry, see Connes'
book &quot;Noncommutative Geometry&quot;, reviewed in &quot;<A HREF = "week39.html">week39</A>&quot;.  Already in this
book Connes, working with Lott, was beginning to explore the idea that
the geometry of our physical universe is noncommutative.  Actually, they
used ideas from noncommutative geometry to study a weird kind of
commutative geometry in which spacetime is &quot;two-sheeted&quot; - two copies
of standard 4-dimensional spacetime, very close together.  In normal
geometry it doesn't even make sense to speak of two separate copies of
spacetime being &quot;close together&quot;, since there is no way to get from one
to the other!  Tricks from noncommutative geometry allow it to make
sense.  They found something amazing: if you do U(1) x SU(2) Yang-Mills
theory on this spacetime, you get the Higgs particle for free!  

<P>
Sorry for the jargon.  What it means is this: in the Standard Model of
particle physics we describe the electromagnetic force and the weak
nuclear force in a unified way using a theory called &quot;U(1) x SU(2)
Yang-Mills theory&quot;, but then we postulate an extra particle, the Higgs
particle, which has the effect of making the electromagnetic force work
quite differently from the weak force.  We say it &quot;breaks the symmetry&quot;
between the two forces.  It has not yet been observed, though particle
physicists hope to see it (or not!) in experiments coming up fairly
soon.  It is a rather puzzling, ad hoc element of the Standard Model.
The amazing thing about the Connes-Lott model is that it arises in a
natural way from the fact that spacetime has two sheets.

<P>
Connes and Lott also studied the strong force, but now Connes has
introduced gravity into his model.  I haven't had time to absorb this
new work yet, so let me simply say what his current model of spacetime
is, and list some of the concrete predictions the new theory makes.  
His spacetime is the noncommutative algebra consisting of smooth functions
on good old 4-dimensional Minkowski spacetime, taking values in the
algebra A given by the direct sum

<P>
                   A = C + H + M_3(C)

<P>
where C is the complex numbers, H is the quaternions, and M_3(C) is the
3x3 complex matrices.  (Exercise: redo Connes' model, replacing M_3(C)
with the octonions.  Hint: develop nonassociative geometry and use
Geoffrey Dixon's theory relating the electromagnetic, weak, and strong
forces to the complex numbers, quaternions, and octonions, respectively.
See &quot;<A HREF = "week59.html">week59</A>&quot; for references to Dixon's work, and an explanation of
quaternions and octonions.)

<P>
The Chamseddine-Connes model predicts that the sine squared of the
Weinberg angle - an important constant in the theory of the
electroweak force - is between .206 and .210.  Unfortunately this
disagrees with the experimental value of .2325, but it's sort of
surprising that they can derive something this close, since in the
Standard Model the Weinberg is just an arbitrary parameter.  They also
derive a Higgs mass of 160-180 GeV, and expect accuracy comparable to
their prediction of the Weinberg angle (about 10%).  

<P>
Well worth pondering!

<P>
<HR>

<P>
<A NAME = "tale">
There is an interesting analogy between the dual of a vector space and
the inverse of a number which I would like to explain now.  I assume you
know that multiplying numbers is a lot like tensoring vector spaces.
For example, just as multiplication distributes over addition, tensoring
distributes over direct sums.  Also, just as there is a number called 1
which is the unit for multiplication, there is a 1-dimensional vector
space, the ground field itself, which is the unit for tensoring.  Let me
take the unusual liberty of writing tensor products by juxtaposition, so
that xy is the tensor product of the vector space x and the vector space
y, and let me call the 1-dimensional vector space that's the unit for
tensoring simply &quot;1&quot;.

<P>
Now, if a number x has an inverse y, we have

<P>
                     yx = 1

<P>
and 

<P>
                     1 = xy.

<P>
Similarly, if a vector space x has a dual y, we have linear maps

<P>
                     e: yx &rarr; 1

<P>
and

<P>
                     i: 1 &rarr; xy

<P>
What are these linear maps?  Well, the whole point of the dual vector
space y is that a vector in y is a linear functional from x to 1.
This &quot;dual pairing&quot; between vectors in y and those in x defines a
linear map e: yx &rarr; 1, often called the &quot;counit&quot;.  On the 
other hand,
the space xy can be thought of as the space of linear transformations of
x.  The linear map i: 1 &rarr; xy sends any scalar (i.e., any vector in 1)
to the corresponding scalar multiple of the identity transformation of
x.

<P>
So we see that dual vector spaces are a bit like inverse numbers, except
that we don't have yx = 1 and 1 = xy, and we don't even have that yx is
<em>isomorphic</em> to 1 and 1 is <em>isomorphic</em> 
to xy.  We just have some maps
going from yx to 1, and from 1 to xy.  

<P>
These maps satisfy two equations, though.  Here's the first.  We start
with x, use the obvious isomorphism to map to 1x, then use i: 1 &rarr; xy to
map this to xyx, then use e: yx &rarr; 1 to map this to x1, and then use the
other obvious isomorphism to map back to x.  This composite of maps
should be the identity on x.  What this says is that the identity linear
transformation of x really acts as the identity!

<P>
Stealing a trick from &quot;<A HREF = "week79.html">week79</A>&quot;, we can draw this as follows.  Draw the
counit e: yx &rarr; 1 as follows:

<PRE>
                 y      x
                  \    /
                   \  / 
                    \/

</PRE>
and draw the unit i: 1 &rarr; xy as follows:

<PRE>
                   /\
                  /  \
                 /    \
                x      y

</PRE>
Then the above equation says that
                   
<PRE>
                   x       x
          /\       |       |
         /  \      |       |
        /    \     |       |
      x|     y\   x/   =   | 
       |       \  /        |
       |        \/         |
       x                   x

</PRE>
Here the left side, which we read from top to bottom, corresponds to the
composite x &rarr; 1x &rarr; xyx &rarr; x1 &rarr; x.  
(The factors of 1 are invisible in the
picture, since they don't do much.)  The left side corresponds to the
identity map x &rarr; x.  

<P>
The second equation goes like this.  We start with y, use the obvious
isomorphism to map to y1, then use the unit to map this to yxy, then use
the counit to map this to 1y, and then use the other obvious isomorphism
to map back to y.  This composite should be the identity on y.  What
this says is that the identity linear transformation of x also acts
dually as the identity on y!   We can draw this as follows:

<PRE>
       y                   y
       |       /\          |
       |      /  \         |
       |     /    \        |
      y\   x/     y|  =    | 
        \  /       |       |
         \/        |       |
                   y       y


</PRE>
If you now steal a peek at &quot;<A HREF = "week79.html">week79</A>&quot;, you'll see that these two equations
are just the same equations used to define adjoint functors in category
theory!  What's going on?  Well, dual vector spaces are analogous to
adjoint functors, clearly.  But more deeply, what we have is an analogy
between duals in any category with tensor products - or &quot;monoidal
category&quot; - and adjoints in any 2-category.

<P>
What's a monoidal category, exactly?  Roughly it's a category with some
sort of &quot;tensor product&quot; and &quot;unit object&quot;.  But we can precisely define
the so-called &quot;strict&quot; monoidal categories as follows: they are simply
2-categories with one object.  (Turn to &quot;<A HREF = "week80.html">week80</A>&quot; for a definition of
2-categories.)   A 2-category has objects, morphisms, and 2-morphisms,
but if there is only one object, we can do the following relabelling
trick: 

<PRE>
             2-morphisms    -------->   morphisms
             morphisms      -------->   objects
             object         -------->   
</PRE>

Namely, we can forget about the object, call the morphisms
&quot;objects&quot;, and call the 2-morphisms &quot;morphisms&quot;.
But since all the new &quot;objects&quot; were really morphisms from the
original single object to itself, they can all be composed, or
&quot;tensored&quot;.  That's why we get a category with &quot;tensor
product&quot;, and similarly, a &quot;unit object&quot;.

<P>
So, just as a category with one object is just a monoid, a 2-category
with one object is a monoidal category!  This is one instance of a trick
that I sketched many more cases of in &quot;<A HREF = "week74.html">week74</A>&quot;.

<P>
Now, in &quot;<A HREF = "week79.html">week79</A>&quot; I defined left and right adjoints of functors between
categories.  Here the only thing I really needed about category
theory was that Cat is a 2-category with categories as its objects,
functors as its morphisms, and natural transformations as its
2-morphisms.  So we can define left and right adjoints of morphisms in
any 2-category by analogy as follows:

<P>
Suppose a and b are objects in a 2-category.  Then we say that the morphism

<P>
L: a &rarr; b

<P>
is a &quot;left adjoint&quot; of the morphism

<P>
R: b &rarr; a

<P>
(and R is a &quot;right adjoint&quot; of L) if there are 2-morphisms

<P>
e: RL =&gt; 1<sub>b</sub>

<P>
i: 1<sub>a</sub> =&gt; LR

<P>
satisfying two magic equations.  If we draw e and i as we did above, 

<PRE>
                 R      L
                  \    /
        e          \  / 
                    \/


                    /\
        i          /  \
                  /    \
                 L      R

</PRE>
then the two magic equations are

                  
<PRE>
                   L       L
          /\       |       |
         /  \      |       |
        /    \     |       |
      L|     R\   L/   =   | 
       |       \  /        |
       |        \/         |
       L                   L


</PRE>
and

<PRE>
       R                   R
       |       /\          |
       |      /  \         |
       |     /    \        |
      R\   L/     R|  =    | 
        \  /       |       |
         \/        |       |
                   R       R


</PRE>
Alternatively, we can state these equations using the 2-categorical
notation described in &quot;<A HREF = "week80.html">week80</A>&quot;, by saying that the following vertical
composites of 2-morphisms are identity morphisms:

<PRE>
           i.1<sub>L</sub>       1<sub>L</sub>.e
L = 1<sub>a</sub> L ======> LRL ======> L 1<sub>a</sub> = L

</PRE>
and
<PRE>
           1<sub>R</sub>.i       e.1<sub>R</sub>
R = R 1<sub>a</sub> ======> RLR ======> 1<sub>b</sub> R = R

</PRE>
where . denotes the horizontal composite.  If you look at these, and
compare them to the graphical notation above, you'll see they are really
saying the same thing.

<P>
The punchline is, when our 2-category has one object, we can think of it
as a monoidal category, and then these equations are the definition of
&quot;duals&quot; - one example being our earlier definition of dual vector
spaces in the monoidal category Vect of vector spaces!

<P>
So adjoint functors and dual vector spaces are both instances of 
the general notion of adjoint 1-morphisms in a 2-category.  Adjointness
is a very basic concept.

<P>
I hope all that made some sense.  

<P>
If this category theory stuff seems confusing, maybe you should read a
3-volume book about it!  I can see you smiling, but seriously, I find
the following reference very useful (despite a certain number of
annoying errors).  You can find a lot of good stuff about adjoint
functors, monoidal categories, and much much more in here:

<P>
2) Francis Borceux, Handbook of Categorical Algebra, Cambridge U. Press
1994.  Volume 1: Basic Category Theory.  Volume 2: Categories and
Structure.  Volume 3: Categories of Sheaves.  




<P>
<A HREF = "week84.html#tale">To continue reading the `Tale of
n-Categories', click here.</A>

<P>


<P>
<P>
<HR>
<P>

