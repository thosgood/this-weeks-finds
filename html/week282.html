<TITLE> week282 </TITLE>

<!-- BEGIN HEADER -->
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week281.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week283.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE>
<H4> October 29, 2009 </H4>
<H2> This Week's Finds in Mathematical Physics (Week 282) </H2>
<H4> John Baez </H4>
<!-- END HEADER -->



<P>
This week I'll get back to explaining some serious math: the relation
between associative, commutative, Lie and Poisson algebras, and how
this relates to quantization.  There's some beautiful algebra and
combinatorics that shows up here: linear operads, their generating
functions, and Stirling numbers of the first kind.

<P> 
But first: the astronomy picture of the week!  Lately we've been
exploring the moons of Saturn - first Enceladus in &quot;<a href =
"week272.html">week272</A>&quot; and &quot;<a href =
"week273.html">week273</A>&quot;, and then Phoebe and Iapetus in
&quot;<a href = "week281.html">week281</A>&quot;.  Someday we should
talk about Rhea - a moon of Saturn with its own rings.  But first
let's take a big detour and sail in to Mercury.

<P>
In fact, the Messenger probe sailed in to Mercury starting on
August 3, 2004.  It's flown past this planet several times, and
in March 2011 it's scheduled to orbit Mercury for a whole year.
It's already taken some detailed photos:

<p>
<div align = "center">
<a href = "http://messenger.jhuapl.edu/gallery/sciencePhotos/image.php?gallery_id=2&image_id=355">
<img width = "400" src = "mercury_lava_floods.jpg">
</a>
</div>
<p>

<P>
1) Messenger, Image gallery,
<a href = "http://messenger.jhuapl.edu/gallery/sciencePhotos/">http://messenger.jhuapl.edu/gallery/sciencePhotos/</a>

<P>
Superficially Mercury looks like the Moon, and thus not very exciting.
But it's actually very different.  First of all, parts of Mercury get
really hot: about 430 Celsius near the equator during the day -
considerably above the melting point of lead.  Second, permanently
shaded regions near the poles are not only cold, they actually have
lots of ice!  Third, Mercury had a violent past.  For example,
the Caloris basin on Mercury is one of the solar system's largest
impact basins.  Formed by a huge asteroid impact long ago, it's about
1,500 kilometers across:

<p>
<div align = "center">
<a href = "http://science.nasa.gov/headlines/y2008/03jul_mercuryupdate.htm">
<img src = "mercury_caloris_basin.jpg">
</a>
<font size = "-1"><br/>
Caloris basin shown in yellow in false color image.<br/>
Orange hues just inside the basin's rim are features thought 
to be volcanic.
</font>
</div>

<p>

<P>
2) NASA, New discoveries at Mercury, August 3, 2008.
<a href = "http://science.nasa.gov/headlines/y2008/03jul_mercuryupdate.htm">http://science.nasa.gov/headlines/y2008/03jul_mercuryupdate.htm</a>

<P>
Fourth, Mercury is the densest planet, with the highest percentage of
iron.  Why is this?  There are various theories.  The most widely
accepted is reminiscent of the &quot;giant impact theory&quot; for
how our Moon formed (see &quot;<a href =
"week273.html">week273</A>&quot;).  It goes like this.  Once upon a
time Mercury was over twice the size it is now, with a more ordinary
chemical composition.  Then it was hit by another body about 1/6 its
own mass!  This stripped off a lot of its crust and mantle, leaving a
smaller Mercury, whose iron core now accounts for a greater percentage
of its mass.

<P>
Fifth, and a direct consequence of the previous point, Mercury has a
strong magnetic field - like Earth, and unlike Venus, Mars, or our
Moon.  And this brings me to the picture I really want you to stare
at: a diagram of how Mercury's magnetic field interacts with the solar
wind, which is very powerful so near the Sun.  The Messenger probe
learned a lot about this when it flew past Mercury on October 6th,
2008:

<p>
<div align = "center">
<a href = "http://www.nasa.gov/mission_pages/messenger/multimedia/magnetic_tornadoes.html">
<img border = "none"; src = "mercury_magnetic_field.jpg">
</a>
</div>

<P>
3) NASA, Magnetic tornadoes could liberate Mercury's tenuous atmosphere,
<a href = "http://www.nasa.gov/mission_pages/messenger/multimedia/magnetic_tornadoes.html">http://www.nasa.gov/mission_pages/messenger/multimedia/magnetic_tornadoes.html</a>

<P>
The pink stuff in this picture is the &quot;magnetopause&quot; - the
zone where the solar wind crashes into Mercury's magnetic field.  And
see the spirals?  These are &quot;flux transfer events&quot;.  Every
so often, the solar magnetic field lines reconnect with those of
Mercury and ions in the solar wind penetrate the magnetopause and rain
down on Mercury's north and south poles.  Similar flux transfer events
happen here on Earth about every 8 minutes:

<P>
4) NASA, Magnetic portals connect Sun and Earth, October 30, 2008.
<a href = "http://science.nasa.gov/headlines/y2008/30oct_ftes.htm?list179029">http://science.nasa.gov/headlines/y2008/30oct_ftes.htm?list179029</a>

<P>
The physics is complex and just starting to be understood: the basic
equations governing the interaction of plasma (that is, ionized gas)
and electromagnetism are devilishly nonlinear and hard to deal with.
This is one reason fusion reactors that use magnetic confinement are
so hard to develop.  In particular, there's been a lot of recent work
on &quot;reconnection&quot;, where magnetic fields pointing in
opposite directions cross-link and accelerate plasma in a
&quot;magnetic slingshot&quot;.  Here's a great article on that
subject:

<P>
5) James L. Burch and James F. Drake, Reconnecting magnetic fields,
American Scientist 97 (2009), 392-399.  Also available at
<a href = "http://mms.space.swri.edu/AmSci-Reconnection.pdf">http://mms.space.swri.edu/AmSci-Reconnection.pdf</a>

<P>
Finally: do you see the yellow &quot;plasmoid&quot; in
the picture above?  That's a coherent blob of plasma and magnetic
field which forms in the the long &quot;magnetotail&quot; behind
Mercury.  Again, these also form near the Earth.  And again, they're
complex and mathematically interesting.  So, while Mercury may look
dead and boring, it's rich in activity if you know where to look!

<P>
Next, some math.

<P>
Today I'd like to talk about 4 of my favorite kinds of algebras:
associative algebras, commutative algebras, Lie algebras and Poisson
algebras.  They're all important in quantum mechanics and quantization,
and they fit together in a very nice way.  There's a lot to say about
this, but I just want to explain one thing: how the relation between
these 4 kinds of algebras gives a pretty pattern involving Stirling
numbers.

<P>
If you don't know what Stirling numbers are, don't worry!  They'll
show up on their own accord, and then we'll see why.

<P>
First: the four kinds of algebra.  Let's review them. 

<P>
An &quot;associative algebra&quot; is a vector space equipped with an
identity element 1 and a binary operation called multiplication that's
linear in each argument.  We demand that these obey a few rules:

<P>
1x = x<br/>
x1 = x<br/>
(xy)z = x(yz)

<P>
In physics, associative algebras often show up as &quot;algebras of
observables&quot; - their elements are things you can measure about a
physical system.

<P>
A &quot;commutative algebra&quot; is an associative algebra that obeys
one extra rule:

<P>
xy = yx

<P>
In classical mechanics, the algebras of observables are always
commutative.  The big deal about quantum mechanics is that we drop
this rule and allow more general associative algebras.  This wreaks
havoc on our intuitions about physics, but in a very nice way.

<P>
A &quot;Lie algebra&quot; is a vector space with a &quot;bracket&quot;
operation which is linear in each argument.  We demand that this obeys
two rules:

<P>
[x,y] = -[y,x]<br/>
[x,[y,z]] = [[x,y],z] + [y,[x,z]]

<P>
These rules seem a lot scarier than the rules above - at least when
you first meet them!  The reason is that while ordinary numbers form
an associative and even commutative algebra, they don't form a Lie
algebra in any interesting way.  Sure, you can define [x,y] = 0, and
it works, but it's dull.  The first nontrivial Lie algebra we meet in
school may be the space of vectors in 3d space, where the bracket is
the cross product.  But most students don't even remember that the
cross product satisfies the second rule above - the so-called
&quot;Jacobi identity&quot;.  So to get comfortable with Lie algebras,
most people need to start with an associative algebra that's not
commutative, and then define the bracket by:

<P>
[x,y] = xy - yx

<P>
This is called the &quot;commutator&quot;, and it's very important in
quantum mechanics, in part because it tells you how far things are
from being classical.  In classical mechanics, the commutators are
zero!

<P>
There's also a deeper and more important reason why commutators and
Lie algebras are important in quantum theory: they show up when we
study <i>symmetries</i> of physical systems.  But that's another story,
tangential to today's tale.

<P>
Anyway, it's fun - or at least good for your moral development - to
check that the associative law for multiplication implies the Jacobi
identity when we define the bracket by [x,y] = xy - yx.

<P>
So, we've got a recipe for turning an associative algebra into a Lie
algebra.  We've also seen a pathetically easy recipe for turning a
commutative algebra into an associative one: just forget that it's
commutative!  

<P>
In the language of category theory, both these recipes are called
&quot;forgetful functors&quot;, because they lose information.  So,
we've got forgetful functors

<P>
CommAlg &rarr; AssocAlg &rarr; LieAlg

<P>
and this little diagram is the crux of our tale.  

<P>
But to see why, I need to introduce the fourth character: Poisson
algebras.  The idea here is to realize that classical mechanics isn't
really true: the world is quantum mechanical.  So, even when we think
our algebra of observables is commutative, it's probably not.  This is
probably just an approximation.  It's not really true that the
commutator [x,y] is zero.  Instead, it's just tiny.

<P>
How do we formalize this?  Well, in reality [x,y] is often
proportional to a tiny constant called Planck's constant, h.  
When this happens, we can write

<P>
[x,y] = h{x,y}

<P>
where {x,y} is some other element of our associative algebra.  

<P>
Mathematically, it's more convenient to treat h as a variable than
as a fixed number. 
So, let's suppose we have an associative algebra A with a special
element h that commutes with everything.  
And let's suppose that A is
equipped with a new bracket operation {x,y} that satisfies the above
equation.

<P>
Then let's consider the algebra A/hA, which we define by taking A and
imposing the relation h = 0.  This amounts to neglecting quantum
effects, so A/hA is called the &quot;classical limit&quot; of our original
algebra A.  

<P>
What is this new algebra like?

<P>
Well, first of all, it's associative.  Second, it's commutative, since
[x,y] was proportional to h, but now we're setting h equal to zero.
And third, it inherits from A a bracket operation {x,y}, called the
&quot;Poisson bracket&quot;.

<P>
What rules does the Poisson bracket satisfy?  Well, since 

<P>
[x,y] = -[y,x]

<P>
we know that

<P>
h{x,y} = -h{y,x}

<P>
in A.  So it seems plausible that

<P>
{x,y} = -{y,x}

<P>
in A/hA.  Unfortunately I can't derive this from my meager assumptions
thus far, since I'm not allowed to divide by h.  So let me also assume
that multiplication by h is one-to-one in A.  Then I know

<P>
{x,y} = -{y,x}

<P>
in A and thus also in A/hA.

<P>
Similarly, from the Jacobi identity for the commutator

<P>
[x,[y,z]] = [[x,y],z] + [y,[x,z]]

<P>
we know that

<P>
{x,{y,z}} = {{x,y},z} + {y,{x,z}}

<P>
in A, and thus also in A/hA.  The same sort of argument also shows
that {x,y} is linear in each argument.

<P>
There's one more rule, too!  Note that in A we have

<P>
[x,yz] = xyz - yzx <br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
       = xyz - yxz + yxz - yzx<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
       = [x,y]z + y[x,z]

<P>
and thus

<P>
{x,yz} = {x,y}z + y{x,z}

<P>
So, this rule holds in A/hA too.  This rule says that the operation
&quot;bracketing with x&quot; obeys the product rule, just like a
derivative.

<P>
And so, we've been led to the definition of a Poisson algebra!  It's a
commutative algebra with an extra operation, the Poisson bracket,
which is linear in each argument and obeys these rules:

<P>
{x,y} = -{y,x}  <br/>
{x,{y,z}} = {{x,y},z} + {y,{x,z}} <br/>
{x,yz} = {x,y}z + y{x,z}<br/>

<P>
Physically, the idea here is that the Poisson bracket is the extra
structure that we get from the fact that classical mechanics arises
from quantum mechanics by neglecting quantities proportional to
Planck's constant.

<P>
Mathematically, the idea is that a Poisson algebra is both a
commutative algebra and a Lie algebra (with the Poisson bracket as its
bracket), obeying the compatibility condition

<P>
{x,yz} = {x,y}z + y{x,z}

<P>
So, besides the forgetful functors I've already drawn, we have two
more:

<P>
PoissonAlg &rarr; CommAlg

<P>
and 

<P>
PoissonAlg &rarr; LieAlg

<P>
But you'll notice that in my above argument I got ahold of the Poisson
algebra axioms starting from an <i>associative</i> algebra of a
special sort: roughly, one that's &quot;noncommutative, but only up to
terms of order h&quot;.  This suggests that Poisson algebras are a
halfway house between associative and commutative algebras.  And I'd
like to make this more precise!

<P>
Technically, these special associative algebras are called
&quot;deformations&quot; of commutative algebras.  And there's a whole
branch of mathematical physics called &quot;deformation
quantization&quot; that studies them.  So, some experts reading the
previous paragraph may think I'm about to explain deformation
quantization.  But much as I'd love to talk about that, I won't now!
That theme will have to remain lurking in the background.

<P>
Instead, I just want to show how the concept of Poisson algebra
emerges from the forgetful functor

<P>
CommAlg &rarr; AssocAlg

<P>
And to do this, I'll need operads.  I explained these back in &quot;<a
href = "week191.html">week191</A>&quot;, so if the word
&quot;operad&quot; fills you with bewilderment or terror instead of
delight, please reread that.  But today I'll be using linear operads,
so let me explain those.

<P>
The concepts of associative algebra and commutative algebra and Lie
algebra and Poisson algebra have a lot in common.  In every case we
start with a vector space and equip it with a bunch of n-ary
operations that are linear in each argument.  Moreover, these
operations are required to satisfy equations where each variable shows
up exactly once in each term, like

<P>
{x,{y,z}} = {{x,y},z} + {y,{x,z}}

<P>
or 

<P>
{x,yz} = {x,y}z + y{x,z}

<P>
And this is precisely what linear operads are designed to handle!

<P>
More precisely, a linear operad O consists of a vector space O<sub>n</sub> for
each natural number n.  We call this the space of "n-ary operations".
They're not operations <i>on</i> anything yet - they're just
&quot;abstract&quot; operations, with names like
&quot;multiplication&quot; or &quot;Poisson bracket&quot;.  We can
draw an n-ary operation as a little black box with n wires coming in
and one coming out:

<PRE>
                  \    |    /
                   \   |   / 
                    \  |  /
                     -----
                    |     | 
                     -----
                       |
                       |
</PRE>
We're allowed to compose these operations in a tree-like fashion:

<PRE>
         \    /     \  |  /       | 
          \  /       \ | /        |
          -----      -----      -----
         |     |    |     |    |     |
          -----      -----      -----
              \        |        /  
               \       |       /
                \      |      /
                 \     |     /
                  \    |    / 
                   \   |   /  
                    \  |  /
                     -----
                    |     | 
                     -----
                       |
                       |
</PRE>

Here we are feeding the outputs of n operations
g<sub>1</sub>,..,g<sub>n</sub> into the inputs of an n-ary operation
f, obtaining a new operation which we call

<P>
f o (g<sub>1</sub>,...,g<sub>n</sub>)

<P>
Since we're doing <i>linear</i> operads todqay, we demand that this
composition operation be linear in each argument.  Moreover we demand
that there be a unary operation serving as the identity for
composition, and we impose an &quot;associative law&quot; that makes a
composite of composites like this well-defined:

<PRE>
              \    /   |  \  |  /   \     / 
               \  /    |   \ | /     \   / 
                ---   ---   ---       ---
               |   | |   | |   |     |   |
                ---   ---   ---       ---
                   \   |   /          /
                    \  |  /          / 
                     \ | /          / 
          -----      -----      -----
         |     |    |     |    |     |
          -----      -----      -----
              \        |        /  
               \       |       /   
                \      |      /
                 \     |     / 
                  \    |    / 
                   \   |   /   
                    \  |  /
                     -----
                    |     | 
                     -----
                       |
                       |
</PRE>
(This picture has a 0-ary operation in it, just to emphasize that this
is allowed.)  Furthermore, we can permute the inputs of an n-ary
operation and get a new operation:
                      
<PRE>
                      \ /   /
                       /   /
                      / \ /    
                     /   /   
                    /   / \
                    \  |  /
                     -----
                    |     | 
                     -----
                       |
                       |
</PRE>

We demand that this give an action of the permutation group on the
O<sub>n</sub>.  And finally, we demand that these permutation group
actions be compatible with composition in two ways.

<P>
The first way is easy to draw:

<PRE>
       \  |  /   |   \   /               \\\ /   / /
        \ | /    |    \ /                 \\/   / /
         ---    ---   ---                  /\\ / /
        | a |  | b | | c |                / \\/ /
         ---    ---   ---                /   / /
           \     /   /                  /   / /\\
            \   /   /                  /   | | \\\  
             \ /   /                  /    | |  \\\
              /   /                  ---   ---   ---
             / \ /           =      | b | | c | | a |
            /   /                    ---   ---   ---
           /   / \                      \   |   /
           \  |  /                       \  |  /
            -----                         -----
           |  d  |                       |  d  | 
            -----                         -----
              |                             |
              |                             |
</PRE>
We can permute the wires leading into d and then compose it with the
operations a,b,c, or compose them in a different order and then
permute the wires.  

<P>
The second way is harder to draw, because both sides of the equation
look exactly the same!  For example:

<PRE>
  \    /   |  |    \ /  
   \  /    |  |     / 
     /     |  |    / \ 
    / \    |  |   /   \
    \  |  /   |   \   /    
     \ | /    |    \ /    
      ---    ---   ---   
     | a |  | b | | c | 
      ---    ---   --- 
         \    |    /
          \   |   /  
           \  |  / 
            ----- 
           |  d  |  
            -----  
              |   
              |  
</PRE>
Here we can either compose the operations a,b,c with d and then
permute the wires leading into the result, or apply permutations to
the wires leading into a,b, and c and then compose the resulting
operations with d.  We get the same answer either way, and indeed
the pictures look exactly the same.

<P>
We use operads to describe algebras.  An &quot;algebra&quot; for a
linear operad O is a vector space V together with maps that turn
elements of O<sub>n</sub> into n-ary operations on V that are linear
in each argument.  If you like representations of groups you might
prefer to call this a &quot;representation&quot; of O on V, since the
idea is that elements of O<sub>n</sub> are getting represented as
actual operations on the vector space V.  Of course we demand that
composing operations in O and permuting their arguments get along with
this process.

<P>
Let's look at 4 examples.

<P>
First, there's an operad Assoc, whose algebras are associative
algebras.  This operad is generated by one binary operation, called
multiplication, and one nullary operation, called 1.  We'll write
these as if they were actual functions, though it's is not really true
until we choose an algebra for this operad.  So, we'll write them as

<P>
(x,y) |&rarr; xy

<P>
and

<P>
() |&rarr; 1

<P>
The second operation looks funny: it's a &quot;nullary
operation&quot;, one that takes no inputs.  A nullary operation is
also known as a &quot;constant&quot;, because its output doesn't
depend on anything.

<P>
Starting from these two operations we can generate lots more by
composition and taking linear combinations.  Then we impose some
relations.  First we impose one saying that these two ternary
operations are equal:

<P>
(x,y,z) |&rarr; (xy)z

<P>
and

<P>
(x,y,z) |&rarr; x(yz)

<P>
I can say this faster, as follows:

<P>
(xy)z = x(yz)

<P>
But remember: now I'm not talking about the associative law in any
<i>particular</i> algebra - I'm talking about an equation that holds
in the operad Assoc, and thus in <i>every</i> algebra of this operad.
We also also impose these laws:

<P>
1x = x</br>
x1 = x

<P>
This completes our &quot;generators and relations&quot; description of
the linear operad Assoc.  We could also describe it by saying what all
the n-ary operations are, and how to compose them.  Either way, it's
clear that the dimension of the space of n-ary operations is n
factorial:

<P>
dim(Assoc<sub>n</sub>) = n!

<P>
For example, here's a basis of the space of 3-ary operations:

<P>
(x,y,z) |&rarr; xyz<br/>
(x,y,z) |&rarr; xzy<br/>
(x,y,z) |&rarr; yxz<br/>
(x,y,z) |&rarr; yzx<br/>
(x,y,z) |&rarr; zxy<br/>
(x,y,z) |&rarr; zyx

<P>
Second, there's an operad Comm, whose algebras are commutative
algebras.  This is just like Assoc except we impose one extra
relation:

<P>
xy = yx

<P>
As a result, all the ways of multiplying n things in different orders
become equal, and we get

<P>
dim(Comm<sub>n</sub>) = 1

<P>
Third, there's an operad Lie, whose algebras are Lie algebras.
This is generated by one binary operation

<P>
(x,y) |&rarr; [x,y]

<P>
satisfying the relations

<P>
[x,y] = -[y,x] <br/>
[x,[y,z]] = [[x,y],z] + [y,[x,z]]

<P>
It's harder to work out the dimension of the space of n-ary operations
in the Lie operad, but the answer is beautiful:

<P>
dim(Lie<sub>n</sub>) = (n-1)!

<P>
Why is this true?  I'll give a proof later on! 

<P>
Fourth, there's an operad Poisson, whose algebras are Poisson
algebras.  This is generated by two binary operations and one nullary
operation:

<P>
(x,y) |&rarr; xy

<P>
(x,y) |&rarr; {x,y}

<P>
() |&rarr; 1

<P>
which obey the relations we've already seen: the commutative algebra
relations for xy, the Lie algebra relations for [x,y], and the product
rule

<P>
{x,yz} = {x,y}z + y{x,z}

<P>
What's the dimension of the space of n-ary operations now?  I'll leave
this as puzzle.  It will be very easy if you pay close attention to
what I'm saying.

<P>
Okay.  Now, you'll notice that we got the operad Comm from the operad
Assoc by adding an extra relation.  So, every operation in Assoc maps
to one in Comm.  This map is linear, and it preserves composition.
So, we say there's a homomorphism of linear operads

<P>
Assoc &rarr; Comm

<P>
Quite generally, whenever we have an operad homomorphism 

<P>
O &rarr; O'

<P>
we get a way to turn O'-algebras into O-algebras, since every
operation in O can be reinterpreted as one in O'.  So, we get a
functor

<P>
O'Alg &rarr; OAlg

<P>
In particular, the homomorphism

<P>
Assoc &rarr; Comm

<P>
gives the forgetful functor we've already seen:

<P>
CommAlg &rarr; AssocAlg

<P>
It's really just another way of talking about this functor!

<P>
With the main characters introduced, now our tale begins in earnest.
Let's use the homomorphism

<P>
Assoc &rarr; Comm 

<P>
to construct the Poisson operad.

<P>
To do this, first note that linear operads are a lot like rings.  In
particular, we can talk about the &quot;kernel&quot; of an operad
homomorphism, and this is always an &quot;ideal&quot;.  The
&quot;kernel&quot; consists of operations that go to zero under the
homomorphism.  Saying it's an &quot;ideal&quot; means that if you
compose any operation with one in the ideal, you get one in the ideal.
For example, in a composite like this:

<PRE>
    \  |  /   |   \   /    
     \ | /    |    \ /    
      ---    ---   ---   
     | a |  | b | | c | 
      ---    ---   --- 
         \    |    /
          \   |   /  
           \  |  / 
            ----- 
           |  d  |  
            -----  
              |   
              |  
</PRE>
if any one of the operations a,b,c,d is in the ideal, the whole
composite is in the ideal.  So if you think of operations as
apples and the operations in the ideal as rotten apples, the rule 
for ideals is &quot;one rotten apple spoils the whole
tree&quot;.  

<P>
Let's take the operad homomorphism

<P>
Assoc &rarr; Comm

<P>
and call its kernel I.  I<sub>n</sub> is the space of n-ary operations
for associative algebras that go to zero when we think of them as
operations for <i>commutative</i> algebras.  Let's see what it's like!
The first interesting case is I<sub>2</sub>.  Assoc<sub>2</sub> is
2-dimensional, with this basis:

<P>
(x,y) |&rarr; xy<br/>
(x,y) |&rarr; yx

<P>
and I<sub>2</sub> is 1-dimensional, with this basis:

<P>
(x,y) |&rarr; xy - yx

<P>
since this is what's zero for commutative algebras.  The quotient
Assoc<sub>2</sub>/I<sub>2</sub> is the same as Comm<sub>2</sub>: it's
a 1-dimensional space, and in this space we have identified the
operations

<P>
(x,y) |&rarr; xy

<P>
and 

<P>
(x,y) |&rarr; yx

<P>
Indeed, if you're used to rings, you shouldn't be surprised
that the quotient of a linear operad by an ideal is always another
operad, and since the homomorphism Assoc &rarr; Comm is onto, we have

<P>
Comm = Assoc/I 

<P>
where I is the kernel of this homomorphism.

<P>
Let me quickly say how we use this to get the Poisson operad, and then
work through the details a bit more slowly.

<P>
As with rings, we can take products of operad ideals.  Given ideals J
and K, their product JK consists of all linear combinations of
composites f o (g<sub>1</sub>, ..., g<sub>n</sub>) where f is in J and
at least one of the g<sub>i</sub>'s in in K.  So, given our ideal I,
we get a sequence of ideals

<P>
I<sup>0</sup>, I<sup>1</sup>, I<sup>2</sup>, I<sup>3</sup>, ....

<P>
each containing the next.  Here we set I<sup>0</sup> = Assoc and
I<sup>1</sup> = I to get things going.  We say the operad Assoc is
&quot;filtered&quot; by this sequence of operad ideals.  In highbrow
terms, this means it's an operad in the category of filtered vector
spaces.  In lowbrow terms: each vector space in the list
above contains the next, and

<P>
I<sup>m</sup> I<sup>n</sup> &sube; I<sup>m+n</sup>

<P>
As with rings, this lets us form the &quot;associated graded&quot;
operad gr(Assoc), which is this direct sum:

<P>
gr(Assoc) = I<sup>0</sup>/I<sup>1</sup> + I<sup>1</sup>/I<sup>2</sup> + I<sup>2</sup>/I<sup>3</sup> + &hellip;

<P>
And this is the Poisson operad!

<P>
I won't prove this; I'll just sketch the idea, and I'm afraid what I
say will only make sense if you have a good intuition for the
difference between &quot;filtered&quot; and &quot;graded&quot; things,
and how the &quot;associated graded&quot; construction converts the
former to the latter.

<P>
Operations in I are those that contain at least one appearance of the
bracket [x,y] = xy - yx: these are precisely the operations that
vanish in a commutative algebra.  For example:

<P>
(x,y,z) |&rarr; [xy,z]

<P>
or 

<P>
(x,y,z) |&rarr; z[x,y]

<P>
Operations in I<sup>2</sup> contain at least two appearances of the
bracket like this:

<P>
(x,y,z) |&rarr; [x,[y,z]]

<P>
And so on.  But the operad Assoc is just &quot;filtered&quot;, not
&quot;graded&quot;, because there's no way to say <i>exactly</i> how
many appearances of the bracket a given operation contains - at least,
no way that's compatible with composition and taking linear
combinations.  For example, you might say these operations contain 0
appearances of the bracket:

<P>
(x,y) |&rarr; xy 

<P>
and

<P>
(x,y) |&rarr; yx

<P>
But their difference <i>is</i> the bracket!

<P>
The &quot;associated graded&quot; construction is designed precisely
to cure this sort of problem: operations in
I<sup>k</sup>/I<sup>k+1</sup> contain exactly k appearances of the
bracket.  And if we look at our example again, we'll see what this
achieves.  In gr(Assoc), the operations

<P>
(x,y) |&rarr; xy 

<P>
and

<P>
(x,y) |&rarr; yx

<P>
live in I<sup>0</sup>/I<sup>1</sup>, but now they're equal, because
they differ by the commutator, which lives in I<sup>1</sup>.  So,
multiplication becomes commutative!  Meanwhile, the operation

<P>
(x,y) |&rarr; xy - yx

<P>
lives in I<sup>1</sup>/I<sup>2</sup>... but now we can call it the
Poisson bracket:

<P>
(x,y) |&rarr; {x,y}

<P>
And it's easy to check that these rules hold in gr(Assoc):

<P>
{x,y} = -{y,x}<br/>
{x,{y,z}} = {{x,y},z} + {y,{x,z}}</br>
{x,yz} = {x,y}z + y{x,z}

<P>
So - waving my hands rapidly here - we see that

<P>
gr(Assoc) = Poisson

<P>
But the fun isn't done!  All this abstract nonsense is just the warmup
to a very nice concrete calculation of how the n-ary operations in
gr(Assoc) break up into grades I<sup>k</sup>/I<sup>k+1</sup>.  And
here is where the Stirling numbers show up.

<P>
Let's look at n = 3.  The space of 3-ary operations in Assoc has
dimension 6.  There's a 2d subspace of operations that live in
I<sup>2</sup> - that is, where the bracket shows up at least twice:

<P>
(x,y,z) |&rarr; [x,[y,z]] <br/>
(x,y,z) |&rarr; [y,[x,z]]

<P>
You might think it was a 3d subspace, but don't forget the Jacobi
identity!  There's a 5d subspace of operations that live in I - that
is, where the bracket shows up at least once.  For example, we can
take the above two together with these three:

<P>
(x,y,z) |&rarr; [x,y]z <br/>
(x,y,z) |&rarr; [y,z]x <br/>
(x,y,z) |&rarr; [x,z]y

<P>
And that leaves one more, for a total of 6:

<P>
(x,y,z) |&rarr; xyz

<P>
A lot of nice patterns show up if you work out more examples.  Here's
the dimension of the space of n-ary operations in the Poisson operad
that lie in I<sup>k</sup>/I<sup>k+1</sup>:
                               
<PRE>
         k = 5   k = 4   k = 3   k = 2   k = 1   k = 0
          
n = 1                                              1
n = 2                                      1       1
n = 3                              2       3       1
n = 4                      6      11       6       1
n = 5             24      50      35      10       1
n = 6     120    274     225      85      15       1
</PRE>
If you're a true expert on combinatories, you'll instantly
recognize these as &quot;Stirling numbers of the first kind&quot;:

<P>
6) Wikipedia, Stirling numbers of the first kind,
<a href = "http://en.wikipedia.org/wiki/Stirling_numbers_of_the_first_kind">http://en.wikipedia.org/wiki/Stirling_numbers_of_the_first_kind</a>

<P>
But even if you're like me, you'll still see some nice patterns!

<P>
First of all, when k = 0 we just get 1.  This is the dimension of
space of n-ary operations in the Poisson operad that don't use the
bracket at all.  Or in other words, operations in Comm:

<P>
I<sup>0</sup>/I<sup>1</sup> = Assoc/I = Comm

<P>
And we know this space is 1-dimensional.  For example, for n = 4 it
has this basis vector:

<P>
(w,x,y,z) |&rarr; wxyz

<P>
Second, when k = 1 we get the triangle numbers 1,3,6,10,....  This is
the dimension of the space of n-ary operations in the Poisson operad
that use the bracket exactly once.  This makes sense if you think
about it: for n = 4 here's a basis:

<P>
(w,x,y,z) |&rarr; {w,x}yz<br/>
(w,x,y,z) |&rarr; {w,y}xz<br/>
(w,x,y,z) |&rarr; {w,z}xy<br/>
(w,x,y,z) |&rarr; {x,y}wz<br/>
(w,x,y,z) |&rarr; {x,z}wy<br/>
(w,x,y,z) |&rarr; {y,z}wx

<P>
We're getting 4 choose 2 different operations.

<P>
Third, the numbers in the nth row add to n!.  That's because the
dimension of a filtered vector space equals that of the associated
graded vector space.  So, the total dimension of Poisson<sub>n</sub>
equals the dimension of Assoc<sub>n</sub>, which is n factorial.

<P>
Fourth, the nth number along the diagonal is (n-1)!.  This is the
dimension of the space of n-ary operations that use the bracket the
maximum number of times: namely, n-1 times.  For example, when n = 3
this is a 2d space with basis

<P>
(x,y,z) |&rarr; {x,{y,z}}<br/>
(x,y,z) |&rarr; {y,{x,z}}

<P>
These are precisely the operations in the Lie operad!  So now we're
seeing the operad inclusion

<P>
Lie &rarr; Assoc

<P>
which gives the forgetful functor

<P>
AssocAlg &rarr; LieAlg

<P>
Indeed, quite generally, you can check that any operad O with an ideal
I has a suboperad whose n-ary operations are those lying in I<sup>n-1</sup>. 

<P>
Finally, when you learn about Stirling numbers, you see the general
pattern.  Stirling numbers count the number of permutations of n
elements that have a fixed number of disjoint cycles.  For example,
these permutations of 4 elements have 3 disjoint cycles:

<P>
(w x) (y) (z)<br/>
(w y) (x) (z)<br/>
(w z) (x) (y)<br/>
(x y) (w) (z)<br/>
(x z) (w) (y)<br/>
(y z) (w) (x)

<P>
These correspond to the following 4-ary operations in the Poisson
operad:

<P>
(w,x,y,z) |&rarr; {w,x}yz<br/>
(w,x,y,z) |&rarr; {w,y}xz<br/>
(w,x,y,z) |&rarr; {w,z}xy<br/>
(w,x,y,z) |&rarr; {x,y}wz<br/>
(w,x,y,z) |&rarr; {x,z}wy<br/>
(w,x,y,z) |&rarr; {y,z}wx

<P>
As you can see, there's a lot of fun and mysterious stuff going on
here.  Todd Trimble wrote a legendary paper &quot;Notes on the Lie
operad&quot; which would probably shed a lot of light on this stuff.
But unfortunately, the reason I call it &quot;legendary&quot; is that
it's almost impossible to find!  If I ever get a copy I'll let you
know.

<P>
For now, I'll wrap the story by proving that the Stirling numbers
are really related to the Poisson operad as claimed.

<P>
The first step is to show that

<P>
dim(Lie<sub>n</sub>) = (n-1)!  

<P>
For this we can use a famous argument, which is probably in Trimble's
paper.  First consider the forgetful functors:

<P>
AssocAlg &rarr; LieAlg &rarr; Vect

<P>
where Vect is the category of vector spaces.  These forgetful functors
have left adjoints.  The first forms the free Lie algebra on a vector
space V.  Let's call this Lie(V):

<P>
Lie: Vect &rarr; LieAlg

<P>
The second forms the free associative algebra on a Lie algebra L.
This is called its &quot;universal enveloping algebra&quot;, U(L):

<P>
U: LieAlg &rarr; AssocAlg

<P>
If we compose these two functors, we get a functor that forms the free
associative algebra on a vector space V.  This is usually called its
&quot;tensor algebra&quot;, but let's write it as Assoc(V), for reasons
soon to become clear:

<P>
Assoc: Vect &rarr; AssocAlg

<P>
So, we have an canonical isomorphism

<P>
Assoc(V) &cong; U(Lie(V))

<P>
But the Poincar&eacute;-Birkhoff-Witt theorem gives a canonical
isomorphism of vector spaces between the universal enveloping algebra
U(L) of a Lie algebra L and its &quot;symmetric algebra&quot; - that
is, the free commutative algebra on its underlying vector space.
Let's write this symmetric algebra as Comm(L).  So, we get a vector
space isomorphism

<P>
Assoc(V) &cong; Comm(Lie(V))

<P>
(Admittedly, the standard ugly proof of the PBW theorem does not give
a <i>canonical</i> isomorphism.  But the good proof does - see
&quot;<a href = "week212.html">week212</A>&quot;.)

<P>
Next, let's use some well-known black magic to describe the above
functors using operads.  The free Lie algebra on a vector space V is
given by

<P>
Lie(V) &cong; &oplus;<sub>n</sub> Lie<sub>n</sub> &otimes;
V<sup>&otimes;n</sup>

<P>
where we tensor over the action of the symmetric group.  Similarly,
the free associative algebra on a vector space V is given by

<P>
Assoc(V) &cong; &oplus;<sub>n</sub> Assoc<sub>n</sub> &otimes;
V<sup>&otimes;n</sup>

<P>
Likewise, the free commutative algebra on V is given by

<P>
Comm(V) &cong; &oplus;<sub>n</sub> Comm<sub>n</sub> &otimes;
V<sup>&otimes;n</sup>

<P>
These are categorified versions of formal power series.  That's
because linear operads are a special case of linear
&quot;species&quot;, or &quot;structure types&quot;.  So, we can
decategorify them and get formal power series called their generating
functions.  I explained this in &quot;<a href =
"week185.html">week185</A>&quot;, &quot;<a href =
"week190.html">week190</A>&quot;, and &quot;<a href =
"week102.html">week102</A>&quot;, but not in the linear case.  It's no
big deal: where we used cardinalities before, now we use dimensions!
We get these generating functions:

<P>
|Lie|(x) = &sum;<sub>n</sub> dim(Lie<sub>n</sub>) x<sup>n</sup>/n!
         
<P>
|Assoc|(x)  = &sum;<sub>n</sub> dim(Assoc<sub>n</sub>) x<sup>n</sup>/n! 
<P>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
         = &sum;<sub>n</sub> x<sup>n</sup> 
<P>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
         = 1/(1-x)

<P>
|Comm|(x)  = &sum;<sub>n</sub> dim(Comm<sub>n</sub>) x<sup>n</sup>/n!  
<P>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
         = &sum;<sub>n</sub> x<sup>n</sup>/n! 
<P>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 
         = exp(x)

<P>
Now, by general abstract nonsense our isomorphism

<P>
Assoc(V) &cong; Comm(Lie(V))

<P>
gives an equation

<P>
|Assoc|(x) = |Comm|(|Lie|(x))

<P>
or 

<P>
1/1-x = exp(|Lie|(x))

<P>
so

<P>
|Lie|(x) = ln(1/1-x) 
<P>
&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
         = &sum;<sub>n</sub> x<sup>n</sup>/n

<P>
but we saw

<P>
|Lie|(x) = &sum;<sub>n</sub> dim(Lie<sub>n</sub>) x<sup>n</sup>/n!

<P>
so 

<P>
dim(Lie<sub>n</sub>) = (n-1)!

<P>
This is a beautiful way of counting the number of n-ary operations in 
the Lie operad.

<P>
Note also that (n-1)! is also the number of permutations of n things
with a single cycle.  So, the Stirling numbers are already showing up.

<P>
Next let's use the fact that for any Lie algebra L, the symmetric
algebra Comm(L) is not just a commutative algebra: it's a Poisson
algebra!  It has a Poisson bracket, called the Kostant-Kirillov
Poisson structure.  Indeed, it's the free Poisson algebra on the Lie
algebra L.

<P>
This implies that Comm(Lie(V)) is the free Poisson algebra on
the vector space V:

<P>
Comm(Lie(V)) &cong; &oplus<sub>n</sub> Poisson<sub>n</sub> &otimes;
V<sup>&otimes;n</sup>

<P>
To get a basis of Poisson<sub>n</sub>, it's therefore enough to consider
commuting products of terms built using Poisson brackets, like this:

<P>
(a,b,c,d,e,f,g,h,i,j) |&rarr; {{a,b},c} {d,e} {f,g} h i j

<P>
Any expression like this can be reinterpreted as a permutation:

<P>
(a b c) (d e) (f g) (h) (i) (j)

<P>
So, by what we've already seen, the dimension of the space of n-ary
operations that involve a product of j terms is the same as the number
of permutations of n things with j cycles.  That's a Stirling number!
And this dimension is also the dimension of the space of n-ary
operations that live in I<sup>k</sup>/I<sup>k+1</sup>, where j + k = n.  

<P>
That last fact was not supposed to be instantly obvious.  But if you
look at the example above, you'll see it works:

<P>
n = 10, since there are 10 letters

<P>
j = 6, since we've got a product of 6 terms built using Poisson
brackets

<P>
k = 4, since we're using Poisson brackets 4 times

<P>
If you think a while, you'll see it always works like this.

<P>
To summarize: the dimension of the space of n-ary operations in
I<sup>k</sup>/I<sup>k+1</sup> is the same as the number of permutations of n
things with n-k disjoint cycles.  

<P>
Even if you didn't follow this argument, I hope you see that
associative, commutative, Lie and Poisson algebras are involved in a
beautiful web of relationships.  

<P>
I didn't get to say much about what all this means for quantization.
Indeed, I haven't really figured it all out yet!  For example, it must
be important that the universal enveloping algebra of a Lie algebra is
a deformation quantization of its symmetric algebra.  This should be a
central part of the story I'm telling, especially because it's crucial
to the proof of the Poincar&eacute;-Birkoff-Witt theorem mentioned in
&quot;<a href = "week212.html">week212</A>&quot;.  But I didn't fully
integrate this stuff into the story.

<P>
I also didn't talk about the relation between the Lie operad and
the homology of the poset of partitions of a finite set, described
at the beginning of this paper:

<P>
7) Benoit Fresse, Koszul duality of operads and homology of
partition posets, in Homotopy Theory: Relations with Algebraic 
Geometry, Group Cohomology, and Algebraic K-theory, eds. 
Paul Gregory Goerss and Stewart Priddy, Contemp. Math 346, 
2004, AMS, Providence, Rhode Island, pp. 115-215.
Also available at <a href = "http://math.univ-lille1.fr/~fresse/PartitionHomology.html">http://math.univ-lille1.fr/~fresse/PartitionHomology.html</a>

<P>
and first discovered by Joyal:

<P>
8) Andr&eacute; Joyal, Foncteurs analytiques et especes de structures, in 
Combinatoire Enumerative, Springer Lecture Notes in Mathematics 1234, 
Springer, Berlin (1986), 126-159. 

<P>
Nor did I bring the homology of the little k-cubes operad into the
game - the relation of this to the Poisson operad was described in
&quot;<a href = "week220.html">week220</A>&quot;, but you'll notice
that this only talks about k &gt; 1.  The story I'm discussing now
concerns the case k = 1, because the algebra Assoc is the homology of
the little 1-cubes operad.  For higher k, I especially recommend this
paper:

<P>
9) Dev Sinha, The homology of the little disks operad, available as 
<a href = "http://arxiv.org/abs/math/0610236">arXiv:math/0610236</a>.

<P>
Finally, here are three side remarks that would have been too
distracting earlier:

<P>
When I said &quot;linear operads are a lot like rings&quot;, I could have
been more precise.  Linear operads are a lot like associative algebras -
and indeed, an associative algebra is the same as a linear operad with
only unary operations!  But since we were talking about the linear
operad <i>for</i> associative algebras, I didn't want to blow your mind by
pointing out that an associative algebra also <i>is</i> a linear operad.
We could also consider operads whose spaces of operations are abelian
groups, with composition being a group homomorphism in each
argument.  An operad like this with only unary operations is the 
same as a ring.  And this is the precise sense in which operad theory
generalizes ring theory.

<P>
When I said &quot;one rotten apple spoils the whole tree&quot;, I felt
like saying &quot;cherry&quot; instead of &quot;apple&quot;, since
Boardman and Vogt talked about &quot;cherry trees&quot; in their work
on operads.  Unfortunately, the proverb &quot;one rotten apple spoils
the whole barrel&quot; requires apples!  For more, see this nice
historical survey:

<P>
10) James Stasheff, Grafting Boardman's cherry trees to quantum field
theory, in Homotopy Invariant Algebraic Structures: A Conference in
Honor of J. Michael Boardman, eds. Jean-Pierre Meyer, Jack
Morava, and W. Stephen Wilson, AMS, Providence, Rhode Island, 1999.
Also available as <a href = "http://www.math.unc.edu/Faculty/jds/boardman.ps">http://www.math.unc.edu/Faculty/jds/boardman.ps</a>

<P>
When I said "Indeed, quite generally, you can check that any operad O
with an ideal I has a suboperad whose n-ary operations are those lying
in I<sup>n-1</sup>", you might have been puzzled by the "-1".  Here's the
point.  All ways of composing operations can be built up from ways like
this:

<PRE>
       |    \    /  |
       |     \  /   |
       |     ---    |
       |    |   |   | 
        \    ---    /
         \    |    /
          \   |   /  
           \  |  / 
            ----- 
           |     |  
            -----  
              |   
              |  
</PRE>

where we compose an m-ary operation and an n-ary operation (together
with some identity operations).  The result is an (m+n-1)-ary operation!
For example, above I'm composing a 3-ary operation and a 2-ary operation
and getting a 4-ary operation.  

<P>
So, if we take an m-ary operation in I<sup>m-1</sup> and compose it with an
n-ary operation in I<sup>n-1</sup>, we get an (n+m)-ary operation which lies 
in I<sup>n+m-2</sup> &sube; I<sup>n+m-1</sup>.    So we get
a suboperad whose n-ary operations are those lying in I<sup>n-1</sup>.

<P>
You might enjoy working out what other ways there are to get
suboperads from an operad with an ideal.  Take all n-ary operations
lying in I<sup>f(n)</sup>.  For what functions f do these form a
suboperad?

<P>
Also, you might enjoy answering these questions, most of which
I haven't tried:

<ul>
<li>  If I is the ideal in
Assoc for which Assoc/I = Comm, what sort of algebras are described by
the operad I<sup>k</sup>?  
<p></p>
</li>
<li>
What about the operad I<sup>k</sup>/I<sup>k+1</sup>?  
<p></p>
</li>
<li>
What about the operad I<sup>k</sup>/I<sup>k+2</sup>, and so on?  
<p></p>
</li>
<li>
And what about the
suboperads of Assoc concocted as in the previous paragraph?
<p></p>
</li>
</ul>

<p>
<HR><P>
<b>Addenda:</b> I thank James Dolan and Urs Schreiber for catching some 
mistakes.  Allen Knutson adds to my list of questions: 

<blockquote>
   Here's another: if gr(Assoc) = Poisson, what is the meaning of 
   the Rees and blowup algebras associated to this filtration?
<p>
   (Given a filtration R = R<sub>0</sub> &supe; R<sub>1</sub>
   &supe;..., e.g. by powers of I, you can look at the subring of R[t]
   that has t<sup>n</sup> R<sub>n</sub> in the nth degree piece;
   that's the blowup algebra.  If you include t<sup>-n</sup> R in the negative
   powers, that's the Rees algebra. If you mod out Rees by (t - c),
   you get R for any nonzero c, and gr(R) for c=0.)
</blockquote>

Of course he means "operad" where he writes "algebra" or "ring" - while
the constructions he describes are most familiar for algebras or rings, 
they work for operads too!

<P>
David Corfield points out:

<blockquote>
<a
href="http://en.wikipedia.org/wiki/Stirling_numbers_of_the_first_kind">
Wikipedia</a> wants to tag your Stirling numbers as 'unsigned', and yet notes
that "that nearly all the relations and identities given on this page are
valid only for unsigned Stirling numbers". Also the <a
href="http://en.wikipedia.org/wiki/Stirling_numbers_and_exponential_generat
ing_functions">link</a> with exponential generating functions goes through
the unsigned version.

<p>
So why deal with the signed version? Is it because

<blockquote>

The Stirling numbers of the first and second kind can be understood to be
inverses of one-another, when taken as triangular matrices.

</blockquote>

</blockquote>
<P>
For more discussion visit the 
<a href =
"http://golem.ph.utexas.edu/category/2009/10/this_weeks_finds_in_mathematic_43.html"><em>n</em>-Category
Caf&eacute;</a>.  In particular, Toby Bartels raised an important
question: what's the physical meaning of treating Planck's constant as
a variable instead of a number in deformation quantization?

<p>
<HR><P>
<i>The worthwhile problems are the ones you can really solve or help
solve, the ones you can really contribute something to.</i> -
Richard Feynman
<p>
<HR><P>
<!-- BEGIN FOOTER -->
&#169; 2009  John Baez<br>
baez@math.removethis.ucr.andthis.edu <br>
<P>
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week281.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week283.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE><!-- END FOOTER -->
