<TITLE> week169 </TITLE>

<!-- BEGIN HEADER -->
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week168.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week170.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE>
<H4> July 4, 2001 </H4>
<H2> This Week's Finds in Mathematical Physics (Week 169) </H2>
<H4> John Baez </H4>
<!-- END HEADER -->

<P>

<P>
When I write This Week's Finds as rarely as I do these days,
so much stuff builds up that I completely despair of ever getting
to all of it... so I'll just randomly mention a few cool things
that are on the top of my mind right now.

<P>
First of all, here's a great new review article on spin foams.
If you're trying to understand spin foam models of quantum gravity, 
this is the place to start:

<P>
1) Daniele Oriti, Spacetime geometry from algebra: spin foam 
models for non-perturbative quantum gravity,
Rep. Prog. Phys. 64 (2001), 1489-1544.  Also available at
<A HREF = "http://xxx.lanl.gov/abs/gr-qc/0106091">gr-qc/0106091</A>.

<P>
You'll learn how spin foam models naturally show up in all sorts 
of different approaches to quantum gravity: loop quantization,
path integral approaches, lattice field theory, matrix models, 
and category-theoretic approaches.  

<P>
Secondly, here's a great introduction to n-categories and
topology:

<P>
2) Tom Leinster, Topology and higher-dimensional category theory:
the rough idea, available at 
<A HREF = "http://xxx.lanl.gov/abs/math.CT/0106240">math.CT/0106240</A>.

<P>
As he says, this is a &quot;Friday-afternoonish description of some
of the dreams people have for higher-dimensional category theory 
and its interactions with topology&quot;.  Much more readable than the 
Monday-morningish papers where people put in all the details!

<P>
And next, here is some stuff I have been thinking about lately.

<P>
As you're probably sick to death of hearing, I'm interested in category
theory and also normed division algebras: the real numbers, complex
numbers, quaternions and octonions.  There's no instantly obvious
relationship between these topics, but naturally I've tried to find
one, since this would let me unify two of my obsessions into one big 
super-obsession.  I recently made a bunch of progress, thanks to finding
these papers:

<P>
3) Markus Rost, On the dimension of a composition algebra, 
Documenta Mathematica 1 (1996), 209-214.  Available at 
<A HREF = "http://www.mathematik.uni-bielefeld.de/DMV-J/vol-01/10.html">http://www.mathematik.uni-bielefeld.de/DMV-J/vol-01/10.html</A>

<P>
4) Dominik Boos, Ein tensorkategorieller Zugang zum Satz von Hurwitz
(A tensor-categorical approach to Hurwitz's theorem), Diplomarbeit
ETH Zurich, March 1998, available at 
<A HREF = "http://www.mathematik.uni-bielefeld.de/~rost/data/boos.pdf">http://www.mathematik.uni-bielefeld.de/~rost/data/boos.pdf</a>

<P>
I'd like to explain what the problem is and how these papers solve it.

<P>
Part of the fun of category theory is that it lets you take mathematical
arguments and generalize them to their full extent by finding the proper
context for them: that is, by figuring out in exactly what sort of
category you can carry out the argument.  Out of laziness and ignorance,
people usually work in the category of sets as a kind of &quot;default
setting&quot;.  This category has many wonderful features - it's like a 
machine that chops, slices, dices, grates, liquefies and purees - but 
usually you don't need <em>all</em> these features to carry out a particular
task.  So, one job of a category theorist is to figure out what
features are actually needed in a given situation, and isolate the
kind of category that has those features.  

<P>
A &quot;kind of category&quot; is sometimes called a
&quot;doctrine&quot;.  I believe this term was invented by Lawvere.  It
must have some technical definition, but luckily I don't know it, so I
will not be restrained by it here.  I'll just talk in a sloppy way about
this question: &quot;in what doctrine can we define the concept of a
normed division algebra?&quot; It'll get technical for a while, so most
of you may want to leave, but then some pretty pictures will show up, so
make sure to come back then.

<P>
First think a minute about &quot;algebras&quot;.  Here by an
&quot;algebra&quot; I mean a finite-dimensional real vector space with a
not-necessarily-associative bilinear product and an element that's both
the left and right unit for this product.  We can define algebras like
this using the category Vect consisting of real vector spaces and linear
operators, without resorting to full power of the category of sets - as
long as we use the tensor product in Vect.  We start by saying an
algebra is an object A in Vect together with a product

<P>
m: A tensor A &rarr; A

<P>
and unit 

<P>
i: I &rarr; A

<P>
where I is the unit object for the tensor product - that is, the real 
numbers.  In case you're confused: the map i here is just the linear 
operator sending the real number 1 to the unit element of A; we're using 
a standard trick for expressing <em>elements</em> as <em>maps</em>.  
Given this stuff,
we can write the left and right unit laws by saying this diagram commutes:


<PRE>

             I tensor A &lt;--------- A -------&gt; A tensor I

                 |                 |              |
    i tensor 1_A |                 |1_A           | 1_A tensor i
                 |                 |              |
                 V         m       V     m        V

             A tensor A ---------&gt; A &lt;-------- A tensor A              

</PRE>
where the unlabelled arrows are some obvious isomorphisms coming from
the fact that I is the unit for the tensor product.  

<P>
Now, this definition could have been stated in <em>any</em> category with 
tensor products; or more technically, any &quot;monoidal category&quot;.  So 
the right doctrine for talking about algebras of this sort is the
doctrine of monoidal categories.  

<P>
What's the right doctrine for defining <em>associative</em> algebras?  Well, we
can write down another commutative diagram to state the associative
law:

<PRE>
        (A tensor A) tensor A ----------------&gt; A tensor (A tensor A)

                  |                                       |
   m tensor 1_A   |                                       | 1_A tensor m
                  |                                       |
                  V                                       V
                               m               m
              A tensor A -----------&gt; A &lt;-----------  A tensor A
</PRE>

where again the unlabelled arrow is the obvious isomorphism.  This works
fine in any monoidal category, so the right doctrine is again that of
monoidal categories.  But instead of speaking of an &quot;associative
algebra&quot; in a monoidal category, folks usually call a gadget of
this sort a &quot;monoid object&quot;- see &quot;<A HREF =
"week89.html">week89</A>&quot; for more on this.  The reason is that if
we take our monoidal category to be Set, a monoid object boils down to a
&quot;monoid&quot;: a set with an associative product and unit element.

<P>
Lots of people like groups more than monoids.   What's the right
doctrine for defining groups?  This time it's definitely NOT the
doctrine of monoidal categories.  The reason is that the equational
laws satisfied by inverses in a group:

<P>
g g<sup>-1</sup> = 1

<P>
g<sup>-1</sup> g = 1

<P>
have duplicated and deleted arguments - the &quot;g&quot; shows up twice
on the left side and not at all on the right!  This is different from
the associative law

<P>
g (h k) = (g h) k

<P>
where each argument shows up once on each side of the equation.

<P>
In a monoidal category we can't &quot;duplicate&quot; or
&quot;delete&quot; arguments: if X is an object in a monoidal category,
there's no god-given map from X to X tensor X, or from X to 1.  This
means we can't use commutative diagrams in a monoidal category to
express equational laws that duplicate or delete arguments.

<P>
However, we <em>can</em> duplicate and delete arguments if we're in a
&quot;category with finite products&quot; - a nice sort of monoidal
category where we <em>do</em> have maps from X to X tensor X and from X to 1.
The best example of this is the category of sets, where the &quot;tensor
product&quot; is just the usual Cartesian product.  This is why we can
easily define groups in the category of sets!  More generally, we can
define &quot;group objects&quot; in any category with finite products.

<P>
So, the right doctrine for talking about groups - or more precisely,
group objects - is the doctrine of categories with finite products.  

<P>
By the way, if you think this stuff is too abstract to be useful, take a
peek at &quot;<A HREF = "week54.html">week54</A>&quot; and &quot;<A HREF
= "week115.html">week115</A>&quot;, where I described how group objects
show up in algebraic topology.  But beware: back then I was engaging in
a bit of overkill, and working in the doctrine of &quot;categories with
finite limits&quot;.  This more powerful doctrine also lets you define
gadgets with partially defined operations, like &quot;category
objects&quot;.  But for group objects, finite products are all we really
need.

<P>
Gradually getting to the point, let us now ask: what's the right
doctrine for talking about <em>division</em> algebras?  It's definitely 
<b>not</b> the
doctrine of monoidal categories.  It's not even the doctrine of
categories with finite products!  The problem is that a division algebra
is defined to be an algebra such that xy = 0 implies x = 0 or y = 0.
This condition is not even an equational law: it doesn't say some
equation holds, it says &quot;this equation implies this one or that one&quot;.
To express such fancier conditions as commutative diagrams, we need a
more powerful doctrine.  

<P>
I'm too lazy to figure out exactly what we need, but certainly the
doctrine of &quot;topoi&quot; will do.  If you don't know what a topos is, give
yourself 40 lashes and read this:

<P>
5) John Baez, Topos theory in a nutshell,
<A HREF = "http://math.ucr.edu/home/baez/topos.html">http://math.ucr.edu/home/baez/topos.html</A>

<P>
However, there are lots of reasons to avoid working in such a powerful
doctrine - basically, it greatly limits the generality with which one
can discuss a subject.  

<P>
So it's very interesting to see how much better we can do if we're
interesed in <em>normed</em> division algebras.  These are algebras equipped
with a norm such that

<P>
|xy| = |x| |y|

<P>
and if we're working in the category of real vector spaces, the only
examples are the real numbers, the complex numbers, the quaternions
and the octonions.  These have all sorts of important applications in
physics, so it's good to see what doctrine we need to talk about them.

<P>
The problem is that the norm is nothing like a linear map.  To get
around this, it's better to work with the inner product, which is
related to the norm by

<P>
|x|<sup>2</sup> = &lt;x,x&gt;  

<P>
The inner product is bilinear, so have a chance of talking about it in
the doctrine of monoidal categories.  Unfortunately, there are a couple
of problems:

<P>
First of all, it's tough to state the positive definiteness of the inner
product:

<P>
if x is nonzero, then &lt;x,x&gt; is greater than 0.

<P>
The easiest way around this is to relax a bit, and instead of demanding
that our algebra have an inner product &lt;x,y&gt;, simply demand that it have
a nondegenerate bilinear form g(x,y).  Believe it or not, this condition
can be stated in any monoidal category.  It's easiest to do this using
pictures - not commutative diagrams, but an equivalent approach using
pictures that look a bit like Feynman diagrams.  These days, lots of
mathematical physicists use pictures like this to do calculations in
monoidal categories.  There are lots of places to learn this stuff, but
if you want something online, it's easiest for me to point you to my notes
on quantum gravity:

<P>
6) John Baez, Toby Bartels, and Miguel Carrion, Quantum gravity 
seminar, <A HREF = "http://math.ucr.edu/home/baez/qg.html">http://math.ucr.edu/home/baez/qg.html</A>
<P>
Okay.  Now that you've read those notes, you know what to do!
We assume our algebra A is equipped with maps 

<P>
g: A tensor A &rarr; I

<P>
and 

<P>
h: I &rarr; A tensor A

<P>
which we draw as 

<PRE>
        |             |
        |             |
         \           / 
          \         /
           \_______/
               g
</PRE>
and
               
<PRE>
            ___h___
           /       \
          /         \
         /           \ 
        |             |
        |             |
</PRE>
respectively.  We demand that

<PRE>
   |                             |                             |
   |                             |                             |
   |                             |                             |
   |            __h__            |            __h__            |
   |           /     \      =    |     =     /     \           |
   |          /       \          |          /       \          | 
   |         /         |         |         |         \         |
    \       /          |         |         |          \       /
     \_____/           |         |         |           \_____/
        g              |         |         |              g         
                       |         |         |
                       |         |         |
                       |         |         |
</PRE>
which says that the bilinear form g is nondegenerate.  To get 
further, we'll also demand that


<PRE>
        |       |            |           |
        |       |            |           |
         \     /             |           |
          \   /              |           |
           \ /       =       |           |
            /                |           |
           / \               |           |
          /   \              |           |
         |     |              \         /
          \   /                \       /
           \_/                  \_____/
            g                      g
</PRE>
This says that the bilinear form g is symmetric, that is:

<P>
g(x,y) = g(y,x).  

<P>
But we can only state this equation if we're in a monoidal category
where we can &quot;switch arguments&quot;, which in pictures goes like this:

<PRE>
          \   /              
           \ /       
            /        
           / \       
          /   \   
</PRE>
A monoidal category with this feature is called a &quot;symmetric
monoidal category&quot; (or more generally a &quot;braided monoidal
category&quot;, but I don't want to get into those complications here).

<P>
So far, so good!  The second problem is figuring out how to state the
condition |xy| = |x| |y|.  If we translate this into a condition on our
bilinear form g, we get

<P>
g(xy,xy) = g(x,x) g(y,y)

<P>
An algebra with a nondegenerate bilinear form having this property is
called a &quot;composition algebra&quot;.  Hurwitz showed that such an
algebra must have dimension 1, 2, 4, or 8.  However, there are examples
other than the famous four, coming from bilinear forms g that aren't
positive definite.  For example, there are the &quot;split
quaternions&quot; in dimension 4, or the &quot;split octonions&quot; in
dimension 8.

<P>
Now, the problem with the above equational law is that it involves
duplication of arguments.  But we can get around this problem by a
standard trick called &quot;polarization&quot;, which people use a lot in 
quantum mechanics.   

<P>
First let's polarize the argument x.  To do this, note that we have

<P>
g(xy,xy) = g(x,x) g(y,y) 
<P>
g(x'y,x'y) = g(x',x') g(y,y)

<P>
and also

<P>
g((x+x')y,(x+x')y) = g(x+x',x+x') g(y,y).

<P>
Subtracting the first two equations from the last and then dividing by
2, we get

<P>
g(xy,x'y) = g(x,x') g(y,y).

<P>
See?  We've eliminated the duplication of the argument x.  This new
equation obviously implies the original one.  

<P>
Next we polarize the argument y.   We have

<P>
g(xy,x'y) = g(x,x') g(y,y)

<P>
g(xy',x'y') = g(x,x') g(y',y')

<P>
and also

<P>
g(x(y+y'),x'(y+y')) = g(x,x') g(y+y',y+y').

<P>
Subtracting the first two equations from the last one, we get

<P>
g(xy,x'y') + g(xy',x'y) = 2 g(x,x') g(y,y')

<P>
Now there is no duplication of arguments.  We've paid a price, though:
now our equation involves addition, so we can only write it down if our
category has the extra feature that we can add morphisms.  For this, we
want our category to be &quot;additive&quot;.  

<P>
So: the right doctrine in which to define composition algebras is
the doctrine of symmetric monoidal additive categories!  

<P>
(Technical note: here we want the monoidal and additive structures
to get along nicely: tensoring of morphisms should be bilinear.)

<P>
Let me summarize by giving all the details.  A &quot;composition
object&quot; is an object A in a symmetric monoidal additive category
which is equipped with morphisms

<PRE>
    \       /                 A tensor A
     \     /                       
      \   /                        |
       \ /                         | 
        m                        m |               &quot;multiplication&quot;
        |                          |
        |                          V
        |                          
        |                          A
                                   

                                   I
        i                          
        |                          |
        |                        i |                    &quot;unit&quot;
        |                          |
        |                          V
                       
                                   A



      |         |              A tensor A
      |         |   
      |         |                  |
       \       /                 g |                &quot;bilinear form&quot;
        \_____/                    V
           g               
                                   I




                                   I
         __h__                                
        /     \                    |                 
       /       \                 h |             &quot;inverse bilinear form&quot;  
      |         |                  | 
      |         |                  V
      |         |                 
                               A tensor A
</PRE>
satisfying the equations already shown:

<PRE>
   |                             |                             |
   |                             |                             |
   |                             |                             |
   |            __h__            |            __h__            |
   |           /     \      =    |     =     /     \           |
   |          /       \          |          /       \          | 
   |         /         |         |         |         \         |
    \       /          |         |         |          \       /
     \_____/           |         |         |           \_____/
        g              |         |         |              g         
                       |         |         |
                       |         |         |
                       |         |         |
</PRE>
and

<PRE>
        |       |            |           |
        |       |            |           |
         \     /             |           |
          \   /              |           |
           \ /       =       |           |
            /                |           |
           / \               |           |
          /   \              |           |
         |     |              \         /
          \   /                \       /
           \_/                  \_____/
            g                      g
</PRE>
together with the left and right unit laws:

                                            
<PRE>
               |             |           |  
               |             |           |  
               |             |           |  
        i      |             |           |      i
        |      |             |           |      |
        |      |             |           |      |
         \     |             |           |     /
          \   /              |            \   /
           \ /       =       |     =       \ /
            m                |              m
            |                |              |
            |                |              |
            |                |              |
            |                |              |
            |                |              |
</PRE>
and best of all, the equation

<P>
g(xy,x'y') + g(xy',x'y) = 2 g(x,x') g(y,y')

<P>
translated into pictures like this:

<PRE>
 \   /   \   /       \     \   /     /          \     \   /     /
  \ /     \ /         \     \ /     /            \     \ /     /
   m       m     +     \     m     /      =  2    \     /     /
    \     /             \    |    /                \___/ \___/
     \___/               \  /    /                   g     g
       g                   /    /
                          /  \ /
                         |    m
                          \__/
                             g
</PRE>
Now, given all this stuff, we can define the &quot;dimension&quot; of our
composition algebra to be the value of this morphism from I to I:
         
<PRE>
     _______
    /       \
   /         \
  |           |
  |           |
   \         /
    \_______/
        g
</PRE>
This reduces to the usual dimension of the algebra A when we're in 
the category Vect.   Of course, only in certain categories is
this dimension bound to be a <em>number</em> - namely, those categories where
every morphism from I to I is some number times the identity morphism.

<P>
By making an extra assumption like this, Boos is able to give a
&quot;picture proof&quot; that in a large class of symmetric monoidal
additive categories, every composition object has dimension 1, 2, 4 or
8.  This is great, because it means we can talk about things like real,
complex, quaternionic and octonionic objects in a wide variety of
categories!  He doesn't prove such objects exist, but I think this
should be easy, at least with some extra assumptions which would allow
us to construct them &quot;by hand&quot;, mimicking standard
constructions of the normed division algebras.

<P>
But now I must warn you of some things.  Boos doesn't state his result
the way I would!  Instead of working with &quot;composition
objects&quot; (which appear to be my own invention), he works with
&quot;vector product algebras&quot;.  These are modelled, not after the
normed division algebras themselves, but after their &quot;imaginary
parts&quot;.  These have both an inner product and a &quot;vector
product&quot;.

<P>
For example, the imaginary quaternions form a 3-dimensional vector 
product algebra with vector product given by

<P>
a x b = (1/2)(ab - ba).

<P>
This is just the usual cross product!  The same formula makes the 
imaginary octonions into a 7-dimensional vector product algebra, 
the imaginary complex numbers into a boring 1-dimensional one... 
and the imaginary real numbers into an even more boring 0-dimensional 
one.

<P>
Boos writes down the axioms for a vector product algebra using pictures 
much like I just did for a composition object, and he shows that under 
some pretty mild conditions you can freely go back and forth between 
the two concepts.  

<P>
I think you can summarize his theorem on vector product algebras as
follows: in all symmetric monoidal R-linear categories where R is a
commutative ring containing Z[1/2] and I is a simple object, vector
product algebras must have dimension 0, 1, 3, or 7.  He doesn't state
his result quite this way, but I'm pretty sure that's what it boils down
to.  As for the jargon: a category is &quot;R-linear&quot; if the
homsets are R-modules and composition of morphisms is bilinear; for
monoidal categories we also want tensoring morphisms to be bilinear.
The ring Z[1/2] consists of all fractions with a power of 2 in the
denominator - Boos needs this because he needs to divide by 2 at some
point in his argument.  For an R-linear category, an object I is
&quot;simple&quot; if hom(I,I) = R.  This allows us to interpret the
dimension of our vector product algebra as an element of R - which Boos
shows is actually one of the integers 0, 1, 3, or 7.

<P>
Let me conclude by showing you Boos' main axiom for vector
product algebras, written in terms of pictures:

<PRE>
 \       /        \   /         \     /     \        /     \        /
  \     /          \ /           \   /       \      /       \      /
   \___/            |             \ /         \    /         \____/ 
   /   \     +      |     =  2     /    -      |  |     -     ____    
  /     \           |             / \         /    \         /    \
 /       \         / \           /   \       /      \       /      \
/         \       /   \         /     \     /        \     /        \
</PRE>
Ain't it cool?  Fans of knot theory will be struck by the resemblance
to various &quot;skein relations&quot;.  Fans of physics will be reminded of
Feynman diagrams.  But what is the secret inner meaning?    

<P>

<p> <hr>
<em>&quot;The perplexity of life arises from there being too many
interesting things in it for us to be interested properly
in any of them.&quot;</em> - <br> G. K. Chesterton, 1909
<P>
<HR><P>
<!-- BEGIN FOOTER -->
&#169; 2001  John Baez<br>
baez@math.removethis.ucr.andthis.edu <br>
<P>
<TABLE WIDTH = 100%> <TR>
<TD WIDTH=10%>
<A HREF = "week168.html">
   <img border = none; src="lastweek.png"></A>
<TD WIDTH=80%>
<CENTER>
<A HREF="README.html">
  <img border = none; src="home.png"><br>
</A>
<A HREF="http://math.ucr.edu/home/baez/TWF.html">
    <img border = none; src="contents.png">
</A>
</CENTER>
<TD WIDTH=10%>
<A HREF = "week170.html">
  <img border = none; src="nextweek.png">
</A>
</TABLE><!-- END FOOTER -->
