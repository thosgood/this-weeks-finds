<TITLE> week284 </TITLE>




<P>
A couple of weeks ago there was a meeting of the American Mathematical
Society here at UC Riverside.  Mathematicians flooded in from across
the western US and even further.  They gave hundreds of 20-minute
talks, drank lots of coffee, ate a few too many pastries, and chatted
with each other.  Julie Bergner and I ran a session at this
conference.  My student Chris Rogers took videos of the talks in our
session, and you can see them here:

<P>
1) Special session on homotopy theory and higher algebraic structures,
AMS Western Section Meeting, November 7-8, 2009.  Talks available as
Quicktime videos at <a href =
"http://math.ucr.edu/~jbergner/amsriverside09.htm">http://math.ucr.edu/~jbergner/amsriverside09.htm</a>

<P>
These talks add up to a nice look at recent work on homotopy theory,
n-categories, and categorification - some of my favorite subjects.
So, I'd like to quickly summarize each talk and give some links to
related papers.

<P>
But first: something a bit less technical!

<P>
Last week I asked you to provide a nice proof of Proposition 10 from
the last book of Euclid - the one where he constructs the Platonic
solids.  Euclid uses this proposition to construct the icosahedron,
but it's appealing in its own right.  In modern language it says:

<P>
<blockquote>
 Inscribe a regular pentagon, hexagon and decagon in a circle,
 and call their side lengths P, H and D.  Then 
<div align = "center">
P<sup>2</sup> = H<sup>2</sup> + D<sup>2</sup>.
</div>
</blockquote>

<P>
I find this fascinating.  One reason is that it's simple but far from
obvious.  Another is that it's secretly all about the golden ratio and
its role in 5-fold symmetry.  And another is that Euclid's proof is
ingenious but not very intuitive - so it seems there should be a
better proof.  For example, a proof that uses the icosahedron!

<P>
(Last week I gave a proof using algebra and trigonometry, but
it wasn't terribly interesting.)

<P>
The science fiction writer Greg Egan said that Euclid's proof was
&quot;really dazzling, but it made me feel like he'd pulled a coin out
from behind my ear.&quot; Egan wrote a modernized version of this
proof, which you can see in the Addenda to &quot;<a href =
"week283.html">week283</A>&quot;.  But he then went on to give a
number of other proofs, including two that I like a lot better:

<P>
2) nLab, Pentagon-decagon-hexagon identity, 
<a href = "http://www.ncatlab.org/nlab/show/pentagon+decagon+hexagon+identity">http://www.ncatlab.org/nlab/show/pentagon+decagon+hexagon+identity</a>

<P>
One of these proofs uses the icosahedron.  As I'd dreamt in &quot;<a
href = "week283.html">week283</A>&quot;, it proceeds by showing that
two right triangles hiding in the icosahedron are congruent.
Namely, the triangles ABC and AB'C' shown here:

<P>
<div align = "center">
<img src = "icosahedron_with_right_triangles.gif">
</div>

<P>
The other proof is purely 2-dimensional.  For this, Egan starts
by recalling Proposition 9 from the same book of Euclid.  This result
states the main property of the &quot;golden triangle&quot;.

<P>
What's a golden triangle?  Well, if you draw a regular pentagon and
connect each vertex to every other, you'll get a pentagram in a
pentagon - but you'll also see lots of tall skinny isosceles
triangles:

<P>
<div align = "center">
<img width = "400" src = "dodecahedron/pentagram.png">
</div>

<P>

These are &quot;golden triangles&quot;.  They have angles
of 36 degrees, 72 degrees, and 72 degrees.  How many are there
in this picture?

<P>
In Proposition 9, Euclid shows that for a golden triangle, the ratio
of the edge lengths is the golden ratio.  Actually he shows something
equivalent, roughly this:

<blockquote>
 Inscribe a regular hexagon and decagon in a circle.  Then the ratio
 of their side lengths is the golden ratio: 
<div align = "center">
D/H = &phi; = (-1 + &radic; 5)/2
</blockquote>

<P>
Why is this equivalent?  Well, if you inscribe a regular decagon in a
circle and draw lines from its center to its vertices, you get ten
golden triangles.  The long edge of each triangle is H, since the
radius of the circle equals the edge of an inscribed circle.  The
short edge is D.

<P>
Oddly, Euclid does not use Proposition 9 to prove Proposition 10, even
though it's relevant and it comes right before!  But Egan's proof uses
it.  Check out the <a href =
"http://www.ncatlab.org/nlab/show/pentagon+decagon+hexagon+identity">nLab
entry</a> for details and pretty pictures.  I think it's great that
21st-century technology is being used to improve a proof dating back to 300 BC.

<P>
Now... on to the talks on homotopy theory and higher algebraic
structures!  I'm afraid the length of my summaries will be
proportional to how much I understood.  You can click on the talk
titles to see the videos.

<P>
Bright and early at 8 am on Saturday morning, Aaron Lauda kicked off
the special session with a talk on &quot;<a href =
"ams_2009/Lauda_AMS_UCR_2009.mov">Categorifying quantum
groups</a>&quot;.  Luckily he'd come from the east coast, so he was
wide awake, and his energy was contagious.

<P>
From the very beginning of This Week's Finds you can see that I was
interested in Crane and Frenkel's dream of categorified <a href =
"http://en.wikipedia.org/wiki/Quantum_group">quantum groups</a>.  Now
this dream is coming true!  Aaron gave a great series of talks on this
subject in Kyoto this February, and you can see them all here:

<P>
3) Aaron Lauda, Kyoto lectures: 
<ul>
<li>
Categorification of quantum sl(2),
</li>
<li>
Categorification of one half of the quantum group, 
</li>
<li>
Categorification of quantum sl(n),
</li>
<li>
Cyclotomic quotients of the rings R(&nu;).
</li>
</ul>
Available at <a href = "http://www.math.columbia.edu/~lauda/talks/kyoto/">http://www.math.columbia.edu/~lauda/talks/kyoto/</a>

<P>
At Riverside he explained what people often call the &quot;Khovanov-Lauda
algebra&quot; R associated to a simply laced Dynkin diagram.  This gives a
way of categorifying the &quot;positive part&quot; of the corresponding quantum
group.  

<P>
4) Mikhail Khovanov and Aaron Lauda, A diagrammatic approach to 
categorification of quantum groups I-III, available as
<a href = "http://arxiv.org/abs/0803.4121">arXiv:0803.4121</a>,
<a href = "http://arxiv.org/abs/0804.2080">arXiv:0804.2080</a>,
and
<a href = "http://arxiv.org/abs/0807.3250">arXiv:0803.3250</a>.

<P>
Huh?  Well, just as the group of matrices has a subgroup consisting of
upper triangular matrices and a subgroup consisting of lower
triangular matrices, so any quantum group breaks into a &quot;positive
part&quot; and a &quot;negative part&quot;, with a bit of overlap.
It's easier to categorify either of these parts than the whole thing,
because when you deal with the whole thing you get formulas involving
negative numbers, which are harder to categorify.

<P>
How does the algebra R help us categorify the positive part of a
quantum group?  Or, for that matter, the negative part? - the two
parts look alike, so we randomly choose to work with the positive
part.  

<P>
The answer is simple: we just form the category of representations 
of R!

<P>
But how do we get back from this category to the positive part of the
quantum group?  In other words, how do we &quot;decategorify&quot;?
Again, the answer is simple: just take its <a href =
"http://ncatlab.org/nlab/show/Grothendieck+group">Grothendieck
group</a>!  A bit more precisely: we take the category of 
<a href = "http://en.wikipedia.org/wiki/Finitely_generated_module">finitely
generated</a> <a href =
"http://en.wikipedia.org/wiki/Projective_module">projective</a>
R-modules, and look at isomorphism classes of these, and let these
generate an abelian group with relations saying that direct sums
should act like sums:

<P>
[M &oplus; N] = [M] + [N]

<P>
This gives a certain &quot;integral form&quot; of the positive part of
the quantum group.  If we tensor this with the complex numbers, we get
the more familiar complex version of the quantum group.

<P>
One of the great virtues of the Khovanov-Lauda algebra is that it has
a nice presentation, with generators and relations given in terms of
pretty pictures.  This is great for computations.  However, the
presentation is a bit complicated, so I can't help but wonder where it
came from.  Maybe there's some nice geometry underlying the whole
story?  

<P>
Indeed, Aaron has also worked on more geometrical approaches to 
categorifying quantum groups, at least for the simplest of simple 
Lie algebras, namely sl(2):

<P>
5) Aaron Lauda, A categorification of quantum sl(2), available
as <a href = "http://arxiv.org/abs/0803.3652">arXiv:0803.3652</a>.
 
<P>
6) Aaron Lauda, Categorified quantum sl(2) and equivariant cohomology 
of iterated flag varieties, available as 
<a href = "http://arxiv.org/abs/0803.3848">arXiv:0803.3848</a>.

<P>
But there are also lots of other people tackling the geometrical side
of the story.  One of these is Anthony Licata of Stanford University!
Right after Aaron, he gave a talk on &quot;<a href =
"ams_2009/Licata_AMS_UCR_2009.mov">Categorification via quiver
varieties</a>&quot;, based on these papers:

<P>
6) Sabin Cautis, Joel Kamnitzer, and Anthony Licata, Coherent
sheaves and categorical sl(2) actions, available as 
<a href = "http://arxiv.org/abs/0902.1796">arXiv:0902.1796</a>.

<P>
7) Sabin Cautis, Joel Kamnitzer, and Anthony Licata, Derived
equivalences for cotangent bundles of Grassmannians via categorical
sl(2) actions, available as 
<a href = "http://arxiv.org/abs/0902.1797">arXiv:0902.1797</a>.

<P>
The first paper studies various notions of a categorified
representation of sl(2).  The second studies an example coming from
cotangent bundles of Grassmannians.  That's a lot of math to compress
into a 20-minute talk!  Luckily Licata was able to do it, by leaving
out all but the most fundamental concepts.

<P>
His work follows the philosophy that &quot;geometrization leads to
categorification&quot;.  This is based on a branch of math called
&quot;geometric representation theory&quot;.  

<P>
The name here is a bit misleading, since a lot of group representation
theory is geometrical in nature.  For example, if we have a group G
acting as symmetries of a space X, we get a representation of G on the
vector space of functions on X.  And there are many sophisticated
refinements of this idea.  But &quot;geometric representation
theory&quot; is different.  It gets representations in unexpected new
ways, often starting from the cohomology of a space X on which G does
<i>not</i> act!

<P>
I think this is the best place to start learning geometric
representation theory:

<P>
8) Neil Chriss and Victor Ginzburg, Representation Theory and Complex
Geometry, Birkhauser, Boston, 1997.

<P>
I've spent some time on this book, but not enough.  The results still
seem strange to me.  They're like an outcropping of unfamiliar rocks
poking through the strata of mathematics that make sense to me.  I'd
need to dig deeper to get a sense of what's going on down there.  Just
thinking about this makes me itch to understand geometric
representation theory better.  I know specific results, but not the
overall pattern!

<P>
You expect, for example, to get representations of sl(2) whenever you
build vector spaces starting from C<sup>2</sup>.  Why?  Because the
group SL(2) acts as symmetries of C<sup>2</sup>, and thus on any
vector space functorially constructed from it.  But Ginzburg found
some unexpected new ways of getting representations of sl(2)... and
Licata sketched how this lets you categorify these representations.

<P>
Here's the example Licata explained.  The group SL(2) acts on
C<sup>2</sup> and thus on its nth tensor power.  Everyone knows that.
But we can also get this representation in an unexpected way.  Start
with the space of all k-dimensional subspaces of C<sup>n</sup>.  This
is called the &quot;Grassmannian&quot; Gr(k,n).  Form a vector space
by taking the cohomology of the cotangent bundle T*Gr(k,n).  Then take
the direct sum of these vector spaces as k goes from 0 to n.

<P>
We get a big fat vector space.  But here's the cool part: Ginzburg
figured out how to make this big fat space into a representation of
sl(2)!  And this representation is isomorphic to the nth tensor power
of C<sup>2</sup>.

<P>
The trick is to get operators on cohomology groups that satisfy the
relations for sl(2).  As usual in geometric representations theory, we
build these using &quot;spans&quot;.  These are setups where you have
three spaces and two maps like this:

<PRE>
                     S
                    / \
                   /   \
                 P/     \Q
                 /       \
                v         v 
               X           Y

</PRE>
We can pull back cohomology classes along P, and then if we're lucky
we can push them forward along Q, getting an operator from the
cohomology of X to the cohomology of Y.  I explained why spans are
geometrically interesting back in &quot;<a href = "week254.html">week254</A>&quot;.

<P>
Anyway, so Ginzburg got a representation of sl(2) using this trick.
To categorify this representation, Licata replaced the cohomology of
T*Gr(k,n) by a category called the &quot;bounded <a href =
"http://en.wikipedia.org/wiki/Derived_category">derived category</a>
of <a href = "http://en.wikipedia.org/wiki/Coherent_sheaf">coherent
sheaves</a>&quot; on this space.  That's a plausible strategy, because
it's known quite generally that for any smooth variety X you can take
the Grothendieck group of this category and get back the cohomology of
X.

<P>
In fact, if you have no idea what a &quot;bounded derived category of
coherent sheaves&quot; is, this should make you want to know!  It's a
categorification of cohomology.  Here's a good place to start learning
more:

<P>
9) Andrei Caldararu, Derived categories of sheaves: a skimming.
Available at 
<a href = "http://www.math.wisc.edu/~andreic/publications/lnPoland.pdf">http://www.math.wisc.edu/~andreic/publications/lnPoland.pdf</a>

<P>
Next came two talks on another approach to categorification, called
&quot;groupoidification&quot;.  This involves replacing vector spaces
by groupoids and linear operators by spans of groupoids.  The reverse
process, &quot;degroupoidification&quot;, is an entirely systematic
procedure for squashing groupoids into vector spaces and spans of
groupoids into linear operators.  I explained how this works back in
&quot;<a href = "week256.html">week256</A>&quot;.

<P>
First Alex Hoffnung spoke about &quot;<a href =
"ams_2009/Hoffnung_AMS_UCR_2009.mov">A categorification of the Hecke
algebra</a>&quot;.  The idea here is to see the <a href =
"http://en.wikipedia.org/wiki/Hecke_algebra">Hecke algebras</a>
associated to <a href =
"http://en.wikipedia.org/wiki/Coxeter%E2%80%93Dynkin_diagram">Dynkin
diagrams</a> as a special case of a much more general construction:
the Hecke bicategory.

<P>
Given a finite group G, the Hecke bicategory Hecke(G) is a gadget
where:

<ul>
<li>
 objects are finite G-sets;
</li>
<li>
 the groupoid of morphisms from X to Y is the weak quotient (X x Y)//G.
</li>
</ul>

<P>
Here the &quot;weak quotient&quot; is a bit like the ordinary quotient
of a set by a group action - but instead making elements <i>equal</i>
when there's a group element mapping one to another, we make them
<i>isomorphic</i>.  So, it's a groupoid.  (For more details, see
&quot;<a href = "week249.html">week249</A>&quot;.)

<P>
Using a systematic procedure for turning groupoids into vector spaces,
we can squash Hecke(G) down into a category that has a mere vector
space of morphisms from X to Y.  

<P>
Now, a category where the set of morphisms between any two objects is
a <i>vector space</i>, and composition is linear in each argument, is
sometimes called an &quot;<a href =
"http://planetmath.org/encyclopedia/Algebroids.html">algebroid</a>&quot;.
Why?  Because an algebroid with one object is an algebra - in the same
way that a groupoid with an object is a group.

<P>
So, the Hecke bicategory gets squashed down into something that
deserves to be called the &quot;Hecke algebroid&quot; of G.

<P>
Now pick a finite field and a Dynkin diagram.  This gives a simple
algebraic group G and a very important G-set X, called the &quot;flag
variety&quot; of G.  Take the Hecke algebroid of G and concentrate
your attention on the morphisms from X to X.  By what I've said, these
form an algebra.  And this is the famous &quot;Hecke algebra&quot;
associated to our Dynkin diagram!  The usual parameter q that appears
in the definition of a Hecke algebra is just the number of elements in
our finite field.

<P>
Alex Hoffnung illustrated his talk with a picture of a cow jumping over
the moon, wearing a bowtie, and getting killed by a lightning bolt. 
You'll have to watch his talk to see how this is relevant.  The
otherwise excellent slides do not explain this joke:

<P>
8) Alex Hoffnung, A categorification of the Hecke algebra, 
<a href = "http://math.ucr.edu/~alex/hecke.pdf">http://math.ucr.edu/~alex/hecke.pdf</a>

<P>
Then Christopher Walker gave a talk on &quot;<a href =
"ams_2009/CWalker_AMS_UCR_2009.mov">A categorification of Hall
algebras</a>&quot;.  Unfortunately, the cameraman showed up a little
late, so the video of his talk starts after a couple of minutes have
gone by.  Fortunately, the next week he passed his oral exam at UCR
with a longer version of the same talk!  So, check out the slides for
that:

<P>
9) Christopher Walker, A categorification of Hall algebras, 
<a href = "http://math.ucr.edu/~cwalker66/Oral_Exam_talk_11_10.pdf">
http://math.ucr.edu/~cwalker66/Oral_Exam_talk_11_10.pdf</a>

<P>
But here's the idea in a nutshell.  Take a simply-laced Dynkin
diagram.  Draw arrows on the edges to get a directed graph.  Let this
graph freely generate a category, say Q.  There's a groupoid of
&quot;quiver representations&quot;, where:

<ul>
<li>
objects are functors from Q to the category of vector spaces over 
some fixed finite field;
</li>
<li>  morphisms are natural isomorphisms.
</li>
</ul>

<P>
Next, apply our systematic procedure for turning groupoids into vector
spaces!  In the case at hand, we get the positive part of the quantum
group associated to our Dynkin diagram.  The usual parameter q that
appears in the definition of a quantum group is just the number of
elements in our finite field.  

<P>
(Here we see a difference from the
Khovanov-Lauda approach, where q is a formal variable.)

<P>
So far, this is actually an old theorem of Ringel.  The trick is to
use it to systematically &quot;groupoidify&quot; quantum groups - or at least
their positive parts - and then work with them at the groupoidified
level.  And that's what Christopher is doing now!  

<P>
His talk explains more, and you can learn more about groupoidification
and its applications to Hecke and Hall algebras here:

<P>
10) John Baez, Alex Hoffnung and Christopher Walker, Higher-dimensional
algebra VII: groupoidification.  
<a href = "http://arxiv.org/abs/0908.4305">arXiv:0908.4305</a>.

<P>
Next came three talks on homotopy theory.  

<P>
Jonathan Lee of Stanford
University spoke on &quot;<a href = "ams_2009/Lee_AMS_UCR_2009.mov">Homotopy colimits and the space of square-zero
upper-triangular matrices</a>&quot;.  You can see slides of his talk here:

<P>
11) Jonathan Lee, Homotopy colimits and the space of square-zero
upper-triangular matrices,
<a href = "http://math.stanford.edu/~jlee/homotopy-talk.pdf">http://math.stanford.edu/~jlee/homotopy-talk.pdf</a>

<P>
He talked about his work on a conjecture of Halperin and Carlsson.
There are different ways to formulate it, but here's a nice
topological way.  Suppose the torus T<sup>n</sup> acts freely on a finite CW
complex X.  Then the sum of the Betti numbers of X is at least
2<sup>n</sup>.  There's also a nice purely algebraic way!  

<P>
Nitu Kitchloo of UC San Diego spoke on &quot;Universal Bott-Samelson 
resolutions&quot;.  As a warmup for this, I should just tell you what
a Bott-Samelson resolution is.

<P>
I spoke quite a bit about Schubert cells in &quot;<a href =
"week184.html">week184</A>&quot; and subsequent Weeks.  The idea is
that if you have a Grassmannian, or more generally any space of the
form G/P where G is a simple Lie group and P is a parabolic subgroup,
it comes equipped with a decomposition into cells.  These are the
&quot;<a href =
"http://en.wikipedia.org/wiki/Schubert_variety">Schubert
cells</a>&quot;.  They're packed with fascinating algebra, geometry,
and combinatorics.  They are, in fact, algebraic varieties!  But,
they're not smooth - they're singular.

<P>
And so, if you were an algebraic geometer, you might be tempted to
&quot;resolve&quot; their singularities: that is, find a smooth
variety that maps onto them in a nice way.  Bott and Samelson figured
out a way to do this... but not just one way.  So, you might want to
find a &quot;best&quot; - or more technically, a &quot;universal&quot;
- Bott-Samelson resolution.  And that's what Nitu Kitchloo talked
about.

<P>
After lunch, Maia Averett of Mills College started the show with a
talk on &quot;<a href = "ams_2009/Averett_AMS_UCR_2009.mov">Real
Johnson-Wilson theories</a>&quot;, based on work with Nitu Kitchloo
and Steve Wilson.  This was heavy-duty homotopy theory of the sort I
can only gape at in awe.  It's part of a big network of ideas which
include <a href =
"http://www.math.harvard.edu/~lurie/papers/survey.pdf">elliptic
cohomology</a> and higher steps in the &quot;chromatic
filtration&quot; - topics I discussed back in &quot;<a href =
"week197.html">week197</A>&quot; and &quot;<a href =
"week255.html">week255</A>&quot;.

<P>
You can see some slides here:

<P>
12) Maia Averett, Real Johnson-Wilson theories, 
<a href = "http://www.math.uchicago.edu/~fiore/1/Averett.pdf">http://www.math.uchicago.edu/~fiore/1/Averett.pdf</a>

<P>
Real Johnson-Wilson theories are certain generalized cohomology
theories (see &quot;<a href = "week149.html">week149</A>&quot;).
They can be thought of as &quot;higher&quot; versions of real
K-theory.  Thanks to complex conjugation, the group Z/2 acts on the
complex K-theory spectrum KU, and if we take the homotopy fixed points
we get the real K-theory spectrum KO.  But complex K-theory is just
the first of the Johnson-Wilson theories!

<P>
To get the others, you do something roughly like this.  (I'm reading
some stuff to figure this out, and I could be getting it wrong.)  The
<a href =
"http://en.wikipedia.org/wiki/Spectrum_%28homotopy_theory%29">spectrum</a>
for <a href = "http://en.wikipedia.org/wiki/Complex_cobordism">complex
cobordism theory</a> is called MU.  If you localize this at 2 you get
something called the <a href =
"http://en.wikipedia.org/wiki/Complex_cobordism#Brown-Peterson_cohomology">Brown-Peterson
spectrum</a>, BP.  The generalized cohomology for this, applied to a
one-point space, is a ring on infinitely many generators.  If you do
some trick to kill off all the generators above the nth, you get the
nth Johnson-Wilson theory.  And since this was built starting from
complex cobordism theory, complex conjugation acts on it.  So, we can
take the homotopy fixed points, you get the nth &quot;real&quot;
Johnson-Wilson theory.

<P>
Emin Tatar of Florida State University spoke on &quot;<a href =
"ams_2009/Tatar_AMS_UCR_2009.mov">Abelian sheaves and Picard
stacks</a>&quot;:

<P>
13) A. Emin Tatar, Abelian sheaves and Picard stacks, 
<a href = "http://www.math.ucr.edu/~jbergner/tatar_slides.pdf">http://www.math.ucr.edu/~jbergner/tatar_slides.pdf</a>

<P>
This talk assumed a fair amount of background, so let me just sketch a
bit of that background.  For more details, try this:

<P>
14) A. Emin Tatar, Length 3 complexes of abelian sheaves and Picard
2-stacks, available as <a href = "http://arxiv.org/abs/0906.2393">arXiv:0906.2393</a>.

<P>
You've probably heard me talk about <a href =
"http://arxiv.org/abs/math/0307200">2-groups</a>.  These are
categorified groups.  More precisely, they're categories with a tensor
product, where every morphism has an inverse and every object x has an
inverse with respect to the tensor product: that is, an object x* such
that

<P>
x &otimes; x* &cong; 1

<P>
and

<P>
x* &otimes; x &cong; 1

<P>
2-groups are a great way to dip your toe in vast ocean of n-category
theory.  They're one step to the right of groups in the n-groupoid
version of the periodic table:

<pre>
                   k-tuply groupal n-groupoids

              n = 0           n = 1             n = 2

k = 0         sets           groupoids        2-groupoids

k = 1        groups          2-groups          3-groups

k = 2        abelian         braided           braided
             groups          2-groups          3-groups

k = 3         &quot; &quot;            symmetric         sylleptic
                             2-groups          3-groups

k = 4         &quot; &quot;             &quot; &quot;              symmetric
                                               3-groups

k = 5         &quot; &quot;             &quot; &quot;                &quot;  &quot;
</pre>

Just as abelian groups are especially simple and nice, so are
symmetric 2-groups.  Where an abelian group obeys the equation

<P>
xy = yx

<P>
a symmetric 2-group instead has an isomorphism 

<P>
S<sub>x,y</sub>: x &otimes; y &rarr; y &otimes; x

<P>
with the property that doing it twice gives the identity:

<P>
S<sub>y,x</sub> S<sub>x,y</sub> = 1

<P>
Lately people have been generalizing a lot of math from abelian
groups to symmetric 2-groups.  See &quot;<a href = "week266.html">week266</A>&quot; for more, and 
especially this:

<P>
15) Mathieu Dupont, Abelian categories in dimension 2, Ph.D thesis,
l'Universite Catholique de Louvain, 2008.  Available as
<a href = "http://arxiv.org/abs/0809.1760">arXiv:0809.1760</a>.
Original available in French at
<a href = "http://hdl.handle.net/2078.1/12735">http://hdl.handle.net/2078.1/12735</a>

<P>
But the simplest symmetric 2-groups are those with this extra 
property:

<P>
S<sub>x,x</sub> = 1

<P>
Emin Tatar calls these &quot;Picard categories&quot;, following Deligne.

<P>
(I would like to call these &quot;Picard 2-groups&quot;, but that might be
confusing, since &quot;Picard group&quot; already means something quite
different.  To add to the confusion, it seems that Dupont and
others use &quot;Picard category&quot; as a synonym for symmetric 2-group!)

<P>
Anyway, there's a nice description of Picard categories.  They're all
equivalent to the 2-groups that you get from 2-term chain complexes of
abelian groups!

<P>
It's nice to see how this works.  Take a 2-term chain complex of
abelian groups:

<PRE>
    d
A &lt;--- B
</PRE>

<P>
Then there's a category where the objects are elements of A, and 
the morphisms from a to a' are elements b of B with 

<P>
a' = a + db

<P>
Addition lets you compose morphisms - but it also lets you add
objects, making this category into a 2-group.  And the abelianness
makes this not just a symmetric 2-group, but even a Picard category!

<P>
But the cool fact is that every Picard category is equivalent to 
one arising this way.  

<P>
In fact, Deligne went a lot further.  There's a general principle that
anything really important that you can do with sets, you can also do
with <a href =
"http://en.wikipedia.org/wiki/Sheaf_%28mathematics%29">sheaves</a> of
sets.  So, you might guess that anything really important you can do
with categories, you can do with sheaves of categories.

<P>
That's morally correct - but not quite technically correct, because we
need to take the definition of &quot;sheaf&quot; and replace some
equations by isomorphisms to make it applicable to categories.  If we
do this, we get the concept of a &quot;<a href =
"http://arxiv.org/abs/math/0412512">stack</a>&quot;.

<P>
Then everything works great.  Just as we can talk about sheaves of
abelian groups, we can talk about stacks of Picard categories - or
&quot;Picard stacks&quot;, for short.  And the cool fact I mentioned
generalizes to these!  Every Picard stack is equivalent to one that
comes from a 2-term complex of sheaves of abelian groups.  This was
proved by Deligne quite a while ago - it's Lemma 1.4.13 here:

<P>
15) Pierre Deligne, La formule de dualit&eacute; globale,
Sem. Geom. Alg&eacute;brique Bois-Marie 1963/64, SGA 4 III, No. XVIII, 
Springer Lecture Notes in Mathematics 305, 1973, pp. 481-587.
Also available at
<a href = "http://www.math.polytechnique.fr/~laszlo/sga4/SGA4-3/sga43.pdf">
http://www.math.polytechnique.fr/~laszlo/sga4/SGA4-3/sga43.pdf</a>

<P>
But you can also see a different proof in Proposition 8.3.2 of
this paper by Tatar's advisor and Behrang Noohi:

<P>
16) Ettore Aldrovandi and Behrang Noohi, Butterflies I: morphisms of
2-group stacks, Adv. Math. 221 (2009), 687-773.  Also available as <a
href = "http://arxiv.org/abs/0808.3627">arXiv:0808.3627</a>.

<P>
Now, what did Tatar do?  He categorified all this stuff once more!
In other words, he defined Picard 2-stacks, and proved that every
Picard 2-stack is equivalent to one coming from a 3-term chain
complex of sheaves of abelian groups!  

<P>
Next, David Spivak of the University of Oregon spoke on &quot;<a href
= "ams_2009/Spivak_AMS_UCR_2009.mov">Mapping spaces in
quasi-categories</a>&quot;.  <a href =
"http://arxiv.org/abs/math/0608040">Quasicategories</a> are a nice way
to formalize the idea of an (&infin;,1)-category - that is, an
&infin;-category where all the morphisms above the 1-morphisms are
weakly invertible.  Technically, quasicategories they're just <a href
= "http://en.wikipedia.org/wiki/Simplicial_set">simplicial sets</a>
with a special property.  So, one can study them using all the
simplicial machinery that homotopy theorists have been developing over
the years.

<P>
However, there are many other ways to formalize
(&infin;,1)-categories.  A classic one is &quot;simplicial
categories&quot;.  These are just categories &quot;enriched over
simplicial sets&quot;.  In other words, they have a simplicial set of
morphisms from any object to any other object, and composition is a
map of simplicial sets.

<P>
(If I'd been willing to use this jargon earlier, I could have defined
an algebroid to be a category &quot;enriched over vector spaces&quot;.
However, I didn't want to scare away all my readers - at least, not so
soon!  By this point I figure all the wimps are gone.)

<P>
A while back, Jacob Lurie described a way to turn any quasicategory
into a simplicial category - see for example Remark 1.1.5.18 here:

<P>
16) Jacob Lurie, Higher Topos Theory, Annals of Mathematics Studies
170, Princeton University Press, Princeton, NJ, 2009.  Also available
as <a href =
"http://arXiv.org/abs/math/0608040">arXiv:math/0608040</A>.

<P>
This involves taking two vertices of our quasicategory - which,
remember, is just a simplicial set with some properties - and
cooking up a simplicial set of &quot;morphisms&quot; from one to the other.
Recently Daniel Dugger and David Spivak have come up with another
way:

<P>
17) Daniel Dugger and David I. Spivak, Rigidification of
quasi-categories, available as <a href = "http://arxiv.org/abs/0910.0814">arXiv:0910.0814</a>.

<P>
18) Daniel Dugger and David I. Spivak, Mapping spaces in
quasi-categories, available as <a href = "http://arxiv.org/abs/0911.0469">arXiv:0911.0469</a>.

<P>
And that's what David explained in his talk!

<P>
The day concluded with two talks of a somewhat more concrete nature.
Ben Williams of Stanford University spoke on &quot;<a href =
"ams_2009/Williams_AMS_UCR_2009.mov">An application of
A<sup>1</sup>-homotopy theory to problems in commutative
algebra</a>&quot;.  Like Jonathan Lee, the problems he was considering
included the conjecture of Halperin and Carlsson that I mentioned
before.  But, he used ideas from A<sup>1</sup>-homotopy theory.  So,
let me say a word about that.

<P>
I actually tried my hand at explaining A<sup>1</sup>-homotopy theory
near the end of &quot;<a href = "week255.html">week255</A>&quot;.
It's an attempt to do homotopy theory for algebraic varieties, where
homotopies are parametrized not by the interval but by the line -
since the line is an algebraic variety.  Algebraic geometers call
the line A<sup>1</sup>, just to make the rest of us feel dumb.

<P>
In his work on A<sup>1</sup>-homotopy theory, Voevodsky studied
certain cohomology groups for a variety X, called &quot;<a href =
"http://en.wikipedia.org/wiki/Motivic_cohomology">motivic cohomology
groups</a>&quot;.  The curious thing is that they're bigraded instead
of just graded.  Instead of getting cohomology groups
H<sup>p</sup>(X,A) with coefficients in an abelian group A, we get
cohomology groups H<sup>p,q</sup>(X,A).

<P>
Why is this?  I wish I understood it better... but I think it's
basically because we could already define cohomology groups for
varieties without this extra notion of homotopies parametrized by
the line... but now we can also define them <i>with</i> that notion, as
well.  The old cohomology groups were defined using sheaves; the 
new one is defined using simplicial sheaves, and the <i>simplicial</i>
aspect of these sheaves gives a new grading.

<P>
And indeed, Voevodsky was able to relate motivic cohomology to another
bigraded gadget: the &quot;higher Chow groups&quot; of the variety X.
These are a lot easier to define, so let me describe those.  Consider
the free abelian group generated by irreducible subvarieties of
codimension k in 

<P>
X &times; &Delta;<sup>n</sup>

<P> 
where &Delta;<sup>n</sup> is the n-simplex.  (Actually, we should
only use subvarieties that hit the faces of the simplex
&quot;properly&quot;.)  As we let n vary, we get a simplicial abelian
group.  But a simplicial abelian group is just a chain complex in
disguise! - I explained how in item H of &quot;<a href =
"week116.html">week116</a>&quot;.

<P>
So, define the higher Chow groups to be the homology groups of this
chain complex.  They depend on two parameters: the
&quot;simplicial&quot; dimension n, but also the
&quot;geometrical&quot; codimension k.

<P>
Obviously it would take me a few years of hard work to get from
this to the point of actually understanding Ben William's talk!  

<P>
Finally, Christian Haesemeyer of UCLA wrapped up the day with a talk
&quot;<a href = "ams_2009/Haesemeyer_AMS_UCR_2009.mov">On the K-theory
of toric varieties</a>&quot;.  For quite a while I've been meaning to
explain toric varieties, which are a marvelous playground for
exploring algebraic geometry.  Roughly: just as an <a href =
"http://en.wikipedia.org/wiki/Algebraic_variety">algebraic variety</a>
looks locally like the solution set of a bunch of polynomial
equations, a <a href =
"http://en.wikipedia.org/wiki/Toric_geometry">toric variety</a> looks
like the solution set of a bunch of polynomial equations <i>where
you're not allowed to add, only multiply!</i>

<P>
This restriction makes them marvelously tractable - you can easily
describe them using pictures called &quot;fans&quot;.  Here's a nice 
informal explanation of how this works:

<P>
19) David Speyer, Toric varieties and polytopes, 
<a href = "http://sbseminar.wordpress.com/2009/02/09/toric-varieties-and-polytopes/">http://sbseminar.wordpress.com/2009/02/09/toric-varieties-and-polytopes/</a>

<P>
Toric varieties and fans, 
<a href = "http://sbseminar.wordpress.com/2009/02/18/toric-varieties-and-fans/">http://sbseminar.wordpress.com/2009/02/18/toric-varieties-and-fans/</a>

<P>
Once you become a fan of fans - and it's easy to do - you can't
resist wanting to take all your favorite invariants of algebraic
varieties and see what they look like for toric varieties.  Like
<a href = "http://en.wikipedia.org/wiki/K-theory">K-theory</a>!

<P>
Hmm.  I'm only described the first day's worth of talks, and it's
taken more than one day.  And I'm left with a lot of questions.
For example:

<ul>
<li>
Aaron Lauda wrote: "It turns out, at least in the simply-laced case,
that our algebras are also isomorphic to the Ext algebras between
simple perverse sheaves on the Lusztig quiver variety.  Lusztig's
bilinear form can be seen as taking the graded dimension of this Ext
algebra, so it is natural that there is a relationship between the two
constructions."  Can someone say more about what's going on here?
Please <i>don't</i> assume I understand what Aaron told me!
<p>
</li>
<li>
How does the representation Licata describes, involving the cohomology
of the cotangent bundle of the Grassmannians Gr(n,k) for k between 0
and n, fit into a more general story?  I think the disjoint union of
these Grassmannians should be thought of as the space of 1-stage
"Springer flags" in n dimensions - where an m-stage Springer flag is a
chain of m subspaces of C<sup>n</sup>.  I vaguely recall that it's
interesting to generalize by letting m be arbitrary.  And I think that
an even more general story - where we pass from sl(2) to sl(N) -
involves Springer flags in the category of quiver representations.  Is
this right?  What's the big picture?
<p>
</li>
<li>
Is my account of Johnson-Wilson theories accurate?  What are the most 
important things that I left out here?
<p>
</li>
<li>
What's "motivic" about Voevodsky's motivic cohomology?  Does he propose a 
definition of motives?  How is it related to Grothendieck's conception of 
motives?  How, from this viewpoint, can we see that motivic cohomology 
should be bigraded?
<p>
</li>
<li>
What other things should I have said, but didn't?
</li>
</ul>

<P>
If you have answers, or just other questions, please visit
the <a href = "http://golem.ph.utexas.edu/category/2009/11/this_weeks_finds_in_mathematic_45.html"><em>n</em>-Category
Caf&eacute;</a>.  

<p>
Happy Thanksgiving!

<p>
<HR><P>
<b>Addenda:</b> I thank Toby Bartels yet again for catching a
messed-up link, and David Corfield for catching some typos.

<p>
For more discussion visit the <a href =
"http://golem.ph.utexas.edu/category/2009/11/this_weeks_finds_in_mathematic_45.html"><em>n</em>-Category
Caf&eacute;</a>.  Please try to answer my questions above!

<p>

<p>
<HR><P>

<i>There are two fundamental and completely different examples in group
theory: the &quot;symmetric group&quot; of permutations of n objects, and the
&quot;linear group&quot; of n by n matrices over a field.  Lusztig says the
linear group is a quantum version of the symmetric group, with 
the value of Planck's constant
telling you which field you're looking at.  He has made that idea
precise in a thousand beautiful ways for the past 30 years.</i> - David Vogan
 
<p>
<HR><P>

